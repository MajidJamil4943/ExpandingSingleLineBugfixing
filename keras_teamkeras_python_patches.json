[
    {
        "commit_id": "c877b894b911a4b2b96579afa5a07df71d439bd7",
        "commit_message": "Fix incorrect argument in JAX flash attention. (#21014)\n\nThe mask is named `array` in `NumpyMask`.",
        "commit_url": "https://github.com/keras-team/keras/commit/c877b894b911a4b2b96579afa5a07df71d439bd7",
        "buggy_code": "mask = splash_attention_mask.NumpyMask(mask=custom_mask)",
        "fixed_code": "mask = splash_attention_mask.NumpyMask(array=custom_mask)",
        "patch": "@@ -1129,7 +1129,7 @@ def wrap_flash_attention(\n         )\n \n     if custom_mask is not None:\n-        mask = splash_attention_mask.NumpyMask(mask=custom_mask)\n+        mask = splash_attention_mask.NumpyMask(array=custom_mask)\n \n     else:\n         mask = splash_attention_mask.CausalMask("
    },
    {
        "commit_id": "d42143ddf3a754d9b8dd04b150f132597855e9e7",
        "commit_message": "Fix typos and add a test case for elastic_transform (#21007)\n\n* fix mis typo\n\n* Add test case\n\n* Re-run test case CI",
        "commit_url": "https://github.com/keras-team/keras/commit/d42143ddf3a754d9b8dd04b150f132597855e9e7",
        "buggy_code": "x, y = x.unsqueeze(0), y.unsqueeze(0)",
        "fixed_code": "x, y = x.unsqueeze(0).to(images.device), y.unsqueeze(0).to(images.device)",
        "patch": "@@ -989,7 +989,7 @@ def elastic_transform(\n     x, y = torch.meshgrid(\n         torch.arange(width), torch.arange(height), indexing=\"xy\"\n     )\n-    x, y = x.unsqueeze(0), y.unsqueeze(0)\n+    x, y = x.unsqueeze(0).to(images.device), y.unsqueeze(0).to(images.device)\n \n     distorted_x = x + alpha * dx\n     distorted_y = y + alpha * dy"
    },
    {
        "commit_id": "b9a49ea6b4971493ee57c71c646b5228fbfc48f8",
        "commit_message": "fix solve method on linalg (#20879)",
        "commit_url": "https://github.com/keras-team/keras/commit/b9a49ea6b4971493ee57c71c646b5228fbfc48f8",
        "buggy_code": "if tf.rank(b) == tf.rank(a) - 1:",
        "fixed_code": "if b.shape.ndims == a.shape.ndims - 1:",
        "patch": "@@ -169,7 +169,7 @@ def qr(x, mode=\"reduced\"):\n \n def solve(a, b):\n     # tensorflow.linalg.solve only supports same rank inputs\n-    if tf.rank(b) == tf.rank(a) - 1:\n+    if b.shape.ndims == a.shape.ndims - 1:\n         b = tf.expand_dims(b, axis=-1)\n         return tf.squeeze(tf.linalg.solve(a, b), axis=-1)\n     return tf.linalg.solve(a, b)"
    },
    {
        "commit_id": "e106d2314e77df8a2f69a900e0b5cf07b8411ca9",
        "commit_message": "Prevent information leakage and improve the ONNX export for the torch backend (#20859)\n\n* Use a better setting for `verbose` and improve the onnx export for the torch backend\r\n\r\n* Fix torch CI",
        "commit_url": "https://github.com/keras-team/keras/commit/e106d2314e77df8a2f69a900e0b5cf07b8411ca9",
        "buggy_code": "config[\"module\"] = torch.load(buffer)",
        "fixed_code": "config[\"module\"] = torch.load(buffer, weights_only=False)",
        "patch": "@@ -153,7 +153,7 @@ def from_config(cls, config):\n \n         if \"module\" in config:\n             buffer = io.BytesIO(config[\"module\"])\n-            config[\"module\"] = torch.load(buffer)\n+            config[\"module\"] = torch.load(buffer, weights_only=False)\n         return cls(**config)\n \n "
    },
    {
        "commit_id": "3d20616ea73602f32ea30e85be4ab505947131cb",
        "commit_message": "Fix JAX GPU CI and make formatter happy (#20749)\n\n* Fix JAX GPU CI\r\n\r\n* Makes formatter happy\r\n\r\n* Makes formatter happy - 2",
        "commit_url": "https://github.com/keras-team/keras/commit/3d20616ea73602f32ea30e85be4ab505947131cb",
        "buggy_code": "return f\"\\\"[{', '.join(map(str, k))}]\\\"\"",
        "fixed_code": "return f'\"[{\", \".join(map(str, k))}]\"'",
        "patch": "@@ -59,7 +59,7 @@ def handle_value(k):\n                 isinstance(k, collections.abc.Iterable)\n                 and not is_zero_dim_ndarray\n             ):\n-                return f\"\\\"[{', '.join(map(str, k))}]\\\"\"\n+                return f'\"[{\", \".join(map(str, k))}]\"'\n             else:\n                 return k\n "
    },
    {
        "commit_id": "3d20616ea73602f32ea30e85be4ab505947131cb",
        "commit_message": "Fix JAX GPU CI and make formatter happy (#20749)\n\n* Fix JAX GPU CI\r\n\r\n* Makes formatter happy\r\n\r\n* Makes formatter happy - 2",
        "commit_url": "https://github.com/keras-team/keras/commit/3d20616ea73602f32ea30e85be4ab505947131cb",
        "buggy_code": "(\"SwapEMAWeights must be used when \" \"`use_ema=True` is set\"),",
        "fixed_code": "(\"SwapEMAWeights must be used when `use_ema=True` is set\"),",
        "patch": "@@ -53,7 +53,7 @@ def test_swap_ema_weights_with_invalid_optimizer(self):\n         model = self._get_compiled_model(use_ema=False)\n         with self.assertRaisesRegex(\n             ValueError,\n-            (\"SwapEMAWeights must be used when \" \"`use_ema=True` is set\"),\n+            (\"SwapEMAWeights must be used when `use_ema=True` is set\"),\n         ):\n             model.fit(\n                 self.x_train,"
    },
    {
        "commit_id": "3d20616ea73602f32ea30e85be4ab505947131cb",
        "commit_message": "Fix JAX GPU CI and make formatter happy (#20749)\n\n* Fix JAX GPU CI\r\n\r\n* Makes formatter happy\r\n\r\n* Makes formatter happy - 2",
        "commit_url": "https://github.com/keras-team/keras/commit/3d20616ea73602f32ea30e85be4ab505947131cb",
        "buggy_code": "\"The `shape` and `dtype` must be provided. \" f\"Received: x={x}\"",
        "fixed_code": "f\"The `shape` and `dtype` must be provided. Received: x={x}\"",
        "patch": "@@ -65,7 +65,7 @@ def make_input_spec(x):\n     if isinstance(x, layers.InputSpec):\n         if x.shape is None or x.dtype is None:\n             raise ValueError(\n-                \"The `shape` and `dtype` must be provided. \" f\"Received: x={x}\"\n+                f\"The `shape` and `dtype` must be provided. Received: x={x}\"\n             )\n         input_spec = x\n     elif isinstance(x, backend.KerasTensor):"
    },
    {
        "commit_id": "3d20616ea73602f32ea30e85be4ab505947131cb",
        "commit_message": "Fix JAX GPU CI and make formatter happy (#20749)\n\n* Fix JAX GPU CI\r\n\r\n* Makes formatter happy\r\n\r\n* Makes formatter happy - 2",
        "commit_url": "https://github.com/keras-team/keras/commit/3d20616ea73602f32ea30e85be4ab505947131cb",
        "buggy_code": "\"`sparse=True` can only be used with the \" \"TensorFlow backend.\"",
        "fixed_code": "\"`sparse=True` can only be used with the TensorFlow backend.\"",
        "patch": "@@ -90,7 +90,7 @@ def __init__(\n         super().__init__(name=name, dtype=dtype)\n         if sparse and backend.backend() != \"tensorflow\":\n             raise ValueError(\n-                \"`sparse=True` can only be used with the \" \"TensorFlow backend.\"\n+                \"`sparse=True` can only be used with the TensorFlow backend.\"\n             )\n \n         argument_validation.validate_string_arg("
    },
    {
        "commit_id": "3d20616ea73602f32ea30e85be4ab505947131cb",
        "commit_message": "Fix JAX GPU CI and make formatter happy (#20749)\n\n* Fix JAX GPU CI\r\n\r\n* Makes formatter happy\r\n\r\n* Makes formatter happy - 2",
        "commit_url": "https://github.com/keras-team/keras/commit/3d20616ea73602f32ea30e85be4ab505947131cb",
        "buggy_code": "\"`sparse=True` can only be used with the \" \"TensorFlow backend.\"",
        "fixed_code": "\"`sparse=True` can only be used with the TensorFlow backend.\"",
        "patch": "@@ -328,7 +328,7 @@ def __init__(\n             )\n         if sparse and backend.backend() != \"tensorflow\":\n             raise ValueError(\n-                \"`sparse=True` can only be used with the \" \"TensorFlow backend.\"\n+                \"`sparse=True` can only be used with the TensorFlow backend.\"\n             )\n         if vocabulary_dtype != \"int64\":\n             raise ValueError("
    },
    {
        "commit_id": "3d20616ea73602f32ea30e85be4ab505947131cb",
        "commit_message": "Fix JAX GPU CI and make formatter happy (#20749)\n\n* Fix JAX GPU CI\r\n\r\n* Makes formatter happy\r\n\r\n* Makes formatter happy - 2",
        "commit_url": "https://github.com/keras-team/keras/commit/3d20616ea73602f32ea30e85be4ab505947131cb",
        "buggy_code": "\"`sparse=True` can only be used with the \" \"TensorFlow backend.\"",
        "fixed_code": "\"`sparse=True` can only be used with the TensorFlow backend.\"",
        "patch": "@@ -314,7 +314,7 @@ def __init__(\n             )\n         if sparse and backend.backend() != \"tensorflow\":\n             raise ValueError(\n-                \"`sparse=True` can only be used with the \" \"TensorFlow backend.\"\n+                \"`sparse=True` can only be used with the TensorFlow backend.\"\n             )\n         self.encoding = encoding\n         super().__init__("
    },
    {
        "commit_id": "3d20616ea73602f32ea30e85be4ab505947131cb",
        "commit_message": "Fix JAX GPU CI and make formatter happy (#20749)\n\n* Fix JAX GPU CI\r\n\r\n* Makes formatter happy\r\n\r\n* Makes formatter happy - 2",
        "commit_url": "https://github.com/keras-team/keras/commit/3d20616ea73602f32ea30e85be4ab505947131cb",
        "buggy_code": "return f\"<{self.__class__.__name__} \" f\"name={self.name}>\"",
        "fixed_code": "return f\"<{self.__class__.__name__} name={self.name}>\"",
        "patch": "@@ -247,7 +247,7 @@ def _check_super_called(self):\n             )\n \n     def __repr__(self):\n-        return f\"<{self.__class__.__name__} \" f\"name={self.name}>\"\n+        return f\"<{self.__class__.__name__} name={self.name}>\"\n \n     def __str__(self):\n         return self.__repr__()"
    },
    {
        "commit_id": "3d20616ea73602f32ea30e85be4ab505947131cb",
        "commit_message": "Fix JAX GPU CI and make formatter happy (#20749)\n\n* Fix JAX GPU CI\r\n\r\n* Makes formatter happy\r\n\r\n* Makes formatter happy - 2",
        "commit_url": "https://github.com/keras-team/keras/commit/3d20616ea73602f32ea30e85be4ab505947131cb",
        "buggy_code": "raise ValueError(\"kth must be an integer. Received:\" f\"kth = {kth}\")",
        "fixed_code": "raise ValueError(f\"kth must be an integer. Received:kth = {kth}\")",
        "patch": "@@ -6754,7 +6754,7 @@ class Argpartition(Operation):\n     def __init__(self, kth, axis=-1):\n         super().__init__()\n         if not isinstance(kth, int):\n-            raise ValueError(\"kth must be an integer. Received:\" f\"kth = {kth}\")\n+            raise ValueError(f\"kth must be an integer. Received:kth = {kth}\")\n         self.kth = kth\n         self.axis = axis\n "
    },
    {
        "commit_id": "3d20616ea73602f32ea30e85be4ab505947131cb",
        "commit_message": "Fix JAX GPU CI and make formatter happy (#20749)\n\n* Fix JAX GPU CI\r\n\r\n* Makes formatter happy\r\n\r\n* Makes formatter happy - 2",
        "commit_url": "https://github.com/keras-team/keras/commit/3d20616ea73602f32ea30e85be4ab505947131cb",
        "buggy_code": "\"Argument `seed` must be an integer. \" f\"Received: seed={seed}\"",
        "fixed_code": "f\"Argument `seed` must be an integer. Received: seed={seed}\"",
        "patch": "@@ -76,7 +76,7 @@ def __init__(self, seed=None, name=None, **kwargs):\n \n         if not isinstance(seed, int):\n             raise ValueError(\n-                \"Argument `seed` must be an integer. \" f\"Received: seed={seed}\"\n+                f\"Argument `seed` must be an integer. Received: seed={seed}\"\n             )\n \n         def seed_initializer(*args, **kwargs):"
    },
    {
        "commit_id": "3d20616ea73602f32ea30e85be4ab505947131cb",
        "commit_message": "Fix JAX GPU CI and make formatter happy (#20749)\n\n* Fix JAX GPU CI\r\n\r\n* Makes formatter happy\r\n\r\n* Makes formatter happy - 2",
        "commit_url": "https://github.com/keras-team/keras/commit/3d20616ea73602f32ea30e85be4ab505947131cb",
        "buggy_code": "return f\"Saved with Keras {version} \" f\"- date: {date}\"",
        "fixed_code": "return f\"Saved with Keras {version} - date: {date}\"",
        "patch": "@@ -500,7 +500,7 @@ def _generate_metadata_info(self, rich_style=False):\n         if rich_style:\n             version = f\"{summary_utils.highlight_symbol(version)}\"\n             date = f\"{summary_utils.highlight_symbol(date)}\"\n-        return f\"Saved with Keras {version} \" f\"- date: {date}\"\n+        return f\"Saved with Keras {version} - date: {date}\"\n \n     def _print_weights_structure(\n         self, weights_dict, indent=0, is_first=True, prefix=\"\", inner_path=\"\""
    },
    {
        "commit_id": "3d20616ea73602f32ea30e85be4ab505947131cb",
        "commit_message": "Fix JAX GPU CI and make formatter happy (#20749)\n\n* Fix JAX GPU CI\r\n\r\n* Makes formatter happy\r\n\r\n* Makes formatter happy - 2",
        "commit_url": "https://github.com/keras-team/keras/commit/3d20616ea73602f32ea30e85be4ab505947131cb",
        "buggy_code": "f'Output dtype: <b>{dtype or \"?\"}</b>'",
        "fixed_code": "f\"Output dtype: <b>{dtype or '?'}</b>\"",
        "patch": "@@ -149,7 +149,7 @@ def format_shape(shape):\n         cols.append(\n             (\n                 '<td bgcolor=\"white\"><font point-size=\"14\">'\n-                f'Output dtype: <b>{dtype or \"?\"}</b>'\n+                f\"Output dtype: <b>{dtype or '?'}</b>\"\n                 \"</font></td>\"\n             )\n         )"
    },
    {
        "commit_id": "8f0461690d9a885ffae5e0a7117aff460ab27ab7",
        "commit_message": "Specify window_length dtype requirement in tf.keras.ops.istft in math.py (#20728)\n\nThe `window_length` parameter in `tf.keras.ops.istft` requires `tf.int32` dtype, but this isn't documented. This can cause unexpected `ValueError` when using `tf.int64` and `tf.int16`\r\n\r\nHere is the Example case:\r\n```\r\nimport tensorflow as tf\r\n\r\ninput_dict = {\r\n    'stfts': tf.constant([[-0.87817144+1.14583987j, -0.32066484+0.25565411j]], dtype=tf.complex128),\r\n    'frame_length': tf.constant(256, dtype=tf.int16),\r\n    'frame_step': tf.constant(5120,dtype=tf.int64)\r\n}\r\nresult = tf.signal.inverse_stft(**input_dict)\r\nprint(result)\r\n```\r\nThe code throws the following error:\r\n```\r\nValueError: window_length: Tensor conversion requested dtype int32 for Tensor with dtype int64\r\n```",
        "commit_url": "https://github.com/keras-team/keras/commit/8f0461690d9a885ffae5e0a7117aff460ab27ab7",
        "buggy_code": "`stft`.",
        "fixed_code": "`stft`. Should be of type `int32`.",
        "patch": "@@ -888,7 +888,7 @@ def istft(\n         sequence_length: An integer representing the sequence length.\n         sequence_stride: An integer representing the sequence hop size.\n         fft_length: An integer representing the size of the FFT that produced\n-            `stft`.\n+            `stft`. Should be of type `int32`.\n         length: An integer representing the output is clipped to exactly length.\n             If not specified, no padding or clipping take place. Defaults to\n             `None`."
    },
    {
        "commit_id": "94977dd48e9ed043ffb789d9b03ddaaa5173fcf6",
        "commit_message": "Refactor `keras/src/export/export_lib` and add `export_onnx` (#20710)\n\n* Refactor export_lib and add export_onnx\r\n\r\nAdd tf2onnx requirements\r\n\r\n* Add onnxruntime dep\r\n\r\n* Update numpy dep\r\n\r\n* Resolve comments",
        "commit_url": "https://github.com/keras-team/keras/commit/94977dd48e9ed043ffb789d9b03ddaaa5173fcf6",
        "buggy_code": "from keras.src.export.export_lib import ExportArchive",
        "fixed_code": "from keras.src.export.saved_model import ExportArchive",
        "patch": "@@ -4,4 +4,4 @@\n since your modifications would be overwritten.\n \"\"\"\n \n-from keras.src.export.export_lib import ExportArchive\n+from keras.src.export.saved_model import ExportArchive"
    },
    {
        "commit_id": "94977dd48e9ed043ffb789d9b03ddaaa5173fcf6",
        "commit_message": "Refactor `keras/src/export/export_lib` and add `export_onnx` (#20710)\n\n* Refactor export_lib and add export_onnx\r\n\r\nAdd tf2onnx requirements\r\n\r\n* Add onnxruntime dep\r\n\r\n* Update numpy dep\r\n\r\n* Resolve comments",
        "commit_url": "https://github.com/keras-team/keras/commit/94977dd48e9ed043ffb789d9b03ddaaa5173fcf6",
        "buggy_code": "from keras.src.export.export_lib import TFSMLayer",
        "fixed_code": "from keras.src.export.tfsm_layer import TFSMLayer",
        "patch": "@@ -4,7 +4,7 @@\n since your modifications would be overwritten.\n \"\"\"\n \n-from keras.src.export.export_lib import TFSMLayer\n+from keras.src.export.tfsm_layer import TFSMLayer\n from keras.src.layers import deserialize\n from keras.src.layers import serialize\n from keras.src.layers.activations.activation import Activation"
    },
    {
        "commit_id": "94977dd48e9ed043ffb789d9b03ddaaa5173fcf6",
        "commit_message": "Refactor `keras/src/export/export_lib` and add `export_onnx` (#20710)\n\n* Refactor export_lib and add export_onnx\r\n\r\nAdd tf2onnx requirements\r\n\r\n* Add onnxruntime dep\r\n\r\n* Update numpy dep\r\n\r\n* Resolve comments",
        "commit_url": "https://github.com/keras-team/keras/commit/94977dd48e9ed043ffb789d9b03ddaaa5173fcf6",
        "buggy_code": "from keras.src.export.export_lib import ExportArchive",
        "fixed_code": "from keras.src.export.saved_model import ExportArchive",
        "patch": "@@ -4,4 +4,4 @@\n since your modifications would be overwritten.\n \"\"\"\n \n-from keras.src.export.export_lib import ExportArchive\n+from keras.src.export.saved_model import ExportArchive"
    },
    {
        "commit_id": "94977dd48e9ed043ffb789d9b03ddaaa5173fcf6",
        "commit_message": "Refactor `keras/src/export/export_lib` and add `export_onnx` (#20710)\n\n* Refactor export_lib and add export_onnx\r\n\r\nAdd tf2onnx requirements\r\n\r\n* Add onnxruntime dep\r\n\r\n* Update numpy dep\r\n\r\n* Resolve comments",
        "commit_url": "https://github.com/keras-team/keras/commit/94977dd48e9ed043ffb789d9b03ddaaa5173fcf6",
        "buggy_code": "from keras.src.export.export_lib import TFSMLayer",
        "fixed_code": "from keras.src.export.tfsm_layer import TFSMLayer",
        "patch": "@@ -4,7 +4,7 @@\n since your modifications would be overwritten.\n \"\"\"\n \n-from keras.src.export.export_lib import TFSMLayer\n+from keras.src.export.tfsm_layer import TFSMLayer\n from keras.src.layers import deserialize\n from keras.src.layers import serialize\n from keras.src.layers.activations.activation import Activation"
    },
    {
        "commit_id": "476a664e711cf9d0bbc0264a4f5cd4bac2f52155",
        "commit_message": "fix: Torch MPS backend failing test (#20709)",
        "commit_url": "https://github.com/keras-team/keras/commit/476a664e711cf9d0bbc0264a4f5cd4bac2f52155",
        "buggy_code": "x = np.random.uniform(size=[1, 2, 3])",
        "fixed_code": "x = np.random.uniform(size=[1, 2, 3]).astype(\"float32\")",
        "patch": "@@ -15,7 +15,7 @@ class BackendUtilsTest(testing.TestCase):\n     )\n     def test_dynamic_backend(self, name):\n         dynamic_backend = backend_utils.DynamicBackend()\n-        x = np.random.uniform(size=[1, 2, 3])\n+        x = np.random.uniform(size=[1, 2, 3]).astype(\"float32\")\n \n         if name == \"numpy\":\n             dynamic_backend.set_backend(name)"
    },
    {
        "commit_id": "8907bcbff80cfd93b6b4c148eb7a660a95ac69ab",
        "commit_message": "fix attention output with symbolic tensors and attention scores (#20689)",
        "commit_url": "https://github.com/keras-team/keras/commit/8907bcbff80cfd93b6b4c148eb7a660a95ac69ab",
        "buggy_code": "if self._return_attention_scores:",
        "fixed_code": "if self._return_attention_scores or return_attention_scores:",
        "patch": "@@ -280,7 +280,7 @@ def compute_output_spec(\n         output_spec = KerasTensor(output_shape, dtype=self.compute_dtype)\n \n         # Handle attention scores if requested\n-        if self._return_attention_scores:\n+        if self._return_attention_scores or return_attention_scores:\n             scores_shape = (\n                 query.shape[0],\n                 query.shape[1],"
    },
    {
        "commit_id": "bce0f5bdfdd43d830f04e4781aa444ce5b954bc8",
        "commit_message": "Add preliminary support of OpenVINO as Keras 3 backend (#19727)\n\n* [POC][OV] Support OpenVINO as Keras 3 backend\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Mark all unsupported ops from numpy space\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Mark unsupported ops in core, image, and linalg spaces\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Mark unsupported ops in math, nn, random, and rnn spaces\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Fix sorting imports\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Format imports\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Fix sorting imports\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Fix sorting imports\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Fix inference\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Remove openvino specific code in common part\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Fix typo\r\n\r\n* Clean-up code\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Recover imports\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Sort imports properly\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Format source code\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Format the rest of source code\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Continue format adjustment\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Add OpenVINO dependency\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Fix inference using OV backend\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Support bert_base_en_uncased and mobilenet_v3_small from Keras Hub\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Remove extra openvino specific code from layer.py\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Apply code-style formatting\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Apply code-style formatting\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Fix remained code-style issue\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Run tests for OpenVINO backend in GHA\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Add config file for openvino backend validation\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Add import test for openvino backend\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Fix error in import_test.py\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Add import_test for openvino backend\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Add openvino specific integration tests in GHA\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Exclude coverage for OpenVINO\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* remove coverage for openvino backend\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Try layer tests for openvino backend\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Run layer tests for openvino backend selectively\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Mark enabled tests for openvino backend in a different way\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Update .github/workflows/actions.yml\r\n\r\n* Fix import for BackendVariable\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Fix errors in layer tests for openvino backend\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Add test for Elu via openvino backend\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Fix sorted imports\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Extend testing for attention\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Update keras/src/layers/attention/attention_test.py\r\n\r\n* Switch on activation tests for openvino backend\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Switch on attention tests for openvino backend\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Update keras/src/layers/attention/additive_attention_test.py\r\n\r\n* Update keras/src/layers/attention/grouped_query_attention_test.py\r\n\r\n* Run conv tests for openvino backend\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Fix convolution in openvino backend\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Work around constant creation for tuple\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Work around constant creation in reshape\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Run depthwise conv tests for openvino backend\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Fix get_ov_output for other x types\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Fix elu translation\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Fix softmax and log_softmax for None axis\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Run nn tests for openvino backend\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Fix numpy operations for axis to be None\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Run operation_test for openvino_backend\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Switch on math_test for openvino backend\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Switch on image tests for openvino backend\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Switch on linalg test for openvino backend\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Extend OpenVINOKerasTensor with new built-in methods and fix shape op\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Switch on core tests for openvino backend\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Use different way of OpenVINO model creation that supports call method\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Unify integration test for openvino\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Support new operations abs, mod, etc.\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Add support for more operations like squeeze, max\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Try to use excluded test files list\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Apply formatting for normalization_test.py\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Correct GHA yml file\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Test that openvino backend is used\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Revert testing change in excluded test files list\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Include testing group\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Include legacy test group\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Exclude legacy group of tests\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Include initializers tests\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Skip tests for initializers group\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Remove export test group from ignore\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Include dtype_policies test group\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Reduce ignored tests\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Fix ops.cast\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Add decorator for custom_gradient\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Shorten line in custom_gradient\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Ignore dtype_policy_map test\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Include callback tests\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Switch on backend tests\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Exclude failing tests\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Correct paths to excluded tests\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Switch on some layers tests\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Remove pytest.mark.openvino_backend\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Register mark requires_trainable_backend\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Ignore test files in a different way\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Try different way to ignore test files\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Fix GHA yml\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Support tuple axis for logsumexp\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Switch on some ops tests\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Switch on some callbacks tests\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Add openvino export\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Update sklearn tests\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Add a comment to skipp numerical_test\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Add custom requirements file for OpenVINO\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Add reqs of openvino installation for api changes check\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Fix types of Variables and switch on some variables tests\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n* Fix nightly code check\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>\r\n\r\n---------\r\n\r\nSigned-off-by: Kazantsev, Roman <roman.kazantsev@intel.com>",
        "commit_url": "https://github.com/keras-team/keras/commit/bce0f5bdfdd43d830f04e4781aa444ce5b954bc8",
        "buggy_code": "if keras.config.backend() == \"numpy\" and (",
        "fixed_code": "if keras.config.backend() in [\"numpy\", \"openvino\"] and (",
        "patch": "@@ -110,7 +110,7 @@ def test_sklearn_estimator_checks(estimator, check):\n     try:\n         check(estimator)\n     except Exception as exc:\n-        if keras.config.backend() == \"numpy\" and (\n+        if keras.config.backend() in [\"numpy\", \"openvino\"] and (\n             isinstance(exc, NotImplementedError)\n             or \"NotImplementedError\" in str(exc)\n         ):"
    },
    {
        "commit_id": "d96f9102e79d5e4a0eca2e2eb138d991c95fd364",
        "commit_message": "Fix typo",
        "commit_url": "https://github.com/keras-team/keras/commit/d96f9102e79d5e4a0eca2e2eb138d991c95fd364",
        "buggy_code": "self.random_generator = self.backend.random.SeedGenerator()",
        "fixed_code": "self.generator = self.backend.random.SeedGenerator()",
        "patch": "@@ -54,7 +54,7 @@ def __init__(self, factor=0.5, data_format=None, **kwargs):\n             )\n         self.factor = factor\n         self.data_format = backend.standardize_data_format(data_format)\n-        self.random_generator = self.backend.random.SeedGenerator()\n+        self.generator = self.backend.random.SeedGenerator()\n \n     def get_random_transformation(self, images, training=True, seed=None):\n         if seed is None:"
    },
    {
        "commit_id": "eec1fbdf90236c2ab8a0c0352d65c30c5b401620",
        "commit_message": "Add `IOU`, `CIOU` and minor fixes to bounding boxes (#20635)\n\n* Add computer affine matrix method and reformat some of the bounding box arguments\r\n\r\n* Add rotation for boxes\r\n\r\n* proper reshape of the rotation matrix\r\n\r\n* iou and random rotation using affine\r\n\r\n* bounding boxes iou\r\n\r\n* - add encode and decode to deltas for bounding boxes\r\n- add iou and ciou methods\r\n\r\n* add api points for encode and decode methods of bounding boxes\r\n\r\n* fix arg name and proper for args for test_affine\r\n\r\n* correct dtype mul",
        "commit_url": "https://github.com/keras-team/keras/commit/eec1fbdf90236c2ab8a0c0352d65c30c5b401620",
        "buggy_code": "format=\"xyxy\",",
        "fixed_code": "bounding_box_format=\"xyxy\",",
        "patch": "@@ -161,7 +161,7 @@ def _get_clipped_bbox(bounding_boxes, h_end, h_start, w_end, w_start):\n             bounding_boxes=bounding_boxes,\n             height=self.height,\n             width=self.width,\n-            format=\"xyxy\",\n+            bounding_box_format=\"xyxy\",\n         )\n \n         bounding_boxes = convert_format("
    },
    {
        "commit_id": "eec1fbdf90236c2ab8a0c0352d65c30c5b401620",
        "commit_message": "Add `IOU`, `CIOU` and minor fixes to bounding boxes (#20635)\n\n* Add computer affine matrix method and reformat some of the bounding box arguments\r\n\r\n* Add rotation for boxes\r\n\r\n* proper reshape of the rotation matrix\r\n\r\n* iou and random rotation using affine\r\n\r\n* bounding boxes iou\r\n\r\n* - add encode and decode to deltas for bounding boxes\r\n- add iou and ciou methods\r\n\r\n* add api points for encode and decode methods of bounding boxes\r\n\r\n* fix arg name and proper for args for test_affine\r\n\r\n* correct dtype mul",
        "commit_url": "https://github.com/keras-team/keras/commit/eec1fbdf90236c2ab8a0c0352d65c30c5b401620",
        "buggy_code": "format=\"xyxy\",",
        "fixed_code": "bounding_box_format=\"xyxy\",",
        "patch": "@@ -162,7 +162,7 @@ def _transform_xyxy(boxes, box_flips):\n             bounding_boxes=bounding_boxes,\n             height=input_height,\n             width=input_width,\n-            format=\"xyxy\",\n+            bounding_box_format=\"xyxy\",\n         )\n \n         bounding_boxes = convert_format("
    },
    {
        "commit_id": "eec1fbdf90236c2ab8a0c0352d65c30c5b401620",
        "commit_message": "Add `IOU`, `CIOU` and minor fixes to bounding boxes (#20635)\n\n* Add computer affine matrix method and reformat some of the bounding box arguments\r\n\r\n* Add rotation for boxes\r\n\r\n* proper reshape of the rotation matrix\r\n\r\n* iou and random rotation using affine\r\n\r\n* bounding boxes iou\r\n\r\n* - add encode and decode to deltas for bounding boxes\r\n- add iou and ciou methods\r\n\r\n* add api points for encode and decode methods of bounding boxes\r\n\r\n* fix arg name and proper for args for test_affine\r\n\r\n* correct dtype mul",
        "commit_url": "https://github.com/keras-team/keras/commit/eec1fbdf90236c2ab8a0c0352d65c30c5b401620",
        "buggy_code": "format=\"xyxy\",",
        "fixed_code": "bounding_box_format=\"xyxy\",",
        "patch": "@@ -252,7 +252,7 @@ def transform_bounding_boxes(\n             bounding_boxes=bounding_boxes,\n             height=input_height,\n             width=input_width,\n-            format=\"xyxy\",\n+            bounding_box_format=\"xyxy\",\n         )\n \n         bounding_boxes = convert_format("
    },
    {
        "commit_id": "eec1fbdf90236c2ab8a0c0352d65c30c5b401620",
        "commit_message": "Add `IOU`, `CIOU` and minor fixes to bounding boxes (#20635)\n\n* Add computer affine matrix method and reformat some of the bounding box arguments\r\n\r\n* Add rotation for boxes\r\n\r\n* proper reshape of the rotation matrix\r\n\r\n* iou and random rotation using affine\r\n\r\n* bounding boxes iou\r\n\r\n* - add encode and decode to deltas for bounding boxes\r\n- add iou and ciou methods\r\n\r\n* add api points for encode and decode methods of bounding boxes\r\n\r\n* fix arg name and proper for args for test_affine\r\n\r\n* correct dtype mul",
        "commit_url": "https://github.com/keras-team/keras/commit/eec1fbdf90236c2ab8a0c0352d65c30c5b401620",
        "buggy_code": "format=\"rel_xyxy\",",
        "fixed_code": "bounding_box_format=\"rel_xyxy\",",
        "patch": "@@ -283,7 +283,7 @@ def transform_bounding_boxes(\n             bounding_boxes=bounding_boxes,\n             height=height_transformed,\n             width=width_transformed,\n-            format=\"rel_xyxy\",\n+            bounding_box_format=\"rel_xyxy\",\n         )\n \n         bounding_boxes = convert_format("
    },
    {
        "commit_id": "57e29a664d0606f7f15543bac1df6325d3f57237",
        "commit_message": "Correct bug for MixUp initialization. (#20630)\n\n* Correct bug for MixUp initialization.\r\n\r\n* Update format indent",
        "commit_url": "https://github.com/keras-team/keras/commit/57e29a664d0606f7f15543bac1df6325d3f57237",
        "buggy_code": "super().__init__(data_format=None, **kwargs)",
        "fixed_code": "super().__init__(data_format=data_format, **kwargs)",
        "patch": "@@ -35,7 +35,7 @@ class MixUp(BaseImagePreprocessingLayer):\n     \"\"\"\n \n     def __init__(self, alpha=0.2, data_format=None, seed=None, **kwargs):\n-        super().__init__(data_format=None, **kwargs)\n+        super().__init__(data_format=data_format, **kwargs)\n         self.alpha = alpha\n         self.seed = seed\n         self.generator = SeedGenerator(seed)"
    },
    {
        "commit_id": "033d96790df08b5942dca98d0c75eaad9740a7ad",
        "commit_message": "Fix using a Python number as an initializer in JAX (#20595)\n\n* Fix the issue when using python number as the initializer in jax\r\n\r\n* Add rise\r\n\r\n* Fix using lambda expression as the initializer",
        "commit_url": "https://github.com/keras-team/keras/commit/033d96790df08b5942dca98d0c75eaad9740a7ad",
        "buggy_code": "self._shape = tuple(value.shape)",
        "fixed_code": "self._shape = self._validate_shape(value.shape)",
        "patch": "@@ -21,7 +21,7 @@\n class Variable(KerasVariable):\n     def _initialize(self, value):\n         # Note that variable.shape is needed by distribution_lib\n-        self._shape = tuple(value.shape)\n+        self._shape = self._validate_shape(value.shape)\n         # We can't import the keras/distribution/distribution_lib\n         # due to circular dependency.\n         distribution = global_state.get_global_attribute(\"distribution\")"
    },
    {
        "commit_id": "e072189ff2cde45ad5874d738efbfdb6d5fcd5f3",
        "commit_message": "Minor fix",
        "commit_url": "https://github.com/keras-team/keras/commit/e072189ff2cde45ad5874d738efbfdb6d5fcd5f3",
        "buggy_code": "if backend.backend() == \"jax\":",
        "fixed_code": "if self.backend.name == \"jax\":",
        "patch": "@@ -143,7 +143,7 @@ def _equalize_channel(self, channel, value_range):\n     def _apply_equalization(self, channel, hist):\n         cdf = self.backend.numpy.cumsum(hist)\n \n-        if backend.backend() == \"jax\":\n+        if self.backend.name == \"jax\":\n             mask = cdf > 0\n             first_nonzero_idx = self.backend.numpy.argmax(mask)\n             cdf_min = self.backend.numpy.take(cdf, first_nonzero_idx)"
    },
    {
        "commit_id": "b02085b9941d68f172e34645b02bdeb5bdd81bc0",
        "commit_message": "Fix the compatibility of the quantization for MHA  (#20562)\n\n* Fix MHA with int8 quant\r\n\r\n* Propagate and delete mask in MHA\r\n\r\n* Fix CI",
        "commit_url": "https://github.com/keras-team/keras/commit/b02085b9941d68f172e34645b02bdeb5bdd81bc0",
        "buggy_code": "model.add(keras.layers.Masking(mask_value=0.)",
        "fixed_code": "model.add(keras.layers.Masking(mask_value=0.0))",
        "patch": "@@ -32,7 +32,7 @@ class Masking(Layer):\n     inputs[:, 5, :] = 0.\n \n     model = keras.models.Sequential()\n-    model.add(keras.layers.Masking(mask_value=0.)\n+    model.add(keras.layers.Masking(mask_value=0.0))\n     model.add(keras.layers.LSTM(32))\n     output = model(inputs)\n     # The time step 3 and 5 will be skipped from LSTM calculation."
    },
    {
        "commit_id": "7943660b9d436d75bd4d816506c3262da63a22a7",
        "commit_message": "Fix dtype of tf argmax",
        "commit_url": "https://github.com/keras-team/keras/commit/7943660b9d436d75bd4d816506c3262da63a22a7",
        "buggy_code": "lambda: tf.argmax(y, axis=-1),",
        "fixed_code": "lambda: tf.argmax(y, axis=-1, output_type=tf.int32),",
        "patch": "@@ -128,7 +128,7 @@ def class_weights_map_fn(*data):\n         if y.shape.rank >= 2:\n             y_classes = tf.__internal__.smart_cond.smart_cond(\n                 tf.shape(y)[-1] > 1,\n-                lambda: tf.argmax(y, axis=-1),\n+                lambda: tf.argmax(y, axis=-1, output_type=tf.int32),\n                 lambda: tf.cast(tf.round(tf.squeeze(y, axis=-1)), tf.int32),\n             )\n         else:"
    },
    {
        "commit_id": "78f1c71dbf33599174602f2c63190c17c587909b",
        "commit_message": "Major rework of `optree_impl` and `dmtree_impl` for consistency. (#20481)\n\nThe `optree` implementation and the `dmtree` implementation of the `tree` API had a nummber of discreptancies. Running unit tests without `optree` installed would fail on a number of tests.\r\n\r\nThe documentation and behavior of the `tree` API was not internally consistent. There was contradicting documentation about the handling of `OrderedDict`s. The behavior of the `optree` implementation was to use the key sorted order for `pack_sequence_as` but use the sequence order for `flatten`, resulting in `flatten` + `pack_sequence_as` not being idempotent (as discovered in https://github.com/keras-team/keras/issues/20538 )\r\n\r\nThe exceptions used to report non-matching structures where different between the two implementation. When `optree` uses `ValueError` for all mimatches, `dmtree` would distinguish between `ValueError` and `TypeError` for some cases. This caused a number of bugs because `TypeError` was often not caught, only `ValueError`.\r\n\r\nThe `assert_same_structure` argument of `check_types` is deprecated and no longer does anything. The `optree` implementation would check the types of the *leaves*, whereas the `dmtree` would check the types of the *collections*. So `check_types=False` with `optree` was fairly, although not completely similar, to `check_types=True` with `dmtree`. The rules is that no two collection types are considered the same, except for `dict`, `OrderedDict` and `defaultdict`.\r\n\r\nBecause `optree` is the default implementation used and `dmtree` is only a fallback, this PR changes the `tree` API behavior to conform to the `optree` approach everywhere. This makes the `optree` implementation a thin wrapper on top of `optree`, whereas large portions of the `dmtree` wrapper are now reimplemented in Python. Note that the `tree` API was initially modelled after `dmtree`, not `optree`.\r\n\r\nThere are a couple of fairly niche known discrepancies between the `optree` implementation and the `dmtree` implementation. They are documented in `dmtree_impl.py`.\r\n\r\n- Fixed references to `unflatten_as` in documentation, which doesn't exist.\r\n- Fixed contradicting documentation in `flatten` and `pack_sequence_as` related to the handling of `OrderedDict`s. The documentation now states that the sequence order is always used.\r\n- Made handling of `OrderedDict`s follow the spec with both `optree` and `dmtree`.\r\n- Made the exceptions raised consistent and documented them. `TypeError` is only for major programmer error (e.g. `func` is not callable), and `ValueError` is used for all structure mismatches.\r\n- Removed all cases where `TypeError` was caught after a `assert_same_structure`.\r\n- Fixed the discrepancy in the behavior for `namedtuple`s. The `optree` behavior is now followed, meaning that the path for fields are indices, not field names.\r\n- Deprecated the `check_types` argument in `assert_same_structure` and implemented the `optree` behavior in `dmtree`.\r\n- Remove `sequence_fn` argument of `pack_sequence_as`, which was not used and force the `optree` implementation to be fully rewritten in Python.\r\n- Added `MAP_TO_NONE` to the API, added support for it in both implementations of `traverse`. This feature was documented, but not accessible and not actually implemented.\r\n- Added support for registered classes with `dmtree`, both with `flatten` and `unflatten` passed at registration time and methods on the class.\r\n- Tracked collections are now supported with `dmtree` (`TrackedList`, `TrackedSet` and `TrackedDict`). In particular, `TrackedSet` would be handled as a leaf and never traversed.\r\n- Removed dependency of tracked collections on `optree` in `tree_flatten` and `tree_unflatten`.\r\n- Tensorflow's `ListWrapper` and `_DictWrapper` are now supported with `dmtree`.\r\n- Implemented a more efficient way for `optree` to verify structures are the same while traversing them with `map_structure` and `map_structure_up_to`. This avoids multiple traversals.\r\n- Added documentation for `list_to_tuples` and `map_shape_structure`.\r\n- Completely rewrote all tree API unit tests, which are now painfully thorough.\r\n- `map_shape_structure` is now unit tested.\r\n- Fixed unintented use of `tree` instead of `keras.tree` in unit test.\r\n- Ran unit tests for all backends with `optree` uninstalled.\r\n\r\nFixes https://github.com/keras-team/keras/issues/20538",
        "commit_url": "https://github.com/keras-team/keras/commit/78f1c71dbf33599174602f2c63190c17c587909b",
        "buggy_code": "except (ValueError, TypeError) as e:",
        "fixed_code": "except ValueError as e:",
        "patch": "@@ -374,7 +374,7 @@ def _clone_functional_model(\n             )\n         try:\n             tree.assert_same_structure(input_tensors, model.input)\n-        except (ValueError, TypeError) as e:\n+        except ValueError as e:\n             raise ValueError(\n                 \"`input_tensors` must have the same structure as model.input\"\n                 f\"\\nReference structure: {model.input}\""
    },
    {
        "commit_id": "78f1c71dbf33599174602f2c63190c17c587909b",
        "commit_message": "Major rework of `optree_impl` and `dmtree_impl` for consistency. (#20481)\n\nThe `optree` implementation and the `dmtree` implementation of the `tree` API had a nummber of discreptancies. Running unit tests without `optree` installed would fail on a number of tests.\r\n\r\nThe documentation and behavior of the `tree` API was not internally consistent. There was contradicting documentation about the handling of `OrderedDict`s. The behavior of the `optree` implementation was to use the key sorted order for `pack_sequence_as` but use the sequence order for `flatten`, resulting in `flatten` + `pack_sequence_as` not being idempotent (as discovered in https://github.com/keras-team/keras/issues/20538 )\r\n\r\nThe exceptions used to report non-matching structures where different between the two implementation. When `optree` uses `ValueError` for all mimatches, `dmtree` would distinguish between `ValueError` and `TypeError` for some cases. This caused a number of bugs because `TypeError` was often not caught, only `ValueError`.\r\n\r\nThe `assert_same_structure` argument of `check_types` is deprecated and no longer does anything. The `optree` implementation would check the types of the *leaves*, whereas the `dmtree` would check the types of the *collections*. So `check_types=False` with `optree` was fairly, although not completely similar, to `check_types=True` with `dmtree`. The rules is that no two collection types are considered the same, except for `dict`, `OrderedDict` and `defaultdict`.\r\n\r\nBecause `optree` is the default implementation used and `dmtree` is only a fallback, this PR changes the `tree` API behavior to conform to the `optree` approach everywhere. This makes the `optree` implementation a thin wrapper on top of `optree`, whereas large portions of the `dmtree` wrapper are now reimplemented in Python. Note that the `tree` API was initially modelled after `dmtree`, not `optree`.\r\n\r\nThere are a couple of fairly niche known discrepancies between the `optree` implementation and the `dmtree` implementation. They are documented in `dmtree_impl.py`.\r\n\r\n- Fixed references to `unflatten_as` in documentation, which doesn't exist.\r\n- Fixed contradicting documentation in `flatten` and `pack_sequence_as` related to the handling of `OrderedDict`s. The documentation now states that the sequence order is always used.\r\n- Made handling of `OrderedDict`s follow the spec with both `optree` and `dmtree`.\r\n- Made the exceptions raised consistent and documented them. `TypeError` is only for major programmer error (e.g. `func` is not callable), and `ValueError` is used for all structure mismatches.\r\n- Removed all cases where `TypeError` was caught after a `assert_same_structure`.\r\n- Fixed the discrepancy in the behavior for `namedtuple`s. The `optree` behavior is now followed, meaning that the path for fields are indices, not field names.\r\n- Deprecated the `check_types` argument in `assert_same_structure` and implemented the `optree` behavior in `dmtree`.\r\n- Remove `sequence_fn` argument of `pack_sequence_as`, which was not used and force the `optree` implementation to be fully rewritten in Python.\r\n- Added `MAP_TO_NONE` to the API, added support for it in both implementations of `traverse`. This feature was documented, but not accessible and not actually implemented.\r\n- Added support for registered classes with `dmtree`, both with `flatten` and `unflatten` passed at registration time and methods on the class.\r\n- Tracked collections are now supported with `dmtree` (`TrackedList`, `TrackedSet` and `TrackedDict`). In particular, `TrackedSet` would be handled as a leaf and never traversed.\r\n- Removed dependency of tracked collections on `optree` in `tree_flatten` and `tree_unflatten`.\r\n- Tensorflow's `ListWrapper` and `_DictWrapper` are now supported with `dmtree`.\r\n- Implemented a more efficient way for `optree` to verify structures are the same while traversing them with `map_structure` and `map_structure_up_to`. This avoids multiple traversals.\r\n- Added documentation for `list_to_tuples` and `map_shape_structure`.\r\n- Completely rewrote all tree API unit tests, which are now painfully thorough.\r\n- `map_shape_structure` is now unit tested.\r\n- Fixed unintented use of `tree` instead of `keras.tree` in unit test.\r\n- Ran unit tests for all backends with `optree` uninstalled.\r\n\r\nFixes https://github.com/keras-team/keras/issues/20538",
        "commit_url": "https://github.com/keras-team/keras/commit/78f1c71dbf33599174602f2c63190c17c587909b",
        "buggy_code": "import tree",
        "fixed_code": "from keras.src import tree",
        "patch": "@@ -1,14 +1,14 @@\n from collections import namedtuple\n \n import numpy as np\n-import tree\n from absl.testing import parameterized\n \n from keras.src import backend\n from keras.src import metrics as losses_module\n from keras.src import metrics as metrics_module\n from keras.src import ops\n from keras.src import testing\n+from keras.src import tree\n from keras.src.trainers.compile_utils import CompileLoss\n from keras.src.trainers.compile_utils import CompileMetrics\n "
    },
    {
        "commit_id": "1412598cfb6264181eb2cd588e5491f6e0d6d6b2",
        "commit_message": "FIX BUG in load_weights_from_hdf5_group_by_name\" legacy_h5_format.py (#20537)\n\n* FIX BUG in load_weights_from_hdf5_group_by_name\" legacy_h5_format.py\r\n\r\n* add top_level_model_weights to get_subclassed_model",
        "commit_url": "https://github.com/keras-team/keras/commit/1412598cfb6264181eb2cd588e5491f6e0d6d6b2",
        "buggy_code": "symbolic_weights = model.trainable_weights + model.non_trainable_weights",
        "fixed_code": "symbolic_weights = model._trainable_variables + model._non_trainable_variables",
        "patch": "@@ -519,7 +519,7 @@ def load_weights_from_hdf5_group_by_name(f, model, skip_mismatch=False):\n             )\n \n     if \"top_level_model_weights\" in f:\n-        symbolic_weights = model.trainable_weights + model.non_trainable_weights\n+        symbolic_weights = model._trainable_variables + model._non_trainable_variables\n         weight_values = load_subset_weights_from_hdf5_group(\n             f[\"top_level_model_weights\"]\n         )"
    },
    {
        "commit_id": "e0f61ee57624700e5bfc6eb917a1d3b17653a778",
        "commit_message": "Tiny fix",
        "commit_url": "https://github.com/keras-team/keras/commit/e0f61ee57624700e5bfc6eb917a1d3b17653a778",
        "buggy_code": "raise NotImplementedError(type(data))",
        "fixed_code": "raise NotImplementedError(f\"Unsupported data type: {type(data)}\")",
        "patch": "@@ -278,7 +278,7 @@ def adapt(self, data):\n                 ) * batch_weight\n                 total_mean = new_total_mean\n         else:\n-            raise NotImplementedError(type(data))\n+            raise NotImplementedError(f\"Unsupported data type: {type(data)}\")\n \n         self.adapt_mean.assign(total_mean)\n         self.adapt_variance.assign(total_var)"
    },
    {
        "commit_id": "553521ee92f72c993ddb3c40d0ced406a3a4b7db",
        "commit_message": "Improve `keras.Variable` by exposing docstrings and ensuring consistency in the codebase (#20544)\n\n* Improve `keras.Variable` by exposing docstrings and ensuring consistency in the codebase\r\n\r\n* Fix CI\r\n\r\n* Update docstrings",
        "commit_url": "https://github.com/keras-team/keras/commit/553521ee92f72c993ddb3c40d0ced406a3a4b7db",
        "buggy_code": "from keras.src.backend.common.variables import KerasVariable",
        "fixed_code": "from keras.src.backend.common.variables import Variable as KerasVariable",
        "patch": "@@ -1,7 +1,7 @@\n from keras.src.backend.common import backend_utils\n from keras.src.backend.common.dtypes import result_type\n from keras.src.backend.common.variables import AutocastScope\n-from keras.src.backend.common.variables import KerasVariable\n+from keras.src.backend.common.variables import Variable as KerasVariable\n from keras.src.backend.common.variables import get_autocast_scope\n from keras.src.backend.common.variables import is_float_dtype\n from keras.src.backend.common.variables import is_int_dtype"
    },
    {
        "commit_id": "553521ee92f72c993ddb3c40d0ced406a3a4b7db",
        "commit_message": "Improve `keras.Variable` by exposing docstrings and ensuring consistency in the codebase (#20544)\n\n* Improve `keras.Variable` by exposing docstrings and ensuring consistency in the codebase\r\n\r\n* Fix CI\r\n\r\n* Update docstrings",
        "commit_url": "https://github.com/keras-team/keras/commit/553521ee92f72c993ddb3c40d0ced406a3a4b7db",
        "buggy_code": "ValueError, \"all keys in argument `mapping` must be KerasVariable\"",
        "fixed_code": "ValueError, \"all keys in argument `mapping` must be Variable\"",
        "patch": "@@ -41,7 +41,7 @@ def test_invalid_key_in_state_mapping(self):\n         value1 = ops.ones(shape=(2,))\n \n         with self.assertRaisesRegex(\n-            ValueError, \"all keys in argument `mapping` must be KerasVariable\"\n+            ValueError, \"all keys in argument `mapping` must be Variable\"\n         ):\n             StatelessScope(state_mapping=[(invalid_key, value1)])\n "
    },
    {
        "commit_id": "553521ee92f72c993ddb3c40d0ced406a3a4b7db",
        "commit_message": "Improve `keras.Variable` by exposing docstrings and ensuring consistency in the codebase (#20544)\n\n* Improve `keras.Variable` by exposing docstrings and ensuring consistency in the codebase\r\n\r\n* Fix CI\r\n\r\n* Update docstrings",
        "commit_url": "https://github.com/keras-team/keras/commit/553521ee92f72c993ddb3c40d0ced406a3a4b7db",
        "buggy_code": "copy of the weights that attached to the KerasVariable are still and",
        "fixed_code": "copy of the weights that attached to the Variable are still and",
        "patch": "@@ -940,7 +940,7 @@ def _purge_model_variables(\n \n         During JAX training, since the training function are stateless, we have\n         to pass in and get the model weights over and over, during which the\n-        copy of the weights that attached to the KerasVariable are still and\n+        copy of the weights that attached to the Variable are still and\n         occupying extra memory. We remove those variable to save memory (for\n         better memory utilization) at the beginning of the epoch, and reattach\n         the value back to variables at the end of the epoch, via"
    },
    {
        "commit_id": "553521ee92f72c993ddb3c40d0ced406a3a4b7db",
        "commit_message": "Improve `keras.Variable` by exposing docstrings and ensuring consistency in the codebase (#20544)\n\n* Improve `keras.Variable` by exposing docstrings and ensuring consistency in the codebase\r\n\r\n* Fix CI\r\n\r\n* Update docstrings",
        "commit_url": "https://github.com/keras-team/keras/commit/553521ee92f72c993ddb3c40d0ced406a3a4b7db",
        "buggy_code": "variable: A `KerasVariable` instance.",
        "fixed_code": "variable: A `Variable` instance.",
        "patch": "@@ -308,7 +308,7 @@ def get_variable_layout(self, variable):\n         \"\"\"Retrieve the `TensorLayout` for the variable.\n \n         Args:\n-            variable: A `KerasVariable` instance.\n+            variable: A `Variable` instance.\n \n         return:\n             The `TensorLayout` for the variable, which can be used by"
    },
    {
        "commit_id": "bef0a9ef40fae1b7798ec1bd758897f03fffce78",
        "commit_message": "Remove `output_shape` property in MHA (#20543)\n\n* Simplify `output_shape` logic in MHA and remove `output_shape` property.\r\n\r\n* Fix CI\r\n\r\n* Update test\r\n\r\n* Update test",
        "commit_url": "https://github.com/keras-team/keras/commit/bef0a9ef40fae1b7798ec1bd758897f03fffce78",
        "buggy_code": "output_shapes = layer.output_shape",
        "fixed_code": "output_shapes = format_shape(layer.output_shape)",
        "patch": "@@ -103,7 +103,7 @@ def format_shape(shape):\n     else:\n         try:\n             if hasattr(layer, \"output_shape\"):\n-                output_shapes = layer.output_shape\n+                output_shapes = format_shape(layer.output_shape)\n             else:\n                 outputs = layer.compute_output_shape(**layer._build_shapes_dict)\n                 output_shapes = tree.map_shape_structure("
    },
    {
        "commit_id": "6bc240c3075cc1726df00bf7fd825f2ad8a38a6a",
        "commit_message": "Fix docstrings",
        "commit_url": "https://github.com/keras-team/keras/commit/6bc240c3075cc1726df00bf7fd825f2ad8a38a6a",
        "buggy_code": "The SquarePlus activation function is defined as:",
        "fixed_code": "The Squareplus activation function is defined as:",
        "patch": "@@ -301,7 +301,7 @@ def silu(x):\n def squareplus(x, b=4):\n     \"\"\"Squareplus activation function.\n \n-    The SquarePlus activation function is defined as:\n+    The Squareplus activation function is defined as:\n \n     `f(x) = (x + sqrt(x^2 + b)) / 2`\n "
    },
    {
        "commit_id": "575ed94f91b42c324f85d3c1ed88add23b950e08",
        "commit_message": "Fix tensorflow `_dot_product_attention_xla` and update `enable_flash_attention` (#20510)\n\n* Fix tensorflow `_dot_product_attention_xla` and update MHA tests\r\n\r\n* Fix tests",
        "commit_url": "https://github.com/keras-team/keras/commit/575ed94f91b42c324f85d3c1ed88add23b950e08",
        "buggy_code": "logits = tf.multiply(logits, tf.cast(logits, logits.dtype))",
        "fixed_code": "logits = tf.multiply(logits, tf.cast(scale, logits.dtype))",
        "patch": "@@ -984,7 +984,7 @@ def _dot_product_attention_xla(query, key, value, bias, mask, is_causal, scale):\n         tf.cast(key, dtype=logits_dtype),\n         optimize=\"optimal\",\n     )\n-    logits = tf.multiply(logits, tf.cast(logits, logits.dtype))\n+    logits = tf.multiply(logits, tf.cast(scale, logits.dtype))\n \n     if bias is not None:\n         logits = tf.add(logits, tf.cast(bias, logits.dtype))"
    },
    {
        "commit_id": "c052cead4cce39e59a239a64d7894559b6821338",
        "commit_message": "Workaround for pydataset hanging issue",
        "commit_url": "https://github.com/keras-team/keras/commit/c052cead4cce39e59a239a64d7894559b6821338",
        "buggy_code": "self.get_temp_dir(), str(random.randint(1, 1e7)), \"tb\"",
        "fixed_code": "self.get_temp_dir(), str(random.randint(1, int(1e7))), \"tb\"",
        "patch": "@@ -125,7 +125,7 @@ def list_summaries(logdir):\n class TestTensorBoardV2(testing.TestCase):\n     def _get_log_dirs(self):\n         logdir = os.path.join(\n-            self.get_temp_dir(), str(random.randint(1, 1e7)), \"tb\"\n+            self.get_temp_dir(), str(random.randint(1, int(1e7))), \"tb\"\n         )\n         train_dir = os.path.join(logdir, \"train\")\n         validation_dir = os.path.join(logdir, \"validation\")"
    },
    {
        "commit_id": "c052cead4cce39e59a239a64d7894559b6821338",
        "commit_message": "Workaround for pydataset hanging issue",
        "commit_url": "https://github.com/keras-team/keras/commit/c052cead4cce39e59a239a64d7894559b6821338",
        "buggy_code": "inputs_struct = tree.map_structure(lambda x: \"*\", inputs)",
        "fixed_code": "inputs_struct = tree.map_structure(lambda x: f\"type({x})\", inputs)",
        "patch": "@@ -221,7 +221,7 @@ def _maybe_warn_inputs_struct_mismatch(self, inputs):\n             model_inputs_struct = tree.map_structure(\n                 lambda x: x.name, self._inputs_struct\n             )\n-            inputs_struct = tree.map_structure(lambda x: \"*\", inputs)\n+            inputs_struct = tree.map_structure(lambda x: f\"type({x})\", inputs)\n             warnings.warn(\n                 \"The structure of `inputs` doesn't match the expected \"\n                 f\"structure: {model_inputs_struct}. \""
    },
    {
        "commit_id": "192b7b25c012dfc9ae567ab1ac12269aab8392f4",
        "commit_message": "Replace isort and flake8 with Ruff checker (#20442)\n\n* Replace isort and flake8 with Ruff checker\r\n\r\n* Resolve issue with shell/api_gen.sh and correction to fix/check logic\r\n\r\n* Resolve E721 to use `is` and `is not` for type comparisons",
        "commit_url": "https://github.com/keras-team/keras/commit/192b7b25c012dfc9ae567ab1ac12269aab8392f4",
        "buggy_code": "if dict == out_type:",
        "fixed_code": "if out_type is dict:",
        "patch": "@@ -192,7 +192,7 @@ def test_restored_multi_output_type(self, out_type):\n         x = layers.Dense(5)(inputs)\n         output_a = layers.Dense(4)(x)\n         output_b = layers.Dense(5)(x)\n-        if dict == out_type:\n+        if out_type is dict:\n             outputs = {\"a\": output_a, \"b\": output_b}\n         else:\n             outputs = out_type([output_a, output_b])"
    },
    {
        "commit_id": "192b7b25c012dfc9ae567ab1ac12269aab8392f4",
        "commit_message": "Replace isort and flake8 with Ruff checker (#20442)\n\n* Replace isort and flake8 with Ruff checker\r\n\r\n* Resolve issue with shell/api_gen.sh and correction to fix/check logic\r\n\r\n* Resolve E721 to use `is` and `is not` for type comparisons",
        "commit_url": "https://github.com/keras-team/keras/commit/192b7b25c012dfc9ae567ab1ac12269aab8392f4",
        "buggy_code": "not dtype == object",
        "fixed_code": "dtype is not object",
        "patch": "@@ -408,7 +408,7 @@ def convert_single_array(x):\n         # Step 2. Normalize floats to floatx.\n         def is_non_floatx_float(dtype):\n             return (\n-                not dtype == object\n+                dtype is not object\n                 and backend.is_float_dtype(dtype)\n                 and not backend.standardize_dtype(dtype) == backend.floatx()\n             )"
    },
    {
        "commit_id": "192b7b25c012dfc9ae567ab1ac12269aab8392f4",
        "commit_message": "Replace isort and flake8 with Ruff checker (#20442)\n\n* Replace isort and flake8 with Ruff checker\r\n\r\n* Resolve issue with shell/api_gen.sh and correction to fix/check logic\r\n\r\n* Resolve E721 to use `is` and `is not` for type comparisons",
        "commit_url": "https://github.com/keras-team/keras/commit/192b7b25c012dfc9ae567ab1ac12269aab8392f4",
        "buggy_code": "if isinstance(value, str) and dtype != object and not is_dtype_str:",
        "fixed_code": "if isinstance(value, str) and dtype is not object and not is_dtype_str:",
        "patch": "@@ -103,7 +103,7 @@ def pad_sequences(\n     is_dtype_str = np.issubdtype(dtype, np.str_) or np.issubdtype(\n         dtype, np.str_\n     )\n-    if isinstance(value, str) and dtype != object and not is_dtype_str:\n+    if isinstance(value, str) and dtype is not object and not is_dtype_str:\n         raise ValueError(\n             f\"`dtype` {dtype} is not compatible with `value`'s type: \"\n             f\"{type(value)}\\nYou should set `dtype=object` for variable length \""
    },
    {
        "commit_id": "cc1b52e79d8c2284dfb4521762d6065147bfb7e5",
        "commit_message": "Fix typos (#20434)\n\n* Fix typos\r\n\r\n* Manually fix E501, lines too long",
        "commit_url": "https://github.com/keras-team/keras/commit/cc1b52e79d8c2284dfb4521762d6065147bfb7e5",
        "buggy_code": "learned to identify racoons may be useful to kick-start a model meant to identify",
        "fixed_code": "learned to identify raccoons may be useful to kick-start a model meant to identify",
        "patch": "@@ -22,7 +22,7 @@\n \n **Transfer learning** consists of taking features learned on one problem, and\n leveraging them on a new, similar problem. For instance, features from a model that has\n-learned to identify racoons may be useful to kick-start a model meant to identify\n+learned to identify raccoons may be useful to kick-start a model meant to identify\n  tanukis.\n \n Transfer learning is usually done for tasks where your dataset has too little data to"
    },
    {
        "commit_id": "cc1b52e79d8c2284dfb4521762d6065147bfb7e5",
        "commit_message": "Fix typos (#20434)\n\n* Fix typos\r\n\r\n* Manually fix E501, lines too long",
        "commit_url": "https://github.com/keras-team/keras/commit/cc1b52e79d8c2284dfb4521762d6065147bfb7e5",
        "buggy_code": "include_preprocessing: boolean denoting whther to",
        "fixed_code": "include_preprocessing: boolean denoting whether to",
        "patch": "@@ -357,7 +357,7 @@ def ConvNeXt(\n             won't be used.\n         default_size: Default input image size.\n         name: An optional name for the model.\n-        include_preprocessing: boolean denoting whther to\n+        include_preprocessing: boolean denoting whether to\n             include preprocessing in the model.\n             When `weights=\"imagenet\"` this should always be `True`.\n             But for other models (e.g., randomly initialized) you should set it"
    },
    {
        "commit_id": "cc1b52e79d8c2284dfb4521762d6065147bfb7e5",
        "commit_message": "Fix typos (#20434)\n\n* Fix typos\r\n\r\n* Manually fix E501, lines too long",
        "commit_url": "https://github.com/keras-team/keras/commit/cc1b52e79d8c2284dfb4521762d6065147bfb7e5",
        "buggy_code": "This is primarly intended for use in the `STFTSpectrogram` layer.",
        "fixed_code": "This is primarily intended for use in the `STFTSpectrogram` layer.",
        "patch": "@@ -167,7 +167,7 @@ class STFTInitializer(Initializer):\n     `hamming` windowing functions. This layer supports periodic windows and\n     scaling-based normalization.\n \n-    This is primarly intended for use in the `STFTSpectrogram` layer.\n+    This is primarily intended for use in the `STFTSpectrogram` layer.\n \n     Examples:\n "
    },
    {
        "commit_id": "cc1b52e79d8c2284dfb4521762d6065147bfb7e5",
        "commit_message": "Fix typos (#20434)\n\n* Fix typos\r\n\r\n* Manually fix E501, lines too long",
        "commit_url": "https://github.com/keras-team/keras/commit/cc1b52e79d8c2284dfb4521762d6065147bfb7e5",
        "buggy_code": "seed: A Python integer to use as random seed incase of `dropout`.",
        "fixed_code": "seed: A Python integer to use as random seed in case of `dropout`.",
        "patch": "@@ -27,7 +27,7 @@ class Attention(Layer):\n             attention scores.\n         dropout: Float between 0 and 1. Fraction of the units to drop for the\n             attention scores. Defaults to `0.0`.\n-        seed: A Python integer to use as random seed incase of `dropout`.\n+        seed: A Python integer to use as random seed in case of `dropout`.\n         score_mode: Function to use to compute attention scores, one of\n             `{\"dot\", \"concat\"}`. `\"dot\"` refers to the dot product between the\n             query and key vectors. `\"concat\"` refers to the hyperbolic tangent"
    },
    {
        "commit_id": "cc1b52e79d8c2284dfb4521762d6065147bfb7e5",
        "commit_message": "Fix typos (#20434)\n\n* Fix typos\r\n\r\n* Manually fix E501, lines too long",
        "commit_url": "https://github.com/keras-team/keras/commit/cc1b52e79d8c2284dfb4521762d6065147bfb7e5",
        "buggy_code": "\"\"\"Coverts an index to a einsum variable name.",
        "fixed_code": "\"\"\"Converts an index to a einsum variable name.",
        "patch": "@@ -642,7 +642,7 @@ def compute_output_spec(\n \n \n def _index_to_einsum_variable(i):\n-    \"\"\"Coverts an index to a einsum variable name.\n+    \"\"\"Converts an index to a einsum variable name.\n \n     We simply map indices to lowercase characters, e.g. 0 -> 'a', 1 -> 'b'.\n     \"\"\""
    },
    {
        "commit_id": "cc1b52e79d8c2284dfb4521762d6065147bfb7e5",
        "commit_message": "Fix typos (#20434)\n\n* Fix typos\r\n\r\n* Manually fix E501, lines too long",
        "commit_url": "https://github.com/keras-team/keras/commit/cc1b52e79d8c2284dfb4521762d6065147bfb7e5",
        "buggy_code": "the underying Adam method is \"*computationally",
        "fixed_code": "the underlying Adam method is \"*computationally",
        "patch": "@@ -15,7 +15,7 @@ class AdamW(adam.Adam):\n \n     According to\n     [Kingma et al., 2014](http://arxiv.org/abs/1412.6980),\n-    the underying Adam method is \"*computationally\n+    the underlying Adam method is \"*computationally\n     efficient, has little memory requirement, invariant to diagonal rescaling of\n     gradients, and is well suited for problems that are large in terms of\n     data/parameters*\"."
    },
    {
        "commit_id": "cc1b52e79d8c2284dfb4521762d6065147bfb7e5",
        "commit_message": "Fix typos (#20434)\n\n* Fix typos\r\n\r\n* Manually fix E501, lines too long",
        "commit_url": "https://github.com/keras-team/keras/commit/cc1b52e79d8c2284dfb4521762d6065147bfb7e5",
        "buggy_code": "The values are drawm from a Beta distribution parametrized",
        "fixed_code": "The values are drawn from a Beta distribution parametrized",
        "patch": "@@ -273,7 +273,7 @@ def binomial(shape, counts, probabilities, dtype=None, seed=None):\n def beta(shape, alpha, beta, dtype=None, seed=None):\n     \"\"\"Draw samples from a Beta distribution.\n \n-    The values are drawm from a Beta distribution parametrized\n+    The values are drawn from a Beta distribution parametrized\n     by alpha and beta.\n \n     Args:"
    },
    {
        "commit_id": "cc1b52e79d8c2284dfb4521762d6065147bfb7e5",
        "commit_message": "Fix typos (#20434)\n\n* Fix typos\r\n\r\n* Manually fix E501, lines too long",
        "commit_url": "https://github.com/keras-team/keras/commit/cc1b52e79d8c2284dfb4521762d6065147bfb7e5",
        "buggy_code": "f\"and {len(loss_weights)} weigths.\"",
        "fixed_code": "f\"and {len(loss_weights)} weights.\"",
        "patch": "@@ -586,7 +586,7 @@ def __init__(self, loss, weight):\n                     raise ValueError(\n                         f\"`loss_weights` must match the number of losses, \"\n                         f\"got {len(tree.flatten(loss))} losses \"\n-                        f\"and {len(loss_weights)} weigths.\"\n+                        f\"and {len(loss_weights)} weights.\"\n                     )\n                 loss_weights = tree.pack_sequence_as(loss, flat_loss_weights)\n             loss = tree.map_structure("
    },
    {
        "commit_id": "cc1b52e79d8c2284dfb4521762d6065147bfb7e5",
        "commit_message": "Fix typos (#20434)\n\n* Fix typos\r\n\r\n* Manually fix E501, lines too long",
        "commit_url": "https://github.com/keras-team/keras/commit/cc1b52e79d8c2284dfb4521762d6065147bfb7e5",
        "buggy_code": "above for the list of arguments it takes and the ouputs it returns.",
        "fixed_code": "above for the list of arguments it takes and the outputs it returns.",
        "patch": "@@ -192,7 +192,7 @@ def my_haiku_module_fn(inputs, training):\n         call_fn: The function to call the model. See description above for the\n             list of arguments it takes and the outputs it returns.\n         init_fn: the function to call to initialize the model. See description\n-            above for the list of arguments it takes and the ouputs it returns.\n+            above for the list of arguments it takes and the outputs it returns.\n             If `None`, then `params` and/or `state` must be provided.\n       params: A `PyTree` containing all the model trainable parameters. This\n             allows passing trained parameters or controlling the initialization."
    },
    {
        "commit_id": "4ba7d6f0b70e90c0270f9e86fccbb2f30d8a0647",
        "commit_message": "Fix additional shape comparison for TF1 compatibility (#20422)\n\nI missed this in #20413. Confirmed this fixes the issue in Colab.",
        "commit_url": "https://github.com/keras-team/keras/commit/4ba7d6f0b70e90c0270f9e86fccbb2f30d8a0647",
        "buggy_code": "x2_squeeze_shape = [d for d in x2.shape if d is None or d > 1]",
        "fixed_code": "x2_squeeze_shape = [d for d in x2.shape.as_list() if d is None or d > 1]",
        "patch": "@@ -39,7 +39,7 @@ def add(x1, x2):\n     # Special case of `tf.add`: `tf.nn.bias_add`\n     # `BiasAdd` can be fused with `MatMul` and `Conv*` kernels\n     # Expecting `x1` to be `inputs` and `x2` to be `bias` (no swapping)\n-    x2_squeeze_shape = [d for d in x2.shape if d is None or d > 1]\n+    x2_squeeze_shape = [d for d in x2.shape.as_list() if d is None or d > 1]\n     if (\n         # `x2` looks like bias (can be squeezed to vector)\n         1 == len(x2_squeeze_shape)"
    },
    {
        "commit_id": "093b055aa0f93c96fb6afa321199f57847886107",
        "commit_message": "Add `mean_with_sample_weight` reduction to `Loss` (#20410)\n\n* Add `normalize_by_sample_weight` to `Loss`\r\n\r\n* Add `\"mean_with_sample_weight\"` reduction for `Loss`\r\n\r\n* Minimize code changes\r\n\r\n* Fix CI bug",
        "commit_url": "https://github.com/keras-team/keras/commit/093b055aa0f93c96fb6afa321199f57847886107",
        "buggy_code": "loss.dtype = \"bfloat16\"",
        "fixed_code": "loss_fn.dtype = \"bfloat16\"",
        "patch": "@@ -271,7 +271,7 @@ def test_dtype_arg(self):\n \n         # `dtype` setter should raise AttributeError\n         with self.assertRaises(AttributeError):\n-            loss.dtype = \"bfloat16\"\n+            loss_fn.dtype = \"bfloat16\"\n \n     def test_default_dtype(self):\n         y_true = np.array([1.0, 0.0, 1.0, 0.0], dtype=\"float32\")"
    },
    {
        "commit_id": "0c2bdff313f7533f0d7e6670a906102cc2fb046d",
        "commit_message": "Fix serialization / deserialization. (#20406)\n\n- Serialization was not taking the registered name and package from the registry.\r\n- Deserialization was selecting symbols by postfix as a fallback.",
        "commit_url": "https://github.com/keras-team/keras/commit/0c2bdff313f7533f0d7e6670a906102cc2fb046d",
        "buggy_code": "\"my_mean_squared_error\",",
        "fixed_code": "\"my_custom_package>my_mean_squared_error\",",
        "patch": "@@ -367,7 +367,7 @@ def test_saved_module_paths_and_class_names(self):\n         )\n         self.assertEqual(\n             config_dict[\"compile_config\"][\"loss\"][\"config\"],\n-            \"my_mean_squared_error\",\n+            \"my_custom_package>my_mean_squared_error\",\n         )\n \n     @pytest.mark.requires_trainable_backend"
    },
    {
        "commit_id": "4b771bb6e5b0a820cf7e1276609ede945f8e5874",
        "commit_message": "Update softmax.py (#20400)\n\nUpdated keras.layers.activations.Softmax() to keras.layers.Softmax().  otherwise will get an error as AttributeError",
        "commit_url": "https://github.com/keras-team/keras/commit/4b771bb6e5b0a820cf7e1276609ede945f8e5874",
        "buggy_code": ">>> softmax_layer = keras.layers.activations.Softmax()",
        "fixed_code": ">>> softmax_layer = keras.layers.Softmax()",
        "patch": "@@ -22,7 +22,7 @@ class Softmax(Layer):\n     ```\n \n     Example:\n-    >>> softmax_layer = keras.layers.activations.Softmax()\n+    >>> softmax_layer = keras.layers.Softmax()\n     >>> input = np.array([1.0, 2.0, 1.0])\n     >>> result = softmax_layer(input)\n     >>> result"
    },
    {
        "commit_id": "8dc19d2d1234366b7e3f0f2f425c58cbbccfed42",
        "commit_message": "Fix CI",
        "commit_url": "https://github.com/keras-team/keras/commit/8dc19d2d1234366b7e3f0f2f425c58cbbccfed42",
        "buggy_code": "and isinstance(y_pred, (tuple, list))",
        "fixed_code": "and hasattr(y_pred, \"__len__\")",
        "patch": "@@ -667,7 +667,7 @@ def call(self, y_true, y_pred, sample_weight=None):\n             # y_true is either flat or leaf\n             if (\n                 not tree.is_nested(y_true)\n-                and isinstance(y_pred, (tuple, list))\n+                and hasattr(y_pred, \"__len__\")\n                 and len(y_pred) == 1\n             ):\n                 y_true = [y_true]"
    },
    {
        "commit_id": "f0869a9cbe29d0f9fff7ed0e086240cea25a133a",
        "commit_message": "Minor fix",
        "commit_url": "https://github.com/keras-team/keras/commit/f0869a9cbe29d0f9fff7ed0e086240cea25a133a",
        "buggy_code": "missing_grad_vars.append(v.name)",
        "fixed_code": "missing_grad_vars.append(v.path)",
        "patch": "@@ -723,7 +723,7 @@ def _filter_empty_gradients(self, grads, vars):\n             if filtered_grads[i] is None:\n                 filtered_grads.pop(i)\n                 v = filtered_vars.pop(i)\n-                missing_grad_vars.append(v.name)\n+                missing_grad_vars.append(v.path)\n \n         if not filtered_grads:\n             raise ValueError(\"No gradients provided for any variable.\")"
    },
    {
        "commit_id": "6b662d100cbfd41131744fd5fd8863a9671b2567",
        "commit_message": "`EpochIterator`, `TensorFlowTrainer` : refactoring and fixes (#20396)\n\n* EpochIterator refactoring\r\nTensorflow trainer's train and test functions refactoring\r\nFix https://github.com/keras-team/keras/issues/20394\r\nFix https://github.com/keras-team/keras/issues/20390\r\nFix https://github.com/keras-team/keras/issues/20344\r\n\r\n* CI test\r\n\r\n* CI fix\r\n\r\n* revert CI conf\r\n\r\n* Removed `_EpochIterator`\r\nRestored `enumerate_epoch`\r\n\r\n* Fix `enumerate_epoch`",
        "commit_url": "https://github.com/keras-team/keras/commit/6b662d100cbfd41131744fd5fd8863a9671b2567",
        "buggy_code": "for step, data_iterator in epoch_iterator.enumerate_epoch():",
        "fixed_code": "for step, data_iterator in epoch_iterator:",
        "patch": "@@ -103,7 +103,7 @@ def test_epoch_iterator(self):\n             distribute_strategy=strategy,\n         )\n         steps_seen = []\n-        for step, data_iterator in epoch_iterator.enumerate_epoch():\n+        for step, data_iterator in epoch_iterator:\n             steps_seen.append(step)\n             batch = next(data_iterator)\n             self.assertEqual(len(batch), 3)"
    },
    {
        "commit_id": "6b662d100cbfd41131744fd5fd8863a9671b2567",
        "commit_message": "`EpochIterator`, `TensorFlowTrainer` : refactoring and fixes (#20396)\n\n* EpochIterator refactoring\r\nTensorflow trainer's train and test functions refactoring\r\nFix https://github.com/keras-team/keras/issues/20394\r\nFix https://github.com/keras-team/keras/issues/20390\r\nFix https://github.com/keras-team/keras/issues/20344\r\n\r\n* CI test\r\n\r\n* CI fix\r\n\r\n* revert CI conf\r\n\r\n* Removed `_EpochIterator`\r\nRestored `enumerate_epoch`\r\n\r\n* Fix `enumerate_epoch`",
        "commit_url": "https://github.com/keras-team/keras/commit/6b662d100cbfd41131744fd5fd8863a9671b2567",
        "buggy_code": "for _, data in iterator.enumerate_epoch():",
        "fixed_code": "for _, data in iterator:",
        "patch": "@@ -1050,7 +1050,7 @@ def to_symbolic_input(v):\n                 )\n \n             if data_batch is None:\n-                for _, data in iterator.enumerate_epoch():\n+                for _, data in iterator:\n                     data_batch = data[0]\n                     break\n             data_batch = tree.map_structure(to_symbolic_input, data_batch)"
    },
    {
        "commit_id": "2cddf9e44ae33631358e8bbbb524a0827b152ac9",
        "commit_message": "Fix test",
        "commit_url": "https://github.com/keras-team/keras/commit/2cddf9e44ae33631358e8bbbb524a0827b152ac9",
        "buggy_code": "atol=0.6,  # TODO: abnormal results for certain configs.",
        "fixed_code": "atol=1.0,  # TODO: results vary across backends",
        "patch": "@@ -328,7 +328,7 @@ def test_fit_flow(self, run_eagerly, jit_compile, use_steps_per_epoch):\n         self.assertAllClose(\n             history[\"mean_squared_error\"],\n             [14.5, 11.5, 8.5],\n-            atol=0.6,  # TODO: abnormal results for certain configs.\n+            atol=1.0,  # TODO: results vary across backends\n         )\n \n     @parameterized.named_parameters("
    },
    {
        "commit_id": "4cdd58c758f32b4b9f75761317a693d220e19776",
        "commit_message": "Fix and test slight issue with KerasFileEditor",
        "commit_url": "https://github.com/keras-team/keras/commit/4cdd58c758f32b4b9f75761317a693d220e19776",
        "buggy_code": "result[key] = value[:]",
        "fixed_code": "result[key] = value[()]",
        "patch": "@@ -480,7 +480,7 @@ def _extract_weights_from_store(self, data, metadata=None, inner_path=\"\"):\n                         value, metadata=metadata, inner_path=inner_path\n                     )\n             else:\n-                result[key] = value[:]\n+                result[key] = value[()]\n         return result, metadata\n \n     def _generate_filepath_info(self, rich_style=False):"
    },
    {
        "commit_id": "713382b7cb3da0665a5657b7d8210baa4315a5ff",
        "commit_message": "Allow passing custom dataset adapters. (#20349)\n\n* Fix embedding  for list input shape\r\n\r\n* Allow passing custom data adapter",
        "commit_url": "https://github.com/keras-team/keras/commit/713382b7cb3da0665a5657b7d8210baa4315a5ff",
        "buggy_code": "return input_shape + (self.output_dim,)",
        "fixed_code": "return (*input_shape, self.output_dim)",
        "patch": "@@ -146,7 +146,7 @@ def compute_mask(self, inputs, mask=None):\n         return ops.not_equal(inputs, 0)\n \n     def compute_output_shape(self, input_shape):\n-        return input_shape + (self.output_dim,)\n+        return (*input_shape, self.output_dim)\n \n     def enable_lora(\n         self, rank, a_initializer=\"he_uniform\", b_initializer=\"zeros\""
    },
    {
        "commit_id": "95ca6a6da5c128c695e92c5142898abf0837ba6a",
        "commit_message": "Fixes for reference before assignment\u2026 (#18640)\n\n* Fixes for reference before assignment found through static analysis tooling\r\n\r\n* Fixes for reference before assignment found through static analysis tooling\r\n\r\n* [keras/layers/preprocessing/discretization_test.py] Remove `assertAllClose` from `test_tf_data_compatibility` ; [keras/{ops/numpy.py,saving/saving_lib.py}] `black`en\r\n\r\n* [keras/ops/numpy.py] Revert to see if segfault resolves on CI\r\n\r\n* [keras/{callbacks/reduce_lr_on_plateau,layers/preprocessing/{center_crop_test,random_crop_test}\r\nops/operation}.py] Resolve issues found through `flake8 --config setup.cfg .`\r\n\r\n* [keras/src/layers/preprocessing/image_preprocessing/center_crop_test.py] Return `output_shape` to being dependent on `image_data_format` on `test_tf_data_compatibility`\r\n\r\n* [keras/src/layers/preprocessing/image_preprocessing/random_crop_test.py] Return `output_shape` to being dependent on `image_data_format` on `test_tf_data_compatibility`\r\n\r\n* [keras/src/layers/preprocessing/image_preprocessing/{center,random}_crop_test.py] Make tuple `output.shape` for comparison against `output_shape` from `image_data_format` on `test_tf_data_compatibility`",
        "commit_url": "https://github.com/keras-team/keras/commit/95ca6a6da5c128c695e92c5142898abf0837ba6a",
        "buggy_code": "operations_with_complete_input.append(operation.name)",
        "fixed_code": "operations_with_complete_input.append(node.operation.name)",
        "patch": "@@ -318,7 +318,7 @@ def map_graph(inputs, outputs):\n                         \"The following previous operations were accessed \"\n                         f\"without issue: {operations_with_complete_input}\"\n                     )\n-                operations_with_complete_input.append(operation.name)\n+                operations_with_complete_input.append(node.operation.name)\n \n             for x in tree.flatten(node.outputs):\n                 computable_tensors.add(x)"
    },
    {
        "commit_id": "95ca6a6da5c128c695e92c5142898abf0837ba6a",
        "commit_message": "Fixes for reference before assignment\u2026 (#18640)\n\n* Fixes for reference before assignment found through static analysis tooling\r\n\r\n* Fixes for reference before assignment found through static analysis tooling\r\n\r\n* [keras/layers/preprocessing/discretization_test.py] Remove `assertAllClose` from `test_tf_data_compatibility` ; [keras/{ops/numpy.py,saving/saving_lib.py}] `black`en\r\n\r\n* [keras/ops/numpy.py] Revert to see if segfault resolves on CI\r\n\r\n* [keras/{callbacks/reduce_lr_on_plateau,layers/preprocessing/{center_crop_test,random_crop_test}\r\nops/operation}.py] Resolve issues found through `flake8 --config setup.cfg .`\r\n\r\n* [keras/src/layers/preprocessing/image_preprocessing/center_crop_test.py] Return `output_shape` to being dependent on `image_data_format` on `test_tf_data_compatibility`\r\n\r\n* [keras/src/layers/preprocessing/image_preprocessing/random_crop_test.py] Return `output_shape` to being dependent on `image_data_format` on `test_tf_data_compatibility`\r\n\r\n* [keras/src/layers/preprocessing/image_preprocessing/{center,random}_crop_test.py] Make tuple `output.shape` for comparison against `output_shape` from `image_data_format` on `test_tf_data_compatibility`",
        "commit_url": "https://github.com/keras-team/keras/commit/95ca6a6da5c128c695e92c5142898abf0837ba6a",
        "buggy_code": "num_outputs = 1",
        "fixed_code": "num_outputs = 1  # default",
        "patch": "@@ -170,6 +170,7 @@ def variables(self):\n         return vars\n \n     def build(self, y_true, y_pred):\n+        num_outputs = 1  # default\n         if self.output_names:\n             output_names = self.output_names\n         elif isinstance(y_pred, dict):\n@@ -182,7 +183,6 @@ def build(self, y_true, y_pred):\n                 output_names = None\n         else:\n             output_names = None\n-            num_outputs = 1\n         if output_names:\n             num_outputs = len(output_names)\n "
    },
    {
        "commit_id": "7bd02bc6b1f3293b77bac72bffc3854e29142041",
        "commit_message": "Move public exports from `exports.py` to `backend/__init__py`. (#20330)\n\nThe main motivation is to use the exported `keras.Variable` class throughout code.\r\nThe exported `keras.Variable` class is a subclass of the backend specific implementation. However, that public class was not used internally to create variables, for instance via `add_weight()`.\r\nThere was no convenient way to detect that a tensor really is a variable. This code would print `False`:\r\n```python\r\nv = self.add_weight(x)\r\nprint(isinstance(v, keras.Variable)\r\n```\r\n\r\nAdditionally, made API exposed in `keras/src/backend/<backend>/__init__.py` consistent between each other and consistent with `keras.src.backend`, which is important when using the `DynamicBackend` feature:\r\n- added `device_scope()` to Numpy backend (a no-op)\r\n- added import for `name_scope()` in all backends\r\n- fixed bug where `SeedGenerator` was not using the dynamic backend specific `name_scope`",
        "commit_url": "https://github.com/keras-team/keras/commit/7bd02bc6b1f3293b77bac72bffc3854e29142041",
        "buggy_code": "if isinstance(variable, KerasVariable):",
        "fixed_code": "if isinstance(variable, Variable):",
        "patch": "@@ -341,7 +341,7 @@ def fori_loop(lower, upper, body_fun, init_val):\n \n \n def stop_gradient(variable):\n-    if isinstance(variable, KerasVariable):\n+    if isinstance(variable, Variable):\n         variable = variable.value\n     return jax.lax.stop_gradient(variable)\n "
    },
    {
        "commit_id": "7bd02bc6b1f3293b77bac72bffc3854e29142041",
        "commit_message": "Move public exports from `exports.py` to `backend/__init__py`. (#20330)\n\nThe main motivation is to use the exported `keras.Variable` class throughout code.\r\nThe exported `keras.Variable` class is a subclass of the backend specific implementation. However, that public class was not used internally to create variables, for instance via `add_weight()`.\r\nThere was no convenient way to detect that a tensor really is a variable. This code would print `False`:\r\n```python\r\nv = self.add_weight(x)\r\nprint(isinstance(v, keras.Variable)\r\n```\r\n\r\nAdditionally, made API exposed in `keras/src/backend/<backend>/__init__.py` consistent between each other and consistent with `keras.src.backend`, which is important when using the `DynamicBackend` feature:\r\n- added `device_scope()` to Numpy backend (a no-op)\r\n- added import for `name_scope()` in all backends\r\n- fixed bug where `SeedGenerator` was not using the dynamic backend specific `name_scope`",
        "commit_url": "https://github.com/keras-team/keras/commit/7bd02bc6b1f3293b77bac72bffc3854e29142041",
        "buggy_code": "with backend.name_scope(self.name, caller=self):",
        "fixed_code": "with self.backend.name_scope(self.name, caller=self):",
        "patch": "@@ -71,7 +71,7 @@ def seed_initializer(*args, **kwargs):\n             dtype = kwargs.get(\"dtype\", None)\n             return self.backend.convert_to_tensor([seed, 0], dtype=dtype)\n \n-        with backend.name_scope(self.name, caller=self):\n+        with self.backend.name_scope(self.name, caller=self):\n             self.state = self.backend.Variable(\n                 seed_initializer,\n                 shape=(2,),"
    },
    {
        "commit_id": "26dea1b431a92432d4e92dbf43f62548c8697450",
        "commit_message": "Fix CI",
        "commit_url": "https://github.com/keras-team/keras/commit/26dea1b431a92432d4e92dbf43f62548c8697450",
        "buggy_code": "@pytest.mask.skipif(",
        "fixed_code": "@pytest.mark.skipif(",
        "patch": "@@ -8334,7 +8334,7 @@ def test_zeros_like(self, dtype):\n         )\n \n \n-@pytest.mask.skipif(\n+@pytest.mark.skipif(\n     testing.torch_uses_gpu(),\n     reason=\"histogram op not implemented for torch on gpu\",\n )"
    },
    {
        "commit_id": "084b7e113d0aa9984af5318e29a19d235c19de6f",
        "commit_message": "Fix set_tensor_attr",
        "commit_url": "https://github.com/keras-team/keras/commit/084b7e113d0aa9984af5318e29a19d235c19de6f",
        "buggy_code": "setattr(tensor, \"_keras_mask\", value)",
        "fixed_code": "setattr(tensor, attr, value)",
        "patch": "@@ -5,7 +5,7 @@\n \n def set_tensor_attr(tensor, attr, value):\n     try:\n-        setattr(tensor, \"_keras_mask\", value)\n+        setattr(tensor, attr, value)\n     except AttributeError:\n         if value is None:\n             return"
    },
    {
        "commit_id": "443284f57b1a105561f9774825784e835cc51048",
        "commit_message": "Fix test for numpy 2",
        "commit_url": "https://github.com/keras-team/keras/commit/443284f57b1a105561f9774825784e835cc51048",
        "buggy_code": "coordinates += np.reshape(a=offset, newshape=(*offset.shape, 1, 1, 1))",
        "fixed_code": "coordinates += np.reshape(offset, newshape=(*offset.shape, 1, 1, 1))",
        "patch": "@@ -351,7 +351,7 @@ def _compute_affine_transform_coordinates(image, transform):\n     # transform the indices\n     coordinates = np.einsum(\"Bhwij, Bjk -> Bhwik\", indices, transform)\n     coordinates = np.moveaxis(coordinates, source=-1, destination=1)\n-    coordinates += np.reshape(a=offset, newshape=(*offset.shape, 1, 1, 1))\n+    coordinates += np.reshape(offset, newshape=(*offset.shape, 1, 1, 1))\n     if need_squeeze:\n         coordinates = np.squeeze(coordinates, axis=0)\n     return coordinates"
    },
    {
        "commit_id": "e80fe5bc1d18f0c8e566224880ca378b808866df",
        "commit_message": "Fix a typo in a docstring in activations.py: (#20305)\n\n\"is define as\" => \"is defined as\"",
        "commit_url": "https://github.com/keras-team/keras/commit/e80fe5bc1d18f0c8e566224880ca378b808866df",
        "buggy_code": "The exponential linear unit (ELU) with `alpha > 0` is define as:",
        "fixed_code": "The exponential linear unit (ELU) with `alpha > 0` is defined as:",
        "patch": "@@ -169,7 +169,7 @@ def softmax(x, axis=-1):\n def elu(x, alpha=1.0):\n     \"\"\"Exponential Linear Unit.\n \n-    The exponential linear unit (ELU) with `alpha > 0` is define as:\n+    The exponential linear unit (ELU) with `alpha > 0` is defined as:\n \n     - `x` if `x > 0`\n     - alpha * `exp(x) - 1` if `x < 0`"
    },
    {
        "commit_id": "4f7f85285acbb15b41f5ddf99722f5504879a1eb",
        "commit_message": "Allow `ops.stop_gradient()` to take a variable. (#20302)\n\nPassing a tensor to `ops.stop_gradient()` always works. However, passing a variable directly would work with the Tensorflow backend but fail with an obscure error message with the JAX backend and the Torch backend, requiring users to write `ops.stop_gradient(variable.value)`.\r\n\r\nThis makes it work directly with variables, which is a common use-case.",
        "commit_url": "https://github.com/keras-team/keras/commit/4f7f85285acbb15b41f5ddf99722f5504879a1eb",
        "buggy_code": "return x * ops.stop_gradient(self.w.value) + self.b",
        "fixed_code": "return x * ops.stop_gradient(self.w) + self.b",
        "patch": "@@ -565,7 +565,7 @@ def __init__(self):\n                 self.b = self.add_weight(shape=(1,), initializer=\"zeros\")\n \n             def call(self, x, training=False):\n-                return x * ops.stop_gradient(self.w.value) + self.b\n+                return x * ops.stop_gradient(self.w) + self.b\n \n         model = models.Sequential([ExampleLayer()])\n         model.compile("
    },
    {
        "commit_id": "79adef4527b072c602ad0d1f87af30ec70197007",
        "commit_message": "Fix rendering issue (#20301)",
        "commit_url": "https://github.com/keras-team/keras/commit/79adef4527b072c602ad0d1f87af30ec70197007",
        "buggy_code": "Call Args:",
        "fixed_code": "Call arguments:",
        "patch": "@@ -28,7 +28,7 @@ class AdditiveAttention(Attention):\n         dropout: Float between 0 and 1. Fraction of the units to drop for the\n             attention scores. Defaults to `0.0`.\n \n-    Call Args:\n+    Call arguments:\n         inputs: List of the following tensors:\n             - `query`: Query tensor of shape `(batch_size, Tq, dim)`.\n             - `value`: Value tensor of shape `(batch_size, Tv, dim)`."
    },
    {
        "commit_id": "79adef4527b072c602ad0d1f87af30ec70197007",
        "commit_message": "Fix rendering issue (#20301)",
        "commit_url": "https://github.com/keras-team/keras/commit/79adef4527b072c602ad0d1f87af30ec70197007",
        "buggy_code": "Call Args:",
        "fixed_code": "Call arguments:",
        "patch": "@@ -33,7 +33,7 @@ class Attention(Layer):\n             query and key vectors. `\"concat\"` refers to the hyperbolic tangent\n             of the concatenation of the `query` and `key` vectors.\n \n-    Call Args:\n+    Call arguments:\n         inputs: List of the following tensors:\n             - `query`: Query tensor of shape `(batch_size, Tq, dim)`.\n             - `value`: Value tensor of shape `(batch_size, Tv, dim)`."
    },
    {
        "commit_id": "36a01f16729cca97876019954f1329b5145a8a3e",
        "commit_message": "Fix CI",
        "commit_url": "https://github.com/keras-team/keras/commit/36a01f16729cca97876019954f1329b5145a8a3e",
        "buggy_code": "result[key] = value",
        "fixed_code": "result[key] = value[:]",
        "patch": "@@ -466,7 +466,7 @@ def _extract_weights_from_store(self, data, metadata=None, inner_path=\"\"):\n                         value, metadata=metadata, inner_path=inner_path\n                     )\n             else:\n-                result[key] = value\n+                result[key] = value[:]\n         return result, metadata\n \n     def _generate_filepath_info(self, rich_style=False):"
    },
    {
        "commit_id": "d35031cd4a03ce07feea5f1e8f3a709c435b7057",
        "commit_message": "Fix code format",
        "commit_url": "https://github.com/keras-team/keras/commit/d35031cd4a03ce07feea5f1e8f3a709c435b7057",
        "buggy_code": "def test_output(self):",
        "fixed_code": "def test_correctness(self):",
        "patch": "@@ -30,7 +30,7 @@ def test_random_brightness_inference(self):\n         output = layer(inputs, training=False)\n         self.assertAllClose(inputs, output)\n \n-    def test_output(self):\n+    def test_correctness(self):\n         seed = 2390\n \n         # Always scale up, but randomly between 0 ~ 255"
    },
    {
        "commit_id": "d35031cd4a03ce07feea5f1e8f3a709c435b7057",
        "commit_message": "Fix code format",
        "commit_url": "https://github.com/keras-team/keras/commit/d35031cd4a03ce07feea5f1e8f3a709c435b7057",
        "buggy_code": "AttributeError, \"Use `add\\(\\)` and `pop\\(\\)`\"",
        "fixed_code": "AttributeError, r\"Use `add\\(\\)` and `pop\\(\\)`\"",
        "patch": "@@ -382,6 +382,6 @@ def test_hasattr(self):\n     def test_layers_setter(self):\n         model = Sequential()\n         with self.assertRaisesRegex(\n-            AttributeError, \"Use `add\\(\\)` and `pop\\(\\)`\"\n+            AttributeError, r\"Use `add\\(\\)` and `pop\\(\\)`\"\n         ):\n             model.layers = [layers.Dense(4)]"
    },
    {
        "commit_id": "e94e0ba2f30aa04c50288468af2da85738f57e3f",
        "commit_message": "Fix typo in documentation. (#20262)\n\nI've found a typo in the documentation for the extract_patches function. It said (patches_height, patches_widht) instead of (patches_height, patches_width).",
        "commit_url": "https://github.com/keras-team/keras/commit/e94e0ba2f30aa04c50288468af2da85738f57e3f",
        "buggy_code": "size: Patch size int or tuple (patch_height, patch_widht)",
        "fixed_code": "size: Patch size int or tuple (patch_height, patch_width)",
        "patch": "@@ -614,7 +614,7 @@ def extract_patches(\n \n     Args:\n         images: Input image or batch of images. Must be 3D or 4D.\n-        size: Patch size int or tuple (patch_height, patch_widht)\n+        size: Patch size int or tuple (patch_height, patch_width)\n         strides: strides along height and width. If not specified, or\n             if `None`, it defaults to the same value as `size`.\n         dilation_rate: This is the input stride, specifying how far two"
    },
    {
        "commit_id": "adcf0e19b4c0268c1a9e44386a698f27a2a79282",
        "commit_message": "Fix import",
        "commit_url": "https://github.com/keras-team/keras/commit/adcf0e19b4c0268c1a9e44386a698f27a2a79282",
        "buggy_code": "import concurrent",
        "fixed_code": "import concurrent.futures",
        "patch": "@@ -1,4 +1,4 @@\n-import concurrent\n+import concurrent.futures\n import inspect\n import platform\n import warnings"
    },
    {
        "commit_id": "c3691f0f6ecd92df8ba7cebdaa7990f396d049be",
        "commit_message": "Fix image resize conversion to original dtype (#20213)\n\n* Fix image resize conversion to original dtype\r\n\r\n* Fix dtype assertion in tests\r\n\r\n* Fix Resizing (preprocessing) layer\r\n\r\n* Revert to TF dtype int check\r\n\r\n* Revert common backend dtype check\r\n\r\n* Saturating cast with custom backend module",
        "commit_url": "https://github.com/keras-team/keras/commit/c3691f0f6ecd92df8ba7cebdaa7990f396d049be",
        "buggy_code": "return tf.cast(resized, images.dtype)",
        "fixed_code": "return resized",
        "patch": "@@ -297,7 +297,7 @@ def resize(\n             resized = tf.transpose(resized, (0, 3, 1, 2))\n         elif len(images.shape) == 3:\n             resized = tf.transpose(resized, (2, 0, 1))\n-    return tf.cast(resized, images.dtype)\n+    return resized\n \n \n AFFINE_TRANSFORM_INTERPOLATIONS = ("
    },
    {
        "commit_id": "efec34132d70d392474665edb585755f57247599",
        "commit_message": "Fix check precision",
        "commit_url": "https://github.com/keras-team/keras/commit/efec34132d70d392474665edb585755f57247599",
        "buggy_code": "self.assertAllClose(out, -1.1178946)",
        "fixed_code": "self.assertAllClose(out, -1.1178946, atol=1e-3)",
        "patch": "@@ -945,7 +945,7 @@ def test_logdet(self):\n             dtype=\"float32\",\n         )\n         out = kmath.logdet(x)\n-        self.assertAllClose(out, -1.1178946)\n+        self.assertAllClose(out, -1.1178946, atol=1e-3)\n \n \n class MathDtypeTest(testing.TestCase, parameterized.TestCase):"
    },
    {
        "commit_id": "067ae7e9cafac013a5a51576937f3209c171690c",
        "commit_message": "Logdet op, fix for Slogdet shape estimation (#20200)\n\n* Fix Slogdet shape estimation.\r\nAdd Logdet op\r\n\r\n* Move logdet op to math namespace\r\n\r\n* Don't export under math namespace",
        "commit_url": "https://github.com/keras-team/keras/commit/067ae7e9cafac013a5a51576937f3209c171690c",
        "buggy_code": "logabsdet = KerasTensor((), dtype=x.dtype)",
        "fixed_code": "logabsdet = KerasTensor(x.shape[:-2], dtype=x.dtype)",
        "patch": "@@ -6513,7 +6513,7 @@ def call(self, x):\n \n     def compute_output_spec(self, x):\n         sign = KerasTensor((), dtype=x.dtype)\n-        logabsdet = KerasTensor((), dtype=x.dtype)\n+        logabsdet = KerasTensor(x.shape[:-2], dtype=x.dtype)\n         return (sign, logabsdet)\n \n "
    },
    {
        "commit_id": "829c9aaca8abc4241b74385d29e9b0ea23b1baec",
        "commit_message": "_get_node_attribute_at_index() raising AttributeError instead of ValueError (#20156)\n\nhttps://github.com/keras-team/keras/issues/20155\r\n\r\nThis commit allows using hasattr() on on node attributes, without raising an error.",
        "commit_url": "https://github.com/keras-team/keras/commit/829c9aaca8abc4241b74385d29e9b0ea23b1baec",
        "buggy_code": "raise ValueError(",
        "fixed_code": "raise AttributeError(",
        "patch": "@@ -282,7 +282,7 @@ def _get_node_attribute_at_index(self, node_index, attr, attr_name):\n             The operation's attribute `attr` at the node of index `node_index`.\n         \"\"\"\n         if not self._inbound_nodes:\n-            raise ValueError(\n+            raise AttributeError(\n                 f\"The layer {self.name} has never been called \"\n                 f\"and thus has no defined {attr_name}.\"\n             )"
    },
    {
        "commit_id": "f4a472547e0cc503aa658d1196da90defa4d2565",
        "commit_message": "Fix typing.cast when subclassing (#20149)",
        "commit_url": "https://github.com/keras-team/keras/commit/f4a472547e0cc503aa658d1196da90defa4d2565",
        "buggy_code": "return typing.cast(Functional, super().__new__(cls))",
        "fixed_code": "return typing.cast(cls, super().__new__(cls))",
        "patch": "@@ -96,7 +96,7 @@ class Functional(Function, Model):\n     \"\"\"\n \n     def __new__(cls, *args, **kwargs):\n-        return typing.cast(Functional, super().__new__(cls))\n+        return typing.cast(cls, super().__new__(cls))\n \n     @tracking.no_automatic_dependency_tracking\n     def __init__(self, inputs, outputs, name=None, **kwargs):"
    },
    {
        "commit_id": "f4a472547e0cc503aa658d1196da90defa4d2565",
        "commit_message": "Fix typing.cast when subclassing (#20149)",
        "commit_url": "https://github.com/keras-team/keras/commit/f4a472547e0cc503aa658d1196da90defa4d2565",
        "buggy_code": "return typing.cast(Model, super().__new__(cls))",
        "fixed_code": "return typing.cast(cls, super().__new__(cls))",
        "patch": "@@ -141,7 +141,7 @@ def __new__(cls, *args, **kwargs):\n             from keras.src.models.functional import Functional\n \n             return Functional.__new__(Functional, *args, **kwargs)\n-        return typing.cast(Model, super().__new__(cls))\n+        return typing.cast(cls, super().__new__(cls))\n \n     def __init__(self, *args, **kwargs):\n         Trainer.__init__(self)"
    },
    {
        "commit_id": "f4a472547e0cc503aa658d1196da90defa4d2565",
        "commit_message": "Fix typing.cast when subclassing (#20149)",
        "commit_url": "https://github.com/keras-team/keras/commit/f4a472547e0cc503aa658d1196da90defa4d2565",
        "buggy_code": "return typing.cast(Sequential, super().__new__(cls))",
        "fixed_code": "return typing.cast(cls, super().__new__(cls))",
        "patch": "@@ -63,7 +63,7 @@ class Sequential(Model):\n     \"\"\"\n \n     def __new__(cls, *args, **kwargs):\n-        return typing.cast(Sequential, super().__new__(cls))\n+        return typing.cast(cls, super().__new__(cls))\n \n     def __init__(self, layers=None, trainable=True, name=None):\n         super().__init__(trainable=trainable, name=name)"
    },
    {
        "commit_id": "befa049bdd04545892354bbad54d86cf3ce45c86",
        "commit_message": "Bug fix in `metrics_utils.py` when using Tensorflow. (#20137)",
        "commit_url": "https://github.com/keras-team/keras/commit/befa049bdd04545892354bbad54d86cf3ce45c86",
        "buggy_code": "pred_shape = y_pred.shape",
        "fixed_code": "pred_shape = ops.shape(y_pred)",
        "patch": "@@ -500,7 +500,7 @@ def update_confusion_matrix_variables(\n             )\n         thresh_label_tile = ops.where(one_thresh, num_labels, 1)\n     else:\n-        pred_shape = y_pred.shape\n+        pred_shape = ops.shape(y_pred)\n         num_predictions = pred_shape[0]\n         if len(y_pred.shape) == 1:\n             num_labels = 1"
    },
    {
        "commit_id": "04ed73e6f9b0a7f835a973ee2ceb3262278e8afb",
        "commit_message": "Fix default value of `logs` in Trainer (#20107)",
        "commit_url": "https://github.com/keras-team/keras/commit/04ed73e6f9b0a7f835a973ee2ceb3262278e8afb",
        "buggy_code": "logs = None",
        "fixed_code": "logs = {}",
        "patch": "@@ -554,7 +554,7 @@ def evaluate(\n         self.make_test_function()\n         self.stop_evaluating = False\n         callbacks.on_test_begin()\n-        logs = None\n+        logs = {}\n         self.reset_metrics()\n \n         self._jax_state_synced = True"
    },
    {
        "commit_id": "04ed73e6f9b0a7f835a973ee2ceb3262278e8afb",
        "commit_message": "Fix default value of `logs` in Trainer (#20107)",
        "commit_url": "https://github.com/keras-team/keras/commit/04ed73e6f9b0a7f835a973ee2ceb3262278e8afb",
        "buggy_code": "logs = None",
        "fixed_code": "logs = {}",
        "patch": "@@ -276,7 +276,7 @@ def evaluate(\n         self.make_test_function()\n         self.stop_evaluating = False\n         callbacks.on_test_begin()\n-        logs = None\n+        logs = {}\n         self.reset_metrics()\n         for step, data in epoch_iterator.enumerate_epoch():\n             callbacks.on_test_batch_begin(step)"
    },
    {
        "commit_id": "04ed73e6f9b0a7f835a973ee2ceb3262278e8afb",
        "commit_message": "Fix default value of `logs` in Trainer (#20107)",
        "commit_url": "https://github.com/keras-team/keras/commit/04ed73e6f9b0a7f835a973ee2ceb3262278e8afb",
        "buggy_code": "logs = None",
        "fixed_code": "logs = {}",
        "patch": "@@ -366,7 +366,7 @@ def evaluate(\n         self.make_test_function()\n         self.stop_evaluating = False\n         callbacks.on_test_begin()\n-        logs = None\n+        logs = {}\n         self.reset_metrics()\n         for step, data in epoch_iterator.enumerate_epoch():\n             callbacks.on_test_batch_begin(step)"
    },
    {
        "commit_id": "933579d3c4a585f236982d05d3a74921f9567415",
        "commit_message": "Fix summary(show_trainable=True) (#20102)",
        "commit_url": "https://github.com/keras-team/keras/commit/933579d3c4a585f236982d05d3a74921f9567415",
        "buggy_code": "if layer.weights:",
        "fixed_code": "if hasattr(layer, \"weights\") and len(layer.weights) > 0:",
        "patch": "@@ -284,7 +284,7 @@ def get_layer_fields(layer, prefix=\"\"):\n         if not sequential_like:\n             fields.append(get_connections(layer))\n         if show_trainable:\n-            if layer.weights:\n+            if hasattr(layer, \"weights\") and len(layer.weights) > 0:\n                 fields.append(\n                     bold_text(\"Y\", color=34)\n                     if layer.trainable"
    },
    {
        "commit_id": "b45be337c6156d90f220beba9f68eeb2e52e2b0d",
        "commit_message": "chore: fix typo (#20099)",
        "commit_url": "https://github.com/keras-team/keras/commit/b45be337c6156d90f220beba9f68eeb2e52e2b0d",
        "buggy_code": "transformation of input strings. For a layer than can split and tokenize",
        "fixed_code": "transformation of input strings. For a layer that can split and tokenize",
        "patch": "@@ -13,7 +13,7 @@ class StringLookup(IndexLookup):\n \n     This layer translates a set of arbitrary strings into integer output via a\n     table-based vocabulary lookup. This layer will perform no splitting or\n-    transformation of input strings. For a layer than can split and tokenize\n+    transformation of input strings. For a layer that can split and tokenize\n     natural language, see the `keras.layers.TextVectorization` layer.\n \n     The vocabulary for the layer must be either supplied on construction or"
    },
    {
        "commit_id": "616cf500a6541bc403d84fa51f3c54173d88482a",
        "commit_message": "Fix code style",
        "commit_url": "https://github.com/keras-team/keras/commit/616cf500a6541bc403d84fa51f3c54173d88482a",
        "buggy_code": "f\"\\nEpoch {epoch +1}: \"",
        "fixed_code": "f\"\\nEpoch {epoch + 1}: \"",
        "patch": "@@ -138,7 +138,7 @@ def on_epoch_end(self, epoch, logs=None):\n                         self.model.optimizer.learning_rate = new_lr\n                         if self.verbose > 0:\n                             io_utils.print_msg(\n-                                f\"\\nEpoch {epoch +1}: \"\n+                                f\"\\nEpoch {epoch + 1}: \"\n                                 \"ReduceLROnPlateau reducing \"\n                                 f\"learning rate to {new_lr}.\"\n                             )"
    },
    {
        "commit_id": "7a6d539ad6ddc82c8fe31674d5d8edb4f76f492f",
        "commit_message": "Fix `reset_state` for some metrics (#20026)",
        "commit_url": "https://github.com/keras-team/keras/commit/7a6d539ad6ddc82c8fe31674d5d8edb4f76f492f",
        "buggy_code": "self.true_positives.assign(0.0)",
        "fixed_code": "self.true_positives.assign(0)",
        "patch": "@@ -338,7 +338,7 @@ def result(self):\n \n     def reset_state(self):\n         # The state of the metric will be reset at the start of each epoch.\n-        self.true_positives.assign(0.0)\n+        self.true_positives.assign(0)\n \n \n model = get_uncompiled_model()"
    },
    {
        "commit_id": "7a6d539ad6ddc82c8fe31674d5d8edb4f76f492f",
        "commit_message": "Fix `reset_state` for some metrics (#20026)",
        "commit_url": "https://github.com/keras-team/keras/commit/7a6d539ad6ddc82c8fe31674d5d8edb4f76f492f",
        "buggy_code": "self.sum.assign(0.0)",
        "fixed_code": "self.sum.assign(0)",
        "patch": "@@ -39,7 +39,7 @@ def result(self):\n         return _sum / (_total + _epsilon)\n \n     def reset_state(self):\n-        self.sum.assign(0.0)\n+        self.sum.assign(0)\n         self.total.assign(0)\n \n "
    },
    {
        "commit_id": "42798665067c1449d3e76b681f06343340098672",
        "commit_message": "Fix `dtype` argument when it is a FloatDTypePolicy (#19896)\n\nMerge `is_quantized` and `quantization_mode`",
        "commit_url": "https://github.com/keras-team/keras/commit/42798665067c1449d3e76b681f06343340098672",
        "buggy_code": "layer._dtype_policy.quantization_mode = mode",
        "fixed_code": "layer._dtype_policy._quantization_mode = mode",
        "patch": "@@ -475,7 +475,7 @@ def test_quantize_invalid_mode(self, mode):\n             NotImplementedError, \"Invalid quantization mode.\"\n         ):\n             # Explicitly set quantization_mode\n-            layer._dtype_policy.quantization_mode = mode\n+            layer._dtype_policy._quantization_mode = mode\n             layer.quantized_call(x)\n         self.assertEqual(layer.dtype_policy, original_dtype_policy)\n "
    },
    {
        "commit_id": "42798665067c1449d3e76b681f06343340098672",
        "commit_message": "Fix `dtype` argument when it is a FloatDTypePolicy (#19896)\n\nMerge `is_quantized` and `quantization_mode`",
        "commit_url": "https://github.com/keras-team/keras/commit/42798665067c1449d3e76b681f06343340098672",
        "buggy_code": "layer._dtype_policy.quantization_mode = mode",
        "fixed_code": "layer._dtype_policy._quantization_mode = mode",
        "patch": "@@ -599,7 +599,7 @@ def test_quantize_invalid_mode(self, mode):\n             NotImplementedError, \"Invalid quantization mode.\"\n         ):\n             # Explicitly set quantization_mode\n-            layer._dtype_policy.quantization_mode = mode\n+            layer._dtype_policy._quantization_mode = mode\n             layer.quantized_call(x)\n         self.assertEqual(layer.dtype_policy, original_dtype_policy)\n "
    },
    {
        "commit_id": "42798665067c1449d3e76b681f06343340098672",
        "commit_message": "Fix `dtype` argument when it is a FloatDTypePolicy (#19896)\n\nMerge `is_quantized` and `quantization_mode`",
        "commit_url": "https://github.com/keras-team/keras/commit/42798665067c1449d3e76b681f06343340098672",
        "buggy_code": "layer._dtype_policy.quantization_mode = mode",
        "fixed_code": "layer._dtype_policy._quantization_mode = mode",
        "patch": "@@ -367,7 +367,7 @@ def test_quantize_invalid_mode(self, mode):\n             NotImplementedError, \"Invalid quantization mode.\"\n         ):\n             # Explicitly set quantization_mode\n-            layer._dtype_policy.quantization_mode = mode\n+            layer._dtype_policy._quantization_mode = mode\n             layer.quantized_call(x)\n         self.assertEqual(layer.dtype_policy, original_dtype_policy)\n "
    },
    {
        "commit_id": "9ea70698b98015dd41fab28e273e6ce9638f3597",
        "commit_message": "Fix for broadcast in metrics reduction. (#19892)\n\nThis would cause dynamic shapes to not work properly with the Tensorflow backend.",
        "commit_url": "https://github.com/keras-team/keras/commit/9ea70698b98015dd41fab28e273e6ce9638f3597",
        "buggy_code": "sample_weight = ops.broadcast_to(sample_weight, values.shape)",
        "fixed_code": "sample_weight = ops.broadcast_to(sample_weight, ops.shape(values))",
        "patch": "@@ -31,7 +31,7 @@ def reduce_to_samplewise_values(values, sample_weight, reduce_fn, dtype):\n             )\n         # Broadcast sample_weight. It doesn't change the multiplication below\n         # but changes the sample_weight reduction applied later.\n-        sample_weight = ops.broadcast_to(sample_weight, values.shape)\n+        sample_weight = ops.broadcast_to(sample_weight, ops.shape(values))\n         values = values * sample_weight\n         if weight_ndim > 1:\n             sample_weight = reduce_fn("
    },
    {
        "commit_id": "727b7ae4e1d366f52c7aaf189207c18f35387176",
        "commit_message": "Fix code formatting error in docstring (#19862)\n\nFor some reason, there is an unclosed backtick the in layer.HashedClossing\r\ndocstring and this breaks the code formatting.\r\n\r\nThis patch puts a closing backtick to fix it.",
        "commit_url": "https://github.com/keras-team/keras/commit/727b7ae4e1d366f52c7aaf189207c18f35387176",
        "buggy_code": "`hash(concatenate(features)) % num_bins.",
        "fixed_code": "`hash(concatenate(features)) % num_bins`.",
        "patch": "@@ -14,7 +14,7 @@ class HashedCrossing(Layer):\n \n     This layer performs crosses of categorical features using the \"hashing\n     trick\". Conceptually, the transformation can be thought of as:\n-    `hash(concatenate(features)) % num_bins.\n+    `hash(concatenate(features)) % num_bins`.\n \n     This layer currently only performs crosses of scalar inputs and batches of\n     scalar inputs. Valid input shapes are `(batch_size, 1)`, `(batch_size,)` and"
    },
    {
        "commit_id": "84b283e6200bcb051ed976782fbb2b123bf9b8fc",
        "commit_message": "fix variable name when add in init function (#19853)",
        "commit_url": "https://github.com/keras-team/keras/commit/84b283e6200bcb051ed976782fbb2b123bf9b8fc",
        "buggy_code": "with self._open_name_scope():",
        "fixed_code": "with backend.name_scope(self.name, caller=self):",
        "patch": "@@ -507,7 +507,7 @@ def add_weight(\n             else:\n                 initializer = \"zeros\"\n         initializer = initializers.get(initializer)\n-        with self._open_name_scope():\n+        with backend.name_scope(self.name, caller=self):\n             variable = backend.Variable(\n                 initializer=initializer,\n                 shape=shape,"
    },
    {
        "commit_id": "857a7acfc2496963dec777e13da8a6486ac50c38",
        "commit_message": "Fix TypeError in `Lambda.from_config` (#19827)",
        "commit_url": "https://github.com/keras-team/keras/commit/857a7acfc2496963dec777e13da8a6486ac50c38",
        "buggy_code": "isinstance(e, (int, None)) for e in output_shape",
        "fixed_code": "isinstance(e, (int, type(None))) for e in output_shape",
        "patch": "@@ -219,7 +219,7 @@ def from_config(cls, config, custom_objects=None, safe_mode=None):\n                     fn_config, custom_objects=custom_objects\n                 )\n                 if isinstance(output_shape, list) and all(\n-                    isinstance(e, (int, None)) for e in output_shape\n+                    isinstance(e, (int, type(None))) for e in output_shape\n                 ):\n                     output_shape = tuple(output_shape)\n                 config[\"output_shape\"] = output_shape"
    },
    {
        "commit_id": "64415ad3c8cae95e39d9c276646bf20c092b0ee2",
        "commit_message": "Refactor `ops.image.*` and the tests (#19777)\n\n* Refactor `ops.image.*` and the tests\r\n\r\n* Fix tests\r\n\r\n* Improve CI\r\n\r\n* Update docstring\r\n\r\n* Update docstings",
        "commit_url": "https://github.com/keras-team/keras/commit/64415ad3c8cae95e39d9c276646bf20c092b0ee2",
        "buggy_code": "image=inputs,",
        "fixed_code": "images=inputs,",
        "patch": "@@ -226,7 +226,7 @@ def call(self, inputs, training=True):\n         if training:\n             rotation_matrix = self._get_rotation_matrix(inputs)\n             transformed_image = self.backend.image.affine_transform(\n-                image=inputs,\n+                images=inputs,\n                 transform=rotation_matrix,\n                 interpolation=self.interpolation,\n                 fill_mode=self.fill_mode,"
    },
    {
        "commit_id": "3756ef96ee6534509e260b89efaca8b5ba1bb474",
        "commit_message": "Remove `convert_to_numpy` in confusion metrics and fix `ops.nonzero` for torch. (#19750)\n\n- Removed the use of `convert_to_numpy` confusion metrics as it prevents jit compilation.\r\n- Fixed Torch implementation of `ops.nonzero`, it was returning a tuple of one tensor instead of just the tensor.\r\n\r\nThe `convert_to_numpy` call was presumably a workaround for the second issue.",
        "commit_url": "https://github.com/keras-team/keras/commit/3756ef96ee6534509e260b89efaca8b5ba1bb474",
        "buggy_code": "return tuple(cast(indices, \"int32\") for indices in torch.nonzero(x).T)",
        "fixed_code": "return cast(torch.nonzero(x).T, \"int32\")",
        "patch": "@@ -1007,7 +1007,7 @@ def ndim(x):\n \n def nonzero(x):\n     x = convert_to_tensor(x)\n-    return tuple(cast(indices, \"int32\") for indices in torch.nonzero(x).T)\n+    return cast(torch.nonzero(x).T, \"int32\")\n \n \n def not_equal(x1, x2):"
    },
    {
        "commit_id": "d68e907fcc7efaade1edbf117b2d37f8ef386fdf",
        "commit_message": "Fix accuracy metric tensor conversion",
        "commit_url": "https://github.com/keras-team/keras/commit/d68e907fcc7efaade1edbf117b2d37f8ef386fdf",
        "buggy_code": "vfunc = np.vectorize(myfunc)",
        "fixed_code": "vfunc = keras.ops.vectorize(myfunc)",
        "patch": "@@ -5262,7 +5262,7 @@ def vectorize(pyfunc, *, excluded=None, signature=None):\n     def myfunc(a, b):\n         return a + b\n \n-    vfunc = np.vectorize(myfunc)\n+    vfunc = keras.ops.vectorize(myfunc)\n     y = vfunc([1, 2, 3, 4], 2)  # Returns Tensor([3, 4, 5, 6])\n     ```\n "
    },
    {
        "commit_id": "6d98b50c5826740c1dceb0d698fbf7b0f64e5b94",
        "commit_message": "Fix np array assignment after convert_to_numpy",
        "commit_url": "https://github.com/keras-team/keras/commit/6d98b50c5826740c1dceb0d698fbf7b0f64e5b94",
        "buggy_code": "return np.asarray(x)",
        "fixed_code": "return np.array(x)",
        "patch": "@@ -128,7 +128,7 @@ def convert_to_numpy(x):\n         x = tf.convert_to_tensor(x)\n     elif isinstance(x, tf.RaggedTensor):\n         x = x.to_tensor()\n-    return np.asarray(x)\n+    return np.array(x)\n \n \n def is_tensor(x):"
    },
    {
        "commit_id": "9a69ecefe1f671ee8a051d88dac221b8f7c9124f",
        "commit_message": "Fix deprecation warning in torch",
        "commit_url": "https://github.com/keras-team/keras/commit/9a69ecefe1f671ee8a051d88dac221b8f7c9124f",
        "buggy_code": "return torch.cholesky(x)",
        "fixed_code": "return torch.linalg.cholesky(x)",
        "patch": "@@ -8,7 +8,7 @@\n \n \n def cholesky(x):\n-    return torch.cholesky(x)\n+    return torch.linalg.cholesky(x)\n \n \n def det(x):"
    },
    {
        "commit_id": "880f0cdd67591474d8ed98a6b192655322b7ecfc",
        "commit_message": "Fix `ops.ctc_decode` (#19633)\n\n* Fix greedy ctc decode\r\n\r\n* Remove print\r\n\r\n* Fix `tf.nn.ctc_beam_search_decoder`\r\n\r\n* Change default `mask_index` to `0`\r\n\r\n* Fix losses test\r\n\r\n* Update",
        "commit_url": "https://github.com/keras-team/keras/commit/880f0cdd67591474d8ed98a6b192655322b7ecfc",
        "buggy_code": "self.assertAllClose(output, 4.389582)",
        "fixed_code": "self.assertAllClose(output, 2.448645)",
        "patch": "@@ -1387,7 +1387,7 @@ def test_correctness(self):\n         logits = (np.arange(24).reshape((2, 4, 3)).astype(\"float32\") - 12) / 100\n         y_true = np.array(([[1, 2, 1, 0], [1, 2, 0, 2]]))\n         output = losses.CTC()(y_true, logits)\n-        self.assertAllClose(output, 4.389582)\n+        self.assertAllClose(output, 2.448645)\n \n \n class DiceTest(testing.TestCase):"
    },
    {
        "commit_id": "d5c95408ca6d35fc4ef12bd844ed42288894cf27",
        "commit_message": "fix(ops): specify NonZero output dtype and add test coverage (#19635)",
        "commit_url": "https://github.com/keras-team/keras/commit/d5c95408ca6d35fc4ef12bd844ed42288894cf27",
        "buggy_code": "return KerasTensor([None] * len(x.shape))",
        "fixed_code": "return KerasTensor([None] * len(x.shape), dtype=\"int32\")",
        "patch": "@@ -3881,7 +3881,7 @@ def call(self, x):\n         return backend.numpy.nonzero(x)\n \n     def compute_output_spec(self, x):\n-        return KerasTensor([None] * len(x.shape))\n+        return KerasTensor([None] * len(x.shape), dtype=\"int32\")\n \n \n @keras_export([\"keras.ops.nonzero\", \"keras.ops.numpy.nonzero\"])"
    },
    {
        "commit_id": "81c004708a8ea9aa135edebf08ba17ba3f95e0d1",
        "commit_message": "Fix `argpartition` cuda bug in torch (#19634)",
        "commit_url": "https://github.com/keras-team/keras/commit/81c004708a8ea9aa135edebf08ba17ba3f95e0d1",
        "buggy_code": "x = np.array([[3, 4, 2], [1, 3, 1]])",
        "fixed_code": "x = np.array([[3, 4, 2], [1, 3, 4]])",
        "patch": "@@ -4328,7 +4328,7 @@ def test_argpartition(self):\n         self.assertAllClose(knp.argpartition(x, 2), np.argpartition(x, 2))\n         self.assertAllClose(knp.Argpartition(2)(x), np.argpartition(x, 2))\n \n-        x = np.array([[3, 4, 2], [1, 3, 1]])\n+        x = np.array([[3, 4, 2], [1, 3, 4]])\n         self.assertAllClose(knp.argpartition(x, 1), np.argpartition(x, 1))\n         self.assertAllClose(knp.Argpartition(1)(x), np.argpartition(x, 1))\n "
    },
    {
        "commit_id": "0f3bd5222bb46ac6da3ed96187e7ec908aa851fa",
        "commit_message": "Fix torch GPU CI",
        "commit_url": "https://github.com/keras-team/keras/commit/0f3bd5222bb46ac6da3ed96187e7ec908aa851fa",
        "buggy_code": "proxy = set_to_zero(torch.ones(x.shape, dtype=torch.int32), bottom_ind)",
        "fixed_code": "proxy = set_to_zero(ones(x.shape, dtype=torch.int32), bottom_ind)",
        "patch": "@@ -1627,7 +1627,7 @@ def set_to_zero(a, i):\n \n     for _ in range(x.dim() - 1):\n         set_to_zero = torch.vmap(set_to_zero)\n-    proxy = set_to_zero(torch.ones(x.shape, dtype=torch.int32), bottom_ind)\n+    proxy = set_to_zero(ones(x.shape, dtype=torch.int32), bottom_ind)\n \n     top_ind = torch.topk(proxy, x.shape[-1] - kth - 1)[1]\n "
    },
    {
        "commit_id": "533bd4342a3f35e162797ba6d62cfdc5477ef109",
        "commit_message": "Minor fix",
        "commit_url": "https://github.com/keras-team/keras/commit/533bd4342a3f35e162797ba6d62cfdc5477ef109",
        "buggy_code": "for m in self._flat_metrics + self._flat_weighted_metrics:",
        "fixed_code": "for m in self.metrics:",
        "patch": "@@ -164,7 +164,7 @@ def variables(self):\n         if not self.built:\n             return []\n         vars = []\n-        for m in self._flat_metrics + self._flat_weighted_metrics:\n+        for m in self.metrics:\n             if m is not None:\n                 vars.extend(m.variables)\n         return vars"
    },
    {
        "commit_id": "63586fa698cad7005f561fcdbb5ce590fb2484b1",
        "commit_message": "Refactor CTC APIs (#19611)\n\n* Add `ctc_loss` and `ctc_decode` for numpy backend, improve imports and tests\r\n\r\n* Support \"beam_search\" strategy for torch's `ctc_decode`\r\n\r\n* Improve `ctc_loss`\r\n\r\n* Cleanup\r\n\r\n* Refactor `ctc_decode`\r\n\r\n* Update docstring\r\n\r\n* Update docstring\r\n\r\n* Add `CTCDecode` operation and ensure dtype inference of `ctc_decode`\r\n\r\n* Fix `name` of `losses.CTC`",
        "commit_url": "https://github.com/keras-team/keras/commit/63586fa698cad7005f561fcdbb5ce590fb2484b1",
        "buggy_code": "name=\"sparse_categorical_crossentropy\",",
        "fixed_code": "name=\"ctc\",",
        "patch": "@@ -1893,7 +1893,7 @@ class CTC(LossFunctionWrapper):\n     def __init__(\n         self,\n         reduction=\"sum_over_batch_size\",\n-        name=\"sparse_categorical_crossentropy\",\n+        name=\"ctc\",\n     ):\n         super().__init__(\n             ctc,"
    },
    {
        "commit_id": "3ebb36fce26c37b5095853a605f07c5f18b57597",
        "commit_message": "One time fix to _tf_keras API.",
        "commit_url": "https://github.com/keras-team/keras/commit/3ebb36fce26c37b5095853a605f07c5f18b57597",
        "buggy_code": "__version__ = \"3.3.1\"",
        "fixed_code": "__version__ = \"3.3.2\"",
        "patch": "@@ -1,7 +1,7 @@\n from keras.src.api_export import keras_export\n \n # Unique source of truth for the version number.\n-__version__ = \"3.3.1\"\n+__version__ = \"3.3.2\"\n \n \n @keras_export(\"keras.version\")"
    },
    {
        "commit_id": "1135431db4513465f4bf6e65bd5111f68cd6b718",
        "commit_message": "Fix small bug in model.save_weights (#19545)",
        "commit_url": "https://github.com/keras-team/keras/commit/1135431db4513465f4bf6e65bd5111f68cd6b718",
        "buggy_code": "return saving_api.save_weights(self, filepath, overwrite=True)",
        "fixed_code": "return saving_api.save_weights(self, filepath, overwrite=overwrite)",
        "patch": "@@ -315,7 +315,7 @@ def save_weights(self, filepath, overwrite=True):\n                 at the target location, or instead ask the user\n                 via an interactive prompt.\n         \"\"\"\n-        return saving_api.save_weights(self, filepath, overwrite=True)\n+        return saving_api.save_weights(self, filepath, overwrite=overwrite)\n \n     @traceback_utils.filter_traceback\n     def load_weights(self, filepath, skip_mismatch=False, **kwargs):"
    },
    {
        "commit_id": "7dae3e918fbc853cb511dfb680757096d6473aa6",
        "commit_message": "Fix issue with deserialization of nested and shared Functional models.",
        "commit_url": "https://github.com/keras-team/keras/commit/7dae3e918fbc853cb511dfb680757096d6473aa6",
        "buggy_code": "return f\"<Node operation={self.operation}, id={id(self)}>\"",
        "fixed_code": "return f\"<Node operation={self.operation.name}, id={id(self)}>\"",
        "patch": "@@ -82,7 +82,7 @@ def __init__(\n         self.is_input = not self.arguments.keras_tensors\n \n     def __repr__(self):\n-        return f\"<Node operation={self.operation}, id={id(self)}>\"\n+        return f\"<Node operation={self.operation.name}, id={id(self)}>\"\n \n     @property\n     def input_tensors(self):"
    },
    {
        "commit_id": "032cdff18a227877e167b80654704ff746f9c17c",
        "commit_message": "fix defaul value for order in mapcoordinates calss (#19507)",
        "commit_url": "https://github.com/keras-team/keras/commit/032cdff18a227877e167b80654704ff746f9c17c",
        "buggy_code": "def __init__(self, order, fill_mode=\"constant\", fill_value=0):",
        "fixed_code": "def __init__(self, order=1, fill_mode=\"constant\", fill_value=0):",
        "patch": "@@ -515,7 +515,7 @@ def _extract_patches(\n \n \n class MapCoordinates(Operation):\n-    def __init__(self, order, fill_mode=\"constant\", fill_value=0):\n+    def __init__(self, order=1, fill_mode=\"constant\", fill_value=0):\n         super().__init__()\n         self.order = order\n         self.fill_mode = fill_mode"
    },
    {
        "commit_id": "30622e3fea21fdd1f1192a38206e20d4d450ddd8",
        "commit_message": "Fix path of the states in `SeedGenerator` and tracking of `torch_params` (#19495)\n\n* Fix `seed_generator` path and counting issue\r\n\r\n* Fix tests\r\n\r\n* Fix tests\r\n\r\n* Address comments\r\n\r\n* Check before adding variable to `self.torch_params`\r\n\r\n* Move `self.torch_params` logic from `Layer` to `TorchLayer`\r\n\r\n* Use hooks to postprocess `torch_params` in torch backend",
        "commit_url": "https://github.com/keras-team/keras/commit/30622e3fea21fdd1f1192a38206e20d4d450ddd8",
        "buggy_code": "expected_num_seed_generators=0,",
        "fixed_code": "expected_num_seed_generators=1,",
        "patch": "@@ -40,7 +40,7 @@ def test_basics(self):\n             expected_output_shape=(2, 8, 16),\n             expected_num_trainable_weights=4,\n             expected_num_non_trainable_weights=0,\n-            expected_num_seed_generators=0,\n+            expected_num_seed_generators=1,\n             expected_num_losses=0,\n             supports_masking=True,\n             run_training_check=False,"
    },
    {
        "commit_id": "30622e3fea21fdd1f1192a38206e20d4d450ddd8",
        "commit_message": "Fix path of the states in `SeedGenerator` and tracking of `torch_params` (#19495)\n\n* Fix `seed_generator` path and counting issue\r\n\r\n* Fix tests\r\n\r\n* Fix tests\r\n\r\n* Address comments\r\n\r\n* Check before adding variable to `self.torch_params`\r\n\r\n* Move `self.torch_params` logic from `Layer` to `TorchLayer`\r\n\r\n* Use hooks to postprocess `torch_params` in torch backend",
        "commit_url": "https://github.com/keras-team/keras/commit/30622e3fea21fdd1f1192a38206e20d4d450ddd8",
        "buggy_code": "expected_num_seed_generators=0,",
        "fixed_code": "expected_num_seed_generators=1,",
        "patch": "@@ -44,7 +44,7 @@ def test_basics(self):\n             expected_output_shape=(2, 8, 16),\n             expected_num_trainable_weights=4,\n             expected_num_non_trainable_weights=0,\n-            expected_num_seed_generators=0,\n+            expected_num_seed_generators=1,\n             expected_num_losses=0,\n             supports_masking=True,\n             run_training_check=False,"
    },
    {
        "commit_id": "cd62a84c093680f6bff9ee54382778babfc7c5bb",
        "commit_message": "Fix code format.",
        "commit_url": "https://github.com/keras-team/keras/commit/cd62a84c093680f6bff9ee54382778babfc7c5bb",
        "buggy_code": "filepath, custom_objects=None, compile=compile",
        "fixed_code": "filepath, custom_objects=custom_objects, compile=compile",
        "patch": "@@ -181,7 +181,7 @@ def load_model(filepath, custom_objects=None, compile=True, safe_mode=True):\n         )\n     if str(filepath).endswith((\".h5\", \".hdf5\")):\n         return legacy_h5_format.load_model_from_hdf5(\n-            filepath, custom_objects=None, compile=compile\n+            filepath, custom_objects=custom_objects, compile=compile\n         )\n     elif str(filepath).endswith(\".keras\"):\n         raise ValueError("
    },
    {
        "commit_id": "7caec085162a6fba076c464851384ebaca2adf56",
        "commit_message": "Fix issue with using a callable as a learning rate (#19484)\n\n* the fix\r\n\r\n* added test",
        "commit_url": "https://github.com/keras-team/keras/commit/7caec085162a6fba076c464851384ebaca2adf56",
        "buggy_code": "return self._learning_rate(self.iterations)",
        "fixed_code": "return self._learning_rate()",
        "patch": "@@ -567,7 +567,7 @@ def _get_current_learning_rate(self):\n         ):\n             return self._learning_rate(self.iterations)\n         elif callable(self._learning_rate):\n-            return self._learning_rate(self.iterations)\n+            return self._learning_rate()\n         return self._learning_rate\n \n     def _filter_empty_gradients(self, grads, vars):"
    },
    {
        "commit_id": "68e0368c680decbc7c9e1da57b56b3a8212b3ec2",
        "commit_message": "Fix error msg",
        "commit_url": "https://github.com/keras-team/keras/commit/68e0368c680decbc7c9e1da57b56b3a8212b3ec2",
        "buggy_code": "\"Use `tf.saved_model.save()` if you want to export a SavedModel \"",
        "fixed_code": "\"Use `model.export(filepath)` if you want to export a SavedModel \"",
        "patch": "@@ -107,7 +107,7 @@ def save_model(model, filepath, overwrite=True, **kwargs):\n             \"Invalid filepath extension for saving. \"\n             \"Please add either a `.keras` extension for the native Keras \"\n             f\"format (recommended) or a `.h5` extension. \"\n-            \"Use `tf.saved_model.save()` if you want to export a SavedModel \"\n+            \"Use `model.export(filepath)` if you want to export a SavedModel \"\n             \"for use with TFLite/TFServing/etc. \"\n             f\"Received: filepath={filepath}.\"\n         )"
    },
    {
        "commit_id": "5dd801a1577919a6457a376c04b4183410a751fb",
        "commit_message": "Fix CI",
        "commit_url": "https://github.com/keras-team/keras/commit/5dd801a1577919a6457a376c04b4183410a751fb",
        "buggy_code": "testing.tensorflow_uses_gpu(), reason=\"Temporary, XLA error\"",
        "fixed_code": "backend.backend() == \"tensorflow\", reason=\"Temporary, XLA error\"",
        "patch": "@@ -4560,7 +4560,7 @@ def test_elementwise_unary_indexed_slices_correctness(\n \n     @parameterized.named_parameters(OTHER_UNARY_OPS_TESTS)\n     @pytest.mark.skipif(\n-        testing.tensorflow_uses_gpu(), reason=\"Temporary, XLA error\"\n+        backend.backend() == \"tensorflow\", reason=\"Temporary, XLA error\"\n     )\n     def test_other_unary_symbolic_sparse_correctness(\n         self, op_function, op_class, np_op, op_kwargs, input_shape"
    },
    {
        "commit_id": "748197cce4852a5638317aa9dcf54a740893d8aa",
        "commit_message": "Fix TF casting behavior for metric reduction",
        "commit_url": "https://github.com/keras-team/keras/commit/748197cce4852a5638317aa9dcf54a740893d8aa",
        "buggy_code": "self._dtype = dtype",
        "fixed_code": "self._dtype = dtype or backend.floatx()",
        "patch": "@@ -85,7 +85,7 @@ def result(self):\n \n     def __init__(self, dtype=None, name=None):\n         self.name = name or auto_name(self.__class__.__name__)\n-        self._dtype = dtype\n+        self._dtype = dtype or backend.floatx()\n         self._metrics = []\n         self._variables = []\n         self._tracker = Tracker("
    },
    {
        "commit_id": "b3ea9e17e93972654d575e73619de21b3fbe0a95",
        "commit_message": "Fix example code in embedding.py (#19449)",
        "commit_url": "https://github.com/keras-team/keras/commit/b3ea9e17e93972654d575e73619de21b3fbe0a95",
        "buggy_code": ">>> model.add(keras.layers.Embedding(1000, 64, input_length=10))",
        "fixed_code": ">>> model.add(keras.layers.Embedding(1000, 64))",
        "patch": "@@ -20,7 +20,7 @@ class Embedding(Layer):\n     Example:\n \n     >>> model = keras.Sequential()\n-    >>> model.add(keras.layers.Embedding(1000, 64, input_length=10))\n+    >>> model.add(keras.layers.Embedding(1000, 64))\n     >>> # The model will take as input an integer matrix of size (batch,\n     >>> # input_length), and the largest integer (i.e. word index) in the input\n     >>> # should be no larger than 999 (vocabulary size)."
    },
    {
        "commit_id": "b2eb9649e66762dacab6d3cb1b8b4ffd3360e96e",
        "commit_message": "Fix issue with shared layer deserialization",
        "commit_url": "https://github.com/keras-team/keras/commit/b2eb9649e66762dacab6d3cb1b8b4ffd3360e96e",
        "buggy_code": "- network_nodes: dict mapping unique node keys to the Node instances",
        "fixed_code": "- nodes: set of Node instances",
        "patch": "@@ -203,7 +203,7 @@ def map_graph(inputs, outputs):\n \n     Returns:\n         A tuple `(nodes, nodes_by_depth, operations, operations_by_depth)`.\n-        - network_nodes: dict mapping unique node keys to the Node instances\n+        - nodes: set of Node instances\n         - nodes_by_depth: dict mapping ints (depth) to lists of node instances.\n         - operations: list of Operation instances.\n         - operations_by_depth: dict mapping ints (depth) to lists of Operation"
    },
    {
        "commit_id": "c24b98a3528c5346370b6c7158674476ebf1c19e",
        "commit_message": "Fix dropout for recurrent dropout (#19397)",
        "commit_url": "https://github.com/keras-team/keras/commit/c24b98a3528c5346370b6c7158674476ebf1c19e",
        "buggy_code": "ones, rate=self.dropout, seed=self.seed_generator",
        "fixed_code": "ones, rate=self.recurrent_dropout, seed=self.seed_generator",
        "patch": "@@ -35,7 +35,7 @@ def get_recurrent_dropout_mask(self, step_input):\n         if self._recurrent_dropout_mask is None and self.recurrent_dropout > 0:\n             ones = ops.ones_like(step_input)\n             self._recurrent_dropout_mask = backend.random.dropout(\n-                ones, rate=self.dropout, seed=self.seed_generator\n+                ones, rate=self.recurrent_dropout, seed=self.seed_generator\n             )\n         return self._recurrent_dropout_mask\n "
    },
    {
        "commit_id": "21341c60853b32648699845902fa254acf1165d6",
        "commit_message": "Fix various docstrings",
        "commit_url": "https://github.com/keras-team/keras/commit/21341c60853b32648699845902fa254acf1165d6",
        "buggy_code": "(i.e. send_as_json is set to False).",
        "fixed_code": "(i.e. when `send_as_json=False`).",
        "patch": "@@ -29,7 +29,7 @@ class RemoteMonitor(Callback):\n         path: String; path relative to `root` to which the events will be sent.\n         field: String; JSON field under which the data will be stored.\n             The field is used only if the payload is sent within a form\n-            (i.e. send_as_json is set to False).\n+            (i.e. when `send_as_json=False`).\n         headers: Dictionary; optional custom HTTP headers.\n         send_as_json: Boolean; whether the request should be\n             sent as `\"application/json\"`."
    },
    {
        "commit_id": "21341c60853b32648699845902fa254acf1165d6",
        "commit_message": "Fix various docstrings",
        "commit_url": "https://github.com/keras-team/keras/commit/21341c60853b32648699845902fa254acf1165d6",
        "buggy_code": "If set to True, then the output of the dot product",
        "fixed_code": "If set to `True`, then the output of the dot product",
        "patch": "@@ -366,7 +366,7 @@ def dot(inputs, axes=-1, **kwargs):\n             axis or axes along which to take the dot product.\n         normalize: Whether to L2-normalize samples along the\n             dot product axis before taking the dot product.\n-            If set to True, then the output of the dot product\n+            If set to `True`, then the output of the dot product\n             is the cosine proximity between the two samples.\n         **kwargs: Standard layer keyword arguments.\n "
    },
    {
        "commit_id": "21341c60853b32648699845902fa254acf1165d6",
        "commit_message": "Fix various docstrings",
        "commit_url": "https://github.com/keras-team/keras/commit/21341c60853b32648699845902fa254acf1165d6",
        "buggy_code": "rotations at inference time, set `training` to True when calling the layer.",
        "fixed_code": "rotations at inference time, pass `training=True` when calling the layer.",
        "patch": "@@ -15,7 +15,7 @@ class RandomRotation(TFDataLayer):\n \n     By default, random rotations are only applied during training.\n     At inference time, the layer does nothing. If you need to apply random\n-    rotations at inference time, set `training` to True when calling the layer.\n+    rotations at inference time, pass `training=True` when calling the layer.\n \n     Input pixel values can be of any range (e.g. `[0., 1.)` or `[0, 255]`) and\n     of integer or floating point dtype."
    },
    {
        "commit_id": "21341c60853b32648699845902fa254acf1165d6",
        "commit_message": "Fix various docstrings",
        "commit_url": "https://github.com/keras-team/keras/commit/21341c60853b32648699845902fa254acf1165d6",
        "buggy_code": "to False, the compilation is omitted without any",
        "fixed_code": "to `False`, the compilation is omitted without any",
        "patch": "@@ -91,7 +91,7 @@ def load_model_from_hdf5(filepath, custom_objects=None, compile=True):\n         as part of the saved model, the model is already\n         compiled. Otherwise, the model is uncompiled and\n         a warning will be displayed. When `compile` is set\n-        to False, the compilation is omitted without any\n+        to `False`, the compilation is omitted without any\n         warning.\n \n     Raises:"
    },
    {
        "commit_id": "21341c60853b32648699845902fa254acf1165d6",
        "commit_message": "Fix various docstrings",
        "commit_url": "https://github.com/keras-team/keras/commit/21341c60853b32648699845902fa254acf1165d6",
        "buggy_code": "be set to False for multi-class data.",
        "fixed_code": "be set to `False` for multi-class data.",
        "patch": "@@ -1136,7 +1136,7 @@ class AUC(Metric):\n             should be flattened into a single label before AUC computation. In\n             the latter case, when multilabel data is passed to AUC, each\n             label-prediction pair is treated as an individual data point. Should\n-            be set to False for multi-class data.\n+            be set to `False` for multi-class data.\n         num_labels: (Optional) The number of labels, used when `multi_label` is\n             True. If `num_labels` is not specified, then state variables get\n             created on the first call to `update_state`."
    },
    {
        "commit_id": "21341c60853b32648699845902fa254acf1165d6",
        "commit_message": "Fix various docstrings",
        "commit_url": "https://github.com/keras-team/keras/commit/21341c60853b32648699845902fa254acf1165d6",
        "buggy_code": "relative_step: bool, defaults to True. If `learning_rate` is a",
        "fixed_code": "relative_step: bool, defaults to `True`. If `learning_rate` is a",
        "patch": "@@ -29,7 +29,7 @@ class Adafactor(optimizer.Optimizer):\n         clip_threshold: float, defaults to 1.0. Clipping threshold. This is a\n             part of Adafactor algorithm, independent from `clipnorm`,\n             `clipvalue`, and `global_clipnorm`.\n-        relative_step: bool, defaults to True. If `learning_rate` is a\n+        relative_step: bool, defaults to `True`. If `learning_rate` is a\n             constant and `relative_step=True`, learning rate will be adjusted\n             based on current iterations. This is a default learning rate decay\n             in Adafactor."
    },
    {
        "commit_id": "21341c60853b32648699845902fa254acf1165d6",
        "commit_message": "Fix various docstrings",
        "commit_url": "https://github.com/keras-team/keras/commit/21341c60853b32648699845902fa254acf1165d6",
        "buggy_code": "applicable to the Keras v3 model format. Defaults to True.",
        "fixed_code": "applicable to the Keras v3 model format. Defaults to `True`.",
        "patch": "@@ -126,7 +126,7 @@ def load_model(filepath, custom_objects=None, compile=True, safe_mode=True):\n         safe_mode: Boolean, whether to disallow unsafe `lambda` deserialization.\n             When `safe_mode=False`, loading an object has the potential to\n             trigger arbitrary code execution. This argument is only\n-            applicable to the Keras v3 model format. Defaults to True.\n+            applicable to the Keras v3 model format. Defaults to `True`.\n \n     Returns:\n         A Keras model instance. If the original model was compiled,"
    },
    {
        "commit_id": "21341c60853b32648699845902fa254acf1165d6",
        "commit_message": "Fix various docstrings",
        "commit_url": "https://github.com/keras-team/keras/commit/21341c60853b32648699845902fa254acf1165d6",
        "buggy_code": "If set to False, sorts the data in alphanumeric order.",
        "fixed_code": "If set to `False`, sorts the data in alphanumeric order.",
        "patch": "@@ -519,7 +519,7 @@ def index_directory(\n             to control the order of the classes\n             (otherwise alphanumerical order is used).\n         shuffle: Whether to shuffle the data. Defaults to `True`.\n-            If set to False, sorts the data in alphanumeric order.\n+            If set to `False`, sorts the data in alphanumeric order.\n         seed: Optional random seed for shuffling.\n         follow_links: Whether to visits subdirectories pointed to by symlinks.\n         verbose: Whether the function prints number of files found and classes."
    },
    {
        "commit_id": "7d7917c1c8250e43c86ad4f345304e26f91190bb",
        "commit_message": "Add more manual implementations for TF's `einsum` (#19368)\n\n* Add more custom subscripts for tf's `einsum`\r\n\r\n* Add `\"abc,dc->abd\"`\r\n\r\n* Fix tests",
        "commit_url": "https://github.com/keras-team/keras/commit/7d7917c1c8250e43c86ad4f345304e26f91190bb",
        "buggy_code": "ValueError, \"Cannot quantize on a layer that isn't yet built.\"",
        "fixed_code": "ValueError, \"Cannot quantize a layer that isn't yet built.\"",
        "patch": "@@ -372,7 +372,7 @@ def test_quantize_dtype_argument(self):\n     def test_quantize_on_unbuilt_layer(self):\n         layer = layers.Dense(units=2)\n         with self.assertRaisesRegex(\n-            ValueError, \"Cannot quantize on a layer that isn't yet built.\"\n+            ValueError, \"Cannot quantize a layer that isn't yet built.\"\n         ):\n             layer.quantize(\"int8\")\n "
    },
    {
        "commit_id": "7d7917c1c8250e43c86ad4f345304e26f91190bb",
        "commit_message": "Add more manual implementations for TF's `einsum` (#19368)\n\n* Add more custom subscripts for tf's `einsum`\r\n\r\n* Add `\"abc,dc->abd\"`\r\n\r\n* Fix tests",
        "commit_url": "https://github.com/keras-team/keras/commit/7d7917c1c8250e43c86ad4f345304e26f91190bb",
        "buggy_code": "ValueError, \"Cannot quantize on a layer that isn't yet built.\"",
        "fixed_code": "ValueError, \"Cannot quantize a layer that isn't yet built.\"",
        "patch": "@@ -480,7 +480,7 @@ def test_quantize_on_unbuilt_layer(self):\n             bias_axes=\"d\",\n         )\n         with self.assertRaisesRegex(\n-            ValueError, \"Cannot quantize on a layer that isn't yet built.\"\n+            ValueError, \"Cannot quantize a layer that isn't yet built.\"\n         ):\n             layer.quantize(\"int8\")\n "
    },
    {
        "commit_id": "e2b43e2e74dfea55105763484b47a082da13b0e7",
        "commit_message": "Replace `dm-tree` with `optree` (#19306)\n\n* Refactor `keras.utils.tree`\r\n\r\n* Fix tests\r\n\r\n* Replace `dm-tree` with `optree`\r\n\r\n* Eliminate `tf.nest`\r\n\r\n* Resolve comments\r\n\r\n* Fix merge conflicts\r\n\r\n* Update exporting path",
        "commit_url": "https://github.com/keras-team/keras/commit/e2b43e2e74dfea55105763484b47a082da13b0e7",
        "buggy_code": "except TypeError as e:",
        "fixed_code": "except (ValueError, TypeError) as e:",
        "patch": "@@ -261,7 +261,7 @@ def _clone_layer(layer):\n             )\n         try:\n             tree.assert_same_structure(input_tensors, model.input)\n-        except TypeError as e:\n+        except (ValueError, TypeError) as e:\n             raise ValueError(\n                 \"`input_tensors` must have the same structure as model.input\"\n                 f\"\\nReference structure: {model.input}\""
    },
    {
        "commit_id": "e2b43e2e74dfea55105763484b47a082da13b0e7",
        "commit_message": "Replace `dm-tree` with `optree` (#19306)\n\n* Refactor `keras.utils.tree`\r\n\r\n* Fix tests\r\n\r\n* Replace `dm-tree` with `optree`\r\n\r\n* Eliminate `tf.nest`\r\n\r\n* Resolve comments\r\n\r\n* Fix merge conflicts\r\n\r\n* Update exporting path",
        "commit_url": "https://github.com/keras-team/keras/commit/e2b43e2e74dfea55105763484b47a082da13b0e7",
        "buggy_code": "\"dm-tree\",",
        "fixed_code": "\"optree\",",
        "patch": "@@ -44,7 +44,7 @@ def get_version(rel_path):\n         \"rich\",\n         \"namex\",\n         \"h5py\",\n-        \"dm-tree\",\n+        \"optree\",\n         \"ml-dtypes\",\n     ],\n     # Supported Python versions"
    },
    {
        "commit_id": "2cb05218baa92accc151ea47f1a198f75508bb35",
        "commit_message": "Fix minor masking bug.",
        "commit_url": "https://github.com/keras-team/keras/commit/2cb05218baa92accc151ea47f1a198f75508bb35",
        "buggy_code": "elif tree.is_nested(value):",
        "fixed_code": "elif tree.is_nested(value) and len(value) > 0:",
        "patch": "@@ -1429,7 +1429,7 @@ def __init__(self, signature, args, kwargs):\n                 tensor_args.append(value)\n                 tensor_arg_names.append(name)\n                 tensor_arg_dict[name] = value\n-            elif tree.is_nested(value):\n+            elif tree.is_nested(value) and len(value) > 0:\n                 flat_values = tree.flatten(value)\n                 if all(is_backend_tensor_or_symbolic(x) for x in flat_values):\n                     tensor_args.append(value)"
    },
    {
        "commit_id": "4f63678a72a2e7c16c32506189e5428d93d7b945",
        "commit_message": "fix isinstance check for tuple input in pack_x_y_sample_weight (#19269)",
        "commit_url": "https://github.com/keras-team/keras/commit/4f63678a72a2e7c16c32506189e5428d93d7b945",
        "buggy_code": "if not isinstance(x, tuple or list):",
        "fixed_code": "if not isinstance(x, (tuple, list)):",
        "patch": "@@ -100,7 +100,7 @@ def pack_x_y_sample_weight(x, y=None, sample_weight=None):\n         # there is no ambiguity. This also makes NumPy and Dataset\n         # consistent in that the user does not have to wrap their Dataset\n         # data in an unnecessary tuple.\n-        if not isinstance(x, tuple or list):\n+        if not isinstance(x, (tuple, list)):\n             return x\n         else:\n             return (x,)"
    },
    {
        "commit_id": "c21e56e3b8202536b8b46ddb5a2aa391bce1499f",
        "commit_message": "Fix typos in multiple files (#19204)\n\n* Fix multiple typos\r\n\r\n* Update demo_jax_distributed.py\r\n\r\nResolved conflict.",
        "commit_url": "https://github.com/keras-team/keras/commit/c21e56e3b8202536b8b46ddb5a2aa391bce1499f",
        "buggy_code": "- For each batch, we call the model on the input data to retrive the predictions,",
        "fixed_code": "- For each batch, we call the model on the input data to retrieve the predictions,",
        "patch": "@@ -123,7 +123,7 @@ def get_model():\n \n - We open a `for` loop that iterates over epochs\n - For each epoch, we open a `for` loop that iterates over the dataset, in batches\n-- For each batch, we call the model on the input data to retrive the predictions,\n+- For each batch, we call the model on the input data to retrieve the predictions,\n then we use them to compute a loss value\n - We call `loss.backward()` to \n - Outside the scope, we retrieve the gradients of the weights"
    },
    {
        "commit_id": "c21e56e3b8202536b8b46ddb5a2aa391bce1499f",
        "commit_message": "Fix typos in multiple files (#19204)\n\n* Fix multiple typos\r\n\r\n* Update demo_jax_distributed.py\r\n\r\nResolved conflict.",
        "commit_url": "https://github.com/keras-team/keras/commit/c21e56e3b8202536b8b46ddb5a2aa391bce1499f",
        "buggy_code": "training data back to words using this mapping, indices need to substract 3.",
        "fixed_code": "training data back to words using this mapping, indices need to subtract 3.",
        "patch": "@@ -141,7 +141,7 @@ def get_word_index(path=\"reuters_word_index.json\"):\n \n     E.g. word index of 'the' is 1, but the in the actual training data, the\n     index of 'the' will be 1 + 3 = 4. Vice versa, to translate word indices in\n-    training data back to words using this mapping, indices need to substract 3.\n+    training data back to words using this mapping, indices need to subtract 3.\n \n     Args:\n         path: where to cache the data (relative to `~/.keras/dataset`)."
    },
    {
        "commit_id": "c21e56e3b8202536b8b46ddb5a2aa391bce1499f",
        "commit_message": "Fix typos in multiple files (#19204)\n\n* Fix multiple typos\r\n\r\n* Update demo_jax_distributed.py\r\n\r\nResolved conflict.",
        "commit_url": "https://github.com/keras-team/keras/commit/c21e56e3b8202536b8b46ddb5a2aa391bce1499f",
        "buggy_code": "`max_tokens` is set, the vocabulary wil be truncated to `max_tokens`",
        "fixed_code": "`max_tokens` is set, the vocabulary will be truncated to `max_tokens`",
        "patch": "@@ -397,7 +397,7 @@ def adapt(self, data, batch_size=None, steps=None):\n         During `adapt()`, the layer will build a vocabulary of all string tokens\n         seen in the dataset, sorted by occurrence count, with ties broken by\n         sort order of the tokens (high to low). At the end of `adapt()`, if\n-        `max_tokens` is set, the vocabulary wil be truncated to `max_tokens`\n+        `max_tokens` is set, the vocabulary will be truncated to `max_tokens`\n         size. For example, adapting a layer with `max_tokens=1000` will compute\n         the 1000 most frequent tokens occurring in the input dataset. If\n         `output_mode='tf-idf'`, `adapt()` will also learn the document"
    },
    {
        "commit_id": "c21e56e3b8202536b8b46ddb5a2aa391bce1499f",
        "commit_message": "Fix typos in multiple files (#19204)\n\n* Fix multiple typos\r\n\r\n* Update demo_jax_distributed.py\r\n\r\nResolved conflict.",
        "commit_url": "https://github.com/keras-team/keras/commit/c21e56e3b8202536b8b46ddb5a2aa391bce1499f",
        "buggy_code": "\"\"\"Resolves backwards compatiblity issues with training config arguments.",
        "fixed_code": "\"\"\"Resolves backwards compatibility issues with training config arguments.",
        "patch": "@@ -234,7 +234,7 @@ def _find_replace_nested_dict(config, find, replace):\n \n \n def _resolve_compile_arguments_compat(obj, obj_config, module):\n-    \"\"\"Resolves backwards compatiblity issues with training config arguments.\n+    \"\"\"Resolves backwards compatibility issues with training config arguments.\n \n     This helper function accepts built-in Keras modules such as optimizers,\n     losses, and metrics to ensure an object being deserialized is compatible"
    },
    {
        "commit_id": "c21e56e3b8202536b8b46ddb5a2aa391bce1499f",
        "commit_message": "Fix typos in multiple files (#19204)\n\n* Fix multiple typos\r\n\r\n* Update demo_jax_distributed.py\r\n\r\nResolved conflict.",
        "commit_url": "https://github.com/keras-team/keras/commit/c21e56e3b8202536b8b46ddb5a2aa391bce1499f",
        "buggy_code": "f\"Unkown value for `{arg_name}` argument of {caller_name}. \"",
        "fixed_code": "f\"Unknown value for `{arg_name}` argument of {caller_name}. \"",
        "patch": "@@ -86,7 +86,7 @@ def validate_string_arg(\n     elif isinstance(value, str) and value in allowable_strings:\n         return\n     raise ValueError(\n-        f\"Unkown value for `{arg_name}` argument of {caller_name}. \"\n+        f\"Unknown value for `{arg_name}` argument of {caller_name}. \"\n         f\"Allowed values are: {allowable_strings}. Received: \"\n         f\"{arg_name}={value}\"\n     )"
    },
    {
        "commit_id": "c21e56e3b8202536b8b46ddb5a2aa391bce1499f",
        "commit_message": "Fix typos in multiple files (#19204)\n\n* Fix multiple typos\r\n\r\n* Update demo_jax_distributed.py\r\n\r\nResolved conflict.",
        "commit_url": "https://github.com/keras-team/keras/commit/c21e56e3b8202536b8b46ddb5a2aa391bce1499f",
        "buggy_code": "`keras.config.disable_interactie_logging()`.",
        "fixed_code": "`keras.config.disable_interactive_logging()`.",
        "patch": "@@ -49,7 +49,7 @@ def is_interactive_logging_enabled():\n \n     To switch between writing logs to stdout and `absl.logging`, you may use\n     `keras.config.enable_interactive_logging()` and\n-    `keras.config.disable_interactie_logging()`.\n+    `keras.config.disable_interactive_logging()`.\n \n     Returns:\n         Boolean, `True` if interactive logging is enabled,"
    },
    {
        "commit_id": "c21e56e3b8202536b8b46ddb5a2aa391bce1499f",
        "commit_message": "Fix typos in multiple files (#19204)\n\n* Fix multiple typos\r\n\r\n* Update demo_jax_distributed.py\r\n\r\nResolved conflict.",
        "commit_url": "https://github.com/keras-team/keras/commit/c21e56e3b8202536b8b46ddb5a2aa391bce1499f",
        "buggy_code": "sequence_fn: Function used to generate a new strcuture instance.",
        "fixed_code": "sequence_fn: Function used to generate a new structure instance.",
        "patch": "@@ -63,7 +63,7 @@ def packed_nest_with_indices(\n         index: Index at which to start reading from flat.\n         is_nested_fn: Function used to test if a value should\n             be treated as a nested structure.\n-        sequence_fn: Function used to generate a new strcuture instance.\n+        sequence_fn: Function used to generate a new structure instance.\n \n     Returns:\n         The tuple (new_index, child), where:"
    },
    {
        "commit_id": "671546ab769b9e8fe32180202a9057f2742321b2",
        "commit_message": "Fix BackupAndRestore epoch counter restoration.",
        "commit_url": "https://github.com/keras-team/keras/commit/671546ab769b9e8fe32180202a9057f2742321b2",
        "buggy_code": "from keras.callbacks.backup_and_restore_callback import BackupAndRestore",
        "fixed_code": "from keras.callbacks.backup_and_restore import BackupAndRestore",
        "patch": "@@ -1,4 +1,4 @@\n-from keras.callbacks.backup_and_restore_callback import BackupAndRestore\n+from keras.callbacks.backup_and_restore import BackupAndRestore\n from keras.callbacks.callback import Callback\n from keras.callbacks.callback_list import CallbackList\n from keras.callbacks.csv_logger import CSVLogger"
    },
    {
        "commit_id": "2ad117c44c5346691a646512ded3d25a5e3cb322",
        "commit_message": "Add `_untrack_variable` to `Layer` and explicitly define `constraint` and `regularizer` to `KerasVariable` (#19206)\n\n* Add `remove_weight` to `Layer`\r\n\r\n* Explicitly define `constraint` and `regularizer` in `KerasVariable`\r\n\r\n* Add `remove_weight` test\r\n\r\n* Fix test\r\n\r\n* Update `remove_weight`\r\n\r\n* Update error msg and remove `remove_weight`",
        "commit_url": "https://github.com/keras-team/keras/commit/2ad117c44c5346691a646512ded3d25a5e3cb322",
        "buggy_code": "if getattr(variable, \"constraint\", None) is not None:",
        "fixed_code": "if variable.constraint is not None:",
        "patch": "@@ -330,7 +330,7 @@ def apply(self, grads, trainable_variables=None):\n             self._backend_apply_gradients(grads, trainable_variables)\n             # Apply variable constraints after applying gradients.\n             for variable in trainable_variables:\n-                if getattr(variable, \"constraint\", None) is not None:\n+                if variable.constraint is not None:\n                     variable.assign(variable.constraint(variable))\n \n     def _backend_apply_gradients(self, grads, trainable_variables):"
    },
    {
        "commit_id": "fffa00400f1e63008f0e1e08f7538a3fbd22e9ea",
        "commit_message": "Fix some docstrings",
        "commit_url": "https://github.com/keras-team/keras/commit/fffa00400f1e63008f0e1e08f7538a3fbd22e9ea",
        "buggy_code": "\"\"\"Wrap a stateless metric function with the Mean metric.",
        "fixed_code": "\"\"\"Wrap a stateless metric function with the `Mean` metric.",
        "patch": "@@ -156,7 +156,7 @@ def result(self):\n \n @keras_export(\"keras.metrics.MeanMetricWrapper\")\n class MeanMetricWrapper(Mean):\n-    \"\"\"Wrap a stateless metric function with the Mean metric.\n+    \"\"\"Wrap a stateless metric function with the `Mean` metric.\n \n     You could use this class to quickly build a mean metric from a function. The\n     function needs to have the signature `fn(y_true, y_pred)` and return a"
    },
    {
        "commit_id": "22a4ea757b247d9c090e6b30cec41ab5975a73f6",
        "commit_message": "Check raised regex in convolutional tests (#19202)\n\n* Strengthen the tests by checking regex\r\n\r\n* Check regex in conv_transpose tests\r\n\r\n* Check regex in depthwise conv tests\r\n\r\n* Check regex in separable conv tests\r\n\r\n* Reformatting\r\n\r\n* Fix linting\r\n\r\n* Fix formatting",
        "commit_url": "https://github.com/keras-team/keras/commit/22a4ea757b247d9c090e6b30cec41ab5975a73f6",
        "buggy_code": "\"strictly  positive value. Received \"",
        "fixed_code": "\"strictly positive value. Received \"",
        "patch": "@@ -132,7 +132,7 @@ def __init__(\n         if self.depth_multiplier is not None and self.depth_multiplier <= 0:\n             raise ValueError(\n                 \"Invalid value for argument `depth_multiplier`. Expected a \"\n-                \"strictly  positive value. Received \"\n+                \"strictly positive value. Received \"\n                 f\"depth_multiplier={self.depth_multiplier}.\"\n             )\n "
    },
    {
        "commit_id": "22a4ea757b247d9c090e6b30cec41ab5975a73f6",
        "commit_message": "Check raised regex in convolutional tests (#19202)\n\n* Strengthen the tests by checking regex\r\n\r\n* Check regex in conv_transpose tests\r\n\r\n* Check regex in depthwise conv tests\r\n\r\n* Check regex in separable conv tests\r\n\r\n* Reformatting\r\n\r\n* Fix linting\r\n\r\n* Fix formatting",
        "commit_url": "https://github.com/keras-team/keras/commit/22a4ea757b247d9c090e6b30cec41ab5975a73f6",
        "buggy_code": "\"strictly  positive value. Received \"",
        "fixed_code": "\"strictly positive value. Received \"",
        "patch": "@@ -135,7 +135,7 @@ def __init__(\n         if self.depth_multiplier is not None and self.depth_multiplier <= 0:\n             raise ValueError(\n                 \"Invalid value for argument `depth_multiplier`. Expected a \"\n-                \"strictly  positive value. Received \"\n+                \"strictly positive value. Received \"\n                 f\"depth_multiplier={self.depth_multiplier}.\"\n             )\n "
    },
    {
        "commit_id": "06ac1c225a891ed8b23133f0cc72cd6d2493d898",
        "commit_message": "#19168: Fix a typo (#19169)\n\nlenght -> length",
        "commit_url": "https://github.com/keras-team/keras/commit/06ac1c225a891ed8b23133f0cc72cd6d2493d898",
        "buggy_code": "lenght of `out`. Defaults to `None`.",
        "fixed_code": "length of `out`. Defaults to `None`.",
        "patch": "@@ -665,7 +665,7 @@ def arange(start, stop=None, step=1, dtype=None):\n         stop: Integer or real, representing the end of the interval. The\n             interval does not include this value, except in some cases where\n             `step` is not an integer and floating point round-off affects the\n-            lenght of `out`. Defaults to `None`.\n+            length of `out`. Defaults to `None`.\n         step: Integer or real, represent the spacing between values. For any\n             output `out`, this is the distance between two adjacent values,\n             `out[i+1] - out[i]`. The default step size is 1. If `step` is"
    },
    {
        "commit_id": "8d58b790e4deda87240b73d23b5c19e1d24921da",
        "commit_message": "Fix loss reduction for rank 1 vs 2",
        "commit_url": "https://github.com/keras-team/keras/commit/8d58b790e4deda87240b73d23b5c19e1d24921da",
        "buggy_code": "values, sample_weight = losses.loss.squeeze_to_same_rank(",
        "fixed_code": "values, sample_weight = losses.loss.squeeze_or_expand_to_same_rank(",
        "patch": "@@ -17,7 +17,7 @@ def reduce_to_samplewise_values(values, sample_weight, reduce_fn, dtype):\n                 sample_weight, mask, dtype=dtype, reduction=\"sum\"\n             )\n         # Update dimensions of weights to match with values if possible.\n-        values, sample_weight = losses.loss.squeeze_to_same_rank(\n+        values, sample_weight = losses.loss.squeeze_or_expand_to_same_rank(\n             values, sample_weight\n         )\n         # Reduce values to same ndim as weight array"
    },
    {
        "commit_id": "4955cb27b503bb346ac6f685d71bfa1686aa1e3a",
        "commit_message": "fix numerical_test (#19096)",
        "commit_url": "https://github.com/keras-team/keras/commit/4955cb27b503bb346ac6f685d71bfa1686aa1e3a",
        "buggy_code": "from tensorflow import keras as tf_keras",
        "fixed_code": "import tf_keras",
        "patch": "@@ -1,7 +1,7 @@\n import keras  # isort: skip, keep it on top for torch test\n \n import numpy as np\n-from tensorflow import keras as tf_keras\n+import tf_keras\n \n NUM_CLASSES = 10\n "
    },
    {
        "commit_id": "f97e3c7963c3c82e6a8bcea49e20ad6063054ed7",
        "commit_message": "Fix CI",
        "commit_url": "https://github.com/keras-team/keras/commit/f97e3c7963c3c82e6a8bcea49e20ad6063054ed7",
        "buggy_code": "np.testing.assert_allclose(output, expected_output, atol=1e-6)",
        "fixed_code": "self.assertAllClose(output, expected_output, atol=1e-6)",
        "patch": "@@ -1099,7 +1099,7 @@ def test_solve_call(self):\n         b = np.array([[9, 8], [5, 4]], dtype=np.float32)\n         output = solve_op.call(a, b)\n         expected_output = np.linalg.solve(a, b)\n-        np.testing.assert_allclose(output, expected_output, atol=1e-6)\n+        self.assertAllClose(output, expected_output, atol=1e-6)\n \n \n class FFT2Test(testing.TestCase):"
    },
    {
        "commit_id": "4993d49fd683d46e441e1847ebe5a31c3281d56b",
        "commit_message": "Implement a new unit test and correct some typos. (#19029)\n\n* test: implement sparse inputs unit test for Discretization layer\r\n\r\nCo-authored-by: AlvaroMaza <alvaromazamontesinos@gmail.com>\r\n\r\n* chore: correct spelling errors in some unit tests\r\n\r\nCo-authored-by: AlvaroMaza <alvaromazamontesinos@gmail.com>\r\n\r\n* fix: correct the implementation of the 'sparse' argument in Discretization.\r\n\r\n* fix `self.sparse` not working.\r\n* set `test_sparse_inputs` to `test_sparse_output`\r\n\r\nCo-authored-by: AlvaroMaza <alvaromazamontesinos@gmail.com>\r\n\r\n---------\r\n\r\nCo-authored-by: AlvaroMaza <alvaromazamontesinos@gmail.com>",
        "commit_url": "https://github.com/keras-team/keras/commit/4993d49fd683d46e441e1847ebe5a31c3281d56b",
        "buggy_code": "backend.backend() != \"tf\",",
        "fixed_code": "backend.backend() != \"tensorflow\",",
        "patch": "@@ -238,7 +238,7 @@ def test_variable_numpy(self):\n         self.assertAllClose(v.numpy(), np.array([1, 2, 3]))\n \n     @pytest.mark.skipif(\n-        backend.backend() != \"tf\",\n+        backend.backend() != \"tensorflow\",\n         reason=\"Tests for MirroredVariable under tf backend\",\n     )\n     def test_variable_numpy_scalar(self):"
    },
    {
        "commit_id": "fe2f54aa5bc42fb23a96449cf90434ab9bb6a2cd",
        "commit_message": "Correct the Error description in cropping layer APIs (#18974)\n\n* Correct the Error description in cropping APIs\r\n\r\n* Fix failing cropping test cases",
        "commit_url": "https://github.com/keras-team/keras/commit/fe2f54aa5bc42fb23a96449cf90434ab9bb6a2cd",
        "buggy_code": "\"Values in `cropping` argument should be greater than the \"",
        "fixed_code": "\"Values in `cropping` argument should be smaller than the \"",
        "patch": "@@ -126,7 +126,7 @@ def test_cropping_2d_error_on_excessive_cropping(\n \n         with self.assertRaisesRegex(\n             ValueError,\n-            \"Values in `cropping` argument should be greater than the \"\n+            \"Values in `cropping` argument should be smaller than the \"\n             \"corresponding spatial dimension of the input.\",\n         ):\n             layer = layers.Cropping2D("
    },
    {
        "commit_id": "fe2f54aa5bc42fb23a96449cf90434ab9bb6a2cd",
        "commit_message": "Correct the Error description in cropping layer APIs (#18974)\n\n* Correct the Error description in cropping APIs\r\n\r\n* Fix failing cropping test cases",
        "commit_url": "https://github.com/keras-team/keras/commit/fe2f54aa5bc42fb23a96449cf90434ab9bb6a2cd",
        "buggy_code": "\"Values in `cropping` argument should be greater than the\"",
        "fixed_code": "\"Values in `cropping` argument should be smaller than the\"",
        "patch": "@@ -190,7 +190,7 @@ def test_cropping_3d_with_excessive_cropping(self, cropping, data_format):\n             input_layer = layers.Input(batch_shape=shape)\n \n         expected_error_msg = (\n-            \"Values in `cropping` argument should be greater than the\"\n+            \"Values in `cropping` argument should be smaller than the\"\n         )\n \n         with self.assertRaisesRegex(ValueError, expected_error_msg):"
    },
    {
        "commit_id": "598d50567ac6b74fc05843d9ad24bfb2f89075da",
        "commit_message": "Fix CI",
        "commit_url": "https://github.com/keras-team/keras/commit/598d50567ac6b74fc05843d9ad24bfb2f89075da",
        "buggy_code": "model.compile(loss=\"mse\", optimizer=optimizer, run_eagerly=True)",
        "fixed_code": "model.compile(loss=\"mse\", optimizer=optimizer)",
        "patch": "@@ -59,7 +59,7 @@ def test_ema_with_model_fit(self):\n         model = models.Sequential(\n             [layers.Dense(2, kernel_initializer=\"ones\", use_bias=False)]\n         )\n-        model.compile(loss=\"mse\", optimizer=optimizer, run_eagerly=True)\n+        model.compile(loss=\"mse\", optimizer=optimizer)\n         model.fit(x_train, y_train, batch_size=1, epochs=2)\n         self.assertAllClose(\n             optimizer._model_variables_moving_average[0].numpy(),"
    },
    {
        "commit_id": "2fbc05db85513395637fadf21210cb8f199182fd",
        "commit_message": "Add a CTC loss class / function (#18967)\n\n* Draft of CTC loss object\r\n\r\n* Finalize CTC loss.\r\n\r\n* Skip np backend\r\n\r\n* Fix code format",
        "commit_url": "https://github.com/keras-team/keras/commit/2fbc05db85513395637fadf21210cb8f199182fd",
        "buggy_code": "target = target.transpose((1, 0))",
        "fixed_code": "target = target.transpose((1, 0)).astype(\"int32\")",
        "patch": "@@ -571,7 +571,7 @@ def ctc_loss(\n     batch_size, max_target_length = target.shape\n \n     output = output.transpose((1, 0, 2))\n-    target = target.transpose((1, 0))\n+    target = target.transpose((1, 0)).astype(\"int32\")\n \n     logits = jnn.log_softmax(output)\n     mgrid_t, mgrid_b = jnp.meshgrid("
    },
    {
        "commit_id": "7972fcac7941de5b71b47a7209241b9682aa03f1",
        "commit_message": "Increase testing tolerance for Conv3d (#18966)\n\n* Increase testing tolerance for Conv3d\r\n\r\nTesting triggered the following:\r\n```\r\nE           Mismatched elements: 1 / 3430 (0.0292%)\r\nE           Max absolute difference: 2.80041689e-06\r\nE           Max relative difference: 0.00729655\r\nE            x: array([[[[[-5.931517e+00,  3.115599e+00,  4.244155e+00,  3.652722e+00,\r\nE                       5.676696e+00],\r\nE                     [-1.901496e+00, -2.906749e+00, -9.651406e+00,  2.638115e+00,...\r\nE            y: array([[[[[-5.931517e+00,  3.115600e+00,  4.244155e+00,  3.652721e+00,\r\nE                       5.676696e+00],\r\nE                     [-1.901495e+00, -2.906749e+00, -9.651406e+00,  2.638115e+00,...```\r\n\r\nIncreasing tolerance to match since it looks like this stems from numerical inaccuracy instead of a backend bug.\r\n\r\n* Change tolerance to 1e-3",
        "commit_url": "https://github.com/keras-team/keras/commit/7972fcac7941de5b71b47a7209241b9682aa03f1",
        "buggy_code": "self.assertAllClose(outputs, expected, rtol=5e-4)",
        "fixed_code": "self.assertAllClose(outputs, expected, rtol=1e-3)",
        "patch": "@@ -783,7 +783,7 @@ def test_conv3d(\n             dilation_rate=dilation_rate,\n             groups=groups,\n         )\n-        self.assertAllClose(outputs, expected, rtol=5e-4)\n+        self.assertAllClose(outputs, expected, rtol=1e-3)\n \n     def test_conv_constraints(self):\n         layer = layers.Conv2D("
    },
    {
        "commit_id": "e45c1382c85c8b53676fcb40fc270c839e1690d8",
        "commit_message": "Minor typo fix (#18963)",
        "commit_url": "https://github.com/keras-team/keras/commit/e45c1382c85c8b53676fcb40fc270c839e1690d8",
        "buggy_code": "f\"Expected on of {allowed}. Received: \"",
        "fixed_code": "f\"Expected one of {allowed}. Received: \"",
        "patch": "@@ -76,7 +76,7 @@ def standardize_reduction(reduction):\n     if reduction not in allowed:\n         raise ValueError(\n             \"Invalid value for argument `reduction`. \"\n-            f\"Expected on of {allowed}. Received: \"\n+            f\"Expected one of {allowed}. Received: \"\n             f\"reduction={reduction}\"\n         )\n     return reduction"
    },
    {
        "commit_id": "e18d450d9f1510c4bb05c558e86d4104e12c7ac2",
        "commit_message": "Fix code style.",
        "commit_url": "https://github.com/keras-team/keras/commit/e18d450d9f1510c4bb05c558e86d4104e12c7ac2",
        "buggy_code": "if (include_top == False) and (input_shape == None):",
        "fixed_code": "if not include_top and input_shape is None:",
        "patch": "@@ -384,7 +384,7 @@ def NASNetMobile(\n             \"at this time due to an outstanding bug. \"\n             \"If interested, please open a PR.\"\n         )\n-    if (include_top == False) and (input_shape == None):\n+    if not include_top and input_shape is None:\n         input_shape = (224, 224, 3)\n     return NASNet(\n         input_shape,"
    },
    {
        "commit_id": "7d431cea42d13f189473f6c0d2d33eaa5228c40f",
        "commit_message": "Fix descrepancies in Conv Module docstrings regarding data_format (#18928)",
        "commit_url": "https://github.com/keras-team/keras/commit/7d431cea42d13f189473f6c0d2d33eaa5228c40f",
        "buggy_code": "`(batch_size, channels, height, width)`",
        "fixed_code": "`(batch_size, height, width, channels)`",
        "patch": "@@ -27,7 +27,7 @@ class Conv2D(BaseConv):\n         data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n             The ordering of the dimensions in the inputs. `\"channels_last\"`\n             corresponds to inputs with shape\n-            `(batch_size, channels, height, width)`\n+            `(batch_size, height, width, channels)`\n             while `\"channels_first\"` corresponds to inputs with shape\n             `(batch_size, channels, height, width)`. It defaults to the\n             `image_data_format` value found in your Keras config file at"
    },
    {
        "commit_id": "7d431cea42d13f189473f6c0d2d33eaa5228c40f",
        "commit_message": "Fix descrepancies in Conv Module docstrings regarding data_format (#18928)",
        "commit_url": "https://github.com/keras-team/keras/commit/7d431cea42d13f189473f6c0d2d33eaa5228c40f",
        "buggy_code": "`(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`.",
        "fixed_code": "`(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.",
        "patch": "@@ -29,7 +29,7 @@ class Conv3D(BaseConv):\n             corresponds to inputs with shape\n             `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n             while `\"channels_first\"` corresponds to inputs with shape\n-            `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`.\n+            `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n             It defaults to the `image_data_format` value found in your Keras\n             config file at `~/.keras/keras.json`. If you never set it, then it\n             will be `\"channels_last\"`."
    },
    {
        "commit_id": "7d431cea42d13f189473f6c0d2d33eaa5228c40f",
        "commit_message": "Fix descrepancies in Conv Module docstrings regarding data_format (#18928)",
        "commit_url": "https://github.com/keras-team/keras/commit/7d431cea42d13f189473f6c0d2d33eaa5228c40f",
        "buggy_code": "`(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`.",
        "fixed_code": "`(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.",
        "patch": "@@ -34,7 +34,7 @@ class Conv3DTranspose(BaseConvTranspose):\n             corresponds to inputs with shape\n             `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n             while `\"channels_first\"` corresponds to inputs with shape\n-            `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`.\n+            `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n             It defaults to the `image_data_format` value found in your Keras\n             config file at `~/.keras/keras.json`. If you never set it, then it\n             will be `\"channels_last\"`."
    },
    {
        "commit_id": "ffc449c250958d55bbfc5fec293e4d3c6c716200",
        "commit_message": "Fix the doc bug in channels_last shape in conv2d_transpose.py (#18911)\n\nFixed the doc bug in channels_last shape description from\r\n\r\n`(batch_size, channels, height, width)` \r\nto \r\n`(batch_size, height, width, channels)`\r\n\r\nto avoid confusion among users.",
        "commit_url": "https://github.com/keras-team/keras/commit/ffc449c250958d55bbfc5fec293e4d3c6c716200",
        "buggy_code": "`(batch_size, channels, height, width)`",
        "fixed_code": "`(batch_size, height, width, channels)`",
        "patch": "@@ -32,7 +32,7 @@ class Conv2DTranspose(BaseConvTranspose):\n         data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n             The ordering of the dimensions in the inputs. `\"channels_last\"`\n             corresponds to inputs with shape\n-            `(batch_size, channels, height, width)`\n+            `(batch_size, height, width, channels)`\n             while `\"channels_first\"` corresponds to inputs with shape\n             `(batch_size, channels, height, width)`. It defaults to the\n             `image_data_format` value found in your Keras config file at"
    },
    {
        "commit_id": "037ec9f5fc61a53c6e1f4c02b7bf1443429dcd45",
        "commit_message": "Fix code format.",
        "commit_url": "https://github.com/keras-team/keras/commit/037ec9f5fc61a53c6e1f4c02b7bf1443429dcd45",
        "buggy_code": "min_lr=0.,",
        "fixed_code": "min_lr=0.0,",
        "patch": "@@ -54,7 +54,7 @@ def __init__(\n         mode=\"auto\",\n         min_delta=1e-4,\n         cooldown=0,\n-        min_lr=0.,\n+        min_lr=0.0,\n         **kwargs,\n     ):\n         super().__init__()"
    },
    {
        "commit_id": "037ec9f5fc61a53c6e1f4c02b7bf1443429dcd45",
        "commit_message": "Fix code format.",
        "commit_url": "https://github.com/keras-team/keras/commit/037ec9f5fc61a53c6e1f4c02b7bf1443429dcd45",
        "buggy_code": "directory, validation_split=0., subset=\"training\"",
        "fixed_code": "directory, validation_split=0.0, subset=\"training\"",
        "patch": "@@ -412,7 +412,7 @@ def test_audio_dataset_from_directory_errors(self):\n             ValueError, \"`validation_split` must be set\"\n         ):\n             _ = audio_dataset_utils.audio_dataset_from_directory(\n-                directory, validation_split=0., subset=\"training\"\n+                directory, validation_split=0.0, subset=\"training\"\n             )\n \n         with self.assertRaisesRegex(ValueError, \"must provide a `seed`\"):"
    },
    {
        "commit_id": "037ec9f5fc61a53c6e1f4c02b7bf1443429dcd45",
        "commit_message": "Fix code format.",
        "commit_url": "https://github.com/keras-team/keras/commit/037ec9f5fc61a53c6e1f4c02b7bf1443429dcd45",
        "buggy_code": "directory, validation_split=0., subset=\"training\"",
        "fixed_code": "directory, validation_split=0.0, subset=\"training\"",
        "patch": "@@ -438,7 +438,7 @@ def test_image_dataset_from_directory_errors(self):\n             ValueError, \"`validation_split` must be set\"\n         ):\n             _ = image_dataset_utils.image_dataset_from_directory(\n-                directory, validation_split=0., subset=\"training\"\n+                directory, validation_split=0.0, subset=\"training\"\n             )\n \n         with self.assertRaisesRegex(ValueError, \"must provide a `seed`\"):"
    },
    {
        "commit_id": "037ec9f5fc61a53c6e1f4c02b7bf1443429dcd45",
        "commit_message": "Fix code format.",
        "commit_url": "https://github.com/keras-team/keras/commit/037ec9f5fc61a53c6e1f4c02b7bf1443429dcd45",
        "buggy_code": "directory, validation_split=0., subset=\"training\"",
        "fixed_code": "directory, validation_split=0.0, subset=\"training\"",
        "patch": "@@ -280,7 +280,7 @@ def test_text_dataset_from_directory_errors(self):\n             ValueError, \"`validation_split` must be set\"\n         ):\n             _ = text_dataset_utils.text_dataset_from_directory(\n-                directory, validation_split=0., subset=\"training\"\n+                directory, validation_split=0.0, subset=\"training\"\n             )\n \n         with self.assertRaisesRegex(ValueError, \"must provide a `seed`\"):"
    },
    {
        "commit_id": "f0b7062e4c6a62c521af491b09d97f009b1add0b",
        "commit_message": "Add `hard_swish` to `ops.nn` and dtype tests for `hard_swish` and `hard_sigmoid` (#18860)\n\n* Add hard swish to nn, add tests for dtype inference\r\n\r\n* Add comments to numpy's hard_sigmoid\r\n\r\n* Fix np behavior issue",
        "commit_url": "https://github.com/keras-team/keras/commit/f0b7062e4c6a62c521af491b09d97f009b1add0b",
        "buggy_code": "return x * ops.relu6(x + 3.0) * (1.0 / 6.0)",
        "fixed_code": "return ops.hard_swish(x)",
        "patch": "@@ -394,7 +394,7 @@ def hard_swish(x):\n     - [A Howard, 2019](https://arxiv.org/abs/1905.02244)\n     \"\"\"\n     x = backend.convert_to_tensor(x)\n-    return x * ops.relu6(x + 3.0) * (1.0 / 6.0)\n+    return ops.hard_swish(x)\n \n \n @keras_export(\"keras.activations.linear\")"
    },
    {
        "commit_id": "724321c7b39a90f6125b79931284aa9932c673a0",
        "commit_message": "Add hardswish (#18852)\n\n* Add `HardSwish` activation\r\n\r\n* Update hard_swish\r\n\r\n* Add `HardSwish` to __init__\r\n\r\n* Replace custom ops with new `HardSwish` in MobileNetV3\r\n\r\n* Try to fix github runner issue\r\n\r\n* Remove HardSwish from `./layers`\r\n\r\n* Fix application_test when using cpu with tensorflow backend\r\n\r\n* Fix mobilenetv3 activation\r\n\r\n* Fix torch tests with `channels_first`",
        "commit_url": "https://github.com/keras-team/keras/commit/724321c7b39a90f6125b79931284aa9932c673a0",
        "buggy_code": "return layers.Multiply()([x, hard_sigmoid(x)])",
        "fixed_code": "return layers.Activation(\"hard_swish\")(x)",
        "patch": "@@ -540,7 +540,7 @@ def hard_sigmoid(x):\n \n \n def hard_swish(x):\n-    return layers.Multiply()([x, hard_sigmoid(x)])\n+    return layers.Activation(\"hard_swish\")(x)\n \n \n # This function is taken from the original tf repo."
    },
    {
        "commit_id": "09b9511e734d3cfd6b382ff43f58a6f8e020966b",
        "commit_message": "Fix error msg test",
        "commit_url": "https://github.com/keras-team/keras/commit/09b9511e734d3cfd6b382ff43f58a6f8e020966b",
        "buggy_code": "with self.assertRaisesRegex(ValueError, \"Received: device='123'\"):",
        "fixed_code": "with self.assertRaisesRegex(ValueError, \"Received: device_name='123'\"):",
        "patch": "@@ -56,7 +56,7 @@ def test_jax_device_scope(self):\n \n     @pytest.mark.skipif(backend.backend() != \"jax\", reason=\"jax only\")\n     def test_invalid_jax_device(self):\n-        with self.assertRaisesRegex(ValueError, \"Received: device='123'\"):\n+        with self.assertRaisesRegex(ValueError, \"Received: device_name='123'\"):\n             backend.device_scope(123).__enter__()\n \n     @pytest.mark.skipif(backend.backend() != \"torch\", reason=\"torch only\")"
    },
    {
        "commit_id": "1ebe1d052e27166ebcd4fe8ffaa6fb7637c97d8f",
        "commit_message": "Add keras.backend.device() API for device scope (#18837)\n\n* Add keras.backend.device() API for device scope\r\n\r\n* Address some review comments.\r\n\r\n* Fix nit.\r\n\r\n* Fix unit test.\r\n\r\n* Fix unit test\r\n\r\n* Fix unit test",
        "commit_url": "https://github.com/keras-team/keras/commit/1ebe1d052e27166ebcd4fe8ffaa6fb7637c97d8f",
        "buggy_code": "with core.device_scope(\"meta\"):",
        "fixed_code": "with core.device(\"meta\"):",
        "patch": "@@ -105,5 +105,5 @@ def test_call_on_meta_device_after_built(self):\n         layer = layers.Normalization()\n         data = np.random.random((32, 4))\n         layer.adapt(data)\n-        with core.device_scope(\"meta\"):\n+        with core.device(\"meta\"):\n             layer(data)"
    },
    {
        "commit_id": "ee2252e1ac5ba6c3cb0a1d5e31e2a86a806363dc",
        "commit_message": "Fix list_device logic (#18800)",
        "commit_url": "https://github.com/keras-team/keras/commit/ee2252e1ac5ba6c3cb0a1d5e31e2a86a806363dc",
        "buggy_code": "return [f\"{device.device_kind}:{device.id}\" for device in jax_devices]",
        "fixed_code": "return [f\"{device.platform}:{device.id}\" for device in jax_devices]",
        "patch": "@@ -26,7 +26,7 @@ def list_devices(device_type=None):\n     \"\"\"\n     device_type = device_type.lower() if device_type else None\n     jax_devices = jax.devices(backend=device_type)\n-    return [f\"{device.device_kind}:{device.id}\" for device in jax_devices]\n+    return [f\"{device.platform}:{device.id}\" for device in jax_devices]\n \n \n def distribute_variable(value, layout):"
    },
    {
        "commit_id": "c6d1f8da7e8d627d9a38b37b04e1f2581a9a8b8c",
        "commit_message": "Fix example",
        "commit_url": "https://github.com/keras-team/keras/commit/c6d1f8da7e8d627d9a38b37b04e1f2581a9a8b8c",
        "buggy_code": "keras.optimizers.schedules.learning_rate_schedule.LearningRateSchedule",
        "fixed_code": "keras.optimizers.schedules.LearningRateSchedule",
        "patch": "@@ -572,7 +572,7 @@ def metrics(self):\n \n # Learning Rate Scheduler for the optimizer\n class LRSchedule(\n-    keras.optimizers.schedules.learning_rate_schedule.LearningRateSchedule\n+    keras.optimizers.schedules.LearningRateSchedule\n ):\n     def __init__(self, post_warmup_learning_rate, warmup_steps):\n         super().__init__()"
    },
    {
        "commit_id": "f0a34582967d73668c4a436fc1296df44222edca",
        "commit_message": "Fix example",
        "commit_url": "https://github.com/keras-team/keras/commit/f0a34582967d73668c4a436fc1296df44222edca",
        "buggy_code": "keras.utils.seed_random_seed(111)",
        "fixed_code": "keras.utils.set_random_seed(111)",
        "patch": "@@ -24,7 +24,7 @@\n from keras.applications import efficientnet\n from keras.layers import TextVectorization\n \n-keras.utils.seed_random_seed(111)\n+keras.utils.set_random_seed(111)\n \n \"\"\"\n ## Download the dataset"
    },
    {
        "commit_id": "00aad90ff20ecebefda0c5ec7db7e1470431c34d",
        "commit_message": "Fix reference variable name in TF",
        "commit_url": "https://github.com/keras-team/keras/commit/00aad90ff20ecebefda0c5ec7db7e1470431c34d",
        "buggy_code": "name = reference_variable.name + \"_\" + name",
        "fixed_code": "name = str(reference_variable.name).replace(\":\", \"_\") + \"_\" + name",
        "patch": "@@ -180,7 +180,7 @@ def add_variable_from_reference(self, reference_variable, name=None):\n         if hasattr(reference_variable, \"path\"):\n             name = reference_variable.path.replace(\"/\", \"_\") + \"_\" + name\n         else:\n-            name = reference_variable.name + \"_\" + name\n+            name = str(reference_variable.name).replace(\":\", \"_\") + \"_\" + name\n         return self.add_variable(\n             shape=reference_variable.shape,\n             initializer=initializer,"
    },
    {
        "commit_id": "cea017b22558f5b00f9f02bb39b9ce0eb13bd0dd",
        "commit_message": "Minor docstring fixes (#18790)\n\n* remove extra ` in some ops docstrings\r\n\r\n- keras.ops.average_pool\r\n- keras.ops.depthwise_conv\r\n- keras.ops.separable_conv\r\n- keras.ops.conv_transpose\r\n\r\n* fix wrong arg name in ops.scatter docstring\r\n\r\n* fix indentation in RecallAtPrecision\r\n\r\n* consistent docstring formatting",
        "commit_url": "https://github.com/keras-team/keras/commit/cea017b22558f5b00f9f02bb39b9ce0eb13bd0dd",
        "buggy_code": "x : Input tensor.",
        "fixed_code": "x: Input tensor.",
        "patch": "@@ -152,7 +152,7 @@ def softmax(x, axis=-1):\n     The input values in are the log-odds of the resulting probability.\n \n     Args:\n-        x : Input tensor.\n+        x: Input tensor.\n         axis: Integer, axis along which the softmax is applied.\n     \"\"\"\n     output = ops.softmax(x, axis=axis)"
    },
    {
        "commit_id": "cea017b22558f5b00f9f02bb39b9ce0eb13bd0dd",
        "commit_message": "Minor docstring fixes (#18790)\n\n* remove extra ` in some ops docstrings\r\n\r\n- keras.ops.average_pool\r\n- keras.ops.depthwise_conv\r\n- keras.ops.separable_conv\r\n- keras.ops.conv_transpose\r\n\r\n* fix wrong arg name in ops.scatter docstring\r\n\r\n* fix indentation in RecallAtPrecision\r\n\r\n* consistent docstring formatting",
        "commit_url": "https://github.com/keras-team/keras/commit/cea017b22558f5b00f9f02bb39b9ce0eb13bd0dd",
        "buggy_code": "attention_mask : A boolean mask of shape",
        "fixed_code": "attention_mask: A boolean mask of shape",
        "patch": "@@ -52,7 +52,7 @@ class GroupedQueryAttention(Layer):\n         key: Optional key tensor of shape\n             `(batch_dim, source_seq_len, feature_dim)`. If not given, will use\n             `value` for both `key` and `value`, which is most common case.\n-        attention_mask : A boolean mask of shape\n+        attention_mask: A boolean mask of shape\n             `(batch_dim, target_seq_len, source_seq_len)`, that prevents\n             attention to certain positions. The boolean mask specifies which\n             query elements can attend to which key elements, where 1 indicates"
    },
    {
        "commit_id": "cea017b22558f5b00f9f02bb39b9ce0eb13bd0dd",
        "commit_message": "Minor docstring fixes (#18790)\n\n* remove extra ` in some ops docstrings\r\n\r\n- keras.ops.average_pool\r\n- keras.ops.depthwise_conv\r\n- keras.ops.separable_conv\r\n- keras.ops.conv_transpose\r\n\r\n* fix wrong arg name in ops.scatter docstring\r\n\r\n* fix indentation in RecallAtPrecision\r\n\r\n* consistent docstring formatting",
        "commit_url": "https://github.com/keras-team/keras/commit/cea017b22558f5b00f9f02bb39b9ce0eb13bd0dd",
        "buggy_code": "updates: A tensor, the values to be set at `indices`.",
        "fixed_code": "values: A tensor, the values to be set at `indices`.",
        "patch": "@@ -46,7 +46,7 @@ def scatter(indices, values, shape):\n     Args:\n         indices: A tensor or list/tuple specifying\n             indices for the values in `values`.\n-        updates: A tensor, the values to be set at `indices`.\n+        values: A tensor, the values to be set at `indices`.\n         shape: Shape of the output tensor.\n \n     Example:"
    },
    {
        "commit_id": "862a9419009ca0410e9d48e64b0034bd7a40019f",
        "commit_message": "Fix example",
        "commit_url": "https://github.com/keras-team/keras/commit/862a9419009ca0410e9d48e64b0034bd7a40019f",
        "buggy_code": "- [Very Deep Self-Attention Networks for End-to-End Speech Recognition](https://arxiv.org/pdf/1904.13377.pdf)",
        "fixed_code": "- [Very Deep Self-Attention Networks for End-to-End Speech Recognition](https://arxiv.org/abs/1904.13377)",
        "patch": "@@ -24,7 +24,7 @@\n **References:**\n \n - [Attention is All You Need](https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)\n-- [Very Deep Self-Attention Networks for End-to-End Speech Recognition](https://arxiv.org/pdf/1904.13377.pdf)\n+- [Very Deep Self-Attention Networks for End-to-End Speech Recognition](https://arxiv.org/abs/1904.13377)\n - [Speech Transformers](https://ieeexplore.ieee.org/document/8462506)\n - [LJSpeech Dataset](https://keithito.com/LJ-Speech-Dataset/)\n \"\"\""
    },
    {
        "commit_id": "f1b5858e7246f6eba035c122590ee34847feabff",
        "commit_message": "Fix pointnet LR",
        "commit_url": "https://github.com/keras-team/keras/commit/f1b5858e7246f6eba035c122590ee34847feabff",
        "buggy_code": "initial_learning_rate=0.003, decay_steps=total_training_steps * 5, decay_rate=0.5, staircase=True",
        "fixed_code": "initial_learning_rate=0.003, decay_steps=training_step_size * 5, decay_rate=0.5, staircase=True",
        "patch": "@@ -506,7 +506,7 @@ def get_shape_segmentation_model(num_points, num_classes):\n print(f\"Total training steps: {total_training_steps}.\")\n \n lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n-    initial_learning_rate=0.003, decay_steps=total_training_steps * 5, decay_rate=0.5, staircase=True\n+    initial_learning_rate=0.003, decay_steps=training_step_size * 5, decay_rate=0.5, staircase=True\n )\n \n steps = range(total_training_steps)"
    },
    {
        "commit_id": "0996b9260ec988f204ef7cbfee5365c3f5580a02",
        "commit_message": "Fix example bug",
        "commit_url": "https://github.com/keras-team/keras/commit/0996b9260ec988f204ef7cbfee5365c3f5580a02",
        "buggy_code": "model = EfficientNetB0(include_top=False, input_tensor=x, weights=\"imagenet\")",
        "fixed_code": "model = EfficientNetB0(include_top=False, input_tensor=inputs, weights=\"imagenet\")",
        "patch": "@@ -321,7 +321,7 @@ def plot_hist(hist):\n \n def build_model(num_classes):\n     inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n-    model = EfficientNetB0(include_top=False, input_tensor=x, weights=\"imagenet\")\n+    model = EfficientNetB0(include_top=False, input_tensor=inputs, weights=\"imagenet\")\n \n     # Freeze the pretrained weights\n     model.trainable = False"
    },
    {
        "commit_id": "bb1fea72b19e33f9c7760bdf268d44cec8e60ac9",
        "commit_message": "Apply `backend.result_type` to `array` and `convert_to_tensor` (#18752)\n\n* Apply `backend.result_type` to `array` and `convert_to_tensor`\r\n\r\n* Fix precision bug in `CosineDecayRestarts`\r\n\r\n* Fix torch's `convert_to_tensor` when dtype is `None` and input is a python number\r\n\r\n* Fix tests for `tf.convert_to_tensor`",
        "commit_url": "https://github.com/keras-team/keras/commit/bb1fea72b19e33f9c7760bdf268d44cec8e60ac9",
        "buggy_code": "return np.array(x, dtype=dtype)",
        "fixed_code": "return convert_to_tensor(x, dtype=dtype)",
        "patch": "@@ -200,7 +200,7 @@ def argsort(x, axis=-1):\n \n \n def array(x, dtype=None):\n-    return np.array(x, dtype=dtype)\n+    return convert_to_tensor(x, dtype=dtype)\n \n \n def average(x, axis=None, weights=None):"
    },
    {
        "commit_id": "bb1fea72b19e33f9c7760bdf268d44cec8e60ac9",
        "commit_message": "Apply `backend.result_type` to `array` and `convert_to_tensor` (#18752)\n\n* Apply `backend.result_type` to `array` and `convert_to_tensor`\r\n\r\n* Fix precision bug in `CosineDecayRestarts`\r\n\r\n* Fix torch's `convert_to_tensor` when dtype is `None` and input is a python number\r\n\r\n* Fix tests for `tf.convert_to_tensor`",
        "commit_url": "https://github.com/keras-team/keras/commit/bb1fea72b19e33f9c7760bdf268d44cec8e60ac9",
        "buggy_code": "return tfnp.array(x, dtype=dtype)",
        "fixed_code": "return convert_to_tensor(x, dtype=dtype)",
        "patch": "@@ -441,7 +441,7 @@ def argsort(x, axis=-1):\n \n \n def array(x, dtype=None):\n-    return tfnp.array(x, dtype=dtype)\n+    return convert_to_tensor(x, dtype=dtype)\n \n \n def average(x, axis=None, weights=None):"
    },
    {
        "commit_id": "8393193076558d5f1476a0d2fe7bc6709a3df9a5",
        "commit_message": "Minor example fix",
        "commit_url": "https://github.com/keras-team/keras/commit/8393193076558d5f1476a0d2fe7bc6709a3df9a5",
        "buggy_code": "score = float(predictions[0])",
        "fixed_code": "score = float(keras.ops.sigmoid(predictions[0]))",
        "patch": "@@ -319,5 +319,5 @@ def make_model(input_shape, num_classes):\n img_array = keras.ops.expand_dims(img_array, 0)  # Create batch axis\n \n predictions = model.predict(img_array)\n-score = float(predictions[0])\n+score = float(keras.ops.sigmoid(predictions[0]))\n print(f\"This image is {100 * (1 - score):.2f}% cat and {100 * score:.2f}% dog.\")"
    },
    {
        "commit_id": "4daefc71016cd24ed9887a014dd5040331258135",
        "commit_message": "Add support for Tensorflow SparseTensors: end to end flow. (#18745)\n\nTraining, evaluation and inference now support sparse tensors end to end.\r\n\r\n- Fixed an issue in graph mode with IndexedSlices.\r\n- Added support for sparse tensors in the input conversion logic.\r\n- Added end to end tests",
        "commit_url": "https://github.com/keras-team/keras/commit/4daefc71016cd24ed9887a014dd5040331258135",
        "buggy_code": "[tf.zeros((1,) + x1.dense_shape[1:], values.dtype), values], axis=0",
        "fixed_code": "[tf.zeros((1,) + values.shape[1:], values.dtype), values], axis=0",
        "patch": "@@ -109,7 +109,7 @@ def values_for_union(indices_expanded, indices_count, values):\n         )\n         to_union_indices = tf.gather(indices_indices, union_indices)\n         values_with_leading_zeros = tf.concat(\n-            [tf.zeros((1,) + x1.dense_shape[1:], values.dtype), values], axis=0\n+            [tf.zeros((1,) + values.shape[1:], values.dtype), values], axis=0\n         )\n         return tf.gather(values_with_leading_zeros, to_union_indices)\n "
    },
    {
        "commit_id": "127a11dfc5cd5c4da8712c863464d1a17ab01e5a",
        "commit_message": "Update image_classification_with_vision_transformer.py (#18738)\n\nFix the broken API call to ops.shape",
        "commit_url": "https://github.com/keras-team/keras/commit/127a11dfc5cd5c4da8712c863464d1a17ab01e5a",
        "buggy_code": "input_shape = ops.backend.shape(images)",
        "fixed_code": "input_shape = ops.shape(images)",
        "patch": "@@ -112,7 +112,7 @@ def __init__(self, patch_size):\n         self.patch_size = patch_size\n \n     def call(self, images):\n-        input_shape = ops.backend.shape(images)\n+        input_shape = ops.shape(images)\n         batch_size = input_shape[0]\n         height = input_shape[1]\n         width = input_shape[2]"
    },
    {
        "commit_id": "0ef8a0f6719418c885b329d9ed129d06bda45c97",
        "commit_message": "Update image_classification_with_vision_transformer.py (#18740)\n\n* Update image_classification_with_vision_transformer.py\r\n\r\nNot sure if this is a bug in checkpoint logic. I got error like below:\r\n\r\n```\r\n\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\nCell In[10], line 41\r\n     37     return history\r\n     40 vit_classifier = create_vit_classifier()\r\n---> 41 history = run_experiment(vit_classifier)\r\n     44 def plot_history(item):\r\n     45     plt.plot(history.history[item], label=item)\r\n\r\nCell In[10], line 23, in run_experiment(model)\r\n     15 checkpoint_filepath = \"/tmp/checkpoint\"\r\n     16 checkpoint_callback = keras.callbacks.ModelCheckpoint(\r\n     17     checkpoint_filepath,\r\n     18     monitor=\"val_accuracy\",\r\n     19     save_best_only=True,\r\n     20     save_weights_only=True,\r\n     21 )\r\n---> 23 history = model.fit(\r\n     24     x=x_train,\r\n     25     y=y_train,\r\n     26     batch_size=batch_size,\r\n     27     epochs=num_epochs,\r\n     28     validation_split=0.1,\r\n     29     callbacks=[checkpoint_callback],\r\n     30 )\r\n     32 model.load_weights(checkpoint_filepath)\r\n     33 _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\r\n\r\nFile /opt/conda/envs/keras-jax/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:123, in filter_traceback.<locals>.error_handler(*args, **kwargs)\r\n    120     filtered_tb = _process_traceback_frames(e.__traceback__)\r\n    121     # To get the full stack trace, call:\r\n    122     # `keras.config.disable_traceback_filtering()`\r\n--> 123     raise e.with_traceback(filtered_tb) from None\r\n    124 finally:\r\n    125     del filtered_tb\r\n\r\nFile /opt/conda/envs/keras-jax/lib/python3.10/site-packages/keras/src/models/model.py:373, in Model.save_weights(self, filepath, overwrite)\r\n    363 \"\"\"Saves all layer weights to a `.weights.h5` file.\r\n    364 \r\n    365 Args:\r\n   (...)\r\n    370         via an interactive prompt.\r\n    371 \"\"\"\r\n    372 if not str(filepath).endswith(\".weights.h5\"):\r\n--> 373     raise ValueError(\r\n    374         \"The filename must end in `.weights.h5`. \"\r\n    375         f\"Received: filepath={filepath}\"\r\n    376     )\r\n    377 try:\r\n    378     exists = os.path.exists(filepath)\r\n\r\nValueError: The filename must end in `.weights.h5`. Received: filepath=/tmp/checkpoint\r\n\r\n```\r\n\r\n* Update image_classification_with_vision_transformer.py",
        "commit_url": "https://github.com/keras-team/keras/commit/0ef8a0f6719418c885b329d9ed129d06bda45c97",
        "buggy_code": "checkpoint_filepath = \"/tmp/checkpoint\"",
        "fixed_code": "checkpoint_filepath = \"/tmp/checkpoint.weights.h5\"",
        "patch": "@@ -276,7 +276,7 @@ def run_experiment(model):\n         ],\n     )\n \n-    checkpoint_filepath = \"/tmp/checkpoint\"\n+    checkpoint_filepath = \"/tmp/checkpoint.weights.h5\"\n     checkpoint_callback = keras.callbacks.ModelCheckpoint(\n         checkpoint_filepath,\n         monitor=\"val_accuracy\","
    },
    {
        "commit_id": "2af542dbfa501b0cc87e77bc191f67ecf382b37e",
        "commit_message": "Minor fix",
        "commit_url": "https://github.com/keras-team/keras/commit/2af542dbfa501b0cc87e77bc191f67ecf382b37e",
        "buggy_code": "- [Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation](https://arxiv.org/pdf/1802.02611.pdf)",
        "fixed_code": "- [Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation](https://arxiv.org/abs/1802.02611)",
        "patch": "@@ -17,7 +17,7 @@\n \n ### References:\n \n-- [Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation](https://arxiv.org/pdf/1802.02611.pdf)\n+- [Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation](https://arxiv.org/abs/1802.02611)\n - [Rethinking Atrous Convolution for Semantic Image Segmentation](https://arxiv.org/abs/1706.05587)\n - [DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs](https://arxiv.org/abs/1606.00915)\n \"\"\""
    },
    {
        "commit_id": "aa02010b6d89b05b43d87fbd62d865c626f3b415",
        "commit_message": "fix tests for channels_first (#18723)\n\n* fix tests for channels_first\r\n\r\n* bug fix",
        "commit_url": "https://github.com/keras-team/keras/commit/aa02010b6d89b05b43d87fbd62d865c626f3b415",
        "buggy_code": "data_format,",
        "fixed_code": "\"channels_last\",",
        "patch": "@@ -122,7 +122,7 @@ def np_conv2d_transpose(\n         strides,\n         padding,\n         output_padding,\n-        data_format,\n+        \"channels_last\",\n         dilation_rate,\n     )\n     jax_padding = compute_conv_transpose_padding_args_for_jax("
    },
    {
        "commit_id": "c1ec2aa65b33306d3ae437bf39771416d115861f",
        "commit_message": "Fix CI",
        "commit_url": "https://github.com/keras-team/keras/commit/c1ec2aa65b33306d3ae437bf39771416d115861f",
        "buggy_code": "directory, class_names=[\"class_0\", \"class_2\"]",
        "fixed_code": "directory, class_names=[\"class_0\", \"wrong_class\"]",
        "patch": "@@ -386,7 +386,7 @@ def test_audio_dataset_from_directory_errors(self):\n             ValueError, \"`class_names` passed did not match\"\n         ):\n             _ = audio_dataset_utils.audio_dataset_from_directory(\n-                directory, class_names=[\"class_0\", \"class_2\"]\n+                directory, class_names=[\"class_0\", \"wrong_class\"]\n             )\n \n         with self.assertRaisesRegex(ValueError, \"there must be exactly 2\"):"
    },
    {
        "commit_id": "c1ec2aa65b33306d3ae437bf39771416d115861f",
        "commit_message": "Fix CI",
        "commit_url": "https://github.com/keras-team/keras/commit/c1ec2aa65b33306d3ae437bf39771416d115861f",
        "buggy_code": "directory, class_names=[\"class_0\", \"class_2\"]",
        "fixed_code": "directory, class_names=[\"class_0\", \"wrong_class\"]",
        "patch": "@@ -370,7 +370,7 @@ def test_image_dataset_from_directory_errors(self):\n             ValueError, \"`class_names` passed did not match\"\n         ):\n             _ = image_dataset_utils.image_dataset_from_directory(\n-                directory, class_names=[\"class_0\", \"class_2\"]\n+                directory, class_names=[\"class_0\", \"wrong_class\"]\n             )\n \n         with self.assertRaisesRegex(ValueError, \"there must be exactly 2\"):"
    },
    {
        "commit_id": "c1ec2aa65b33306d3ae437bf39771416d115861f",
        "commit_message": "Fix CI",
        "commit_url": "https://github.com/keras-team/keras/commit/c1ec2aa65b33306d3ae437bf39771416d115861f",
        "buggy_code": "directory, class_names=[\"class_0\", \"class_2\"]",
        "fixed_code": "directory, class_names=[\"class_0\", \"wrong_class\"]",
        "patch": "@@ -253,7 +253,7 @@ def test_text_dataset_from_directory_errors(self):\n             ValueError, \"`class_names` passed did not match\"\n         ):\n             _ = text_dataset_utils.text_dataset_from_directory(\n-                directory, class_names=[\"class_0\", \"class_2\"]\n+                directory, class_names=[\"class_0\", \"wrong_class\"]\n             )\n \n         with self.assertRaisesRegex(ValueError, \"there must be exactly 2\"):"
    },
    {
        "commit_id": "b7c0e045338b437a3214d7b94cc1b13b0f4f0401",
        "commit_message": "fix `class_names` arg checking thinko (#18724)\n\nWithout this fix, passing valid values to `class_names` would raise\r\na ValueError. E.g.,\r\n```\r\nimage_dataset_from_directory(dir, class_names = ['one', 'two', 'three'])\r\n```\r\nwould error, even when the subdirectories are `['one', 'two', 'three']`",
        "commit_url": "https://github.com/keras-team/keras/commit/b7c0e045338b437a3214d7b94cc1b13b0f4f0401",
        "buggy_code": "if set(class_names).issubset(set(subdirs)):",
        "fixed_code": "if not set(class_names).issubset(set(subdirs)):",
        "patch": "@@ -546,7 +546,7 @@ def index_directory(\n                         subdir = subdir[:-1]\n                     subdirs.append(subdir)\n         if class_names is not None:\n-            if set(class_names).issubset(set(subdirs)):\n+            if not set(class_names).issubset(set(subdirs)):\n                 raise ValueError(\n                     \"The `class_names` passed did not match the \"\n                     \"names of the subdirectories of the target directory. \""
    },
    {
        "commit_id": "a6d1fe1c712d8c3602e7c0a618d12a49bd3dba99",
        "commit_message": "Change weight_decay arg description for AdamW (#18720)\n\nAdamW has inserted arguments and weight_decay is one among them. But in the description for it is mentioned like below.\r\nweight_decay: Float, defaults to None. If set, weight decay is applied.\r\n\r\nBut this is wrong for AdamW where default value is not None but 0.004. SInce these inserted arguments are coming from the variable base_optimizer_keyword_args from base_optimzer.py file, I am proposing to change the description to remove the mention of default value from the description like below.\r\n\r\nweight_decay: Float. If set, weight decay is applied.\r\n\r\nThis change can be reflected into other Adam optimizer classes like adadelta,adafactor,adagrad,adam and adamax and they already have weight_decay set to None in the arguments, users can refer it from arguments itself. Or if it worth to have default value to be mentioned in the description may be we can remove the weight_decay argument from inserted argument and explicitly add it to each of this Class.\r\n\r\nI proposed first one as it is simple fix.If second fix is worth it may be I can go for it upon confirmation.\r\n\r\nFixes #18712",
        "commit_url": "https://github.com/keras-team/keras/commit/a6d1fe1c712d8c3602e7c0a618d12a49bd3dba99",
        "buggy_code": "weight_decay: Float, defaults to None. If set, weight decay is applied.",
        "fixed_code": "weight_decay: Float. If set, weight decay is applied.",
        "patch": "@@ -698,7 +698,7 @@ def __setattr__(self, name, value):\n base_optimizer_keyword_args = \"\"\"name: String. The name to use\n           for momentum accumulator weights created by\n           the optimizer.\n-        weight_decay: Float, defaults to None. If set, weight decay is applied.\n+        weight_decay: Float. If set, weight decay is applied.\n         clipnorm: Float. If set, the gradient of each weight is individually\n           clipped so that its norm is no higher than this value.\n         clipvalue: Float. If set, the gradient of each weight is clipped to be"
    },
    {
        "commit_id": "4b36becd3da98538356e6adbb63a9995b62dece0",
        "commit_message": "Fix code format.",
        "commit_url": "https://github.com/keras-team/keras/commit/4b36becd3da98538356e6adbb63a9995b62dece0",
        "buggy_code": "print(f\"Build failed.\")",
        "fixed_code": "print(\"Build failed.\")",
        "patch": "@@ -182,7 +182,7 @@ def build_and_save_output(root_path, __version__):\n     if whl_path:\n         print(f\"Build successful. Wheel file available at {whl_path}\")\n     else:\n-        print(f\"Build failed.\")\n+        print(\"Build failed.\")\n     return whl_path\n \n "
    },
    {
        "commit_id": "8647a3c351965e845f15656bd63f8048aca4696b",
        "commit_message": "Update line 543 in metrics_utils.py (#18644)\n\nChanged `y_pred.shape` to `ops.shape(y_pred)` for broadcasting of sample weights to avoid shape error in tensorflow. Fix for issue #18620 .",
        "commit_url": "https://github.com/keras-team/keras/commit/8647a3c351965e845f15656bd63f8048aca4696b",
        "buggy_code": "ops.cast(sample_weight, dtype=y_pred.dtype), y_pred.shape",
        "fixed_code": "ops.cast(sample_weight, dtype=y_pred.dtype), ops.shape(y_pred)",
        "patch": "@@ -540,7 +540,7 @@ def update_confusion_matrix_variables(\n \n     if sample_weight is not None:\n         sample_weight = ops.broadcast_to(\n-            ops.cast(sample_weight, dtype=y_pred.dtype), y_pred.shape\n+            ops.cast(sample_weight, dtype=y_pred.dtype), ops.shape(y_pred)\n         )\n         weights_tiled = ops.tile(\n             ops.reshape(sample_weight, thresh_tiles), data_tiles"
    },
    {
        "commit_id": "ebad23cc1cf5071a58dc30470695aacc695fd045",
        "commit_message": "fix: typos in `mask_propagation` test (#18616)",
        "commit_url": "https://github.com/keras-team/keras/commit/ebad23cc1cf5071a58dc30470695aacc695fd045",
        "buggy_code": "def test_query_mask_progagation(self):",
        "fixed_code": "def test_query_mask_propagation(self):",
        "patch": "@@ -170,7 +170,7 @@ def test_initializer(self):\n         backend.backend() == \"numpy\",\n         reason=\"Numpy backend does not support masking.\",\n     )\n-    def test_query_mask_progagation(self):\n+    def test_query_mask_propagation(self):\n         \"\"\"Test automatic propagation of the query's mask.\"\"\"\n         layer = layers.MultiHeadAttention(num_heads=2, key_dim=2)\n         self.assertTrue(layer.supports_masking)"
    },
    {
        "commit_id": "6222bc9e535a197b2a1121427e40ea9ea3a4be94",
        "commit_message": "Fix BackupRestore Test (#18571)",
        "commit_url": "https://github.com/keras-team/keras/commit/6222bc9e535a197b2a1121427e40ea9ea3a4be94",
        "buggy_code": "shape=(), initializer=\"zeros\", dtype=\"int32\", trainable=False",
        "fixed_code": "shape=(), initializer=\"zeros\", dtype=\"float32\", trainable=False",
        "patch": "@@ -32,7 +32,7 @@ class CanaryLayer(layers.Layer):\n     def __init__(self):\n         super().__init__()\n         self.counter = self.add_weight(\n-            shape=(), initializer=\"zeros\", dtype=\"int32\", trainable=False\n+            shape=(), initializer=\"zeros\", dtype=\"float32\", trainable=False\n         )\n \n     def call(self, x):"
    },
    {
        "commit_id": "817509cfd8ee8b604c7db236592ff0e1a0992210",
        "commit_message": "Route around TF bug in safe_embedding_lookup_sparse.",
        "commit_url": "https://github.com/keras-team/keras/commit/817509cfd8ee8b604c7db236592ff0e1a0992210",
        "buggy_code": "embedding_weights=x,",
        "fixed_code": "embedding_weights=tf.convert_to_tensor(x),",
        "patch": "@@ -810,7 +810,7 @@ def take(x, indices, axis=None):\n             )\n             return tfnp.take(x, tf.sparse.to_dense(indices), axis=axis)\n         return tf.nn.safe_embedding_lookup_sparse(\n-            embedding_weights=x,\n+            embedding_weights=tf.convert_to_tensor(x),\n             sparse_ids=tf.sparse.expand_dims(indices, axis=-1),\n             default_id=0,\n         )"
    },
    {
        "commit_id": "c8a5a8969a8712a9a1939937ce34158e04cfc09d",
        "commit_message": "Update writing_a_custom_training_loop_in_jax.py (#18546)\n\nFixed possible code error",
        "commit_url": "https://github.com/keras-team/keras/commit/c8a5a8969a8712a9a1939937ce34158e04cfc09d",
        "buggy_code": "grads, trainable_variables, optimizer_variables",
        "fixed_code": "optimizer_variables, grads, trainable_variables",
        "patch": "@@ -217,7 +217,7 @@ def train_step(state, data):\n         trainable_variables, non_trainable_variables, x, y\n     )\n     trainable_variables, optimizer_variables = optimizer.stateless_apply(\n-        grads, trainable_variables, optimizer_variables\n+        optimizer_variables, grads, trainable_variables\n     )\n     # Return updated state\n     return loss, ("
    },
    {
        "commit_id": "1ab9642de3a7961bd0173ba257b26c5a4dfce374",
        "commit_message": "torch backend use torch dataloader directly (#18509)\n\n* torch backend use torch dataloader directly\r\n\r\n* fix the tests",
        "commit_url": "https://github.com/keras-team/keras/commit/1ab9642de3a7961bd0173ba257b26c5a4dfce374",
        "buggy_code": "from keras.trainers.data_adapters.torch_data_adapter import (",
        "fixed_code": "from keras.trainers.data_adapters.torch_data_loader_adapter import (",
        "patch": "@@ -4,7 +4,7 @@\n \n from keras import backend\n from keras import testing\n-from keras.trainers.data_adapters.torch_data_adapter import (\n+from keras.trainers.data_adapters.torch_data_loader_adapter import (\n     TorchDataLoaderAdapter,\n )\n "
    },
    {
        "commit_id": "ece41771c764538f13043252f9056690777b912a",
        "commit_message": "Formatting the error string.",
        "commit_url": "https://github.com/keras-team/keras/commit/ece41771c764538f13043252f9056690777b912a",
        "buggy_code": "\"stateless_apply is not supported by the TF based \" \"optimizer. \"",
        "fixed_code": "\"stateless_apply is not supported by the TF based optimizer.\"",
        "patch": "@@ -35,7 +35,7 @@ def stateless_apply(self, optimizer_variables, grads, trainable_variables):\n         # This is mainly due to the interaction with tf.distribute.Strategy,\n         # which requires tf.Variable as the inputs for most of its APIs.\n         raise ValueError(\n-            \"stateless_apply is not supported by the TF based \" \"optimizer. \"\n+            \"stateless_apply is not supported by the TF based optimizer.\"\n         )\n \n     def _var_key(self, variable):"
    },
    {
        "commit_id": "eea9c6db754f0e96a8142487bc8196ff0d7fd840",
        "commit_message": "Fix code format.",
        "commit_url": "https://github.com/keras-team/keras/commit/eea9c6db754f0e96a8142487bc8196ff0d7fd840",
        "buggy_code": "self.assertAllClose(ref_out, out, atol=0.3)",
        "fixed_code": "self.assertAllClose(ref_out, out, atol=1e-3, rtol=1e-3)",
        "patch": "@@ -329,7 +329,7 @@ def test_affine_transform(self, interpolation, fill_mode, data_format):\n         if data_format == \"channels_first\":\n             ref_out = np.transpose(ref_out, (0, 3, 1, 2))\n         self.assertEqual(tuple(out.shape), tuple(ref_out.shape))\n-        self.assertAllClose(ref_out, out, atol=0.3)\n+        self.assertAllClose(ref_out, out, atol=1e-3, rtol=1e-3)\n \n     @parameterized.parameters(\n         ["
    },
    {
        "commit_id": "34081e1cb9cff079bf0c226b431baeee73ac19d9",
        "commit_message": "Add `ops.random.shuffle` (#907)\n\n* Add `ops.random.shuffle`\r\n\r\n* Address comment\r\n\r\n* Update docstring\r\n\r\n* Fix typo",
        "commit_url": "https://github.com/keras-team/keras/commit/34081e1cb9cff079bf0c226b431baeee73ac19d9",
        "buggy_code": "return tf.identity(n)",
        "fixed_code": "return tfnp.identity(n, dtype=dtype)",
        "patch": "@@ -330,7 +330,7 @@ def hstack(xs):\n \n \n def identity(n, dtype=\"float32\"):\n-    return tf.identity(n)\n+    return tfnp.identity(n, dtype=dtype)\n \n \n def imag(x):"
    },
    {
        "commit_id": "f56d7b0c41fa58ba30bd92cf48ae07ea0b4ef677",
        "commit_message": "fix tf_data test failure",
        "commit_url": "https://github.com/keras-team/keras/commit/f56d7b0c41fa58ba30bd92cf48ae07ea0b4ef677",
        "buggy_code": "return tfnp.identity(n, dtype=dtype)",
        "fixed_code": "return tf.identity(n)",
        "patch": "@@ -330,7 +330,7 @@ def hstack(xs):\n \n \n def identity(n, dtype=\"float32\"):\n-    return tfnp.identity(n, dtype=dtype)\n+    return tf.identity(n)\n \n \n def imag(x):"
    },
    {
        "commit_id": "f56d7b0c41fa58ba30bd92cf48ae07ea0b4ef677",
        "commit_message": "fix tf_data test failure",
        "commit_url": "https://github.com/keras-team/keras/commit/f56d7b0c41fa58ba30bd92cf48ae07ea0b4ef677",
        "buggy_code": "layer = layers.Discretization(bin_boundaries=[0.0, 0.35, 0.5, 1.0])",
        "fixed_code": "layer = layers.Discretization(bin_boundaries=[0.0, 0.35, 0.5, 1.0], dtype=\"float32\")",
        "patch": "@@ -70,7 +70,7 @@ def test_correctness(self):\n \n     def test_tf_data_compatibility(self):\n         # With fixed bins\n-        layer = layers.Discretization(bin_boundaries=[0.0, 0.35, 0.5, 1.0])\n+        layer = layers.Discretization(bin_boundaries=[0.0, 0.35, 0.5, 1.0], dtype=\"float32\")\n         x = np.array([[-1.0, 0.0, 0.1, 0.2, 0.4, 0.5, 1.0, 1.2, 0.98]])\n         self.assertAllClose(layer(x), np.array([[0, 1, 1, 1, 2, 3, 4, 4, 3]]))\n         ds = tf_data.Dataset.from_tensor_slices(x).batch(1).map(layer)"
    },
    {
        "commit_id": "536a8167bfdeba3f2254f422d35c1ae57ef7ba45",
        "commit_message": "fix import error and ops.identity error",
        "commit_url": "https://github.com/keras-team/keras/commit/536a8167bfdeba3f2254f422d35c1ae57ef7ba45",
        "buggy_code": "return tfnp.identity(n, dtype=dtype)",
        "fixed_code": "return tf.identity(n)",
        "patch": "@@ -330,7 +330,7 @@ def hstack(xs):\n \n \n def identity(n, dtype=\"float32\"):\n-    return tfnp.identity(n, dtype=dtype)\n+    return tf.identity(n)\n \n \n def imag(x):"
    },
    {
        "commit_id": "f09974ab5febef89db4b8a195f544fbaa3c66da3",
        "commit_message": "Use `ops.rsqrt`, improve normalization layers and enable ops fusion in tflite (#892)\n\n* Add `rsqrt` to numpy backend\r\n\r\n* Improve normalization\r\n\r\n* Fix order bug\r\n\r\n* Update LayerNormalization\r\n\r\n* Improve unit test coverage\r\n\r\n* Use np native",
        "commit_url": "https://github.com/keras-team/keras/commit/f09974ab5febef89db4b8a195f544fbaa3c66da3",
        "buggy_code": "x_inv_norm = 1 / ops.sqrt(ops.maximum(square_sum, 1e-12))",
        "fixed_code": "x_inv_norm = ops.rsqrt(ops.maximum(square_sum, 1e-12))",
        "patch": "@@ -45,7 +45,7 @@ def call(self, inputs):\n         x = ops.cast(inputs, self.compute_dtype)\n \n         square_sum = ops.sum(ops.square(x), axis=self.axis, keepdims=True)\n-        x_inv_norm = 1 / ops.sqrt(ops.maximum(square_sum, 1e-12))\n+        x_inv_norm = ops.rsqrt(ops.maximum(square_sum, 1e-12))\n         return ops.multiply(x, x_inv_norm)\n \n     def compute_output_shape(self, input_shape):"
    },
    {
        "commit_id": "1e6d1eb9a8148268f56879bfb15567435c8d6352",
        "commit_message": "syntax fix (#898)",
        "commit_url": "https://github.com/keras-team/keras/commit/1e6d1eb9a8148268f56879bfb15567435c8d6352",
        "buggy_code": "random_tensor = keep_prob + keras.random.random.uniform(shape, 0, 1)",
        "fixed_code": "random_tensor = keep_prob + keras.random.uniform(shape, 0, 1)",
        "patch": "@@ -256,7 +256,7 @@ def call(self, x, training=None):\n         if training:\n             keep_prob = 1 - self.drop_prob\n             shape = (keras.ops.shape(x)[0],) + (1,) * (len(x.shape) - 1)\n-            random_tensor = keep_prob + keras.random.random.uniform(shape, 0, 1)\n+            random_tensor = keep_prob + keras.random.uniform(shape, 0, 1)\n             random_tensor = keras.ops.floor(random_tensor)\n             return (x / keep_prob) * random_tensor\n         return x"
    },
    {
        "commit_id": "8361f6fd0e7ff1e54e67acb426b973f486413711",
        "commit_message": "Fix summary when optimizer is None (#879)",
        "commit_url": "https://github.com/keras-team/keras/commit/8361f6fd0e7ff1e54e67acb426b973f486413711",
        "buggy_code": "if model.compiled and model.optimizer.built:",
        "fixed_code": "if model.compiled and model.optimizer and model.optimizer.built:",
        "patch": "@@ -308,7 +308,7 @@ def print_layer(layer, nested_level=0):\n     non_trainable_count = count_params(model.non_trainable_weights)\n     non_trainable_memory_size = weight_memory_size(model.non_trainable_weights)\n \n-    if model.compiled and model.optimizer.built:\n+    if model.compiled and model.optimizer and model.optimizer.built:\n         optimizer_weight_count = count_params(model.optimizer.variables)\n         optimizer_memory_size = weight_memory_size(model.optimizer.variables)\n     else:"
    },
    {
        "commit_id": "68a46c30131d8ea32a2b6961f2228c5cd7e8854d",
        "commit_message": "Fix `stop_gradient` in np (#872)\n\n* Fix `stop_gradient` in np\r\n\r\n* Add unit test",
        "commit_url": "https://github.com/keras-team/keras/commit/68a46c30131d8ea32a2b6961f2228c5cd7e8854d",
        "buggy_code": "pass",
        "fixed_code": "return x",
        "patch": "@@ -212,7 +212,7 @@ def fori_loop(lower, upper, body_fun, init_val):\n \n \n def stop_gradient(x):\n-    pass\n+    return x\n \n \n def unstack(x, num=None, axis=0):"
    },
    {
        "commit_id": "4b0e74884d26181159f841ac6221a13a204a6a2b",
        "commit_message": "Improve the flexibility of `standardize_dtype` and fix `pad` in torch backend (#828)\n\n* improve flexibility in dtype check for torch\r\n\r\n* Update\r\n\r\n* Fix bugs\r\n\r\n* Update\r\n\r\n* Fix padding for torch backend\r\n\r\n* Update",
        "commit_url": "https://github.com/keras-team/keras/commit/4b0e74884d26181159f841ac6221a13a204a6a2b",
        "buggy_code": "return np.digitize(x, bins)",
        "fixed_code": "return np.digitize(x, bins).astype(np.int32)",
        "patch": "@@ -216,7 +216,7 @@ def diagonal(x, offset=0, axis1=0, axis2=1):\n \n \n def digitize(x, bins):\n-    return np.digitize(x, bins)\n+    return np.digitize(x, bins).astype(np.int32)\n \n \n def dot(x, y):"
    },
    {
        "commit_id": "3b02dddeaa2943b1085d3dfd8ee4d69c9046f619",
        "commit_message": "Fixed misc mixed precision issues (#805)\n\n* Fixed misc mixed precision issues\r\n\r\n* Fix numpy backend\r\n\r\n* Address comments",
        "commit_url": "https://github.com/keras-team/keras/commit/3b02dddeaa2943b1085d3dfd8ee4d69c9046f619",
        "buggy_code": "return resized",
        "fixed_code": "return tf.cast(resized, image.dtype)",
        "patch": "@@ -47,7 +47,7 @@ def resize(\n             resized = tf.transpose(resized, (0, 3, 1, 2))\n         elif len(image.shape) == 3:\n             resized = tf.transpose(resized, (2, 0, 1))\n-    return resized\n+    return tf.cast(resized, image.dtype)\n \n \n AFFINE_TRANSFORM_INTERPOLATIONS = ("
    },
    {
        "commit_id": "3b02dddeaa2943b1085d3dfd8ee4d69c9046f619",
        "commit_message": "Fixed misc mixed precision issues (#805)\n\n* Fixed misc mixed precision issues\r\n\r\n* Fix numpy backend\r\n\r\n* Address comments",
        "commit_url": "https://github.com/keras-team/keras/commit/3b02dddeaa2943b1085d3dfd8ee4d69c9046f619",
        "buggy_code": "return outputs",
        "fixed_code": "return ops.cast(outputs, input_dtype)",
        "patch": "@@ -236,7 +236,7 @@ def call(self, inputs, training=None, mask=None):\n             beta = ops.reshape(self.beta, broadcast_shape)\n             beta = ops.cast(beta, outputs.dtype)\n             outputs = outputs + beta\n-        return outputs\n+        return ops.cast(outputs, input_dtype)\n \n     def get_config(self):\n         base_config = super().get_config()"
    },
    {
        "commit_id": "3b02dddeaa2943b1085d3dfd8ee4d69c9046f619",
        "commit_message": "Fixed misc mixed precision issues (#805)\n\n* Fixed misc mixed precision issues\r\n\r\n* Fix numpy backend\r\n\r\n* Address comments",
        "commit_url": "https://github.com/keras-team/keras/commit/3b02dddeaa2943b1085d3dfd8ee4d69c9046f619",
        "buggy_code": "return output",
        "fixed_code": "return ops.cast(output, inputs.dtype)",
        "patch": "@@ -79,7 +79,7 @@ def call(self, inputs, training=False):\n             self.normalize_weights()\n \n         output = self.layer(inputs)\n-        return output\n+        return ops.cast(output, inputs.dtype)\n \n     def compute_output_shape(self, input_shape):\n         return self.layer.compute_output_shape(input_shape)"
    },
    {
        "commit_id": "4da630253d45c8c2f9ea23be6c8f82cf8393c21f",
        "commit_message": "Split fix (#789)\n\n* fixed split compute_output_spec bug\r\n\r\n* tuple tweak\r\n\r\n* fixed int-arg bug\r\n\r\n* added unit test",
        "commit_url": "https://github.com/keras-team/keras/commit/4da630253d45c8c2f9ea23be6c8f82cf8393c21f",
        "buggy_code": "if isinstance(indices_or_sections, list):",
        "fixed_code": "if isinstance(indices_or_sections, (list, tuple)):",
        "patch": "@@ -772,7 +772,7 @@ def sort(x, axis=-1):\n \n def split(x, indices_or_sections, axis=0):\n     x = convert_to_tensor(x)\n-    if isinstance(indices_or_sections, list):\n+    if isinstance(indices_or_sections, (list, tuple)):\n         idxs = convert_to_tensor(indices_or_sections)\n         start_size = indices_or_sections[0]\n         end_size = x.shape[axis] - indices_or_sections[-1]"
    },
    {
        "commit_id": "3b1bf505985989e0691348fd62e303a9b9f133a2",
        "commit_message": "Fix error message which would print the article \"the\" twice. (#764)\n\nIn all cases, `arg_description` already contains the article \"the\". The error message would then contain \"the\" twice, for instance \"Intead, the the targets should...\".\r\n\r\nAlso fixed some formatting issues caught by lint.",
        "commit_url": "https://github.com/keras-team/keras/commit/3b1bf505985989e0691348fd62e303a9b9f133a2",
        "buggy_code": "f\"should not be passed. Instead, the {arg_description} should \"",
        "fixed_code": "f\"should not be passed. Instead, {arg_description} should \"",
        "patch": "@@ -220,7 +220,7 @@ def num_batches(self):\n def raise_unsupported_arg(arg_name, arg_description, input_type):\n     raise ValueError(\n         f\"When providing `x` as a {input_type}, `{arg_name}` \"\n-        f\"should not be passed. Instead, the {arg_description} should \"\n+        f\"should not be passed. Instead, {arg_description} should \"\n         f\"be included as part of the {input_type}.\"\n     )\n "
    },
    {
        "commit_id": "35f5cf865908578ea3cfadae83b838cf65d2301b",
        "commit_message": "Fix CI",
        "commit_url": "https://github.com/keras-team/keras/commit/35f5cf865908578ea3cfadae83b838cf65d2301b",
        "buggy_code": "trainable_weights = [v.value for v in self.trainable_weights]",
        "fixed_code": "trainable_weights = self.trainable_weights",
        "patch": "@@ -63,7 +63,7 @@ def train_step(self, data):\n \n         # Compute gradients\n         if self.trainable_weights:\n-            trainable_weights = [v.value for v in self.trainable_weights]\n+            trainable_weights = self.trainable_weights\n             gradients = tape.gradient(loss, trainable_weights)\n \n             # Update weights"
    },
    {
        "commit_id": "7f01ac7129e981829e0f49572886b9c793889863",
        "commit_message": "Enhanced Docstrings and Examples in /ops/function.py, /ops/math.py and /ops/nn.py. (#736)\n\n* docstrings improvement\r\n\r\n* fix formatting issues\r\n\r\n* format enhancement\r\n\r\n* using the Black Code Style\r\n\r\n* fix indents",
        "commit_url": "https://github.com/keras-team/keras/commit/7f01ac7129e981829e0f49572886b9c793889863",
        "buggy_code": "- nodes: list of Node instances.",
        "fixed_code": "- network_nodes: dict mapping unique node keys to the Node instances",
        "patch": "@@ -180,7 +180,7 @@ def map_graph(inputs, outputs):\n \n     Returns:\n         A tuple `(nodes, nodes_by_depth, operations, operations_by_depth)`.\n-        - nodes: list of Node instances.\n+        - network_nodes: dict mapping unique node keys to the Node instances\n         - nodes_by_depth: dict mapping ints (depth) to lists of node instances.\n         - operations: list of Operation instances.\n         - operations_by_depth: dict mapping ints (depth) to lists of Operation"
    },
    {
        "commit_id": "2d8e54d1911ddae5a24c576c918eb0a198667a27",
        "commit_message": "Fix erroneous SegmentSum call in SegmentMax class (#713)",
        "commit_url": "https://github.com/keras-team/keras/commit/2d8e54d1911ddae5a24c576c918eb0a198667a27",
        "buggy_code": "return SegmentSum(num_segments, sorted).symbolic_call(data, segment_ids)",
        "fixed_code": "return SegmentMax(num_segments, sorted).symbolic_call(data, segment_ids)",
        "patch": "@@ -106,7 +106,7 @@ def segment_max(data, segment_ids, num_segments=None, sorted=False):\n     array([9 12], shape=(2,), dtype=int32)\n     \"\"\"\n     if any_symbolic_tensors((data,)):\n-        return SegmentSum(num_segments, sorted).symbolic_call(data, segment_ids)\n+        return SegmentMax(num_segments, sorted).symbolic_call(data, segment_ids)\n     return backend.math.segment_max(\n         data, segment_ids, num_segments=num_segments, sorted=sorted\n     )"
    },
    {
        "commit_id": "7635d96ce2a969c8d090412bc2801deb39b7e205",
        "commit_message": "Little cleanup in backend - config.py / export.py (#709)\n\n* Fix examples sections\r\n\r\n* Improve error message",
        "commit_url": "https://github.com/keras-team/keras/commit/7635d96ce2a969c8d090412bc2801deb39b7e205",
        "buggy_code": "raise RuntimeError(\"Invalid backend.\")",
        "fixed_code": "raise RuntimeError(f\"Invalid backend: {backend.backend()}\")",
        "patch": "@@ -12,7 +12,7 @@\n \n     BackendVariable = NumpyVariable\n else:\n-    raise RuntimeError(\"Invalid backend.\")\n+    raise RuntimeError(f\"Invalid backend: {backend.backend()}\")\n \n \n @keras_core_export(\"keras_core.backend.Variable\")"
    },
    {
        "commit_id": "bba1810a4af72fe68323b4384e85577eee282a10",
        "commit_message": "Fix typo in WhileLoop docstring (#703)",
        "commit_url": "https://github.com/keras-team/keras/commit/bba1810a4af72fe68323b4384e85577eee282a10",
        "buggy_code": "\"\"\"While loop implemetation.",
        "fixed_code": "\"\"\"While loop implementation.",
        "patch": "@@ -230,7 +230,7 @@ def while_loop(\n     loop_vars,\n     maximum_iterations=None,\n ):\n-    \"\"\"While loop implemetation.\n+    \"\"\"While loop implementation.\n \n     Args:\n         cond: A callable that represents the termination condition of the loop."
    },
    {
        "commit_id": "018eef87945ae4c5dd7dbb852ce12094374a5fbc",
        "commit_message": "Fix issue with predict_on_batch + input list",
        "commit_url": "https://github.com/keras-team/keras/commit/018eef87945ae4c5dd7dbb852ce12094374a5fbc",
        "buggy_code": "batch_outputs, state = self.predict_function(state, [x])",
        "fixed_code": "batch_outputs, state = self.predict_function(state, [(x,)])",
        "patch": "@@ -717,7 +717,7 @@ def predict_on_batch(self, x):\n         trainable_variables = self.trainable_variables\n         non_trainable_variables = self.non_trainable_variables\n         state = (trainable_variables, non_trainable_variables)\n-        batch_outputs, state = self.predict_function(state, [x])\n+        batch_outputs, state = self.predict_function(state, [(x,)])\n         batch_outputs = tree.map_structure(lambda x: np.array(x), batch_outputs)\n         return batch_outputs\n "
    },
    {
        "commit_id": "018eef87945ae4c5dd7dbb852ce12094374a5fbc",
        "commit_message": "Fix issue with predict_on_batch + input list",
        "commit_url": "https://github.com/keras-team/keras/commit/018eef87945ae4c5dd7dbb852ce12094374a5fbc",
        "buggy_code": "batch_outputs = self.predict_function((x,))",
        "fixed_code": "batch_outputs = self.predict_function([(x,)])",
        "patch": "@@ -306,7 +306,7 @@ def test_on_batch(\n \n     def predict_on_batch(self, x):\n         self.make_predict_function()\n-        batch_outputs = self.predict_function((x,))\n+        batch_outputs = self.predict_function([(x,)])\n         batch_outputs = tree.map_structure(\n             backend.convert_to_numpy, batch_outputs\n         )"
    },
    {
        "commit_id": "018eef87945ae4c5dd7dbb852ce12094374a5fbc",
        "commit_message": "Fix issue with predict_on_batch + input list",
        "commit_url": "https://github.com/keras-team/keras/commit/018eef87945ae4c5dd7dbb852ce12094374a5fbc",
        "buggy_code": "batch_outputs = self.predict_function((x,))",
        "fixed_code": "batch_outputs = self.predict_function([(x,)])",
        "patch": "@@ -560,7 +560,7 @@ def data():\n \n     def predict_on_batch(self, x):\n         self.make_predict_function()\n-        batch_outputs = self.predict_function((x,))\n+        batch_outputs = self.predict_function([(x,)])\n         batch_outputs = tf.nest.map_structure(\n             convert_to_np_if_not_ragged, batch_outputs\n         )"
    },
    {
        "commit_id": "018eef87945ae4c5dd7dbb852ce12094374a5fbc",
        "commit_message": "Fix issue with predict_on_batch + input list",
        "commit_url": "https://github.com/keras-team/keras/commit/018eef87945ae4c5dd7dbb852ce12094374a5fbc",
        "buggy_code": "batch_outputs = self.predict_function((x,))",
        "fixed_code": "batch_outputs = self.predict_function([(x,)])",
        "patch": "@@ -526,7 +526,7 @@ def test_on_batch(\n \n     def predict_on_batch(self, x):\n         self.make_predict_function()\n-        batch_outputs = self.predict_function((x,))\n+        batch_outputs = self.predict_function([(x,)])\n         batch_outputs = tree.map_structure(\n             backend.convert_to_numpy, batch_outputs\n         )"
    },
    {
        "commit_id": "c93f1be73ee74a05643c7383d96190ea231d3784",
        "commit_message": "Add Export for TF backend (#692)\n\n* Add saved model test\r\n\r\n* Add TF tracking attribute\r\n\r\n* Add tests for functional and subclassed\r\n\r\n* Fix saving trackables\r\n\r\n* Fix test assertions\r\n\r\n* Fix formatting\r\n\r\n* Add comments for attribute tracking\r\n\r\n* Change saved model test description\r\n\r\n* Add backend conditional for attribute\r\n\r\n* Change package name\r\n\r\n* Change epoch nums\r\n\r\n* Revert epochs\r\n\r\n* Add set verbose logging utility and debug callback tests\r\n\r\n* Fix formatting\r\n\r\n* Initial port of model export\r\n\r\n* Fix imports\r\n\r\n* Add save spec methods to TF layer\r\n\r\n* Add export function to Keras Core base model\r\n\r\n* Downgrade naming error to warning and debug TF variable collections check\r\n\r\n* Simplify weight reloading\r\n\r\n* Fix formatting, add TODOs\r\n\r\n* Unify tf_utils under backend/tensorflow\r\n\r\n* Fix docstring and import\r\n\r\n* Fix module utils import\r\n\r\n* Fix lookup layers export and add test\r\n\r\n* Change naming to TFSMLayer\r\n\r\n* Remove parameterized\r\n\r\n* Comment out failing test",
        "commit_url": "https://github.com/keras-team/keras/commit/c93f1be73ee74a05643c7383d96190ea231d3784",
        "buggy_code": "from keras_core.utils import tf_utils",
        "fixed_code": "from keras_core.backend.tensorflow import tf_utils",
        "patch": "@@ -2,9 +2,9 @@\n \n from keras_core import backend\n from keras_core.api_export import keras_core_export\n+from keras_core.backend.tensorflow import tf_utils\n from keras_core.layers.layer import Layer\n from keras_core.utils import backend_utils\n-from keras_core.utils import tf_utils\n from keras_core.utils.module_utils import tensorflow as tf\n \n "
    },
    {
        "commit_id": "5534880cb85f7a2445c3c8eb6499ff784a04f5c8",
        "commit_message": "Fix typo",
        "commit_url": "https://github.com/keras-team/keras/commit/5534880cb85f7a2445c3c8eb6499ff784a04f5c8",
        "buggy_code": "traced function (e.g. a `jax.jit`-transformed function) since",
        "fixed_code": "a traced function (e.g. a `jax.jit`-transformed function) since",
        "patch": "@@ -109,7 +109,7 @@ def global_rng_state():\n \n     In JAX, if you're using unseeded random ops, be mindful that\n     their outputs will be unchanged across different calls of\n-    traced function (e.g. a `jax.jit`-transformed function) since\n+    a traced function (e.g. a `jax.jit`-transformed function) since\n     traced functions in JAX are fully stateless. To get\n     different outputs across different calls, you will need to pass the\n     global RNG state in and out of the function boundary, like this:"
    },
    {
        "commit_id": "2b5f28f65fd76f04607ad8e8d8786f5cdcb8b895",
        "commit_message": "Merge pull request #18314 from ganeshiva:patch-1\n\nPiperOrigin-RevId: 553219889",
        "commit_url": "https://github.com/keras-team/keras/commit/2b5f28f65fd76f04607ad8e8d8786f5cdcb8b895",
        "buggy_code": "`keras.utils.disable_interactie_logging()`.",
        "fixed_code": "`keras.utils.disable_interactive_logging()`.",
        "patch": "@@ -58,7 +58,7 @@ def is_interactive_logging_enabled():\n \n     To switch between writing logs to stdout and `absl.logging`, you may use\n     `keras.utils.enable_interactive_logging()` and\n-    `keras.utils.disable_interactie_logging()`.\n+    `keras.utils.disable_interactive_logging()`.\n \n     Returns:\n       Boolean (True if interactive logging is enabled and False otherwise)."
    },
    {
        "commit_id": "f2076e1046cab7f34e46bb9ff2ae643379d81a62",
        "commit_message": "Fix code style",
        "commit_url": "https://github.com/keras-team/keras/commit/f2076e1046cab7f34e46bb9ff2ae643379d81a62",
        "buggy_code": "assert isinstance(x, jnp.ndarray)",
        "fixed_code": "self.assertTrue(isinstance(x, jnp.ndarray))",
        "patch": "@@ -152,4 +152,4 @@ def test_jax_rngkey_seed(self):\n         self.assertEqual(rng.shape, (2,))\n         self.assertEqual(rng.dtype, jnp.uint32)\n         x = random.randint((3, 5), 0, 10, seed=rng)\n-        assert isinstance(x, jnp.ndarray)\n\\ No newline at end of file\n+        self.assertTrue(isinstance(x, jnp.ndarray))"
    },
    {
        "commit_id": "24fa8f2e46578d1dc43d5500827c22e5e53e93e5",
        "commit_message": "Only ignore xx_mask arguments for the build shapes dict (#632)\n\nSilly bug, our mask call args look like `xx_mask` not `mask_xx`, we had\r\nthe order flipped.",
        "commit_url": "https://github.com/keras-team/keras/commit/24fa8f2e46578d1dc43d5500827c22e5e53e93e5",
        "buggy_code": "if k == \"mask\" or k.startswith(\"mask_\"):",
        "fixed_code": "if k == \"mask\" or k.endswith(\"_mask\"):",
        "patch": "@@ -1353,7 +1353,7 @@ def get_shapes_dict(call_spec):\n     \"\"\"\n     shapes_dict = {}\n     for k, v in call_spec.tensor_arguments_dict.items():\n-        if k == \"mask\" or k.startswith(\"mask_\"):\n+        if k == \"mask\" or k.endswith(\"_mask\"):\n             # Do not include mask tensors in shapes dict\n             continue\n         if k == \"kwargs\" or k == \"args\":"
    },
    {
        "commit_id": "a0673fef4e1410745b87cc6955006a79bb7f2a89",
        "commit_message": "fix load of models with Add and Concat layers (#626)\n\n* fix load of models with Add and_Concat layers\r\n\r\nsome of models I saved with Model.save() didn't load\r\n`keras_core.saving.load_model()`\r\n\r\n* reformat to make linter happy",
        "commit_url": "https://github.com/keras-team/keras/commit/a0673fef4e1410745b87cc6955006a79bb7f2a89",
        "buggy_code": "if not isinstance(input_shape[0], tuple):",
        "fixed_code": "if not isinstance(input_shape[0], (tuple, list)):",
        "patch": "@@ -61,7 +61,7 @@ def _compute_elemwise_op_output_shape(self, shape1, shape2):\n \n     def build(self, input_shape):\n         # Used purely for shape validation.\n-        if not isinstance(input_shape[0], tuple):\n+        if not isinstance(input_shape[0], (tuple, list)):\n             raise ValueError(\n                 \"A merge layer should be called on a list of inputs. \"\n                 f\"Received: input_shape={input_shape} (not a list of shapes)\""
    },
    {
        "commit_id": "ff4bae8a70d1f263bacbc2f7b1ae737b8a0c4b77",
        "commit_message": "Torch fix",
        "commit_url": "https://github.com/keras-team/keras/commit/ff4bae8a70d1f263bacbc2f7b1ae737b8a0c4b77",
        "buggy_code": "with StatelessScope():",
        "fixed_code": "with StatelessScope(), torch.no_grad():",
        "patch": "@@ -228,7 +228,7 @@ def symbolic_call(fn, args, kwargs, fill_value):\n                 )\n                 return fn(*eager_args, **eager_kwargs)\n \n-    with StatelessScope():\n+    with StatelessScope(), torch.no_grad():\n         outputs = symbolic_call(fn, args, kwargs, fill_value=83)\n \n         none_in_shape = any(map(has_none_shape, tree.flatten((args, kwargs))))"
    },
    {
        "commit_id": "b660875f51c6cd9456e8722bfe10c2cd9d45b060",
        "commit_message": "Add tf.keras backwards compat for nearly all non-experimental symbols (#603)\n\n* Add tf.keras backwards compatibility for nearly all non-experimental symbols\r\n\r\n* Remove print statements\r\n\r\n* Fix identity init",
        "commit_url": "https://github.com/keras-team/keras/commit/b660875f51c6cd9456e8722bfe10c2cd9d45b060",
        "buggy_code": "__version__ = \"0.1.2\"",
        "fixed_code": "__version__ = \"0.1.3\"",
        "patch": "@@ -1,2 +1,2 @@\n # Unique source of truth for the version number.\n-__version__ = \"0.1.2\"\n+__version__ = \"0.1.3\""
    },
    {
        "commit_id": "8d5e9b2163ec9b7d9f70920d1c7992b6df6820ec",
        "commit_message": "fix categorical_crossentropy implementation when axis is not -1\n\nPiperOrigin-RevId: 550960122",
        "commit_url": "https://github.com/keras-team/keras/commit/8d5e9b2163ec9b7d9f70920d1c7992b6df6820ec",
        "buggy_code": "num_classes = tf.cast(tf.shape(y_true)[-1], y_pred.dtype)",
        "fixed_code": "num_classes = tf.cast(tf.shape(y_true)[axis], y_pred.dtype)",
        "patch": "@@ -2209,7 +2209,7 @@ def categorical_crossentropy(\n         )\n \n     def _smooth_labels():\n-        num_classes = tf.cast(tf.shape(y_true)[-1], y_pred.dtype)\n+        num_classes = tf.cast(tf.shape(y_true)[axis], y_pred.dtype)\n         return y_true * (1.0 - label_smoothing) + (\n             label_smoothing / num_classes\n         )"
    },
    {
        "commit_id": "b11396fdc040caa68633c7996aa2e0a89b1ade55",
        "commit_message": "Address the issue for init state dtype in RNN.\n\nThe backend.variable was asssuming float32 when dtype is not provided. The RNN init state should pass the init state dtype to the backend.variable.\n\nSeehttps://github.com/keras-team/keras/issues/15164 for more details.\n\nPiperOrigin-RevId: 550619673",
        "commit_url": "https://github.com/keras-team/keras/commit/b11396fdc040caa68633c7996aa2e0a89b1ade55",
        "buggy_code": "backend.variable, flat_init_state_values",
        "fixed_code": "lambda v: backend.variable(v, v.dtype), flat_init_state_values",
        "patch": "@@ -906,7 +906,7 @@ def reset_states(self, states=None):\n                     )\n                 )\n             flat_states_variables = tf.nest.map_structure(\n-                backend.variable, flat_init_state_values\n+                lambda v: backend.variable(v, v.dtype), flat_init_state_values\n             )\n             self.states = tf.nest.pack_sequence_as(\n                 self.cell.state_size, flat_states_variables"
    },
    {
        "commit_id": "5bea3f6bfd83551529e0c56416ecb963e5a9691e",
        "commit_message": "Fix API generation bug",
        "commit_url": "https://github.com/keras-team/keras/commit/5bea3f6bfd83551529e0c56416ecb963e5a9691e",
        "buggy_code": "@keras_core_export(\"keras_core.initializers.deserialize\")",
        "fixed_code": "@keras_core_export(\"keras_core.constraints.deserialize\")",
        "patch": "@@ -28,7 +28,7 @@ def serialize(constraint):\n     return serialization_lib.serialize_keras_object(constraint)\n \n \n-@keras_core_export(\"keras_core.initializers.deserialize\")\n+@keras_core_export(\"keras_core.constraints.deserialize\")\n def deserialize(config, custom_objects=None):\n     \"\"\"Return a Keras constraint object via its config.\"\"\"\n     return serialization_lib.deserialize_keras_object("
    },
    {
        "commit_id": "1dd4de852276182be7a53a8dbb99b32cc60ae0ce",
        "commit_message": "Add FFT Ops (#480)\n\n* Add FFT Ops\r\n\r\n* Fixes\r\n\r\n* Fix torch\r\n\r\n* Address Matt's comments\r\n\r\n* Address Francois' comments\r\n\r\n* Shift docstrings to correct fns\r\n\r\n* Add NumPy backend FFT ops\r\n\r\n* Fix numpy backend\r\n\r\n* Minor change\r\n\r\n* Redirect NumPy FFT to JAX",
        "commit_url": "https://github.com/keras-team/keras/commit/1dd4de852276182be7a53a8dbb99b32cc60ae0ce",
        "buggy_code": "if isinstance(self.cell, Layer) and self.cell._call_has_training_arg:",
        "fixed_code": "if isinstance(self.cell, Layer) and self.cell._call_has_training_arg():",
        "patch": "@@ -323,7 +323,7 @@ def reset_state(self):\n \n     def inner_loop(self, sequences, initial_state, mask, training=False):\n         cell_kwargs = {}\n-        if isinstance(self.cell, Layer) and self.cell._call_has_training_arg:\n+        if isinstance(self.cell, Layer) and self.cell._call_has_training_arg():\n             cell_kwargs[\"training\"] = training\n \n         def step(inputs, states):"
    },
    {
        "commit_id": "1dd4de852276182be7a53a8dbb99b32cc60ae0ce",
        "commit_message": "Add FFT Ops (#480)\n\n* Add FFT Ops\r\n\r\n* Fixes\r\n\r\n* Fix torch\r\n\r\n* Address Matt's comments\r\n\r\n* Address Francois' comments\r\n\r\n* Shift docstrings to correct fns\r\n\r\n* Add NumPy backend FFT ops\r\n\r\n* Fix numpy backend\r\n\r\n* Minor change\r\n\r\n* Redirect NumPy FFT to JAX",
        "commit_url": "https://github.com/keras-team/keras/commit/1dd4de852276182be7a53a8dbb99b32cc60ae0ce",
        "buggy_code": "if isinstance(cell, Layer) and cell._call_has_training_arg:",
        "fixed_code": "if isinstance(cell, Layer) and cell._call_has_training_arg():",
        "patch": "@@ -90,7 +90,7 @@ def call(self, inputs, states, training=False, **kwargs):\n         new_states = []\n         for cell, states in zip(self.cells, states):\n             states = list(states) if tree.is_nested(states) else [states]\n-            if isinstance(cell, Layer) and cell._call_has_training_arg:\n+            if isinstance(cell, Layer) and cell._call_has_training_arg():\n                 kwargs[\"training\"] = training\n             else:\n                 kwargs.pop(\"training\", None)"
    },
    {
        "commit_id": "1dd4de852276182be7a53a8dbb99b32cc60ae0ce",
        "commit_message": "Add FFT Ops (#480)\n\n* Add FFT Ops\r\n\r\n* Fixes\r\n\r\n* Fix torch\r\n\r\n* Address Matt's comments\r\n\r\n* Address Francois' comments\r\n\r\n* Shift docstrings to correct fns\r\n\r\n* Add NumPy backend FFT ops\r\n\r\n* Fix numpy backend\r\n\r\n* Minor change\r\n\r\n* Redirect NumPy FFT to JAX",
        "commit_url": "https://github.com/keras-team/keras/commit/1dd4de852276182be7a53a8dbb99b32cc60ae0ce",
        "buggy_code": "and operation._call_has_training_arg",
        "fixed_code": "and operation._call_has_training_arg()",
        "patch": "@@ -542,7 +542,7 @@ def operation_fn(operation, training):\n     def call(*args, **kwargs):\n         if (\n             hasattr(operation, \"_call_has_training_arg\")\n-            and operation._call_has_training_arg\n+            and operation._call_has_training_arg()\n             and training is not None\n         ):\n             kwargs[\"training\"] = training"
    },
    {
        "commit_id": "d7b3eae31f30e8fab4485ef4ff1709838df5a0ba",
        "commit_message": "Add `affine_transform` op to all backends (#477)\n\n* Add affine op\r\n\r\n* Sync import convention\r\n\r\n* Use `np.random.random`\r\n\r\n* Refactor jax implementation\r\n\r\n* Fix\r\n\r\n* Address fchollet's comments\r\n\r\n* Update docstring\r\n\r\n* Fix test\r\n\r\n* Replace method with interpolation\r\n\r\n* Replace method with interpolation\r\n\r\n* Replace method with interpolation\r\n\r\n* Update test",
        "commit_url": "https://github.com/keras-team/keras/commit/d7b3eae31f30e8fab4485ef4ff1709838df5a0ba",
        "buggy_code": "method=self.interpolation,",
        "fixed_code": "interpolation=self.interpolation,",
        "patch": "@@ -81,7 +81,7 @@ def call(self, inputs):\n             outputs = self.backend.image.resize(\n                 inputs,\n                 size=size,\n-                method=self.interpolation,\n+                interpolation=self.interpolation,\n                 data_format=self.data_format,\n             )\n         return outputs"
    },
    {
        "commit_id": "d7b3eae31f30e8fab4485ef4ff1709838df5a0ba",
        "commit_message": "Add `affine_transform` op to all backends (#477)\n\n* Add affine op\r\n\r\n* Sync import convention\r\n\r\n* Use `np.random.random`\r\n\r\n* Refactor jax implementation\r\n\r\n* Fix\r\n\r\n* Address fchollet's comments\r\n\r\n* Update docstring\r\n\r\n* Fix test\r\n\r\n* Replace method with interpolation\r\n\r\n* Replace method with interpolation\r\n\r\n* Replace method with interpolation\r\n\r\n* Update test",
        "commit_url": "https://github.com/keras-team/keras/commit/d7b3eae31f30e8fab4485ef4ff1709838df5a0ba",
        "buggy_code": "x = ops.image.resize(x, new_shape, method=interpolation)",
        "fixed_code": "x = ops.image.resize(x, new_shape, interpolation=interpolation)",
        "patch": "@@ -160,7 +160,7 @@ def _resize_images(\n             x = ops.repeat(x, height_factor, axis=1)\n             x = ops.repeat(x, width_factor, axis=2)\n         else:\n-            x = ops.image.resize(x, new_shape, method=interpolation)\n+            x = ops.image.resize(x, new_shape, interpolation=interpolation)\n         if data_format == \"channels_first\":\n             x = ops.transpose(x, [0, 3, 1, 2])\n "
    },
    {
        "commit_id": "d7b3eae31f30e8fab4485ef4ff1709838df5a0ba",
        "commit_message": "Add `affine_transform` op to all backends (#477)\n\n* Add affine op\r\n\r\n* Sync import convention\r\n\r\n* Use `np.random.random`\r\n\r\n* Refactor jax implementation\r\n\r\n* Fix\r\n\r\n* Address fchollet's comments\r\n\r\n* Update docstring\r\n\r\n* Fix test\r\n\r\n* Replace method with interpolation\r\n\r\n* Replace method with interpolation\r\n\r\n* Replace method with interpolation\r\n\r\n* Update test",
        "commit_url": "https://github.com/keras-team/keras/commit/d7b3eae31f30e8fab4485ef4ff1709838df5a0ba",
        "buggy_code": "img, size=size, method=interpolation, data_format=data_format",
        "fixed_code": "img, size=size, interpolation=interpolation, data_format=data_format",
        "patch": "@@ -439,7 +439,7 @@ def smart_resize(\n             ]\n \n     img = backend_module.image.resize(\n-        img, size=size, method=interpolation, data_format=data_format\n+        img, size=size, interpolation=interpolation, data_format=data_format\n     )\n \n     if isinstance(x, np.ndarray):"
    },
    {
        "commit_id": "42bdabf76ad0f1b03f2f662b573bdee627d1561f",
        "commit_message": "Resolve shape via ops in broadcast_to operation (#547)",
        "commit_url": "https://github.com/keras-team/keras/commit/42bdabf76ad0f1b03f2f662b573bdee627d1561f",
        "buggy_code": "sample_weight = ops.broadcast_to(sample_weight, y_true.shape)",
        "fixed_code": "sample_weight = ops.broadcast_to(sample_weight, ops.shape(y_true))",
        "patch": "@@ -106,7 +106,7 @@ def update_state(self, y_true, y_pred, sample_weight=None):\n         if len(sample_weight.shape) > 1:\n             sample_weight = ops.reshape(sample_weight, [-1])\n \n-        sample_weight = ops.broadcast_to(sample_weight, y_true.shape)\n+        sample_weight = ops.broadcast_to(sample_weight, ops.shape(y_true))\n \n         if self.ignore_class is not None:\n             ignore_class = ops.convert_to_tensor("
    },
    {
        "commit_id": "97135b796642329611df5a35dfd4c66975f71445",
        "commit_message": "Fix KerasTensor namespace",
        "commit_url": "https://github.com/keras-team/keras/commit/97135b796642329611df5a35dfd4c66975f71445",
        "buggy_code": "inputs, keras_core.backend.KerasTensor",
        "fixed_code": "inputs, keras_core.KerasTensor",
        "patch": "@@ -22,7 +22,7 @@ def __init__(self, **kwargs):\n \n     def __call__(self, inputs, **kwargs):\n         if backend_utils.in_tf_graph() and not isinstance(\n-            inputs, keras_core.backend.KerasTensor\n+            inputs, keras_core.KerasTensor\n         ):\n             # We're in a TF graph, e.g. a tf.data pipeline.\n             self.backend.set_backend(\"tensorflow\")"
    },
    {
        "commit_id": "de96a5dd05f8d06c15c317e070b9746e1d9a6ce9",
        "commit_message": "fix: typo",
        "commit_url": "https://github.com/keras-team/keras/commit/de96a5dd05f8d06c15c317e070b9746e1d9a6ce9",
        "buggy_code": "self.backend.all((training, h_diff >= 0, w_diff >= 0)),",
        "fixed_code": "self.backend.ops.all((training, h_diff >= 0, w_diff >= 0)),",
        "patch": "@@ -132,7 +132,7 @@ def resize():\n             return self.backend.cast(outputs, self.compute_dtype)\n \n         outputs = self.backend.cond(\n-            self.backend.all((training, h_diff >= 0, w_diff >= 0)),\n+            self.backend.ops.all((training, h_diff >= 0, w_diff >= 0)),\n             random_crop,\n             resize,\n         )"
    },
    {
        "commit_id": "c8953e5a7d3742b77296a2e009214e4cceb417a9",
        "commit_message": "Fix build",
        "commit_url": "https://github.com/keras-team/keras/commit/c8953e5a7d3742b77296a2e009214e4cceb417a9",
        "buggy_code": "from keras_core.src import __version__  # noqa: E402",
        "fixed_code": "from keras_core.src.version import __version__  # noqa: E402",
        "patch": "@@ -60,7 +60,7 @@ def build():\n         namex.generate_api_files(package, code_directory=\"src\", verbose=True)\n \n         # Make sure to export the __version__ string\n-        from keras_core.src import __version__  # noqa: E402\n+        from keras_core.src.version import __version__  # noqa: E402\n \n         with open(os.path.join(package, \"__init__.py\")) as f:\n             init_contents = f.read()"
    },
    {
        "commit_id": "c60b47b71d9f8a79797e78948878e7b2a3ca8125",
        "commit_message": "bug fix for torch gpu (#438)\n\nCo-authored-by: Haifeng Jin <haifeng-jin@users.noreply.github.com>",
        "commit_url": "https://github.com/keras-team/keras/commit/c60b47b71d9f8a79797e78948878e7b2a3ca8125",
        "buggy_code": "x = np.array(x, dtype=dtype)",
        "fixed_code": "x = backend.convert_to_numpy(x).astype(dtype)",
        "patch": "@@ -304,7 +304,7 @@ def convert_single_array(x):\n             # `torch.Tensor`, as well as any other tensor-like object that has\n             # added numpy support.\n             if hasattr(x, \"__array__\"):\n-                x = np.array(x, dtype=dtype)\n+                x = backend.convert_to_numpy(x).astype(dtype)\n             else:\n                 raise ValueError(\n                     \"Expected a NumPy array, tf.Tensor, tf.RaggedTensor, \""
    },
    {
        "commit_id": "5f4c9e7083bc649941e5c00b9b1d7a926deaa159",
        "commit_message": "Minor fix",
        "commit_url": "https://github.com/keras-team/keras/commit/5f4c9e7083bc649941e5c00b9b1d7a926deaa159",
        "buggy_code": "if layer._call_has_training_arg():",
        "fixed_code": "if layer._call_has_training_arg() and training is not None:",
        "patch": "@@ -179,7 +179,7 @@ def call(self, inputs, training=None, mask=None):\n             kwargs = {}\n             if layer._call_has_mask_arg():\n                 kwargs[\"mask\"] = mask\n-            if layer._call_has_training_arg():\n+            if layer._call_has_training_arg() and training is not None:\n                 kwargs[\"training\"] = training\n             outputs = layer(inputs, **kwargs)\n             inputs = outputs"
    },
    {
        "commit_id": "92475f309e19380d4a6b7bfea773be80d09177ba",
        "commit_message": "Fix the get_device() function for the torch backend (#418)",
        "commit_url": "https://github.com/keras-team/keras/commit/92475f309e19380d4a6b7bfea773be80d09177ba",
        "buggy_code": "get_default_device()",
        "fixed_code": "return get_default_device()",
        "patch": "@@ -46,7 +46,7 @@ def get_default_device():\n def get_device():\n     device = global_state.get_global_attribute(\"torch_device\", None)\n     if device is None:\n-        get_default_device()\n+        return get_default_device()\n     return device\n \n "
    },
    {
        "commit_id": "0423639799dcf5fa2fbde882af7d2e499b1ee446",
        "commit_message": "Merge pull request #18251 from pdyakov:patch-1\n\nPiperOrigin-RevId: 544451680",
        "commit_url": "https://github.com/keras-team/keras/commit/0423639799dcf5fa2fbde882af7d2e499b1ee446",
        "buggy_code": "v.assign(tf.zeros(v.shape))",
        "fixed_code": "v.assign(tf.zeros(v.shape, dtype=v.dtype))",
        "patch": "@@ -598,7 +598,7 @@ def result(self):\n \n     def reset_state(self):\n         for v in self.variables:\n-            v.assign(tf.zeros(v.shape))\n+            v.assign(tf.zeros(v.shape, dtype=v.dtype))\n \n     def get_config(self):\n         config = {"
    },
    {
        "commit_id": "f0b99c51cf7adb600e064480ae60c52c4bf44bb2",
        "commit_message": "Fix code style",
        "commit_url": "https://github.com/keras-team/keras/commit/f0b99c51cf7adb600e064480ae60c52c4bf44bb2",
        "buggy_code": "with backend.StatelessScope(state_mapping=mapping) as scope:",
        "fixed_code": "with backend.StatelessScope(state_mapping=mapping):",
        "patch": "@@ -154,7 +154,7 @@ def stateless_result(self, metric_variables):\n         mapping = list(zip(self.variables, metric_variables))\n \n         # Call in stateless scope\n-        with backend.StatelessScope(state_mapping=mapping) as scope:\n+        with backend.StatelessScope(state_mapping=mapping):\n             res = self.result()\n         return res\n "
    },
    {
        "commit_id": "402dcdcb2a2df441cdc34c2079dfdb12e7740d10",
        "commit_message": "Minor fix",
        "commit_url": "https://github.com/keras-team/keras/commit/402dcdcb2a2df441cdc34c2079dfdb12e7740d10",
        "buggy_code": "v.assign(ops.zeros(v.shape))",
        "fixed_code": "v.assign(ops.zeros(v.shape, dtype=v.dtype))",
        "patch": "@@ -554,7 +554,7 @@ def result(self):\n \n     def reset_state(self):\n         for v in self.variables:\n-            v.assign(ops.zeros(v.shape))\n+            v.assign(ops.zeros(v.shape, dtype=v.dtype))\n \n     def get_config(self):\n         config = {"
    },
    {
        "commit_id": "964db435b24a948662ebc96e806735d56a4f1479",
        "commit_message": "Add support for RaggedTensors for TensorFlow backend (#385)\n\n* Add support for RaggedTensors for TensorFlow backend\r\n\r\n* Add tests for Layer and Functional base classes\r\n\r\n* Add a test for the Sequential model\r\n\r\n* Move skipif decorator after named_parameters decorator\r\n\r\n* Fix the test for the FunctionalModel\r\n\r\n* Use a custom layer in Functional test\r\n\r\n* Use 4 space indent in docs\r\n\r\n* Fix PEP 501: line too long",
        "commit_url": "https://github.com/keras-team/keras/commit/964db435b24a948662ebc96e806735d56a4f1479",
        "buggy_code": "ARRAY_TYPES = (np.ndarray,)",
        "fixed_code": "ARRAY_TYPES = (np.ndarray, tf.RaggedTensor)",
        "patch": "@@ -14,7 +14,7 @@\n # Leave jax, tf, and torch arrays off this list. Instead we will use\n # `__array__` to detect these types. Doing so allows us to avoid importing a\n # backend framework we are not currently using just to do type-checking.\n-ARRAY_TYPES = (np.ndarray,)\n+ARRAY_TYPES = (np.ndarray, tf.RaggedTensor)\n if pandas:\n     ARRAY_TYPES = ARRAY_TYPES + (pandas.Series, pandas.DataFrame)\n "
    },
    {
        "commit_id": "eaa95600ef3e5c52ebfa82ed742ae02406d22e77",
        "commit_message": "fix tf assign (#408)\n\nCo-authored-by: chenmoneygithub <chenmoney@chenmoney-gpu-tf.us-west1-a.c.keras-team-gcp.internal>",
        "commit_url": "https://github.com/keras-team/keras/commit/eaa95600ef3e5c52ebfa82ed742ae02406d22e77",
        "buggy_code": "self.value.assign(value)",
        "fixed_code": "self._value.assign(tf.cast(value, self._value.dtype))",
        "patch": "@@ -28,7 +28,7 @@ def _initialize(self, value):\n         )\n \n     def _direct_assign(self, value):\n-        self.value.assign(value)\n+        self._value.assign(tf.cast(value, self._value.dtype))\n \n     def _convert_to_tensor(self, value, dtype=None):\n         return convert_to_tensor(value, dtype=dtype)"
    },
    {
        "commit_id": "ca8f90ac2e82344409e2f23b112fc8670aa1078d",
        "commit_message": "Fix issue with internal losses with jax backend.",
        "commit_url": "https://github.com/keras-team/keras/commit/ca8f90ac2e82344409e2f23b112fc8670aa1078d",
        "buggy_code": "ref_inputs = [self._inputs_struct]",
        "fixed_code": "ref_inputs = [self._nested_inputs]",
        "patch": "@@ -211,7 +211,7 @@ def _flatten_to_reference_inputs(self, inputs, allow_extra_keys=True):\n         if isinstance(inputs, dict):\n             ref_inputs = self._inputs_struct\n             if not nest.is_nested(ref_inputs):\n-                ref_inputs = [self._inputs_struct]\n+                ref_inputs = [self._nested_inputs]\n             if isinstance(ref_inputs, dict):\n                 # In the case that the graph is constructed with dict input\n                 # tensors, We will use the original dict key to map with the"
    },
    {
        "commit_id": "f53cca04e1401ddec7a359ce78be3d484f9f0454",
        "commit_message": "Fix typo in functional model input flattening (#402)\n\n* Fix typo in functional model input flattening\r\n\r\n* Add unit test",
        "commit_url": "https://github.com/keras-team/keras/commit/f53cca04e1401ddec7a359ce78be3d484f9f0454",
        "buggy_code": "ref_inputs = [self._nested_inputs]",
        "fixed_code": "ref_inputs = [self._inputs_struct]",
        "patch": "@@ -211,7 +211,7 @@ def _flatten_to_reference_inputs(self, inputs, allow_extra_keys=True):\n         if isinstance(inputs, dict):\n             ref_inputs = self._inputs_struct\n             if not nest.is_nested(ref_inputs):\n-                ref_inputs = [self._nested_inputs]\n+                ref_inputs = [self._inputs_struct]\n             if isinstance(ref_inputs, dict):\n                 # In the case that the graph is constructed with dict input\n                 # tensors, We will use the original dict key to map with the"
    },
    {
        "commit_id": "6810a0870e7c7d082c7774409f3d8ecaeecbf88c",
        "commit_message": "Fix torch bug #2",
        "commit_url": "https://github.com/keras-team/keras/commit/6810a0870e7c7d082c7774409f3d8ecaeecbf88c",
        "buggy_code": "output += inputs[i]",
        "fixed_code": "output = output + inputs[i]",
        "patch": "@@ -32,7 +32,7 @@ class Average(Merge):\n     def _merge_function(self, inputs):\n         output = inputs[0]\n         for i in range(1, len(inputs)):\n-            output += inputs[i]\n+            output = output + inputs[i]\n         return output / len(inputs)\n \n "
    },
    {
        "commit_id": "f42f8e28fd1e106c9392e8ba8fbb8e556af10e71",
        "commit_message": "Fix torch bug",
        "commit_url": "https://github.com/keras-team/keras/commit/f42f8e28fd1e106c9392e8ba8fbb8e556af10e71",
        "buggy_code": "output += inputs[i]",
        "fixed_code": "output = output + inputs[i]",
        "patch": "@@ -32,7 +32,7 @@ class Add(Merge):\n     def _merge_function(self, inputs):\n         output = inputs[0]\n         for i in range(1, len(inputs)):\n-            output += inputs[i]\n+            output = output + inputs[i]\n         return output\n \n "
    },
    {
        "commit_id": "1fe5d5e27f16eb55d1bdc3acc2fd5688e0be0c38",
        "commit_message": "Allow list shapes to truncated normal (#395)\n\nWe could also update our `self.add_variable` code to always pass tuple\r\nshapes, but I think the right fix is to allow either tuple or list\r\nshapes with a defensive cast.",
        "commit_url": "https://github.com/keras-team/keras/commit/1fe5d5e27f16eb55d1bdc3acc2fd5688e0be0c38",
        "buggy_code": "x = normal(shape + (4,), mean=0, stddev=1, dtype=dtype, seed=seed)",
        "fixed_code": "x = normal(tuple(shape) + (4,), mean=0, stddev=1, dtype=dtype, seed=seed)",
        "patch": "@@ -99,7 +99,7 @@ def randint(shape, minval, maxval, dtype=\"int32\", seed=None):\n def truncated_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n     # Take a larger standard normal dist, discard values outside 2 * stddev\n     # Offset by mean and stddev\n-    x = normal(shape + (4,), mean=0, stddev=1, dtype=dtype, seed=seed)\n+    x = normal(tuple(shape) + (4,), mean=0, stddev=1, dtype=dtype, seed=seed)\n     valid = (x > -2) & (x < 2)\n     indexes = valid.max(-1, keepdim=True)[1]\n     trunc_x = torch.empty(shape, device=get_device())"
    },
    {
        "commit_id": "9a2ee731b870313a9207007d8ae8ac5865b3b004",
        "commit_message": "Update Torch ops.array (#375)\n\n* Update Torch ops.array\r\n\r\nThis was previously inconsistent with Jax and TF, where ops.array produces an array/tensor of the native backend type. Instead this produced a NumPy array\r\n\r\n* Add ops test\r\n\r\n* Fix metrics tests\r\n\r\n* Update torch np.tile implementation",
        "commit_url": "https://github.com/keras-team/keras/commit/9a2ee731b870313a9207007d8ae8ac5865b3b004",
        "buggy_code": "ops.reshape(thresholds, thresh_pretile_shape), ops.array(thresh_tiles)",
        "fixed_code": "ops.reshape(thresholds, thresh_pretile_shape), thresh_tiles",
        "patch": "@@ -509,7 +509,7 @@ def update_confusion_matrix_variables(\n         data_tiles = [num_thresholds, 1]\n \n     thresh_tiled = ops.tile(\n-        ops.reshape(thresholds, thresh_pretile_shape), ops.array(thresh_tiles)\n+        ops.reshape(thresholds, thresh_pretile_shape), thresh_tiles\n     )\n \n     # Tile the predictions for every threshold."
    },
    {
        "commit_id": "5f9d052566f92821b323dabb111eb4679624ddfb",
        "commit_message": "Merge pull request #18233 from tilakrayal:patch-8\n\nPiperOrigin-RevId: 541932649",
        "commit_url": "https://github.com/keras-team/keras/commit/5f9d052566f92821b323dabb111eb4679624ddfb",
        "buggy_code": "if name in (\"mixed_float16\", \"mixed_bloat16\"):",
        "fixed_code": "if name in (\"mixed_float16\", \"mixed_bfloat16\"):",
        "patch": "@@ -198,7 +198,7 @@ def __init__(self, name):\n             raise TypeError(f\"'name' must be a string, but got: {name}\")\n         self._name = name\n         self._compute_dtype, self._variable_dtype = self._parse_name(name)\n-        if name in (\"mixed_float16\", \"mixed_bloat16\"):\n+        if name in (\"mixed_float16\", \"mixed_bfloat16\"):\n             device_compatibility_check.log_device_compatibility_check(name)\n \n     def _parse_name(self, name):"
    },
    {
        "commit_id": "e4243535f6d3fd412daebbea2fe4658b8a593bed",
        "commit_message": "fix typo (#373)",
        "commit_url": "https://github.com/keras-team/keras/commit/e4243535f6d3fd412daebbea2fe4658b8a593bed",
        "buggy_code": "@pytest.mark.skipIf(",
        "fixed_code": "@pytest.mark.skipif(",
        "patch": "@@ -357,7 +357,7 @@ def call(self, x, training=False):\n         y = layer(x)\n         self.assertEqual(ops.min(y), 1)\n \n-    @pytest.mark.skipIf(\n+    @pytest.mark.skipif(\n         backend.backend() == \"torch\",\n         reason=\"Torch backend has unimplemtned ops for mixed precision on CPU.\",\n     )"
    },
    {
        "commit_id": "8d453471d0ab180e31c1d259dd18084ab222cc69",
        "commit_message": "Fix torch failures (#365)\n\n* init\r\n\r\n* Fix dropout ops\r\n\r\n* Small fixes\r\n\r\n* fix norm layers\r\n\r\n* fix tets\r\n\r\n* more fixes\r\n\r\n* clean up\r\n\r\n* fix\r\n\r\n* fix format\r\n\r\n* fix\r\n\r\n* fix\r\n\r\n* fix comments\r\n\r\n* fix opes\r\n\r\n* fix casting\r\n\r\n* small fix\r\n\r\n* callback\r\n\r\n* more fixes\r\n\r\n* small\r\n\r\n* MEGA\r\n\r\n* clean up",
        "commit_url": "https://github.com/keras-team/keras/commit/8d453471d0ab180e31c1d259dd18084ab222cc69",
        "buggy_code": "output = np.array(output)",
        "fixed_code": "output = backend.convert_to_numpy(output)",
        "patch": "@@ -30,7 +30,7 @@ def test_max_norm(self):\n     def test_non_neg(self):\n         constraint_fn = constraints.NonNeg()\n         output = constraint_fn(get_example_array())\n-        output = np.array(output)\n+        output = backend.convert_to_numpy(output)\n         self.assertTrue((np.min(output, axis=1) >= 0.0).all())\n \n     def test_unit_norm(self):"
    },
    {
        "commit_id": "6376740aca209be59e6a1fda79635d45cb8a32e7",
        "commit_message": "Fix layer test in Torch backend (#360)\n\n* init\r\n\r\n* Fix dropout ops\r\n\r\n* Small fixes\r\n\r\n* fix norm layers\r\n\r\n* fix tets\r\n\r\n* more fixes\r\n\r\n* clean up\r\n\r\n* fix\r\n\r\n* fix format\r\n\r\n* fix\r\n\r\n* fix comments\r\n\r\n* fix comments\r\n\r\n* remove redundant copy\r\n\r\n* revert jax change to dodge the odd recursion issue",
        "commit_url": "https://github.com/keras-team/keras/commit/6376740aca209be59e6a1fda79635d45cb8a32e7",
        "buggy_code": "inv *= scale",
        "fixed_code": "inv = inv * scale",
        "patch": "@@ -205,7 +205,7 @@ def _broadcast(v):\n         # Compute the batch normalization.\n         inv = 1 / ops.sqrt(variance + self.epsilon)\n         if scale is not None:\n-            inv *= scale\n+            inv = inv * scale\n \n         x = offset - mean * inv if offset is not None else -mean * inv\n         outputs = inputs * ops.cast(inv, inputs.dtype) + ops.cast("
    },
    {
        "commit_id": "6376740aca209be59e6a1fda79635d45cb8a32e7",
        "commit_message": "Fix layer test in Torch backend (#360)\n\n* init\r\n\r\n* Fix dropout ops\r\n\r\n* Small fixes\r\n\r\n* fix norm layers\r\n\r\n* fix tets\r\n\r\n* more fixes\r\n\r\n* clean up\r\n\r\n* fix\r\n\r\n* fix format\r\n\r\n* fix\r\n\r\n* fix comments\r\n\r\n* fix comments\r\n\r\n* remove redundant copy\r\n\r\n* revert jax change to dodge the odd recursion issue",
        "commit_url": "https://github.com/keras-team/keras/commit/6376740aca209be59e6a1fda79635d45cb8a32e7",
        "buggy_code": "inputs = tf.convert_to_tensor(np.array(inputs))",
        "fixed_code": "inputs = tf.convert_to_tensor(backend.convert_to_numpy(inputs))",
        "patch": "@@ -187,7 +187,7 @@ def compute_output_spec(self, inputs):\n \n     def __call__(self, inputs):\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, backend.KerasTensor)):\n-            inputs = tf.convert_to_tensor(np.array(inputs))\n+            inputs = tf.convert_to_tensor(backend.convert_to_numpy(inputs))\n         if not self.built:\n             self.build(inputs.shape)\n         return super().__call__(inputs)"
    },
    {
        "commit_id": "6376740aca209be59e6a1fda79635d45cb8a32e7",
        "commit_message": "Fix layer test in Torch backend (#360)\n\n* init\r\n\r\n* Fix dropout ops\r\n\r\n* Small fixes\r\n\r\n* fix norm layers\r\n\r\n* fix tets\r\n\r\n* more fixes\r\n\r\n* clean up\r\n\r\n* fix\r\n\r\n* fix format\r\n\r\n* fix\r\n\r\n* fix comments\r\n\r\n* fix comments\r\n\r\n* remove redundant copy\r\n\r\n* revert jax change to dodge the odd recursion issue",
        "commit_url": "https://github.com/keras-team/keras/commit/6376740aca209be59e6a1fda79635d45cb8a32e7",
        "buggy_code": "inputs = tf.convert_to_tensor(np.array(inputs))",
        "fixed_code": "inputs = tf.convert_to_tensor(backend.convert_to_numpy(inputs))",
        "patch": "@@ -68,7 +68,7 @@ def __init__(self, height, width, seed=None, name=None, **kwargs):\n \n     def call(self, inputs, training=True):\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n-            inputs = tf.convert_to_tensor(np.array(inputs))\n+            inputs = tf.convert_to_tensor(backend.convert_to_numpy(inputs))\n         outputs = self.layer.call(inputs, training=training)\n         if (\n             backend.backend() != \"tensorflow\""
    },
    {
        "commit_id": "6376740aca209be59e6a1fda79635d45cb8a32e7",
        "commit_message": "Fix layer test in Torch backend (#360)\n\n* init\r\n\r\n* Fix dropout ops\r\n\r\n* Small fixes\r\n\r\n* fix norm layers\r\n\r\n* fix tets\r\n\r\n* more fixes\r\n\r\n* clean up\r\n\r\n* fix\r\n\r\n* fix format\r\n\r\n* fix\r\n\r\n* fix comments\r\n\r\n* fix comments\r\n\r\n* remove redundant copy\r\n\r\n* revert jax change to dodge the odd recursion issue",
        "commit_url": "https://github.com/keras-team/keras/commit/6376740aca209be59e6a1fda79635d45cb8a32e7",
        "buggy_code": "inputs = tf.convert_to_tensor(np.array(inputs))",
        "fixed_code": "inputs = tf.convert_to_tensor(backend.convert_to_numpy(inputs))",
        "patch": "@@ -60,7 +60,7 @@ def __init__(\n \n     def call(self, inputs, training=True):\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n-            inputs = tf.convert_to_tensor(np.array(inputs))\n+            inputs = tf.convert_to_tensor(backend.convert_to_numpy(inputs))\n         outputs = self.layer.call(inputs, training=training)\n         if (\n             backend.backend() != \"tensorflow\""
    },
    {
        "commit_id": "6376740aca209be59e6a1fda79635d45cb8a32e7",
        "commit_message": "Fix layer test in Torch backend (#360)\n\n* init\r\n\r\n* Fix dropout ops\r\n\r\n* Small fixes\r\n\r\n* fix norm layers\r\n\r\n* fix tets\r\n\r\n* more fixes\r\n\r\n* clean up\r\n\r\n* fix\r\n\r\n* fix format\r\n\r\n* fix\r\n\r\n* fix comments\r\n\r\n* fix comments\r\n\r\n* remove redundant copy\r\n\r\n* revert jax change to dodge the odd recursion issue",
        "commit_url": "https://github.com/keras-team/keras/commit/6376740aca209be59e6a1fda79635d45cb8a32e7",
        "buggy_code": "inputs = tf.convert_to_tensor(np.array(inputs))",
        "fixed_code": "inputs = tf.convert_to_tensor(backend.convert_to_numpy(inputs))",
        "patch": "@@ -103,7 +103,7 @@ def __init__(\n \n     def call(self, inputs, training=True):\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n-            inputs = tf.convert_to_tensor(np.array(inputs))\n+            inputs = tf.convert_to_tensor(backend.convert_to_numpy(inputs))\n         outputs = self.layer.call(inputs, training=training)\n         if (\n             backend.backend() != \"tensorflow\""
    },
    {
        "commit_id": "6376740aca209be59e6a1fda79635d45cb8a32e7",
        "commit_message": "Fix layer test in Torch backend (#360)\n\n* init\r\n\r\n* Fix dropout ops\r\n\r\n* Small fixes\r\n\r\n* fix norm layers\r\n\r\n* fix tets\r\n\r\n* more fixes\r\n\r\n* clean up\r\n\r\n* fix\r\n\r\n* fix format\r\n\r\n* fix\r\n\r\n* fix comments\r\n\r\n* fix comments\r\n\r\n* remove redundant copy\r\n\r\n* revert jax change to dodge the odd recursion issue",
        "commit_url": "https://github.com/keras-team/keras/commit/6376740aca209be59e6a1fda79635d45cb8a32e7",
        "buggy_code": "inputs = tf.convert_to_tensor(np.array(inputs))",
        "fixed_code": "inputs = tf.convert_to_tensor(backend.convert_to_numpy(inputs))",
        "patch": "@@ -93,7 +93,7 @@ def __init__(\n \n     def call(self, inputs, training=True):\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n-            inputs = tf.convert_to_tensor(np.array(inputs))\n+            inputs = tf.convert_to_tensor(backend.convert_to_numpy(inputs))\n         outputs = self.layer.call(inputs, training=training)\n         if (\n             backend.backend() != \"tensorflow\""
    },
    {
        "commit_id": "6376740aca209be59e6a1fda79635d45cb8a32e7",
        "commit_message": "Fix layer test in Torch backend (#360)\n\n* init\r\n\r\n* Fix dropout ops\r\n\r\n* Small fixes\r\n\r\n* fix norm layers\r\n\r\n* fix tets\r\n\r\n* more fixes\r\n\r\n* clean up\r\n\r\n* fix\r\n\r\n* fix format\r\n\r\n* fix\r\n\r\n* fix comments\r\n\r\n* fix comments\r\n\r\n* remove redundant copy\r\n\r\n* revert jax change to dodge the odd recursion issue",
        "commit_url": "https://github.com/keras-team/keras/commit/6376740aca209be59e6a1fda79635d45cb8a32e7",
        "buggy_code": "inputs = tf.convert_to_tensor(np.array(inputs))",
        "fixed_code": "inputs = tf.convert_to_tensor(backend.convert_to_numpy(inputs))",
        "patch": "@@ -116,7 +116,7 @@ def __init__(\n \n     def call(self, inputs, training=True):\n         if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n-            inputs = tf.convert_to_tensor(np.array(inputs))\n+            inputs = tf.convert_to_tensor(backend.convert_to_numpy(inputs))\n         outputs = self.layer.call(inputs, training=training)\n         if (\n             backend.backend() != \"tensorflow\""
    },
    {
        "commit_id": "6376740aca209be59e6a1fda79635d45cb8a32e7",
        "commit_message": "Fix layer test in Torch backend (#360)\n\n* init\r\n\r\n* Fix dropout ops\r\n\r\n* Small fixes\r\n\r\n* fix norm layers\r\n\r\n* fix tets\r\n\r\n* more fixes\r\n\r\n* clean up\r\n\r\n* fix\r\n\r\n* fix format\r\n\r\n* fix\r\n\r\n* fix comments\r\n\r\n* fix comments\r\n\r\n* remove redundant copy\r\n\r\n* revert jax change to dodge the odd recursion issue",
        "commit_url": "https://github.com/keras-team/keras/commit/6376740aca209be59e6a1fda79635d45cb8a32e7",
        "buggy_code": "np.testing.assert_array_equal(",
        "fixed_code": "self.assertAllClose(",
        "patch": "@@ -88,7 +88,7 @@ def test_upsampling_3d(\n     def test_upsampling_3d_correctness(self):\n         input_shape = (2, 1, 2, 1, 3)\n         x = np.arange(np.prod(input_shape)).reshape(input_shape)\n-        np.testing.assert_array_equal(\n+        self.assertAllClose(\n             layers.UpSampling3D(size=(2, 2, 2))(x),\n             np.array(\n                 ["
    },
    {
        "commit_id": "272590f71e5f360bf58f3b52ad26dffead265fc2",
        "commit_message": "Merge pull request #18223 from SuryanarayanaY:patch-2\n\nPiperOrigin-RevId: 540306882",
        "commit_url": "https://github.com/keras-team/keras/commit/272590f71e5f360bf58f3b52ad26dffead265fc2",
        "buggy_code": "padding: Int, or tuple of int (length 2), or dictionary.",
        "fixed_code": "padding: Int, or tuple of int (length 2).",
        "patch": "@@ -56,7 +56,7 @@ class ZeroPadding1D(Layer):\n         [ 0  0  0]]], shape=(2, 6, 3), dtype=int64)\n \n     Args:\n-        padding: Int, or tuple of int (length 2), or dictionary.\n+        padding: Int, or tuple of int (length 2).\n             - If int:\n             How many zeros to add at the beginning and end of\n             the padding dimension (axis 1)."
    },
    {
        "commit_id": "49c6ddbc428829d89c1cbdb413465079f00ddcc3",
        "commit_message": "bug fix for torch sample_weights on *_on_batch methods (#332)\n\nCo-authored-by: Haifeng Jin <haifeng-jin@users.noreply.github.com>",
        "commit_url": "https://github.com/keras-team/keras/commit/49c6ddbc428829d89c1cbdb413465079f00ddcc3",
        "buggy_code": "values *= sample_weight",
        "fixed_code": "values = values * sample_weight",
        "patch": "@@ -146,7 +146,7 @@ def reduce_weighted_values(\n         sample_weight = ops.cast(sample_weight, values.dtype)\n         # Update dimensions of `sample_weight` to match `losses`.\n         values, sample_weight = squeeze_to_same_rank(values, sample_weight)\n-        values *= sample_weight\n+        values = values * sample_weight\n \n     # Apply reduction function to the individual weighted losses.\n     loss = reduce_values(values, reduction)"
    },
    {
        "commit_id": "2aea261d7f9f5786d2a3f1a634fb86cf13a61465",
        "commit_message": "Fix op-return dependencies on tf.function\n\nPiperOrigin-RevId: 539691927",
        "commit_url": "https://github.com/keras-team/keras/commit/2aea261d7f9f5786d2a3f1a634fb86cf13a61465",
        "buggy_code": "return m.update_state(100)",
        "fixed_code": "m.update_state(100)",
        "patch": "@@ -224,7 +224,7 @@ def test_function_wrapped_reset_state(self):\n         @tf.function\n         def reset_in_fn():\n             m.reset_state()\n-            return m.update_state(100)\n+            m.update_state(100)\n \n         for _ in range(5):\n             self.evaluate(reset_in_fn())"
    },
    {
        "commit_id": "83636fc1917654564a7eff6e58edf52bb24e318d",
        "commit_message": "Small ops fixes for Torch unit tests (#316)\n\n* Add PyTorch numpy functionality\r\n\r\n* Add dtype conversion\r\n\r\n* Partial fix for PyTorch numpy tests\r\n\r\n* small logic fix\r\n\r\n* Revert numpy_test\r\n\r\n* Add tensor conversion to numpy\r\n\r\n* Fix some arithmetic tests\r\n\r\n* Fix some torch functions for numpy compatibility\r\n\r\n* Fix pytorch ops for numpy compatibility, add TODOs\r\n\r\n* Fix formatting\r\n\r\n* Implement nits and fix dtype standardization\r\n\r\n* Add pytest skipif decorator and fix nits\r\n\r\n* Fix formatting and rename dtypes map\r\n\r\n* Split tests by backend\r\n\r\n* Merge space\r\n\r\n* Fix dtype issues from new type checking\r\n\r\n* Implement torch.full and torch.full_like numpy compatible\r\n\r\n* Implements logspace and linspace with tensor support for start and stop\r\n\r\n* Replace len of shape with ndim\r\n\r\n* Fix formatting\r\n\r\n* Implement torch.trace\r\n\r\n* Implement eye k diagonal arg\r\n\r\n* Implement torch.tri\r\n\r\n* Fix formatting issues\r\n\r\n* Fix torch.take dimensionality\r\n\r\n* Add split functionality\r\n\r\n* Revert torch.eye implementation to prevent conflict\r\n\r\n* Implement all padding modes\r\n\r\n* Adds torch image resizing and torchvision dependency.\r\n\r\n* Fix conditional syntax\r\n\r\n* Make torchvision import optional\r\n\r\n* Partial implementation of torch RNN\r\n\r\n* Duplicate torch demo file\r\n\r\n* Small ops fixes for torch unit tests\r\n\r\n* delete nonfunctional gpu test file\r\n\r\n* Revert rnn and formatting fixes\r\n\r\n* Revert progbar\r\n\r\n* Fix formatting",
        "commit_url": "https://github.com/keras-team/keras/commit/83636fc1917654564a7eff6e58edf52bb24e318d",
        "buggy_code": "max_x = torch.max(x, dim=axis, keepdim=True).values",
        "fixed_code": "max_x = torch.amax(x, dim=axis, keepdim=True)",
        "patch": "@@ -58,7 +58,7 @@ def logsumexp(x, axis=None, keepdims=False):\n         max_x = torch.max(x)\n         return torch.log(torch.sum(torch.exp(x - max_x))) + max_x\n \n-    max_x = torch.max(x, dim=axis, keepdim=True).values\n+    max_x = torch.amax(x, dim=axis, keepdim=True)\n     result = (\n         torch.log(torch.sum(torch.exp(x - max_x), dim=axis, keepdim=True))\n         + max_x"
    },
    {
        "commit_id": "bf0bd94515d9e3c1e4778e30866e45a8ee20ca48",
        "commit_message": "Fix Aurelien's issue",
        "commit_url": "https://github.com/keras-team/keras/commit/bf0bd94515d9e3c1e4778e30866e45a8ee20ca48",
        "buggy_code": "lambda x: ops.convert_to_tensor(x, dtype=y_pred.dtype), y_true",
        "fixed_code": "lambda x: ops.convert_to_tensor(x, dtype=dtype), y_true",
        "patch": "@@ -38,7 +38,7 @@ def __call__(self, y_true, y_pred, sample_weight=None):\n                 lambda x: ops.convert_to_tensor(x, dtype=dtype), y_pred\n             )\n             y_true = nest.map_structure(\n-                lambda x: ops.convert_to_tensor(x, dtype=y_pred.dtype), y_true\n+                lambda x: ops.convert_to_tensor(x, dtype=dtype), y_true\n             )\n \n             losses = self.call(y_true, y_pred)"
    },
    {
        "commit_id": "5c3177064111d0ef8f9b35279208bbb406544e0e",
        "commit_message": "Add WGAN example and fix minor issues.",
        "commit_url": "https://github.com/keras-team/keras/commit/5c3177064111d0ef8f9b35279208bbb406544e0e",
        "buggy_code": "@keras_core_export(\"keras_core.datasets.mnist.load_data\")",
        "fixed_code": "@keras_core_export(\"keras_core.datasets.fashion_mnist.load_data\")",
        "patch": "@@ -9,7 +9,7 @@\n from keras_core.utils.file_utils import get_file\n \n \n-@keras_core_export(\"keras_core.datasets.mnist.load_data\")\n+@keras_core_export(\"keras_core.datasets.fashion_mnist.load_data\")\n def load_data():\n     \"\"\"Loads the Fashion-MNIST dataset.\n "
    },
    {
        "commit_id": "6ca701bb42ef4be9edd7e6f428498730d77a0eb1",
        "commit_message": "Merge pull request #18205 from keras-team:sachinprasadhs-patch-6\n\nPiperOrigin-RevId: 538835899",
        "commit_url": "https://github.com/keras-team/keras/commit/6ca701bb42ef4be9edd7e6f428498730d77a0eb1",
        "buggy_code": "Call Args:",
        "fixed_code": "Call arguments:",
        "patch": "@@ -42,7 +42,7 @@ class BaseDenseAttention(base_layer.BaseRandomLayer):\n         dropout: Float between 0 and 1. Fraction of the units to drop for the\n             attention scores.\n \n-    Call Args:\n+    Call arguments:\n         inputs: List of the following tensors:\n             * query: Query `Tensor` of shape `[batch_size, Tq, dim]`.\n             * value: Value `Tensor` of shape `[batch_size, Tv, dim]`."
    },
    {
        "commit_id": "b061f40b1d9911fc6b0958868de6213b38ed37ec",
        "commit_message": "[NumPy] Fix uses of functions deprecated in NumPy 1.25.\n\nNumPy 1.25 deprecates a number of function aliases (https://github.com/numpy/numpy/releases/tag/v1.25.0rc1)\n\nThis change replaces uses of the deprecated names with their recommended replacements:\n* `np.round_` -> `np.round`\n* `np.product` -> `np.prod`\n* `np.cumproduct` -> `np.cumprod`\n* `np.sometrue` -> `np.any`\n* `np.alltrue` -> `np.all`\n\nThe deprecated functions will issue a `DeprecationWarning` under NumPy 1.25, and will be removed in NumPy 2.0.\n\nPiperOrigin-RevId: 538824429",
        "commit_url": "https://github.com/keras-team/keras/commit/b061f40b1d9911fc6b0958868de6213b38ed37ec",
        "buggy_code": "np.alltrue(decode_truth[i] == backend.eval(decode_pred_tf[i]))",
        "fixed_code": "np.all(decode_truth[i] == backend.eval(decode_pred_tf[i]))",
        "patch": "@@ -2415,7 +2415,7 @@ def test_ctc_decode(self):\n         log_prob_pred = backend.eval(log_prob_pred_tf)\n         for i in range(top_paths):\n             self.assertTrue(\n-                np.alltrue(decode_truth[i] == backend.eval(decode_pred_tf[i]))\n+                np.all(decode_truth[i] == backend.eval(decode_pred_tf[i]))\n             )\n         self.assertAllClose(log_prob_truth, log_prob_pred)\n "
    },
    {
        "commit_id": "f7dccb740a3f40cbecb2609f9e303aa4689c8c56",
        "commit_message": "Change the order of param \"mesh\" for DTensor based strategy.\n\nThis will make it consistent with the existing API, so that user won't hit issue if they use positional arg to init the strategy instance.\n\nPiperOrigin-RevId: 538803225",
        "commit_url": "https://github.com/keras-team/keras/commit/f7dccb740a3f40cbecb2609f9e303aa4689c8c56",
        "buggy_code": "strategy = dtensor_mirrored_strategy.MirroredStrategy(self.mesh)",
        "fixed_code": "strategy = dtensor_mirrored_strategy.MirroredStrategy(mesh=self.mesh)",
        "patch": "@@ -49,7 +49,7 @@ def setUp(self):\n         self.mesh = self.configTestMesh(mesh_dict)\n \n     def test_strategy_backed_by_dtensor(self):\n-        strategy = dtensor_mirrored_strategy.MirroredStrategy(self.mesh)\n+        strategy = dtensor_mirrored_strategy.MirroredStrategy(mesh=self.mesh)\n \n         with strategy.scope():\n             self.assertTrue(utils.running_with_dtensor_strategy())"
    },
    {
        "commit_id": "942d5958d4b8f696a5154032bf859b7db47db511",
        "commit_message": "Fix JAX test.",
        "commit_url": "https://github.com/keras-team/keras/commit/942d5958d4b8f696a5154032bf859b7db47db511",
        "buggy_code": "layers.Input(shape=input_shape, batch_size=batch_size),",
        "fixed_code": "layers.Input(shape=input_shape),",
        "patch": "@@ -30,7 +30,7 @@\n \n model = keras_core.Sequential(\n     [\n-        layers.Input(shape=input_shape, batch_size=batch_size),\n+        layers.Input(shape=input_shape),\n         layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n         layers.MaxPooling2D(pool_size=(2, 2)),\n         layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),"
    },
    {
        "commit_id": "942d5958d4b8f696a5154032bf859b7db47db511",
        "commit_message": "Fix JAX test.",
        "commit_url": "https://github.com/keras-team/keras/commit/942d5958d4b8f696a5154032bf859b7db47db511",
        "buggy_code": "`keras_core.mixed_precision.set_dtype_policy('mixed_float16')`.",
        "fixed_code": "`keras_core.mixed_precision.set_global_policy('mixed_float16')`.",
        "patch": "@@ -42,7 +42,7 @@ def set_floatx(value):\n     as this will likely cause numeric stability issues.\n     Instead, mixed precision, which leverages\n     a mix of `float16` and `float32`. It can be configured by calling\n-    `keras_core.mixed_precision.set_dtype_policy('mixed_float16')`.\n+    `keras_core.mixed_precision.set_global_policy('mixed_float16')`.\n \n     Args:\n         value: String; `'float16'`, `'float32'`, or `'float64'`."
    },
    {
        "commit_id": "942d5958d4b8f696a5154032bf859b7db47db511",
        "commit_message": "Fix JAX test.",
        "commit_url": "https://github.com/keras-team/keras/commit/942d5958d4b8f696a5154032bf859b7db47db511",
        "buggy_code": "if backend.backend() != \"tensorflow\":",
        "fixed_code": "if backend.backend() != \"tensorflow\" and tf.executing_eagerly():",
        "patch": "@@ -100,7 +100,7 @@ def compute_output_shape(self, input_shape):\n \n     def call(self, inputs):\n         outputs = self.layer.call(inputs)\n-        if backend.backend() != \"tensorflow\":\n+        if backend.backend() != \"tensorflow\" and tf.executing_eagerly():\n             outputs = backend.convert_to_tensor(outputs)\n         return outputs\n "
    },
    {
        "commit_id": "2923ef03f87fe2851fb6efa535df08ed14b3c09c",
        "commit_message": "Fix documentation about mixed precision. (#268)",
        "commit_url": "https://github.com/keras-team/keras/commit/2923ef03f87fe2851fb6efa535df08ed14b3c09c",
        "buggy_code": "`keras_core.mixed_precision.set_global_policy('mixed_float16')`.",
        "fixed_code": "`keras_core.mixed_precision.set_dtype_policy('mixed_float16')`.",
        "patch": "@@ -42,7 +42,7 @@ def set_floatx(value):\n     as this will likely cause numeric stability issues.\n     Instead, mixed precision, which leverages\n     a mix of `float16` and `float32`. It can be configured by calling\n-    `keras_core.mixed_precision.set_global_policy('mixed_float16')`.\n+    `keras_core.mixed_precision.set_dtype_policy('mixed_float16')`.\n \n     Args:\n         value: String; `'float16'`, `'float32'`, or `'float64'`."
    },
    {
        "commit_id": "5b1470a35e5d5dd7e8a8b11a93cfa8834a07160b",
        "commit_message": "fix math.segment_sum for torch backend (#263)\n\nCo-authored-by: Haifeng Jin <haifeng-jin@users.noreply.github.com>",
        "commit_url": "https://github.com/keras-team/keras/commit/5b1470a35e5d5dd7e8a8b11a93cfa8834a07160b",
        "buggy_code": "return torch.maximum(result, initial)",
        "fixed_code": "return torch.maximum(result, torch.full(result.shape, initial))",
        "patch": "@@ -58,7 +58,7 @@ def max(x, axis=None, keepdims=False, initial=None):\n         result = result.values\n \n     if initial is not None:\n-        return torch.maximum(result, initial)\n+        return torch.maximum(result, torch.full(result.shape, initial))\n     return result\n \n "
    },
    {
        "commit_id": "3cda5ad72712471a950da03c2ba45dd96fe6068a",
        "commit_message": "fix the torch tensor np conversion (#259)\n\n* fix the torch tensor np conversion\r\n\r\n* format the code\r\n\r\n* rebase main\r\n\r\n* fix tensorboard test\r\n\r\n---------\r\n\r\nCo-authored-by: Haifeng Jin <haifeng-jin@users.noreply.github.com>",
        "commit_url": "https://github.com/keras-team/keras/commit/3cda5ad72712471a950da03c2ba45dd96fe6068a",
        "buggy_code": "return np.array(self.value)",
        "fixed_code": "return np.array(self)",
        "patch": "@@ -81,7 +81,7 @@ def _maybe_autocast(self, value):\n         return value\n \n     def numpy(self):\n-        return np.array(self.value)\n+        return np.array(self)\n \n     @property\n     def value(self):"
    },
    {
        "commit_id": "3cda5ad72712471a950da03c2ba45dd96fe6068a",
        "commit_message": "fix the torch tensor np conversion (#259)\n\n* fix the torch tensor np conversion\r\n\r\n* format the code\r\n\r\n* rebase main\r\n\r\n* fix tensorboard test\r\n\r\n---------\r\n\r\nCo-authored-by: Haifeng Jin <haifeng-jin@users.noreply.github.com>",
        "commit_url": "https://github.com/keras-team/keras/commit/3cda5ad72712471a950da03c2ba45dd96fe6068a",
        "buggy_code": "np.testing.assert_allclose(np_output, expected_out)",
        "fixed_code": "self.assertAllClose(np_output, expected_out)",
        "patch": "@@ -56,7 +56,7 @@ def test_upsampling_2d(self, data_format, length_row, length_col):\n             expected_out = np.repeat(inputs, length_row, axis=1)\n             expected_out = np.repeat(expected_out, length_col, axis=2)\n \n-        np.testing.assert_allclose(np_output, expected_out)\n+        self.assertAllClose(np_output, expected_out)\n \n     @parameterized.product(\n         data_format=[\"channels_first\", \"channels_last\"],"
    },
    {
        "commit_id": "3cda5ad72712471a950da03c2ba45dd96fe6068a",
        "commit_message": "fix the torch tensor np conversion (#259)\n\n* fix the torch tensor np conversion\r\n\r\n* format the code\r\n\r\n* rebase main\r\n\r\n* fix tensorboard test\r\n\r\n---------\r\n\r\nCo-authored-by: Haifeng Jin <haifeng-jin@users.noreply.github.com>",
        "commit_url": "https://github.com/keras-team/keras/commit/3cda5ad72712471a950da03c2ba45dd96fe6068a",
        "buggy_code": "np.testing.assert_allclose(np_output, expected_out)",
        "fixed_code": "self.assertAllClose(np_output, expected_out)",
        "patch": "@@ -83,7 +83,7 @@ def test_upsampling_3d(\n             expected_out = np.repeat(expected_out, length_dim2, axis=2)\n             expected_out = np.repeat(expected_out, length_dim3, axis=3)\n \n-        np.testing.assert_allclose(np_output, expected_out)\n+        self.assertAllClose(np_output, expected_out)\n \n     def test_upsampling_3d_correctness(self):\n         input_shape = (2, 1, 2, 1, 3)"
    },
    {
        "commit_id": "6aac2389d533b365fb28656092aeaf6848d3d285",
        "commit_message": "Fix torch bug",
        "commit_url": "https://github.com/keras-team/keras/commit/6aac2389d533b365fb28656092aeaf6848d3d285",
        "buggy_code": "batch[1], class_weight",
        "fixed_code": "batch[1], self.class_weight",
        "patch": "@@ -225,7 +225,7 @@ def _standardize_batch(self, batch):\n                 )\n             if len(batch) == 2:\n                 sw = data_adapter_utils.class_weight_to_sample_weights(\n-                    batch[1], class_weight\n+                    batch[1], self.class_weight\n                 )\n                 batch = batch + (sw,)\n         return batch"
    },
    {
        "commit_id": "43071a78553b36a4074c929cf98bb07afe2a9ea7",
        "commit_message": "Fix arange to have the same defaults as numpy (#237)",
        "commit_url": "https://github.com/keras-team/keras/commit/43071a78553b36a4074c929cf98bb07afe2a9ea7",
        "buggy_code": "def arange(start, stop=None, step=None, dtype=None):",
        "fixed_code": "def arange(start, stop=None, step=1, dtype=None):",
        "patch": "@@ -90,7 +90,7 @@ def append(\n     return jnp.append(x1, x2, axis=axis)\n \n \n-def arange(start, stop=None, step=None, dtype=None):\n+def arange(start, stop=None, step=1, dtype=None):\n     return jnp.arange(start, stop, step=step, dtype=dtype)\n \n "
    },
    {
        "commit_id": "43071a78553b36a4074c929cf98bb07afe2a9ea7",
        "commit_message": "Fix arange to have the same defaults as numpy (#237)",
        "commit_url": "https://github.com/keras-team/keras/commit/43071a78553b36a4074c929cf98bb07afe2a9ea7",
        "buggy_code": "def arange(start, stop=None, step=None, dtype=None):",
        "fixed_code": "def arange(start, stop=None, step=1, dtype=None):",
        "patch": "@@ -94,7 +94,7 @@ def append(\n     return tfnp.append(x1, x2, axis=axis)\n \n \n-def arange(start, stop=None, step=None, dtype=None):\n+def arange(start, stop=None, step=1, dtype=None):\n     return tfnp.arange(start, stop, step=step, dtype=dtype)\n \n "
    },
    {
        "commit_id": "4b903c7eca7b709c15910f102cbaf55d6195d785",
        "commit_message": "Fix export name of MultiHeadAttention layer (#235)",
        "commit_url": "https://github.com/keras-team/keras/commit/4b903c7eca7b709c15910f102cbaf55d6195d785",
        "buggy_code": "@keras_core_export(\"keras_core.layers.Attention\")",
        "fixed_code": "@keras_core_export(\"keras_core.layers.MultiHeadAttention\")",
        "patch": "@@ -15,7 +15,7 @@\n from keras_core.layers.regularization.dropout import Dropout\n \n \n-@keras_core_export(\"keras_core.layers.Attention\")\n+@keras_core_export(\"keras_core.layers.MultiHeadAttention\")\n class MultiHeadAttention(Layer):\n     \"\"\"MultiHeadAttention layer.\n "
    },
    {
        "commit_id": "c3a37294580d4f914b467006040eee7be659cbe8",
        "commit_message": "Fix spelling of one_hot encoding.\n\nPiperOrigin-RevId: 536881336",
        "commit_url": "https://github.com/keras-team/keras/commit/c3a37294580d4f914b467006040eee7be659cbe8",
        "buggy_code": "`num_oov_indices` dimensions in the ont_hot encoding represent OOV values.",
        "fixed_code": "`num_oov_indices` dimensions in the one_hot encoding represent OOV values.",
        "patch": "@@ -192,7 +192,7 @@ class IntegerLookup(index_lookup.IndexLookup):\n     **One-hot output**\n \n     Configure the layer with `output_mode='one_hot'`. Note that the first\n-    `num_oov_indices` dimensions in the ont_hot encoding represent OOV values.\n+    `num_oov_indices` dimensions in the one_hot encoding represent OOV values.\n \n     >>> vocab = [12, 36, 1138, 42]\n     >>> data = tf.constant([12, 36, 1138, 42, 7]) # Note OOV tokens"
    },
    {
        "commit_id": "c3a37294580d4f914b467006040eee7be659cbe8",
        "commit_message": "Fix spelling of one_hot encoding.\n\nPiperOrigin-RevId: 536881336",
        "commit_url": "https://github.com/keras-team/keras/commit/c3a37294580d4f914b467006040eee7be659cbe8",
        "buggy_code": "`num_oov_indices` dimensions in the ont_hot encoding represent OOV values.",
        "fixed_code": "`num_oov_indices` dimensions in the one_hot encoding represent OOV values.",
        "patch": "@@ -188,7 +188,7 @@ class StringLookup(index_lookup.IndexLookup):\n     **One-hot output**\n \n     Configure the layer with `output_mode='one_hot'`. Note that the first\n-    `num_oov_indices` dimensions in the ont_hot encoding represent OOV values.\n+    `num_oov_indices` dimensions in the one_hot encoding represent OOV values.\n \n     >>> vocab = [\"a\", \"b\", \"c\", \"d\"]\n     >>> data = tf.constant([\"a\", \"b\", \"c\", \"d\", \"z\"])"
    },
    {
        "commit_id": "96a6fae639b8b6fd08edc9828e31c0f78b1764e9",
        "commit_message": "Fix test",
        "commit_url": "https://github.com/keras-team/keras/commit/96a6fae639b8b6fd08edc9828e31c0f78b1764e9",
        "buggy_code": "expected_num_non_trainable_weights=2,",
        "fixed_code": "expected_num_non_trainable_weights=3,",
        "patch": "@@ -17,7 +17,7 @@ def test_normalization_basics(self):\n             input_shape=(2, 3),\n             expected_output_shape=(2, 3),\n             expected_num_trainable_weights=0,\n-            expected_num_non_trainable_weights=2,\n+            expected_num_non_trainable_weights=3,\n             expected_num_seed_generators=0,\n             expected_num_losses=0,\n             supports_masking=True,"
    },
    {
        "commit_id": "2f92f7ce22283e40ecdddf7bce3faef651927590",
        "commit_message": "Fix a warning on the jax backend (#198)\n\nint64 is not a supported type in jax bye default. Trying to use it gets\r\nthe following error.\r\n\r\nUserWarning: Explicitly requested dtype int64 requested in array is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\r\n  target = jnp.array(target, dtype=\"int64\")\r\n\r\nWe can stick to int32 (which is what will be used anyway).",
        "commit_url": "https://github.com/keras-team/keras/commit/2f92f7ce22283e40ecdddf7bce3faef651927590",
        "buggy_code": "target = jnp.array(target, dtype=\"int64\")",
        "fixed_code": "target = jnp.array(target, dtype=\"int32\")",
        "patch": "@@ -493,7 +493,7 @@ def categorical_crossentropy(target, output, from_logits=False, axis=-1):\n \n \n def sparse_categorical_crossentropy(target, output, from_logits=False, axis=-1):\n-    target = jnp.array(target, dtype=\"int64\")\n+    target = jnp.array(target, dtype=\"int32\")\n     output = jnp.array(output)\n     if len(target.shape) == len(output.shape) and target.shape[-1] == 1:\n         target = jnp.squeeze(target, axis=-1)"
    },
    {
        "commit_id": "2cae421d476a980e516a19ba5d429825e8765e22",
        "commit_message": "Fix convlstm correctness.",
        "commit_url": "https://github.com/keras-team/keras/commit/2cae421d476a980e516a19ba5d429825e8765e22",
        "buggy_code": "recurrent_activation=\"hard_sigmoid\",",
        "fixed_code": "recurrent_activation=\"sigmoid\",",
        "patch": "@@ -129,7 +129,7 @@ def __init__(\n         data_format=None,\n         dilation_rate=1,\n         activation=\"tanh\",\n-        recurrent_activation=\"hard_sigmoid\",\n+        recurrent_activation=\"sigmoid\",\n         use_bias=True,\n         kernel_initializer=\"glorot_uniform\",\n         recurrent_initializer=\"orthogonal\","
    },
    {
        "commit_id": "2cae421d476a980e516a19ba5d429825e8765e22",
        "commit_message": "Fix convlstm correctness.",
        "commit_url": "https://github.com/keras-team/keras/commit/2cae421d476a980e516a19ba5d429825e8765e22",
        "buggy_code": "recurrent_activation=\"hard_sigmoid\",",
        "fixed_code": "recurrent_activation=\"sigmoid\",",
        "patch": "@@ -129,7 +129,7 @@ def __init__(\n         data_format=None,\n         dilation_rate=1,\n         activation=\"tanh\",\n-        recurrent_activation=\"hard_sigmoid\",\n+        recurrent_activation=\"sigmoid\",\n         use_bias=True,\n         kernel_initializer=\"glorot_uniform\",\n         recurrent_initializer=\"orthogonal\","
    },
    {
        "commit_id": "2cae421d476a980e516a19ba5d429825e8765e22",
        "commit_message": "Fix convlstm correctness.",
        "commit_url": "https://github.com/keras-team/keras/commit/2cae421d476a980e516a19ba5d429825e8765e22",
        "buggy_code": "recurrent_activation=\"hard_sigmoid\",",
        "fixed_code": "recurrent_activation=\"sigmoid\",",
        "patch": "@@ -128,7 +128,7 @@ def __init__(\n         data_format=None,\n         dilation_rate=1,\n         activation=\"tanh\",\n-        recurrent_activation=\"hard_sigmoid\",\n+        recurrent_activation=\"sigmoid\",\n         use_bias=True,\n         kernel_initializer=\"glorot_uniform\",\n         recurrent_initializer=\"orthogonal\","
    },
    {
        "commit_id": "4dd75e0f2754dfa538d278c94a264d4b5d581033",
        "commit_message": "Enable jit compile in training tests; fix some bugs.",
        "commit_url": "https://github.com/keras-team/keras/commit/4dd75e0f2754dfa538d278c94a264d4b5d581033",
        "buggy_code": "model.compile(optimizer=\"sgd\", loss=\"mse\", jit_compile=False)",
        "fixed_code": "model.compile(optimizer=\"sgd\", loss=\"mse\", jit_compile=True)",
        "patch": "@@ -273,7 +273,7 @@ def call(self, x):\n                     return self.layer(x)\n \n             model = TestModel(layer)\n-            model.compile(optimizer=\"sgd\", loss=\"mse\", jit_compile=False)\n+            model.compile(optimizer=\"sgd\", loss=\"mse\", jit_compile=True)\n             input_data = nest.map_structure(lambda x: np.array(x), input_data)\n             output_data = nest.map_structure(lambda x: np.array(x), output_data)\n             model.fit(input_data, output_data, verbose=0)"
    },
    {
        "commit_id": "427c5330057f1a5e4f2f9aaa2a5e47d9ca15d1b7",
        "commit_message": "Enable training tests and fix a range of bugs",
        "commit_url": "https://github.com/keras-team/keras/commit/427c5330057f1a5e4f2f9aaa2a5e47d9ca15d1b7",
        "buggy_code": "outputs = ops.reshape(outputs, input_shape)",
        "fixed_code": "outputs = ops.reshape(outputs, ops.shape(inputs))",
        "patch": "@@ -215,7 +215,7 @@ def _broadcast(v):\n         outputs = ops.cast(outputs, input_dtype)\n \n         # If some components of the shape got lost due to adjustments, fix that.\n-        outputs = ops.reshape(outputs, input_shape)\n+        outputs = ops.reshape(outputs, ops.shape(inputs))\n \n         return outputs\n "
    },
    {
        "commit_id": "fe21b1aa71a96806956dd086f945da97399a32dc",
        "commit_message": "Fix a range of bugs",
        "commit_url": "https://github.com/keras-team/keras/commit/fe21b1aa71a96806956dd086f945da97399a32dc",
        "buggy_code": "input_shape = inputs.shape",
        "fixed_code": "input_shape = ops.shape(inputs)",
        "patch": "@@ -38,7 +38,7 @@ def compute_output_shape(self, input_shape):\n         return (input_shape[0], self.n, input_shape[1])\n \n     def call(self, inputs):\n-        input_shape = inputs.shape\n+        input_shape = ops.shape(inputs)\n         reshaped = ops.reshape(inputs, (input_shape[0], 1, input_shape[1]))\n         return ops.repeat(reshaped, self.n, axis=1)\n "
    },
    {
        "commit_id": "fe21b1aa71a96806956dd086f945da97399a32dc",
        "commit_message": "Fix a range of bugs",
        "commit_url": "https://github.com/keras-team/keras/commit/fe21b1aa71a96806956dd086f945da97399a32dc",
        "buggy_code": "return ops.reshape(inputs, (inputs.shape[0],) + self.target_shape)",
        "fixed_code": "return ops.reshape(inputs, (ops.shape(inputs)[0],) + self.target_shape)",
        "patch": "@@ -47,7 +47,7 @@ def compute_output_shape(self, input_shape):\n         )\n \n     def call(self, inputs):\n-        return ops.reshape(inputs, (inputs.shape[0],) + self.target_shape)\n+        return ops.reshape(inputs, (ops.shape(inputs)[0],) + self.target_shape)\n \n     def get_config(self):\n         config = {\"target_shape\": self.target_shape}"
    },
    {
        "commit_id": "752f4b581b34e0b261453f41c292a706080b9d01",
        "commit_message": "Add `torch.math.*` (#189)\n\n* initial\r\n\r\n* Add ops\r\n\r\n* fix comments",
        "commit_url": "https://github.com/keras-team/keras/commit/752f4b581b34e0b261453f41c292a706080b9d01",
        "buggy_code": "dtype = to_torch_dtype(dtype or x.dtype)",
        "fixed_code": "dtype = to_torch_dtype(dtype or getattr(x, \"dtype\", None))",
        "patch": "@@ -49,7 +49,7 @@ def __torch_function__(self, func, types, args=(), kwargs=None):\n \n def convert_to_tensor(x, dtype=None):\n     # TODO: Need to address device placement arg of `as_tensor`\n-    dtype = to_torch_dtype(dtype or x.dtype)\n+    dtype = to_torch_dtype(dtype or getattr(x, \"dtype\", None))\n     if isinstance(x, Variable):\n         if dtype and dtype != x.dtype:\n             return x.value.to(dtype)"
    },
    {
        "commit_id": "ed4d749199c0cb4fe17b02cdaa0fddd7600c27a8",
        "commit_message": "Fix tests",
        "commit_url": "https://github.com/keras-team/keras/commit/ed4d749199c0cb4fe17b02cdaa0fddd7600c27a8",
        "buggy_code": "not backend.DYNAMIC_BATCH_SIZE_OK,",
        "fixed_code": "not backend.DYNAMIC_SHAPES_OK,",
        "patch": "@@ -65,7 +65,7 @@ def test_zero_padding_3d_with_same_padding(self, padding, data_format):\n             self.assertAllClose(outputs[:, 2:-2, 2:-2, 2:-2, :], inputs)\n \n     @pytest.mark.skipif(\n-        not backend.DYNAMIC_BATCH_SIZE_OK,\n+        not backend.DYNAMIC_SHAPES_OK,\n         reason=\"Backend does not support dynamic batch sizes\",\n     )\n     def test_zero_padding_3d_with_dynamic_spatial_dim(self):"
    },
    {
        "commit_id": "b4de088ee877ed9ad62e8819cb7a05b1c021ef1a",
        "commit_message": "Fix error message in `keras_core.layers.ZeroPadding3D`. (#185)",
        "commit_url": "https://github.com/keras-team/keras/commit/b4de088ee877ed9ad62e8819cb7a05b1c021ef1a",
        "buggy_code": "f\"Received: {padding}.\"",
        "fixed_code": "f\"Received: padding={padding}.\"",
        "patch": "@@ -95,7 +95,7 @@ def __init__(\n                 \"((left_dim1_pad, right_dim1_pad),\"\n                 \" (left_dim2_pad, right_dim2_pad),\"\n                 \" (left_dim3_pad, right_dim2_pad)). \"\n-                f\"Received: {padding}.\"\n+                f\"Received: padding={padding}.\"\n             )\n         self.input_spec = InputSpec(ndim=5)\n "
    },
    {
        "commit_id": "a426717f1011df09df12d23c4c79bcb3f685fecb",
        "commit_message": "Add IoU metrics: IoU, BinaryIoU, OneHotIoU, OneHotMeanIoU,  (#127)\n\n* Begin iou metrics\r\n\r\n* Attempt conversion without confusion matrix backend\r\n\r\n* Working ioumetrics, missing scatter op\r\n\r\n* Formatting\r\n\r\n* Docstring formatting\r\n\r\n* Add IoU metrics to manifest\r\n\r\n* Update with scatter op\r\n\r\n* Fix scatter op for repeated indices\r\n\r\n* Formatting\r\n\r\n* Supress warning for core operation import\r\n\r\n* Formatting",
        "commit_url": "https://github.com/keras-team/keras/commit/a426717f1011df09df12d23c4c79bcb3f685fecb",
        "buggy_code": "return zeros.at[key].set(values)",
        "fixed_code": "return zeros.at[key].add(values)",
        "patch": "@@ -156,4 +156,4 @@ def vectorized_map(function, elements):\n def scatter(indices, values, shape):\n     zeros = jnp.zeros(shape, values.dtype)\n     key = tuple(jnp.moveaxis(indices, -1, 0))\n-    return zeros.at[key].set(values)\n+    return zeros.at[key].add(values)"
    },
    {
        "commit_id": "39f8ef5e3c011cf3a80b2002e4e880573957d62b",
        "commit_message": "Fix numerical test",
        "commit_url": "https://github.com/keras-team/keras/commit/39f8ef5e3c011cf3a80b2002e4e880573957d62b",
        "buggy_code": "mask *= total / ops.maximum(valid, backend.epsilon())",
        "fixed_code": "mask *= total / (valid + backend.epsilon())",
        "patch": "@@ -155,7 +155,7 @@ def apply_mask(sample_weight, mask, dtype, reduction):\n             #   = sum(loss * sample_weight) / valid\n             total = ops.cast(ops.shape(mask)[0], dtype=dtype)\n             valid = ops.sum(mask)  # May be 0!\n-            mask *= total / ops.maximum(valid, backend.epsilon())\n+            mask *= total / (valid + backend.epsilon())\n \n         if sample_weight is not None:\n             sample_weight = ops.cast(sample_weight, dtype=dtype)"
    },
    {
        "commit_id": "0ed50561d7af7efe9e043a27c7d89f904d228426",
        "commit_message": "Fix conv layer signatures",
        "commit_url": "https://github.com/keras-team/keras/commit/0ed50561d7af7efe9e043a27c7d89f904d228426",
        "buggy_code": "data_format=\"channels_last\",",
        "fixed_code": "data_format=None,",
        "patch": "@@ -98,7 +98,7 @@ def __init__(\n         kernel_size,\n         strides=1,\n         padding=\"valid\",\n-        data_format=\"channels_last\",\n+        data_format=None,\n         dilation_rate=1,\n         groups=1,\n         activation=None,"
    },
    {
        "commit_id": "0ed50561d7af7efe9e043a27c7d89f904d228426",
        "commit_message": "Fix conv layer signatures",
        "commit_url": "https://github.com/keras-team/keras/commit/0ed50561d7af7efe9e043a27c7d89f904d228426",
        "buggy_code": "data_format=\"channels_last\",",
        "fixed_code": "data_format=None,",
        "patch": "@@ -97,7 +97,7 @@ def __init__(\n         kernel_size,\n         strides=1,\n         padding=\"valid\",\n-        data_format=\"channels_last\",\n+        data_format=None,\n         dilation_rate=1,\n         activation=None,\n         use_bias=True,"
    },
    {
        "commit_id": "2d40cb20b974ced614850e9d5568b13536f1cdd5",
        "commit_message": "Adds CategoryEncoding layer, bincount op, and tests (#161)\n\n* Adds unit normalization and tests\r\n\r\n* Adds layer normalization and initial tests\r\n\r\n* Fixes formatting in docstrings\r\n\r\n* Fix type issues for JAX\r\n\r\n* Fix nits\r\n\r\n* Initial stash for group_normalization and spectral_normalization\r\n\r\n* Adds spectral normalization and tests\r\n\r\n* Adds group normalization and tests\r\n\r\n* Formatting fixes\r\n\r\n* Fix small nit in docstring\r\n\r\n* Fix docstring and tests\r\n\r\n* Adds RandomContrast and associated tests\r\n\r\n* Remove arithmetic comment\r\n\r\n* Adds RandomBrightness and tests\r\n\r\n* Fix docstring and format\r\n\r\n* Fix nits and add backend generator\r\n\r\n* Inlines random_contrast helper\r\n\r\n* Add bincount op\r\n\r\n* Add CategoryEncoding layer and tests\r\n\r\n* Fix formatting\r\n\r\n* Fix JAX issues\r\n\r\n* Fix JAX bincount\r\n\r\n* Formatting and small fix\r\n\r\n* Fix nits and docstrings\r\n\r\n* Add args to bincount op test",
        "commit_url": "https://github.com/keras-team/keras/commit/2d40cb20b974ced614850e9d5568b13536f1cdd5",
        "buggy_code": "self.assertAllClose(outputs, expected)",
        "fixed_code": "self.assertAllClose(outputs, expected, atol=1e-5)",
        "patch": "@@ -417,4 +417,4 @@ def test_conv3d_transpose(\n         tf_keras_layer.bias.assign(bias_weights)\n         outputs = layer(inputs)\n         expected = tf_keras_layer(inputs)\n-        self.assertAllClose(outputs, expected)\n+        self.assertAllClose(outputs, expected, atol=1e-5)"
    },
    {
        "commit_id": "44e8d04338b8fe9f8e305eb18fb1fe07c428376f",
        "commit_message": "Fix metrics bug",
        "commit_url": "https://github.com/keras-team/keras/commit/44e8d04338b8fe9f8e305eb18fb1fe07c428376f",
        "buggy_code": "self.assertAllClose(outputs, expected)",
        "fixed_code": "self.assertAllClose(outputs, expected, atol=1e-5)",
        "patch": "@@ -417,4 +417,4 @@ def test_conv3d_transpose(\n         tf_keras_layer.bias.assign(bias_weights)\n         outputs = layer(inputs)\n         expected = tf_keras_layer(inputs)\n-        self.assertAllClose(outputs, expected)\n+        self.assertAllClose(outputs, expected, atol=1e-5)"
    },
    {
        "commit_id": "c036417b081b211dde99840d3aaef0cdf2001ce5",
        "commit_message": "Minor bug fix (#144)",
        "commit_url": "https://github.com/keras-team/keras/commit/c036417b081b211dde99840d3aaef0cdf2001ce5",
        "buggy_code": "self.data_adapter = tf_dataset_adapter.PyDatasetAdapter(",
        "fixed_code": "self.data_adapter = py_dataset_adapter.PyDatasetAdapter(",
        "patch": "@@ -94,7 +94,7 @@ def __init__(\n             #     \"(via `.shuffle(tf.data.AUTOTUNE)`)\"\n             # )\n         elif isinstance(x, py_dataset_adapter.PyDataset):\n-            self.data_adapter = tf_dataset_adapter.PyDatasetAdapter(\n+            self.data_adapter = py_dataset_adapter.PyDatasetAdapter(\n                 x, class_weight=class_weight, shuffle=shuffle\n             )\n             if y is not None:"
    },
    {
        "commit_id": "d360a45139e19a0436e5c4ce7f4ce5c1965593fb",
        "commit_message": "[keras/layers/preprocessing] fix comments in RandomWidth, change to 'horizontally' instead of 'vertically'\n\nChange-Id: Ib9b3093391ef6bda66b347c4dbb34a9d1fb42cf8",
        "commit_url": "https://github.com/keras-team/keras/commit/d360a45139e19a0436e5c4ce7f4ce5c1965593fb",
        "buggy_code": "for resizing vertically. When represented as a single float,",
        "fixed_code": "for resizing horizontally. When represented as a single float,",
        "patch": "@@ -1651,7 +1651,7 @@ class RandomWidth(base_layer.BaseRandomLayer):\n     Args:\n         factor: A positive float (fraction of original width),\n             or a tuple of size 2 representing lower and upper bound\n-            for resizing vertically. When represented as a single float,\n+            for resizing horizontally. When represented as a single float,\n             this value is used for both the upper and\n             lower bound. For instance, `factor=(0.2, 0.3)`\n             results in an output with"
    },
    {
        "commit_id": "2484922d54ca8a94a5fda05e1f4bc480b1ef6ba1",
        "commit_message": "Add transposed convolution layer (#131)\n\n* add transposed convolution layer\r\n\r\n* fix comments",
        "commit_url": "https://github.com/keras-team/keras/commit/2484922d54ca8a94a5fda05e1f4bc480b1ef6ba1",
        "buggy_code": ">>> x = np.random.normal(4, 10, 10, 128)",
        "fixed_code": ">>> x = np.random.rand(4, 10, 10, 128)",
        "patch": "@@ -80,7 +80,7 @@ class Conv2D(BaseConv):\n \n     Examples:\n \n-    >>> x = np.random.normal(4, 10, 10, 128)\n+    >>> x = np.random.rand(4, 10, 10, 128)\n     >>> y = keras_core.layers.Conv2D(32, 3, activation='relu')(x)\n     >>> print(y.shape)\n     (4, 8, 8, 32)"
    },
    {
        "commit_id": "981cb286e64155ea3feb0f504b7238d3e1019a4b",
        "commit_message": "All f1metrics: FBetaScore and F1Score (#121)\n\n* Add all F1 metrics\r\n\r\n* Formatting\r\n\r\n* Fix jax tests by explicit casting\r\n\r\n* Remove tf specific numpy comparison\r\n\r\n* Formatting",
        "commit_url": "https://github.com/keras-team/keras/commit/981cb286e64155ea3feb0f504b7238d3e1019a4b",
        "buggy_code": ">>> m.result().numpy()",
        "fixed_code": ">>> m.result()",
        "patch": "@@ -203,7 +203,7 @@ class RootMeanSquaredError(reduction_metrics.Mean):\n     >>> m.reset_state()\n     >>> m.update_state([[0, 1], [0, 0]], [[1, 1], [0, 0]],\n     ...                sample_weight=[1, 0])\n-    >>> m.result().numpy()\n+    >>> m.result()\n     0.70710677\n \n     Usage with `compile()` API:"
    },
    {
        "commit_id": "0322038b8a0e75771886b2092636435fc0154973",
        "commit_message": "Implement trainable setting + fix tracing hack",
        "commit_url": "https://github.com/keras-team/keras/commit/0322038b8a0e75771886b2092636435fc0154973",
        "buggy_code": "if training:",
        "fixed_code": "if training and self.trainable:",
        "patch": "@@ -190,7 +190,7 @@ def compute_output_shape(self, input_shape):\n \n     def call(self, inputs, training=None, mask=None):\n         # TODO: support masking during stats computation.\n-        if training:\n+        if training and self.trainable:\n             mean = ops.mean(inputs, axis=self._reduction_axes)\n             variance = ops.var(inputs, axis=self._reduction_axes)\n             outputs = (inputs - mean) / ops.sqrt(variance + self.epsilon)"
    },
    {
        "commit_id": "3111ae0aacd4085de6fa57850abca972d235cbf9",
        "commit_message": "Fix tests",
        "commit_url": "https://github.com/keras-team/keras/commit/3111ae0aacd4085de6fa57850abca972d235cbf9",
        "buggy_code": "if sample_weight.shape.rank == 1:",
        "fixed_code": "if len(sample_weight.shape) == 1:",
        "patch": "@@ -496,7 +496,7 @@ def update_state(self, y_true, y_pred, sample_weight=None):\n \n         sample_weight = ops.convert_to_tensor(sample_weight, dtype=self.dtype)\n \n-        if sample_weight.shape.rank == 1:\n+        if len(sample_weight.shape) == 1:\n             # Make sure there's a features dimension\n             sample_weight = ops.expand_dims(sample_weight, axis=1)\n "
    },
    {
        "commit_id": "3111ae0aacd4085de6fa57850abca972d235cbf9",
        "commit_message": "Fix tests",
        "commit_url": "https://github.com/keras-team/keras/commit/3111ae0aacd4085de6fa57850abca972d235cbf9",
        "buggy_code": "result = r2.result().numpy()",
        "fixed_code": "result = r2.result()",
        "patch": "@@ -311,7 +311,7 @@ def _run_test(\n     ):\n         r2 = metrics.R2Score(class_aggregation, num_regressors, dtype=\"float32\")\n         r2.update_state(y_true, y_pred, sample_weights)\n-        result = r2.result().numpy()\n+        result = r2.result()\n         self.assertAllClose(result, reference_result, atol=1e-6)\n \n     def test_config(self):"
    },
    {
        "commit_id": "c99de04feb3f914753e8c3ba186b8659d226df6b",
        "commit_message": "Fix test",
        "commit_url": "https://github.com/keras-team/keras/commit/c99de04feb3f914753e8c3ba186b8659d226df6b",
        "buggy_code": "x += residual",
        "fixed_code": "x = keras.layers.add([x, residual])",
        "patch": "@@ -32,7 +32,7 @@ def get_functional_model(keras):\n         moving_mean_initializer=\"uniform\", gamma_initializer=\"uniform\"\n     )(x)\n     x = keras.layers.Dense(4, activation=\"relu\")(x)\n-    x += residual\n+    x = keras.layers.add([x, residual])\n     outputs = keras.layers.Dense(5, activation=\"softmax\")(x)\n     return keras.Model(inputs, outputs)\n "
    },
    {
        "commit_id": "08a99a75666d22f7df616fe89f9ac1e9750d6b9a",
        "commit_message": "Fix typo",
        "commit_url": "https://github.com/keras-team/keras/commit/08a99a75666d22f7df616fe89f9ac1e9750d6b9a",
        "buggy_code": "shape = layer.output.dtype",
        "fixed_code": "dtype = layer.output.dtype",
        "patch": "@@ -121,7 +121,7 @@ def make_layer_label(layer, **kwargs):\n     if show_dtype:\n         dtype = None\n         try:\n-            shape = layer.output.dtype\n+            dtype = layer.output.dtype\n         except ValueError:\n             pass\n         cols.append("
    },
    {
        "commit_id": "4594ab246dd6aae3089025e294643e0ba3ffe0df",
        "commit_message": "Add RootMeanSquaredError (#91)\n\n* Add meanX metrics\r\n\r\n* All regression metrics except for root mean squared error\r\n\r\n* Formatting issues\r\n\r\n* Add RootMeanSquaredError\r\n\r\n* Docstring spacing\r\n\r\n* Line too long fix",
        "commit_url": "https://github.com/keras-team/keras/commit/4594ab246dd6aae3089025e294643e0ba3ffe0df",
        "buggy_code": "logcosh = log((exp(error) + exp(-error))/2)`",
        "fixed_code": "logcosh = mean(log((exp(error) + exp(-error))/2), axis=-1)`",
        "patch": "@@ -226,7 +226,7 @@ class LogCosh(LossFunctionWrapper):\n \n     ```python\n     error = y_pred - y_true\n-    logcosh = log((exp(error) + exp(-error))/2)`\n+    logcosh = mean(log((exp(error) + exp(-error))/2), axis=-1)`\n     ```\n     where x is the error `y_pred - y_true`.\n "
    },
    {
        "commit_id": "c79e431e1709c47bc19eb7cb64012f907155ecaa",
        "commit_message": "Fix missing return line in the print log.\n\nPiperOrigin-RevId: 528882184",
        "commit_url": "https://github.com/keras-team/keras/commit/c79e431e1709c47bc19eb7cb64012f907155ecaa",
        "buggy_code": "f\"is_nightly={is_nightly}\"",
        "fixed_code": "f\"is_nightly={is_nightly}\\n\"",
        "patch": "@@ -480,7 +480,7 @@ def test_wheel(wheel_path, expected_version, requirements_path):\n             f\"dist_directory={dist_directory}\\n\"\n             f\"package_directory={package_directory}\\n\"\n             f\"src_directory={src_directory}\\n\"\n-            f\"is_nightly={is_nightly}\"\n+            f\"is_nightly={is_nightly}\\n\"\n             f\"rc={rc}\"\n         )\n     if os.path.exists(build_directory):"
    },
    {
        "commit_id": "a702c33ea0aaa552eff34c3adb2a62140c48d079",
        "commit_message": "Fix activations clip usage (#63)\n\n* Fix activations clip usage\r\n\r\n* fix activation clip",
        "commit_url": "https://github.com/keras-team/keras/commit/a702c33ea0aaa552eff34c3adb2a62140c48d079",
        "buggy_code": "x = backend.clip(x, 0.0, max_value)",
        "fixed_code": "x = backend.numpy.clip(x, 0.0, max_value)",
        "patch": "@@ -95,7 +95,7 @@ def static_call(x, negative_slope=0.0, max_value=None, threshold=0.0):\n             x = backend.nn.relu(x)\n \n         if clip_max:\n-            x = backend.clip(x, 0.0, max_value)\n+            x = backend.numpy.clip(x, 0.0, max_value)\n \n         if negative_slope != 0.0:\n             x -= negative_slope * negative_part"
    },
    {
        "commit_id": "d8ce551b0f58f7774ecb70a6bce35351a2dcf7d1",
        "commit_message": "Fix JAX CI.",
        "commit_url": "https://github.com/keras-team/keras/commit/d8ce551b0f58f7774ecb70a6bce35351a2dcf7d1",
        "buggy_code": "layer(layers.Input((2, 2)))",
        "fixed_code": "layer(layers.Input(batch_shape=(2, 2)))",
        "patch": "@@ -151,7 +151,7 @@ def call(self, x):\n \n         # KerasTensors are no op\n         layer = ActivityRegularizer(activity_regularizer=\"l1\")\n-        layer(layers.Input((2, 2)))\n+        layer(layers.Input(batch_shape=(2, 2)))\n         self.assertLen(layer.losses, 0)\n \n     def test_add_loss(self):"
    },
    {
        "commit_id": "1e4ddaf5de8aa5294d0dba73df1866e35ed4ac68",
        "commit_message": "Fix a pretty major bug",
        "commit_url": "https://github.com/keras-team/keras/commit/1e4ddaf5de8aa5294d0dba73df1866e35ed4ac68",
        "buggy_code": "if len(x) == 1:",
        "fixed_code": "if isinstance(x, (list, tuple)) and len(x) == 1:",
        "patch": "@@ -449,7 +449,7 @@ def functional_like_constructor(cls):\n \n \n def unpack_singleton(x):\n-    if len(x) == 1:\n+    if isinstance(x, (list, tuple)) and len(x) == 1:\n         return x[0]\n     return x\n "
    },
    {
        "commit_id": "1e4ddaf5de8aa5294d0dba73df1866e35ed4ac68",
        "commit_message": "Fix a pretty major bug",
        "commit_url": "https://github.com/keras-team/keras/commit/1e4ddaf5de8aa5294d0dba73df1866e35ed4ac68",
        "buggy_code": "def assertAllClose(self, x1, x2, atol=1e-7, rtol=1e-7):",
        "fixed_code": "def assertAllClose(self, x1, x2, atol=1e-6, rtol=1e-6):",
        "patch": "@@ -15,7 +15,7 @@ def get_temp_dir(self):\n         self.addCleanup(lambda: shutil.rmtree(temp_dir))\n         return temp_dir\n \n-    def assertAllClose(self, x1, x2, atol=1e-7, rtol=1e-7):\n+    def assertAllClose(self, x1, x2, atol=1e-6, rtol=1e-6):\n         np.testing.assert_allclose(x1, x2, atol=atol, rtol=rtol)\n \n     def assertAlmostEqual(self, x1, x2, decimal=3):"
    },
    {
        "commit_id": "add7a3564fef81073f63ff99336faae709aac7d5",
        "commit_message": "Fix some bugs",
        "commit_url": "https://github.com/keras-team/keras/commit/add7a3564fef81073f63ff99336faae709aac7d5",
        "buggy_code": "except Exception as e:",
        "fixed_code": "except Exception:",
        "patch": "@@ -233,7 +233,7 @@ def is_shape_tuple(s):\n                 try:\n                     self(input_tensors)\n                     self._build_shapes_dict = config\n-                except Exception as e:\n+                except Exception:\n                     failure = True\n             elif \"shapes_dict\" in config:\n                 # Case: inputs were recorded as multiple keyword arguments."
    },
    {
        "commit_id": "add7a3564fef81073f63ff99336faae709aac7d5",
        "commit_message": "Fix some bugs",
        "commit_url": "https://github.com/keras-team/keras/commit/add7a3564fef81073f63ff99336faae709aac7d5",
        "buggy_code": "if build_config:",
        "fixed_code": "if build_config and not instance.built:",
        "patch": "@@ -661,7 +661,7 @@ class ModifiedMeanSquaredError(keras_core.losses.MeanSquaredError):\n     with custom_obj_scope, safe_mode_scope:\n         instance = cls.from_config(inner_config)\n         build_config = config.get(\"build_config\", None)\n-        if build_config:\n+        if build_config and not instance.built:\n             instance.build_from_config(build_config)\n         compile_config = config.get(\"compile_config\", None)\n         if compile_config:"
    },
    {
        "commit_id": "ce4ecc6cc29fcc8a75512f845988994cb07a02ad",
        "commit_message": "Fix API export for non-namex case (#33)",
        "commit_url": "https://github.com/keras-team/keras/commit/ce4ecc6cc29fcc8a75512f845988994cb07a02ad",
        "buggy_code": "pass",
        "fixed_code": "self.path = path",
        "patch": "@@ -42,7 +42,7 @@ def __call__(self, symbol):\n \n     class keras_core_export:\n         def __init__(self, path):\n-            pass\n+            self.path = path\n \n         def __call__(self, symbol):\n             register_internal_serializable(self.path, symbol)"
    },
    {
        "commit_id": "b3409e383ce920958c5b7d63c6a149c3113e597e",
        "commit_message": "Add Hinge losses (#31)\n\n* add hinge, squared_hine, and categorical hinge losses\r\n\r\n* add tests for hinge, squared_hinge, and categorical hinge losses\r\n\r\n* fix keyword argument for jax cond\r\n\r\n* format docstrings for hinge losses\r\n\r\n* format hinge losses tests\r\n\r\n* fix linting errors in activations init and test_case py files\r\n\r\n* fix bug in reduce_values function\r\n\r\n* rename _transform_binary_labels to convert_binary_labels_to_hinge\r\n\r\n* fix casting of  values in  class\r\n\r\n* convert shape values to tensor\r\n\r\n* add hinge metrics and the corresponding tests\r\n\r\n* revert formatting in activations init",
        "commit_url": "https://github.com/keras-team/keras/commit/b3409e383ce920958c5b7d63c6a149c3113e597e",
        "buggy_code": "return jax.lax.cond(pred, true_fn=true_fn, false_fun=false_fn)",
        "fixed_code": "return jax.lax.cond(pred, true_fun=true_fn, false_fun=false_fn)",
        "patch": "@@ -44,7 +44,7 @@ def cast(x, dtype):\n \n \n def cond(pred, true_fn, false_fn):\n-    return jax.lax.cond(pred, true_fn=true_fn, false_fun=false_fn)\n+    return jax.lax.cond(pred, true_fun=true_fn, false_fun=false_fn)\n \n \n def name_scope(name):"
    },
    {
        "commit_id": "a6b690b198b47fb113eaa05eb2e2496714732b26",
        "commit_message": "Fix typo.",
        "commit_url": "https://github.com/keras-team/keras/commit/a6b690b198b47fb113eaa05eb2e2496714732b26",
        "buggy_code": "minval: Floats, defaults to 1. Upper bound of the range of",
        "fixed_code": "maxval: Floats, defaults to 1. Upper bound of the range of",
        "patch": "@@ -46,7 +46,7 @@ def uniform(shape, minval=0.0, maxval=1.0, dtype=None, seed=None):\n         shape: The shape of the random values to generate.\n         minval: Floats, defaults to 0. Lower bound of the range of\n             random values to generate (inclusive).\n-        minval: Floats, defaults to 1. Upper bound of the range of\n+        maxval: Floats, defaults to 1. Upper bound of the range of\n             random values to generate (exclusive).\n         dtype: Optional dtype of the tensor. Only floating point types are\n             supported. If not specified, `keras.backend.floatx()` is used,"
    },
    {
        "commit_id": "4d1ca982a64b86c1ac3a113f66c4f17986fba243",
        "commit_message": "Catches user error for loading complex model without explicit deserialization in `from_config`, supplies useful information instead of DictWrapper error.\n\nPiperOrigin-RevId: 525888033",
        "commit_url": "https://github.com/keras-team/keras/commit/4d1ca982a64b86c1ac3a113f66c4f17986fba243",
        "buggy_code": "with self.assertRaisesRegex(TypeError, \"object is not callable\"):",
        "fixed_code": "with self.assertRaisesRegex(TypeError, \"are explicitly deserialized\"):",
        "patch": "@@ -859,7 +859,7 @@ def test_complex_model_without_explicit_deserialization(self):\n \n         model.save(temp_filepath)\n \n-        with self.assertRaisesRegex(TypeError, \"object is not callable\"):\n+        with self.assertRaisesRegex(TypeError, \"are explicitly deserialized\"):\n             _ = keras.models.load_model(temp_filepath)\n \n "
    },
    {
        "commit_id": "524068db0ea27734e5ab49c80c0995586049c714",
        "commit_message": "[keras/metrics/iou_metrics.py] Fix sentence in docstrings ; [keras/metrics/confusion_metrics.py] Backtick keyword in docstring",
        "commit_url": "https://github.com/keras-team/keras/commit/524068db0ea27734e5ab49c80c0995586049c714",
        "buggy_code": "value is generated for each threshold value. Defaults to 0.5.",
        "fixed_code": "value is generated for each threshold value. Defaults to `0.5`.",
        "patch": "@@ -40,7 +40,7 @@ class _ConfusionMatrixConditionCount(base_metric.Metric):\n         threshold values in [0, 1]. A threshold is compared with prediction\n         values to determine the truth value of predictions\n         (i.e., above the threshold is `true`, below is `false`). One metric\n-        value is generated for each threshold value. Defaults to 0.5.\n+        value is generated for each threshold value. Defaults to `0.5`.\n       name: (Optional) string name of the metric instance.\n       dtype: (Optional) data type of the metric result.\n     \"\"\""
    },
    {
        "commit_id": "d3b96fdebbca5873fb4f188e4af849d20a134821",
        "commit_message": "Added MeanSquaredLogarithmicError and MeanAbsolutePercentageError (#15)\n\n* Added MeanAbsoluteError and started testing for losses.\r\n\r\nAdded testing for MeanSquaredError and MeanAbsoluteError as well as testing utils.\r\n\r\n* Formatting fix for docstrings\r\n\r\n* Switch docstrings to keras_core\r\n\r\n* Add MeanAbsolutePercentageError and MeanSquaredLogarithmicError\r\n\r\nAdd regression errors and testing. Cleaned up formatting for other files.\r\n\r\n* More merge conflicts\r\n\r\n* Backend import merge conflict\r\n\r\n* Minor docstring touchup",
        "commit_url": "https://github.com/keras-team/keras/commit/d3b96fdebbca5873fb4f188e4af849d20a134821",
        "buggy_code": "def assertAllEqual(self, x1, x2, decimal=3):",
        "fixed_code": "def assertAlmostEqual(self, x1, x2, decimal=3):",
        "patch": "@@ -7,5 +7,5 @@ class TestCase(unittest.TestCase):\n     def assertAllClose(self, x1, x2, atol=1e-7, rtol=1e-7):\n         np.testing.assert_allclose(x1, x2, atol=atol, rtol=rtol)\n \n-    def assertAllEqual(self, x1, x2, decimal=3):\n+    def assertAlmostEqual(self, x1, x2, decimal=3):\n         np.testing.assert_almost_equal(x1, x2, decimal=decimal)"
    },
    {
        "commit_id": "4bf04920f260e4bb3070c70673ea510e82beed9a",
        "commit_message": "Fix jax jit_compile setting",
        "commit_url": "https://github.com/keras-team/keras/commit/4bf04920f260e4bb3070c70673ea510e82beed9a",
        "buggy_code": "if not self.run_eagerly and not self.jit_compile:",
        "fixed_code": "if not self.run_eagerly and self.jit_compile:",
        "patch": "@@ -154,7 +154,7 @@ def _train_step(state, data):\n             )\n             return logs, state\n         \n-        if not self.run_eagerly and not self.jit_compile:\n+        if not self.run_eagerly and self.jit_compile:\n             @jax.jit\n             def train_step(state, data):\n                 return _train_step(state, data)"
    },
    {
        "commit_id": "46c186ff4607fec31c085163b8958ccf998f5b5c",
        "commit_message": "Minor fix for the masked batch norm dtype inconsistency between input and mask.\n\nPiperOrigin-RevId: 525534100",
        "commit_url": "https://github.com/keras-team/keras/commit/46c186ff4607fec31c085163b8958ccf998f5b5c",
        "buggy_code": "mask_weights = tf.cast(mask, tf.float32, name=\"mask_weights\")",
        "fixed_code": "mask_weights = tf.cast(mask, y.dtype, name=\"mask_weights\")",
        "patch": "@@ -1165,7 +1165,7 @@ def _sync_calculate_mean_and_var(\n                 )\n \n             if mask is not None:\n-                mask_weights = tf.cast(mask, tf.float32, name=\"mask_weights\")\n+                mask_weights = tf.cast(mask, y.dtype, name=\"mask_weights\")\n                 mask_weights = tf.expand_dims(\n                     mask_weights, axis=-1, name=\"mask_weights_broadcasted\"\n                 )"
    },
    {
        "commit_id": "bd1d26dc8c4fa15238801315eb2f0fad7dd01c44",
        "commit_message": "Merge pull request #17744 from sudoLife:patch-1\n\nPiperOrigin-RevId: 521843987",
        "commit_url": "https://github.com/keras-team/keras/commit/bd1d26dc8c4fa15238801315eb2f0fad7dd01c44",
        "buggy_code": "f\"{k} is deprecated in the new Keras optimizer, please\"",
        "fixed_code": "f\"{k} is deprecated in the new Keras optimizer, please \"",
        "patch": "@@ -133,7 +133,7 @@ def _process_kwargs(self, kwargs):\n         for k in kwargs:\n             if k in legacy_kwargs:\n                 raise ValueError(\n-                    f\"{k} is deprecated in the new Keras optimizer, please\"\n+                    f\"{k} is deprecated in the new Keras optimizer, please \"\n                     \"check the docstring for valid arguments, or use the \"\n                     \"legacy optimizer, e.g., \"\n                     f\"tf.keras.optimizers.legacy.{self.__class__.__name__}.\""
    },
    {
        "commit_id": "00b6a12f78dc621a54d2ca4fcac7c24ce4b22325",
        "commit_message": "Update some isinstance checks of `tf.compat.v1.Variable` to `tf.compat.v2.Variable`.\n\nAlso fix calls to the deprecated Variable.initialized_value implementation by directly copying it to the use cases.\n\nThese changes are in preparation for changing `tensorflow/python/ops/resource_variable_ops.BaseResourceVariable` to inherit from `tensorflow/python/ops/variables.Variable` instead of `tensorflow/python/ops/variables.VariableV1`.\n\nSince `tensorflow/python/ops/variables.VariableV1` inherits from `tensorflow/python/ops/variables.Variable`, these changes are backwards compatible.\n\nPiperOrigin-RevId: 518989647",
        "commit_url": "https://github.com/keras-team/keras/commit/00b6a12f78dc621a54d2ca4fcac7c24ce4b22325",
        "buggy_code": "self.assertEqual(self.evaluate(x.initialized_value()), 7)",
        "fixed_code": "self.assertEqual(self.evaluate(x.read_value()), 7)",
        "patch": "@@ -167,7 +167,7 @@ def evaluate(var):\n                         x.synchronization, x._variable.synchronization\n                     )\n                     self.assertEqual(x.aggregation, x._variable.aggregation)\n-                    self.assertEqual(self.evaluate(x.initialized_value()), 7)\n+                    self.assertEqual(self.evaluate(x.read_value()), 7)\n                     if not tf.executing_eagerly():\n                         if not tf.distribute.has_strategy():\n                             # These functions are not supported for"
    },
    {
        "commit_id": "5fbe19ecadbdf69acb13f1b3aac3c411b1427c83",
        "commit_message": "fix",
        "commit_url": "https://github.com/keras-team/keras/commit/5fbe19ecadbdf69acb13f1b3aac3c411b1427c83",
        "buggy_code": "has either `kernel` or `embeddings` attribute.",
        "fixed_code": "has either a `kernel` or an `embeddings` attribute.",
        "patch": "@@ -33,7 +33,7 @@ class SpectralNormalization(Wrapper):\n \n     Args:\n       layer: a `tf.keras.layers.Layer` instance that\n-        has either `kernel` or `embeddings` attribute.\n+        has either a `kernel` or an `embeddings` attribute.\n       power_iterations: `int`, the number of iterations during normalization.\n \n     Examples:"
    },
    {
        "commit_id": "2f003f9f11e4b8efad33d4078ddae8533fd19f51",
        "commit_message": "Fix the epsilon sign in Adam.\n\nPiperOrigin-RevId: 513895046",
        "commit_url": "https://github.com/keras-team/keras/commit/2f003f9f11e4b8efad33d4078ddae8533fd19f51",
        "buggy_code": "var.assign_sub((m * alpha) / (tf.sqrt(v) - coefficients[\"epsilon\"]))",
        "fixed_code": "var.assign_sub((m * alpha) / (tf.sqrt(v) + coefficients[\"epsilon\"]))",
        "patch": "@@ -464,7 +464,7 @@ def _resource_apply_dense(self, grad, var, apply_state=None):\n             vhat = self.get_slot(var, \"vhat\")\n             vhat.assign(tf.maximum(vhat, v))\n             v = vhat\n-        var.assign_sub((m * alpha) / (tf.sqrt(v) - coefficients[\"epsilon\"]))\n+        var.assign_sub((m * alpha) / (tf.sqrt(v) + coefficients[\"epsilon\"]))\n \n     @tf.function(jit_compile=True)\n     def _resource_apply_sparse(self, grad, var, indices, apply_state=None):"
    },
    {
        "commit_id": "8b9f81df42d672a675e6519f4e8558f8bb5462c0",
        "commit_message": "Fix ModelCheckpoint trained-on batch counting\n\nWhen setting the steps_per_execution argument to a value N>1 when\ncalling model.compile(), the on_train_batch_end() method of\nmodel.fit()'s callbacks only gets called every N batches with an\nargument batch equal to the 0-indexed index of the last batch which has\nbeen trained on. That is, after the first N trained-on batches,\non_train_batch_end() gets called with its batch argument equal to N-1,\nthen N trained-on batches later, to 2N-1, etc. until the end of the\nepoch.\n\nIn order to handle this situation, ModelCheckpoint uses a\n_last_batch_seen member integer variable to record the value of the\nbatch argument of its on_train_batch_end() method the last time this\nmethod was called. When on_train_batch_end() is called again,\nModelCheckpoint then computes (in its _should_save_on_batch() method)\nadd_batches = batch - self._last_batch_seen in order to know the number\nof batches which have been trained on between two consecutive calls to\nits on_train_batch_end() method.\n\nHowever, the _last_batch_seen member variable is initialized to 0 which\nmeans that, when using steps_per_execution=N, the first time\non_train_batch_end() is called after N batches have been trained on\n(with a batch argument equal to N-1), only N-1 batches are counted since\nadd_batches = batch - self._last_batch_seen = (N-1) - 0 = N-1 instead\nof N. This makes ModelCheckpoint miss one batch when counting them and\neffectively offset its save_freq contructor argument by 1. Therefore an\ninitialization value of -1 is needed.\n\nIn the special cases of steps_per_execution=1 or\nsteps_per_execution=None (which are equivalent), the bug was hidden by\nthe fact that the condition to check for a new epoch (batch <=\nself._last_batch_seen) was true since on the first call to\non_train_batch_end() both the batch argument and _last_batch_seen\nvariable were equal to 0. In this case, the number of batches trained on\nis counted by computing add_batches = batch + 1 = 1, which is indeed the\ncorrect result.",
        "commit_url": "https://github.com/keras-team/keras/commit/8b9f81df42d672a675e6519f4e8558f8bb5462c0",
        "buggy_code": "self._last_batch_seen = 0",
        "fixed_code": "self._last_batch_seen = -1",
        "patch": "@@ -1351,7 +1351,7 @@ def __init__(\n         self.save_freq = save_freq\n         self.epochs_since_last_save = 0\n         self._batches_seen_since_last_saving = 0\n-        self._last_batch_seen = 0\n+        self._last_batch_seen = -1\n         self.best = initial_value_threshold\n \n         if save_weights_only:"
    },
    {
        "commit_id": "5688b5a8aa8663a84dbde199035f034da4949bf9",
        "commit_message": "Fix spelling error in Initializer warning",
        "commit_url": "https://github.com/keras-team/keras/commit/5688b5a8aa8663a84dbde199035f034da4949bf9",
        "buggy_code": "\"the initializer, or avoid using the same initalizer \"",
        "fixed_code": "\"the initializer, or avoid using the same initializer \"",
        "patch": "@@ -122,7 +122,7 @@ def _warn_reuse(self):\n                     \"and being called multiple times, which will return \"\n                     \"identical values each time (even if the initializer is \"\n                     \"unseeded). Please update your code to provide a seed to \"\n-                    \"the initializer, or avoid using the same initalizer \"\n+                    \"the initializer, or avoid using the same initializer \"\n                     \"instance more than once.\"\n                 )\n         else:"
    },
    {
        "commit_id": "bce4ac97d71108f5b2ab96bc72a6396bc9eca2f3",
        "commit_message": "Fix test_application_classifier_activation test",
        "commit_url": "https://github.com/keras-team/keras/commit/bce4ac97d71108f5b2ab96bc72a6396bc9eca2f3",
        "buggy_code": "def test_application_classifier_activation(self, app):",
        "fixed_code": "def test_application_classifier_activation(self, app, _):",
        "patch": "@@ -192,7 +192,7 @@ def test_application_pooling(self, app, last_dim):\n         self.assertShapeEqual(output_shape, (None, last_dim))\n \n     @parameterized.parameters(MODEL_LIST)\n-    def test_application_classifier_activation(self, app):\n+    def test_application_classifier_activation(self, app, _):\n         model = app(\n             weights=None, include_top=True, classifier_activation=\"softmax\"\n         )"
    },
    {
        "commit_id": "db1ec98f1510547b0272b568f27fbb57814afba8",
        "commit_message": "fix grammar",
        "commit_url": "https://github.com/keras-team/keras/commit/db1ec98f1510547b0272b568f27fbb57814afba8",
        "buggy_code": "A ordinal regression matrix representation of the input as a NumPy",
        "fixed_code": "An ordinal regression matrix representation of the input as a NumPy",
        "patch": "@@ -90,7 +90,7 @@ def to_ordinal(y, num_classes=None, dtype=\"float32\"):\n         dtype: The data type expected by the input. Default: `'float32'`.\n \n     Returns:\n-        A ordinal regression matrix representation of the input as a NumPy\n+        An ordinal regression matrix representation of the input as a NumPy\n         array. The class axis is placed last.\n \n     Example:"
    },
    {
        "commit_id": "f7d863c92c07804377114e9aabd4ed13f5cc698e",
        "commit_message": "Fix line length format in `batch_normalization_test.py`\n\nPiperOrigin-RevId: 504623813",
        "commit_url": "https://github.com/keras-team/keras/commit/f7d863c92c07804377114e9aabd4ed13f5cc698e",
        "buggy_code": "\"\"\"Tests that batchnorm layer is trainable when learning phase is enabled.",
        "fixed_code": "\"\"\"Tests that batchnorm layer is trainable when learning phase enabled.",
        "patch": "@@ -602,7 +602,7 @@ def test_that_trainable_disables_updates(self, layer):\n             self.assertAllClose(x1, x2, atol=1e-7)\n \n     def test_batchnorm_trainable(self, layer):\n-        \"\"\"Tests that batchnorm layer is trainable when learning phase is enabled.\n+        \"\"\"Tests that batchnorm layer is trainable when learning phase enabled.\n \n         Computes mean and std for current inputs then\n         applies batch normalization using them."
    },
    {
        "commit_id": "ded2cab54502980481264f7fa1d819a11152eab3",
        "commit_message": "fix space",
        "commit_url": "https://github.com/keras-team/keras/commit/ded2cab54502980481264f7fa1d819a11152eab3",
        "buggy_code": "dim(the query input's last dimension).",
        "fixed_code": "dim (the query input's last dimension).",
        "patch": "@@ -188,7 +188,7 @@ class MultiHeadAttention(Layer):\n       use_bias: Boolean, whether the dense layers use bias vectors/matrices.\n       output_shape: The expected shape of an output tensor, besides the batch\n         and sequence dims. If not specified, projects back to the query feature\n-        dim(the query input's last dimension).\n+        dim (the query input's last dimension).\n       attention_axes: axes over which the attention is applied. `None` means\n         attention over all axes, but batch, heads, and features.\n       kernel_initializer: Initializer for dense layer kernels."
    },
    {
        "commit_id": "1d158c53c90100bf91004cf7feb98b71534202a2",
        "commit_message": "fix",
        "commit_url": "https://github.com/keras-team/keras/commit/1d158c53c90100bf91004cf7feb98b71534202a2",
        "buggy_code": "dim(the query input last dimension).",
        "fixed_code": "dim(the query input's last dimension).",
        "patch": "@@ -188,7 +188,7 @@ class MultiHeadAttention(Layer):\n       use_bias: Boolean, whether the dense layers use bias vectors/matrices.\n       output_shape: The expected shape of an output tensor, besides the batch\n         and sequence dims. If not specified, projects back to the query feature\n-        dim(the query input last dimension).\n+        dim(the query input's last dimension).\n       attention_axes: axes over which the attention is applied. `None` means\n         attention over all axes, but batch, heads, and features.\n       kernel_initializer: Initializer for dense layer kernels."
    },
    {
        "commit_id": "416fa79283c1b499c1ad299d2394608034f1a423",
        "commit_message": "test fail due to shape `mismatch`\n\n`assertTrue` fails for label shape `(3, 2, 1)` as   ordinal->label creates shape `(3, 2)` hence the mismatch. Using `reshape(label)` with `ordinal` before comparison is a fix.",
        "commit_url": "https://github.com/keras-team/keras/commit/416fa79283c1b499c1ad299d2394608034f1a423",
        "buggy_code": "np.all(np.sum(np.cumprod(ordinal, -1), -1) == label)",
        "fixed_code": "ordinal.cumprod(-1).sum(-1).reshape(label.shape) == label",
        "patch": "@@ -72,7 +72,7 @@ def test_to_ordinal(self):\n             self.assertTrue(np.all(np.logical_or(ordinal == 0, ordinal == 1)))\n             # Get original labels back from ordinal matrix\n             self.assertTrue(\n-                np.all(np.sum(np.cumprod(ordinal, -1), -1) == label)\n+                ordinal.cumprod(-1).sum(-1).reshape(label.shape) == label\n             )\n \n "
    },
    {
        "commit_id": "c2e007e3e7b18bcef8fe7dc059d2c3d2ed7dbdf4",
        "commit_message": "Fix timeseries_dataset_from_array counts when sequence_stride > 1",
        "commit_url": "https://github.com/keras-team/keras/commit/c2e007e3e7b18bcef8fe7dc059d2c3d2ed7dbdf4",
        "buggy_code": "num_seqs = end_index - start_index - (sequence_length * sampling_rate) + 1",
        "fixed_code": "num_seqs = end_index - start_index - ((sequence_length-1) * sampling_rate)",
        "patch": "@@ -209,7 +209,7 @@ def timeseries_dataset_from_array(\n \n     # Determine the lowest dtype to store start positions (to lower memory\n     # usage).\n-    num_seqs = end_index - start_index - (sequence_length * sampling_rate) + 1\n+    num_seqs = end_index - start_index - ((sequence_length-1) * sampling_rate)\n     if targets is not None:\n         num_seqs = min(num_seqs, len(targets))\n     if num_seqs < 2147483647:"
    },
    {
        "commit_id": "5711bc6d3bbc1d9ece1f17badbbbbbd2451d9a9b",
        "commit_message": "Add saving v3 integration tests (and fix some minor bugs).\n\nPiperOrigin-RevId: 492339586",
        "commit_url": "https://github.com/keras-team/keras/commit/5711bc6d3bbc1d9ece1f17badbbbbbd2451d9a9b",
        "buggy_code": "return None",
        "fixed_code": "return {}",
        "patch": "@@ -77,4 +77,4 @@ def get_model(\n \n \n def get_custom_objects():\n-    return None\n+    return {}"
    },
    {
        "commit_id": "5711bc6d3bbc1d9ece1f17badbbbbbd2451d9a9b",
        "commit_message": "Add saving v3 integration tests (and fix some minor bugs).\n\nPiperOrigin-RevId: 492339586",
        "commit_url": "https://github.com/keras-team/keras/commit/5711bc6d3bbc1d9ece1f17badbbbbbd2451d9a9b",
        "buggy_code": "return None",
        "fixed_code": "return {}",
        "patch": "@@ -81,4 +81,4 @@ def get_model(\n \n \n def get_custom_objects():\n-    return None\n+    return {}"
    },
    {
        "commit_id": "c457f769cca3c8e090a33f2e80bbc13c07ad5ae4",
        "commit_message": "Fix issues with eager tensor capture in graph mode.\n\nPiperOrigin-RevId: 491798890",
        "commit_url": "https://github.com/keras-team/keras/commit/c457f769cca3c8e090a33f2e80bbc13c07ad5ae4",
        "buggy_code": "\"vocabulary_size\": self.vocabulary_size(),",
        "fixed_code": "\"vocabulary_size\": self._frozen_vocab_size,",
        "patch": "@@ -429,7 +429,7 @@ def get_config(self):\n             \"vocabulary_dtype\": self.vocabulary_dtype,\n             \"idf_weights\": utils.listify_tensors(self.input_idf_weights),\n             \"vocabulary\": utils.listify_tensors(self.input_vocabulary),\n-            \"vocabulary_size\": self.vocabulary_size(),\n+            \"vocabulary_size\": self._frozen_vocab_size,\n         }\n         base_config = super().get_config()\n         return dict(list(base_config.items()) + list(config.items()))"
    },
    {
        "commit_id": "f9a7a60802a7fc8c2dbb1e9ce69f62822dbd6055",
        "commit_message": "Change the order of function tracing for saved model.\n\nSince the dropout layer and other layers that uses RNG will create the variable when training=True, if user code branched based on that, the current order will raise an error from tf.function about creating variable in non-first call.\n\nChange to trace the training=True function first to avoid this potential issue.\n\nPiperOrigin-RevId: 488663939",
        "commit_url": "https://github.com/keras-team/keras/commit/f9a7a60802a7fc8c2dbb1e9ce69f62822dbd6055",
        "buggy_code": "fn, args, kwargs, training = _thread_local_data.trace_queue.pop()",
        "fixed_code": "fn, args, kwargs, training = _thread_local_data.trace_queue.pop(0)",
        "patch": "@@ -384,7 +384,7 @@ def tracing_scope():\n     finally:\n         # Run traces from the queue.\n         while _thread_local_data.trace_queue:\n-            fn, args, kwargs, training = _thread_local_data.trace_queue.pop()\n+            fn, args, kwargs, training = _thread_local_data.trace_queue.pop(0)\n             if training is not None:\n                 with backend.deprecated_internal_learning_phase_scope(training):\n                     fn.get_concrete_function(*args, **kwargs)"
    },
    {
        "commit_id": "c4cc71642c4817733f4bc9973181d295488e56e1",
        "commit_message": "Merge pull request #17224 from chunduriv:patch-8\n\nPiperOrigin-RevId: 487096584",
        "commit_url": "https://github.com/keras-team/keras/commit/c4cc71642c4817733f4bc9973181d295488e56e1",
        "buggy_code": "http://jmlr.org/proceedings/papers/v28/sutskever13.pdf).",
        "fixed_code": "http://proceedings.mlr.press/v28/sutskever13.pdf).",
        "patch": "@@ -89,7 +89,7 @@ class SGD(optimizer.Optimizer):\n \n     Reference:\n         - For `nesterov=True`, See [Sutskever et al., 2013](\n-          http://jmlr.org/proceedings/papers/v28/sutskever13.pdf).\n+          http://proceedings.mlr.press/v28/sutskever13.pdf).\n     \"\"\"\n \n     def __init__("
    },
    {
        "commit_id": "7a9bbdd3313ec5642ed9819f834562a447b1ba4f",
        "commit_message": "Merge pull request #17196 from sushreebarsa:patch-4\n\nPiperOrigin-RevId: 485667670",
        "commit_url": "https://github.com/keras-team/keras/commit/7a9bbdd3313ec5642ed9819f834562a447b1ba4f",
        "buggy_code": "http://jmlr.org/proceedings/papers/v28/sutskever13.pdf).",
        "fixed_code": "https://github.com/mlresearch/v28/blob/gh-pages/sutskever13.pdf).",
        "patch": "@@ -98,7 +98,7 @@ class SGD(optimizer_v2.OptimizerV2):\n \n     Reference:\n         - For `nesterov=True`, See [Sutskever et al., 2013](\n-          http://jmlr.org/proceedings/papers/v28/sutskever13.pdf).\n+          https://github.com/mlresearch/v28/blob/gh-pages/sutskever13.pdf).\n     \"\"\"\n \n     _HAS_AGGREGATE_GRAD = True"
    },
    {
        "commit_id": "5ef06f96f1612eb8ded3d00967d26cb29c953d45",
        "commit_message": "Fix the ordering issue of newly added `mask` param in the BN layer.\n\nPiperOrigin-RevId: 485485280",
        "commit_url": "https://github.com/keras-team/keras/commit/5ef06f96f1612eb8ded3d00967d26cb29c953d45",
        "buggy_code": "def call(self, inputs, mask=None, training=None):",
        "fixed_code": "def call(self, inputs, training=None, mask=None):",
        "patch": "@@ -874,7 +874,7 @@ def _get_training_value(self, training=None):\n                 training = False\n         return training\n \n-    def call(self, inputs, mask=None, training=None):\n+    def call(self, inputs, training=None, mask=None):\n         inputs = tf.cast(inputs, self.compute_dtype)\n         training = self._get_training_value(training)\n         # Determine a boolean value for `training`: could be True, False, or"
    },
    {
        "commit_id": "fd2951d40ea933030cd650d656faf5311dd6b40d",
        "commit_message": "Fix line-too-long lint errors across the codebase.\n\nPiperOrigin-RevId: 484002276",
        "commit_url": "https://github.com/keras-team/keras/commit/fd2951d40ea933030cd650d656faf5311dd6b40d",
        "buggy_code": "\"\"\"Instantiates the EfficientNet architecture using given scaling coefficients.",
        "fixed_code": "\"\"\"Instantiates the EfficientNet architecture.",
        "patch": "@@ -250,7 +250,7 @@ def EfficientNet(\n     classes=1000,\n     classifier_activation=\"softmax\",\n ):\n-    \"\"\"Instantiates the EfficientNet architecture using given scaling coefficients.\n+    \"\"\"Instantiates the EfficientNet architecture.\n \n     Args:\n       width_coefficient: float, scaling coefficient for network width."
    },
    {
        "commit_id": "fd2951d40ea933030cd650d656faf5311dd6b40d",
        "commit_message": "Fix line-too-long lint errors across the codebase.\n\nPiperOrigin-RevId: 484002276",
        "commit_url": "https://github.com/keras-team/keras/commit/fd2951d40ea933030cd650d656faf5311dd6b40d",
        "buggy_code": "\"\"\"Implements the Squeeze and excite block (https://arxiv.org/abs/1709.01507).",
        "fixed_code": "\"\"\"Implements the Squeeze & Excite block (https://arxiv.org/abs/1709.01507).",
        "patch": "@@ -433,7 +433,7 @@ def apply(x):\n \n \n def SqueezeAndExciteBlock(filters_in, se_filters, name=None):\n-    \"\"\"Implements the Squeeze and excite block (https://arxiv.org/abs/1709.01507).\n+    \"\"\"Implements the Squeeze & Excite block (https://arxiv.org/abs/1709.01507).\n \n     Args:\n       filters_in: input filters to the block"
    },
    {
        "commit_id": "fd2951d40ea933030cd650d656faf5311dd6b40d",
        "commit_message": "Fix line-too-long lint errors across the codebase.\n\nPiperOrigin-RevId: 484002276",
        "commit_url": "https://github.com/keras-team/keras/commit/fd2951d40ea933030cd650d656faf5311dd6b40d",
        "buggy_code": "\"\"\"Runs a profiler session that interferes with the one from the callback.",
        "fixed_code": "\"\"\"Runs a profiler session that interferes with the callback's one.",
        "patch": "@@ -3486,7 +3486,7 @@ def test_TensorBoard_autoTrace(self):\n         self.assertEqual(1, self._count_xplane_file(logdir=self.logdir))\n \n     def test_TensorBoard_autoTrace_outerProfiler(self):\n-        \"\"\"Runs a profiler session that interferes with the one from the callback.\n+        \"\"\"Runs a profiler session that interferes with the callback's one.\n \n         The callback will not generate a profile but execution will proceed\n         without crashing due to unhandled exceptions."
    },
    {
        "commit_id": "fd2951d40ea933030cd650d656faf5311dd6b40d",
        "commit_message": "Fix line-too-long lint errors across the codebase.\n\nPiperOrigin-RevId: 484002276",
        "commit_url": "https://github.com/keras-team/keras/commit/fd2951d40ea933030cd650d656faf5311dd6b40d",
        "buggy_code": "\"\"\"Test that fused batch norm works when the last device may get empty data.",
        "fixed_code": "\"\"\"Test that fused BN works when the last device gets empty data.",
        "patch": "@@ -359,7 +359,7 @@ def dnn_correctness(\n         )\n     )\n     def test_fused_batch_norm_uneven_batch(self, distribution):\n-        \"\"\"Test that fused batch norm works when the last device may get empty data.\n+        \"\"\"Test that fused BN works when the last device gets empty data.\n \n         Adapted from\n         https://www.tensorflow.org/tutorials/distribute/custom_training"
    },
    {
        "commit_id": "fd2951d40ea933030cd650d656faf5311dd6b40d",
        "commit_message": "Fix line-too-long lint errors across the codebase.\n\nPiperOrigin-RevId: 484002276",
        "commit_url": "https://github.com/keras-team/keras/commit/fd2951d40ea933030cd650d656faf5311dd6b40d",
        "buggy_code": "\"\"\"Maybe load initial epoch from ckpt considering possible worker recovery.",
        "fixed_code": "\"\"\"Maybe load 1st epoch from checkpoint, considering worker recovery.",
        "patch": "@@ -185,7 +185,7 @@ def delete_backup(self):\n     def maybe_load_initial_counters_from_ckpt(\n         self, steps_per_epoch, initial_epoch, mode\n     ):\n-        \"\"\"Maybe load initial epoch from ckpt considering possible worker recovery.\n+        \"\"\"Maybe load 1st epoch from checkpoint, considering worker recovery.\n \n         When `_ckpt_saved_epoch` attribute exists and is not\n         `CKPT_SAVED_EPOCH_UNUSED_VALUE`, this is under multi-worker training"
    },
    {
        "commit_id": "fd2951d40ea933030cd650d656faf5311dd6b40d",
        "commit_message": "Fix line-too-long lint errors across the codebase.\n\nPiperOrigin-RevId: 484002276",
        "commit_url": "https://github.com/keras-team/keras/commit/fd2951d40ea933030cd650d656faf5311dd6b40d",
        "buggy_code": "\"\"\"Check and raise error when user provided metrics has any duplications.",
        "fixed_code": "\"\"\"Raise error when user provided metrics have any duplications.",
        "patch": "@@ -401,7 +401,7 @@ def __init__(\n         self._from_serialized = from_serialized\n \n     def _check_duplicated_metrics(self, metrics, weighted_metrics):\n-        \"\"\"Check and raise error when user provided metrics has any duplications.\n+        \"\"\"Raise error when user provided metrics have any duplications.\n \n         Note that metrics are stateful container, a shared metric instance\n         between model.metric and model.weighted_metric will make the same"
    },
    {
        "commit_id": "fd2951d40ea933030cd650d656faf5311dd6b40d",
        "commit_message": "Fix line-too-long lint errors across the codebase.\n\nPiperOrigin-RevId: 484002276",
        "commit_url": "https://github.com/keras-team/keras/commit/fd2951d40ea933030cd650d656faf5311dd6b40d",
        "buggy_code": "\"\"\"Builds the config, which consists of the node graph and serialized layers.",
        "fixed_code": "\"\"\"Build the config, which consists of the node graph and serialized layers.",
        "patch": "@@ -1522,7 +1522,7 @@ def process_layer(layer_data):\n \n \n def get_network_config(network, serialize_layer_fn=None, config=None):\n-    \"\"\"Builds the config, which consists of the node graph and serialized layers.\n+    \"\"\"Build the config, which consists of the node graph and serialized layers.\n \n     Args:\n       network: A Network object."
    },
    {
        "commit_id": "fd2951d40ea933030cd650d656faf5311dd6b40d",
        "commit_message": "Fix line-too-long lint errors across the codebase.\n\nPiperOrigin-RevId: 484002276",
        "commit_url": "https://github.com/keras-team/keras/commit/fd2951d40ea933030cd650d656faf5311dd6b40d",
        "buggy_code": "\"\"\"Overload an operator with the same implementation as a base Tensor class.",
        "fixed_code": "\"\"\"Overload operator with the same implementation as the Tensor class.",
        "patch": "@@ -429,7 +429,7 @@ def _overload_all_operators(cls, tensor_class):\n \n     @classmethod\n     def _overload_operator(cls, tensor_class, operator):\n-        \"\"\"Overload an operator with the same implementation as a base Tensor class.\n+        \"\"\"Overload operator with the same implementation as the Tensor class.\n \n         We pull the operator out of the class dynamically to avoid ordering\n         issues."
    },
    {
        "commit_id": "fd2951d40ea933030cd650d656faf5311dd6b40d",
        "commit_message": "Fix line-too-long lint errors across the codebase.\n\nPiperOrigin-RevId: 484002276",
        "commit_url": "https://github.com/keras-team/keras/commit/fd2951d40ea933030cd650d656faf5311dd6b40d",
        "buggy_code": "\"\"\"Extract a tuple of tensors `inputs, targets, sample_weight` from a dataset.",
        "fixed_code": "\"\"\"Extract tuple of tensors `inputs, targets, sample_weight` from a dataset.",
        "patch": "@@ -1830,7 +1830,7 @@ def initialize_iterator(iterator):\n \n \n def extract_tensors_from_dataset(dataset):\n-    \"\"\"Extract a tuple of tensors `inputs, targets, sample_weight` from a dataset.\n+    \"\"\"Extract tuple of tensors `inputs, targets, sample_weight` from a dataset.\n \n     Args:\n       dataset: Dataset instance."
    },
    {
        "commit_id": "fd2951d40ea933030cd650d656faf5311dd6b40d",
        "commit_message": "Fix line-too-long lint errors across the codebase.\n\nPiperOrigin-RevId: 484002276",
        "commit_url": "https://github.com/keras-team/keras/commit/fd2951d40ea933030cd650d656faf5311dd6b40d",
        "buggy_code": "\"\"\"Computes expected output shape of the layer or a column's dense tensor.",
        "fixed_code": "\"\"\"Computes expected output shape of the dense tensor of the layer.",
        "patch": "@@ -86,7 +86,7 @@ def build(self, _):\n         super().build(None)\n \n     def _output_shape(self, input_shape, num_elements):\n-        \"\"\"Computes expected output shape of the layer or a column's dense tensor.\n+        \"\"\"Computes expected output shape of the dense tensor of the layer.\n \n         Args:\n           input_shape: Tensor or array with batch shape."
    },
    {
        "commit_id": "fd2951d40ea933030cd650d656faf5311dd6b40d",
        "commit_message": "Fix line-too-long lint errors across the codebase.\n\nPiperOrigin-RevId: 484002276",
        "commit_url": "https://github.com/keras-team/keras/commit/fd2951d40ea933030cd650d656faf5311dd6b40d",
        "buggy_code": "\"\"\"Test multi-worker training flow demo'ed in go/multi-worker-with-keras.",
        "fixed_code": "\"\"\"Test multi-worker training flow demoed in go/multi-worker-with-keras.",
        "patch": "@@ -149,7 +149,7 @@ def testSingleWorkerModelFit(self):\n         )\n     )\n     def testMwmsWithModelFit(self, mode):\n-        \"\"\"Test multi-worker training flow demo'ed in go/multi-worker-with-keras.\n+        \"\"\"Test multi-worker training flow demoed in go/multi-worker-with-keras.\n \n         This test should be kept in sync with the code samples in\n         go/multi-worker-with-keras."
    },
    {
        "commit_id": "fd2951d40ea933030cd650d656faf5311dd6b40d",
        "commit_message": "Fix line-too-long lint errors across the codebase.\n\nPiperOrigin-RevId: 484002276",
        "commit_url": "https://github.com/keras-team/keras/commit/fd2951d40ea933030cd650d656faf5311dd6b40d",
        "buggy_code": "\"\"\"Apply N-D convolution with un-shared weights using a single sparse matmul.",
        "fixed_code": "\"\"\"Apply N-D convolution with unshared weights using a single sparse matmul.",
        "patch": "@@ -139,7 +139,7 @@ def local_conv_matmul(inputs, kernel, kernel_mask, output_shape):\n def local_conv_sparse_matmul(\n     inputs, kernel, kernel_idxs, kernel_shape, output_shape\n ):\n-    \"\"\"Apply N-D convolution with un-shared weights using a single sparse matmul.\n+    \"\"\"Apply N-D convolution with unshared weights using a single sparse matmul.\n \n     This method outputs `inputs . tf.sparse.SparseTensor(indices=kernel_idxs,\n     values=kernel, dense_shape=kernel_shape)`, with `.` standing for"
    },
    {
        "commit_id": "fd2951d40ea933030cd650d656faf5311dd6b40d",
        "commit_message": "Fix line-too-long lint errors across the codebase.\n\nPiperOrigin-RevId: 484002276",
        "commit_url": "https://github.com/keras-team/keras/commit/fd2951d40ea933030cd650d656faf5311dd6b40d",
        "buggy_code": "\"\"\"Tests that batchnorm layer is trainable when learning phase is enabled.",
        "fixed_code": "\"\"\"Tests that BN layer is trainable when learning phase is enabled.",
        "patch": "@@ -558,7 +558,7 @@ def test_that_trainable_disables_updates(self, layer):\n             self.assertAllClose(x1, x2, atol=1e-7)\n \n     def test_batchnorm_trainable(self, layer):\n-        \"\"\"Tests that batchnorm layer is trainable when learning phase is enabled.\n+        \"\"\"Tests that BN layer is trainable when learning phase is enabled.\n \n         Computes mean and std for current inputs then\n         applies batch normalization using them."
    },
    {
        "commit_id": "fd2951d40ea933030cd650d656faf5311dd6b40d",
        "commit_message": "Fix line-too-long lint errors across the codebase.\n\nPiperOrigin-RevId: 484002276",
        "commit_url": "https://github.com/keras-team/keras/commit/fd2951d40ea933030cd650d656faf5311dd6b40d",
        "buggy_code": "\"\"\"Pooling layer for arbitrary pooling functions, for 2D inputs (e.g. images).",
        "fixed_code": "\"\"\"Pooling layer for arbitrary pooling functions, for 2D data (e.g. images).",
        "patch": "@@ -24,7 +24,7 @@\n \n \n class Pooling2D(Layer):\n-    \"\"\"Pooling layer for arbitrary pooling functions, for 2D inputs (e.g. images).\n+    \"\"\"Pooling layer for arbitrary pooling functions, for 2D data (e.g. images).\n \n     This class only exists for code reuse. It will never be an exposed API.\n "
    },
    {
        "commit_id": "fd2951d40ea933030cd650d656faf5311dd6b40d",
        "commit_message": "Fix line-too-long lint errors across the codebase.\n\nPiperOrigin-RevId: 484002276",
        "commit_url": "https://github.com/keras-team/keras/commit/fd2951d40ea933030cd650d656faf5311dd6b40d",
        "buggy_code": "\"\"\"Sets vocabulary (and optionally document frequency) data for this layer.",
        "fixed_code": "\"\"\"Sets vocabulary (and optionally document frequency) for this layer.",
        "patch": "@@ -437,7 +437,7 @@ def get_config(self):\n         return dict(list(base_config.items()) + list(config.items()))\n \n     def set_vocabulary(self, vocabulary, idf_weights=None):\n-        \"\"\"Sets vocabulary (and optionally document frequency) data for this layer.\n+        \"\"\"Sets vocabulary (and optionally document frequency) for this layer.\n \n         This method sets the vocabulary and idf weights for this layer directly,\n         instead of analyzing a dataset through `adapt`. It should be used"
    },
    {
        "commit_id": "fd2951d40ea933030cd650d656faf5311dd6b40d",
        "commit_message": "Fix line-too-long lint errors across the codebase.\n\nPiperOrigin-RevId: 484002276",
        "commit_url": "https://github.com/keras-team/keras/commit/fd2951d40ea933030cd650d656faf5311dd6b40d",
        "buggy_code": "\"\"\"Maps `PreprocessingStage` inputs to inputs at `current_layer_index`.",
        "fixed_code": "\"\"\"Maps this object's inputs to those at current_layer_index.",
        "patch": "@@ -72,7 +72,7 @@ def adapt(self, data, reset_state=True):\n                 continue\n \n             def map_fn(x):\n-                \"\"\"Maps `PreprocessingStage` inputs to inputs at `current_layer_index`.\n+                \"\"\"Maps this object's inputs to those at current_layer_index.\n \n                 Args:\n                   x: Batch of inputs seen in entry of the `PreprocessingStage`"
    },
    {
        "commit_id": "fd2951d40ea933030cd650d656faf5311dd6b40d",
        "commit_message": "Fix line-too-long lint errors across the codebase.\n\nPiperOrigin-RevId: 484002276",
        "commit_url": "https://github.com/keras-team/keras/commit/fd2951d40ea933030cd650d656faf5311dd6b40d",
        "buggy_code": "\"\"\"Sets vocabulary (and optionally document frequency) data for this layer.",
        "fixed_code": "\"\"\"Sets vocabulary (and optionally document frequency) for this layer.",
        "patch": "@@ -521,7 +521,7 @@ def get_config(self):\n         return dict(list(base_config.items()) + list(config.items()))\n \n     def set_vocabulary(self, vocabulary, idf_weights=None):\n-        \"\"\"Sets vocabulary (and optionally document frequency) data for this layer.\n+        \"\"\"Sets vocabulary (and optionally document frequency) for this layer.\n \n         This method sets the vocabulary and idf weights for this layer directly,\n         instead of analyzing a dataset through 'adapt'. It should be used"
    },
    {
        "commit_id": "fd2951d40ea933030cd650d656faf5311dd6b40d",
        "commit_message": "Fix line-too-long lint errors across the codebase.\n\nPiperOrigin-RevId: 484002276",
        "commit_url": "https://github.com/keras-team/keras/commit/fd2951d40ea933030cd650d656faf5311dd6b40d",
        "buggy_code": "\"\"\"Run the cell and then apply the residual_fn on its inputs to its outputs.",
        "fixed_code": "\"\"\"Run the cell and apply the residual_fn.",
        "patch": "@@ -511,7 +511,7 @@ def __init__(self, cell, residual_fn=None, **kwargs):\n         self._residual_fn = residual_fn\n \n     def _call_wrapped_cell(self, inputs, state, cell_call_fn, **kwargs):\n-        \"\"\"Run the cell and then apply the residual_fn on its inputs to its outputs.\n+        \"\"\"Run the cell and apply the residual_fn.\n \n         Args:\n           inputs: cell inputs."
    },
    {
        "commit_id": "fd2951d40ea933030cd650d656faf5311dd6b40d",
        "commit_message": "Fix line-too-long lint errors across the codebase.\n\nPiperOrigin-RevId: 484002276",
        "commit_url": "https://github.com/keras-team/keras/commit/fd2951d40ea933030cd650d656faf5311dd6b40d",
        "buggy_code": "\"\"\"Run the cell and then apply the residual_fn on its inputs to its outputs.",
        "fixed_code": "\"\"\"Run the cell and apply the residual_fn.",
        "patch": "@@ -551,7 +551,7 @@ def __init__(self, cell, residual_fn=None, **kwargs):\n         self._residual_fn = residual_fn\n \n     def _call_wrapped_cell(self, inputs, state, cell_call_fn, **kwargs):\n-        \"\"\"Run the cell and then apply the residual_fn on its inputs to its outputs.\n+        \"\"\"Run the cell and apply the residual_fn.\n \n         Args:\n           inputs: cell inputs."
    },
    {
        "commit_id": "fd2951d40ea933030cd650d656faf5311dd6b40d",
        "commit_message": "Fix line-too-long lint errors across the codebase.\n\nPiperOrigin-RevId: 484002276",
        "commit_url": "https://github.com/keras-team/keras/commit/fd2951d40ea933030cd650d656faf5311dd6b40d",
        "buggy_code": "\"\"\"Tuple used by LSTM Cells for `state_size`, `zero_state`, and output state.",
        "fixed_code": "\"\"\"Tuple used by LSTM Cells for `state_size`, `zero_state`, & output state.",
        "patch": "@@ -648,7 +648,7 @@ def get_config(self):\n @keras_export(v1=[\"keras.__internal__.legacy.rnn_cell.LSTMStateTuple\"])\n @tf_export(v1=[\"nn.rnn_cell.LSTMStateTuple\"])\n class LSTMStateTuple(_LSTMStateTuple):\n-    \"\"\"Tuple used by LSTM Cells for `state_size`, `zero_state`, and output state.\n+    \"\"\"Tuple used by LSTM Cells for `state_size`, `zero_state`, & output state.\n \n     Stores two elements: `(c, h)`, in that order. Where `c` is the hidden state\n     and `h` is the output."
    },
    {
        "commit_id": "fd2951d40ea933030cd650d656faf5311dd6b40d",
        "commit_message": "Fix line-too-long lint errors across the codebase.\n\nPiperOrigin-RevId: 484002276",
        "commit_url": "https://github.com/keras-team/keras/commit/fd2951d40ea933030cd650d656faf5311dd6b40d",
        "buggy_code": "\"\"\"Functional interface for 1D convolution layer (e.g. temporal convolution).",
        "fixed_code": "\"\"\"Functional interface for 1D convolution (e.g. temporal convolution).",
        "patch": "@@ -180,7 +180,7 @@ def conv1d(\n     name=None,\n     reuse=None,\n ):\n-    \"\"\"Functional interface for 1D convolution layer (e.g. temporal convolution).\n+    \"\"\"Functional interface for 1D convolution (e.g. temporal convolution).\n \n     This layer creates a convolution kernel that is convolved\n     (actually cross-correlated) with the layer input to produce a tensor of"
    },
    {
        "commit_id": "fd2951d40ea933030cd650d656faf5311dd6b40d",
        "commit_message": "Fix line-too-long lint errors across the codebase.\n\nPiperOrigin-RevId: 484002276",
        "commit_url": "https://github.com/keras-team/keras/commit/fd2951d40ea933030cd650d656faf5311dd6b40d",
        "buggy_code": "\"\"\"TF2-compatible VariableStore that avoids collections & tracks regularizers.",
        "fixed_code": "\"\"\"TF2-safe VariableStore that avoids collections & tracks regularizers.",
        "patch": "@@ -136,7 +136,7 @@ def validate_synchronization_aggregation_trainable(\n \n \n class _EagerVariableStore(tf.Module):\n-    \"\"\"TF2-compatible VariableStore that avoids collections & tracks regularizers.\n+    \"\"\"TF2-safe VariableStore that avoids collections & tracks regularizers.\n \n     New variable names and new variables can be created; all stored\n     variables are initialized with the initializer passed to __init__."
    },
    {
        "commit_id": "fd2951d40ea933030cd650d656faf5311dd6b40d",
        "commit_message": "Fix line-too-long lint errors across the codebase.\n\nPiperOrigin-RevId: 484002276",
        "commit_url": "https://github.com/keras-team/keras/commit/fd2951d40ea933030cd650d656faf5311dd6b40d",
        "buggy_code": "\"\"\"Computes the focal cross-entropy loss between true labels and predictions.",
        "fixed_code": "\"\"\"Computes focal cross-entropy loss between true labels and predictions.",
        "patch": "@@ -670,7 +670,7 @@ def __init__(\n \n @keras_export(\"keras.losses.BinaryFocalCrossentropy\")\n class BinaryFocalCrossentropy(LossFunctionWrapper):\n-    \"\"\"Computes the focal cross-entropy loss between true labels and predictions.\n+    \"\"\"Computes focal cross-entropy loss between true labels and predictions.\n \n     Binary cross-entropy loss is often used for binary (0 or 1) classification\n     tasks. The loss function requires the following inputs:"
    },
    {
        "commit_id": "fd2951d40ea933030cd650d656faf5311dd6b40d",
        "commit_message": "Fix line-too-long lint errors across the codebase.\n\nPiperOrigin-RevId: 484002276",
        "commit_url": "https://github.com/keras-team/keras/commit/fd2951d40ea933030cd650d656faf5311dd6b40d",
        "buggy_code": "\"\"\"Variable that will cast itself to a different dtype in applicable contexts.",
        "fixed_code": "\"\"\"Variable that casts itself to a different dtype in applicable contexts.",
        "patch": "@@ -39,7 +39,7 @@ def numpy_text(tensor, is_repr=False):\n \n \n class AutoCastVariable(tf.Variable, tf.__internal__.types.Tensor):\n-    \"\"\"Variable that will cast itself to a different dtype in applicable contexts.\n+    \"\"\"Variable that casts itself to a different dtype in applicable contexts.\n \n     This class wraps a floating-point `tf.Variable`. It emulates the variable\n     interface and delegates to the wrapped variable, but it additionally will"
    },
    {
        "commit_id": "fd2951d40ea933030cd650d656faf5311dd6b40d",
        "commit_message": "Fix line-too-long lint errors across the codebase.\n\nPiperOrigin-RevId: 484002276",
        "commit_url": "https://github.com/keras-team/keras/commit/fd2951d40ea933030cd650d656faf5311dd6b40d",
        "buggy_code": "\"\"\"Serializes a `LearningRateSchedule` into a JSON-compatible representation.",
        "fixed_code": "\"\"\"Serializes a `LearningRateSchedule` into a JSON-compatible dict.",
        "patch": "@@ -1091,7 +1091,7 @@ def get_config(self):\n \n @keras_export(\"keras.optimizers.schedules.serialize\")\n def serialize(learning_rate_schedule):\n-    \"\"\"Serializes a `LearningRateSchedule` into a JSON-compatible representation.\n+    \"\"\"Serializes a `LearningRateSchedule` into a JSON-compatible dict.\n \n     Args:\n       learning_rate_schedule: The `LearningRateSchedule` object to serialize."
    },
    {
        "commit_id": "fd2951d40ea933030cd650d656faf5311dd6b40d",
        "commit_message": "Fix line-too-long lint errors across the codebase.\n\nPiperOrigin-RevId: 484002276",
        "commit_url": "https://github.com/keras-team/keras/commit/fd2951d40ea933030cd650d656faf5311dd6b40d",
        "buggy_code": "\"\"\"Iterator capable of reading images from a directory on disk as a dataframe.",
        "fixed_code": "\"\"\"Iterator capable of reading images from a directory as a dataframe.",
        "patch": "@@ -841,7 +841,7 @@ def validate_filename(filename, white_list_formats):\n \n \n class DataFrameIterator(BatchFromFilesMixin, Iterator):\n-    \"\"\"Iterator capable of reading images from a directory on disk as a dataframe.\n+    \"\"\"Iterator capable of reading images from a directory as a dataframe.\n \n     Args:\n         dataframe: Pandas dataframe containing the filepaths relative to"
    },
    {
        "commit_id": "fd2951d40ea933030cd650d656faf5311dd6b40d",
        "commit_message": "Fix line-too-long lint errors across the codebase.\n\nPiperOrigin-RevId: 484002276",
        "commit_url": "https://github.com/keras-team/keras/commit/fd2951d40ea933030cd650d656faf5311dd6b40d",
        "buggy_code": "\"\"\"A regularizer that encourages input vectors to be orthogonal to each other.",
        "fixed_code": "\"\"\"Regularizer that encourages input vectors to be orthogonal to each other.",
        "patch": "@@ -329,7 +329,7 @@ def get_config(self):\n     v1=[],\n )\n class OrthogonalRegularizer(Regularizer):\n-    \"\"\"A regularizer that encourages input vectors to be orthogonal to each other.\n+    \"\"\"Regularizer that encourages input vectors to be orthogonal to each other.\n \n     It can be applied to either the rows of a matrix (`mode=\"rows\"`) or its\n     columns (`mode=\"columns\"`). When applied to a `Dense` kernel of shape"
    },
    {
        "commit_id": "fd2951d40ea933030cd650d656faf5311dd6b40d",
        "commit_message": "Fix line-too-long lint errors across the codebase.\n\nPiperOrigin-RevId: 484002276",
        "commit_url": "https://github.com/keras-team/keras/commit/fd2951d40ea933030cd650d656faf5311dd6b40d",
        "buggy_code": "\"\"\"Checks that the loaded weights and metrics are the same as the original.",
        "fixed_code": "\"\"\"Checks that loaded weights & metrics are the same as the original.",
        "patch": "@@ -468,7 +468,7 @@ def _save_model_dir(self, dirname=\"saved_model\"):\n         return os.path.join(temp_dir, dirname)\n \n     def _assert_same_weights_and_metrics(self, model, loaded_model):\n-        \"\"\"Checks that the loaded weights and metrics are the same as the original.\n+        \"\"\"Checks that loaded weights & metrics are the same as the original.\n \n         Args:\n           model: original model"
    },
    {
        "commit_id": "fd2951d40ea933030cd650d656faf5311dd6b40d",
        "commit_message": "Fix line-too-long lint errors across the codebase.\n\nPiperOrigin-RevId: 484002276",
        "commit_url": "https://github.com/keras-team/keras/commit/fd2951d40ea933030cd650d656faf5311dd6b40d",
        "buggy_code": "r\"\"\"Computes exact Laplacian kernel value(s) for tensors x and y using stddev.",
        "fixed_code": "r\"\"\"Computes exact Laplacian kernel value(s) for tensors x & y using stddev.",
        "patch": "@@ -84,7 +84,7 @@ def exact_gaussian_kernel(x, y, stddev):\n \n \n def exact_laplacian_kernel(x, y, stddev):\n-    r\"\"\"Computes exact Laplacian kernel value(s) for tensors x and y using stddev.\n+    r\"\"\"Computes exact Laplacian kernel value(s) for tensors x & y using stddev.\n \n     The Laplacian kernel for vectors u, v is defined as follows:\n          K(u, v) = exp(-||u-v|| / stddev)"
    },
    {
        "commit_id": "fd2951d40ea933030cd650d656faf5311dd6b40d",
        "commit_message": "Fix line-too-long lint errors across the codebase.\n\nPiperOrigin-RevId: 484002276",
        "commit_url": "https://github.com/keras-team/keras/commit/fd2951d40ea933030cd650d656faf5311dd6b40d",
        "buggy_code": "\"\"\"Prints a summary for a single layer (including topological connections).",
        "fixed_code": "\"\"\"Prints a summary for a single layer (including its connections).",
        "patch": "@@ -352,7 +352,7 @@ def print_layer_summary(layer, nested_level=0):\n         print_row(fields, positions, nested_level)\n \n     def print_layer_summary_with_connections(layer, nested_level=0):\n-        \"\"\"Prints a summary for a single layer (including topological connections).\n+        \"\"\"Prints a summary for a single layer (including its connections).\n \n         Args:\n             layer: target layer."
    },
    {
        "commit_id": "cce064403f0ac3fdea12007d31159533719c4f98",
        "commit_message": "Keras: Fix docstring for tf.keras.optimizer. -> tf.keras.optimizers.\n\nPiperOrigin-RevId: 481721074",
        "commit_url": "https://github.com/keras-team/keras/commit/cce064403f0ac3fdea12007d31159533719c4f98",
        "buggy_code": "`tf.keras.optimizer.legacy.Optimizer` instance.",
        "fixed_code": "`tf.keras.optimizers.legacy.Optimizer` instance.",
        "patch": "@@ -196,7 +196,7 @@ def convert_to_legacy_optimizer(optimizer):\n \n     This function takes in a `tf.keras.optimizers.experimental.Optimizer`\n     instance and converts it to the corresponding\n-    `tf.keras.optimizer.legacy.Optimizer` instance.\n+    `tf.keras.optimizers.legacy.Optimizer` instance.\n     For example, `tf.keras.optimizers.experimental.Adam(...)` to\n     `tf.keras.optimizers.legacy.Adam(...)`.\n "
    },
    {
        "commit_id": "f329850e830b3c7d4f7f2bed3627f88ade8cf6b2",
        "commit_message": "keras: fix typo in keras optimizers migration recommendation\n\n  tf.keras.optimizer.legacy -> tf.keras.optimizers.legacy\n\nPiperOrigin-RevId: 481720094",
        "commit_url": "https://github.com/keras-team/keras/commit/f329850e830b3c7d4f7f2bed3627f88ade8cf6b2",
        "buggy_code": "f\"`tf.keras.optimizer.legacy.{self.__class__.__name__}`.\"",
        "fixed_code": "f\"`tf.keras.optimizers.legacy.{self.__class__.__name__}`.\"",
        "patch": "@@ -127,7 +127,7 @@ def _create_or_restore_slot_variable(self, **kwargs):\n             \"errors. Please update the optimizer referenced in your code \"\n             \"to be an instance of \"\n             \"`tf.keras.optimizers.legacy.Optimizer`, e.g.: \"\n-            f\"`tf.keras.optimizer.legacy.{self.__class__.__name__}`.\"\n+            f\"`tf.keras.optimizers.legacy.{self.__class__.__name__}`.\"\n         )\n \n     def _var_key(self, variable):"
    },
    {
        "commit_id": "eedaf5aba9c7c99995a09c1e8e4ebd681ca96ba9",
        "commit_message": "Fix typo\n\nMinor typo is fixed.",
        "commit_url": "https://github.com/keras-team/keras/commit/eedaf5aba9c7c99995a09c1e8e4ebd681ca96ba9",
        "buggy_code": "(words maybe include the `'` character). These sequences are then",
        "fixed_code": "(words may include the `'` character). These sequences are then",
        "patch": "@@ -209,7 +209,7 @@ class Tokenizer(object):\n \n     By default, all punctuation is removed, turning the texts into\n     space-separated sequences of words\n-    (words maybe include the `'` character). These sequences are then\n+    (words may include the `'` character). These sequences are then\n     split into lists of tokens. They will then be indexed or vectorized.\n \n     `0` is a reserved index that won't be assigned to any word."
    },
    {
        "commit_id": "181d73a909e6c443f7f3ab4fc3ba3c84f01cd802",
        "commit_message": "Merge pull request #17150 from sushreebarsa:patch-3\n\nPiperOrigin-RevId: 481148068",
        "commit_url": "https://github.com/keras-team/keras/commit/181d73a909e6c443f7f3ab4fc3ba3c84f01cd802",
        "buggy_code": "return random.randint(1, 1e9)",
        "fixed_code": "return random.randint(1, int(1e9))",
        "patch": "@@ -2029,7 +2029,7 @@ def _create_seed(self, user_specified_seed):\n         elif getattr(_SEED_GENERATOR, \"generator\", None):\n             return _SEED_GENERATOR.generator.randint(1, 1e9)\n         else:\n-            return random.randint(1, 1e9)\n+            return random.randint(1, int(1e9))\n \n     def random_normal(\n         self, shape, mean=0.0, stddev=1.0, dtype=None, nonce=None"
    },
    {
        "commit_id": "67c428f7e0431b1a8197dcf939936653d0a3a059",
        "commit_message": "Fix typos in docstrings",
        "commit_url": "https://github.com/keras-team/keras/commit/67c428f7e0431b1a8197dcf939936653d0a3a059",
        "buggy_code": ">>> # Only 6 more epochs are run, since first trainning got interrupted at",
        "fixed_code": ">>> # Only 6 more epochs are run, since first training got interrupted at",
        "patch": "@@ -1776,7 +1776,7 @@ class BackupAndRestore(Callback):\n     >>> history = model.fit(np.arange(100).reshape(5, 20), np.zeros(5),\n     ...                     epochs=10, batch_size=1, callbacks=[callback],\n     ...                     verbose=0)\n-    >>> # Only 6 more epochs are run, since first trainning got interrupted at\n+    >>> # Only 6 more epochs are run, since first training got interrupted at\n     >>> # zero-indexed epoch 4, second training will continue from 4 to 9.\n     >>> len(history.history['loss'])\n     6"
    },
    {
        "commit_id": "67c428f7e0431b1a8197dcf939936653d0a3a059",
        "commit_message": "Fix typos in docstrings",
        "commit_url": "https://github.com/keras-team/keras/commit/67c428f7e0431b1a8197dcf939936653d0a3a059",
        "buggy_code": "\"\"\"Returns true if this RaggedTensor has the same row_lenghts across",
        "fixed_code": "\"\"\"Returns true if this RaggedTensor has the same row_lengths across",
        "patch": "@@ -1503,7 +1503,7 @@ def _ragged_tensor_apply_loss(loss_fn, y_true, y_pred, y_pred_extra_dim=False):\n     \"\"\"\n \n     def rt_is_equiv_dense(rt):\n-        \"\"\"Returns true if this RaggedTensor has the same row_lenghts across\n+        \"\"\"Returns true if this RaggedTensor has the same row_lengths across\n \n            all ragged dimensions and thus can be converted to a dense tensor\n            without loss of information."
    },
    {
        "commit_id": "0ca8f0dd81506c4dbc75da0e36917a36ee7c351e",
        "commit_message": "Argument documentation minor fix.",
        "commit_url": "https://github.com/keras-team/keras/commit/0ca8f0dd81506c4dbc75da0e36917a36ee7c351e",
        "buggy_code": "to monitor improvement. This allows a warm-up period in which",
        "fixed_code": "to monitor improvement. This allows for a warm-up period in which",
        "patch": "@@ -1947,7 +1947,7 @@ class EarlyStopping(Callback):\n           improves on `baseline`, training will run for `patience`\n           epochs and restore weights from the best epoch in that set.\n       start_from_epoch: Number of epochs to wait before starting\n-          to monitor improvement. This allows a warm-up period in which\n+          to monitor improvement. This allows for a warm-up period in which\n           no improvement is expected and thus training will not be stopped.\n \n "
    },
    {
        "commit_id": "70e550307a6de96e276086164e365e8120093154",
        "commit_message": "Fix IndexError when outs is empty",
        "commit_url": "https://github.com/keras-team/keras/commit/70e550307a6de96e276086164e365e8120093154",
        "buggy_code": "if len(outs) >= 0:",
        "fixed_code": "if len(outs) > 0:",
        "patch": "@@ -460,7 +460,7 @@ def _test_step_fn(inputs):\n     callbacks._call_end_hook(mode)\n \n     scope.__exit__(None, None, None)\n-    if len(outs) >= 0:\n+    if len(outs) > 0:\n         outs[0] /= target_steps\n \n     if len(outs) == 1:"
    },
    {
        "commit_id": "5280dc6f252856915989e147cd709d4bb8040793",
        "commit_message": "Fix RegNet when input_tensor is given",
        "commit_url": "https://github.com/keras-team/keras/commit/5280dc6f252856915989e147cd709d4bb8040793",
        "buggy_code": "inputs = layer_utils.get_source_inputs(input_tensor)",
        "fixed_code": "inputs = layer_utils.get_source_inputs(input_tensor)[0]",
        "patch": "@@ -951,7 +951,7 @@ def RegNet(\n             img_input = input_tensor\n \n     if input_tensor is not None:\n-        inputs = layer_utils.get_source_inputs(input_tensor)\n+        inputs = layer_utils.get_source_inputs(input_tensor)[0]\n     else:\n         inputs = img_input\n "
    },
    {
        "commit_id": "4a53041aea5a37f317df4a0cb0b6996a956cc077",
        "commit_message": "Fix ConvNeXt when input_tensor is given",
        "commit_url": "https://github.com/keras-team/keras/commit/4a53041aea5a37f317df4a0cb0b6996a956cc077",
        "buggy_code": "inputs = utils.layer_utils.get_source_inputs(input_tensor)",
        "fixed_code": "inputs = utils.layer_utils.get_source_inputs(input_tensor)[0]",
        "patch": "@@ -447,7 +447,7 @@ def ConvNeXt(\n             img_input = input_tensor\n \n     if input_tensor is not None:\n-        inputs = utils.layer_utils.get_source_inputs(input_tensor)\n+        inputs = utils.layer_utils.get_source_inputs(input_tensor)[0]\n     else:\n         inputs = img_input\n "
    },
    {
        "commit_id": "a557eb088020085d3b717b8aba1c54c7fdfb7f21",
        "commit_message": "Merge pull request #17038 from mohantym:patch-1\n\nPiperOrigin-RevId: 475875263",
        "commit_url": "https://github.com/keras-team/keras/commit/a557eb088020085d3b717b8aba1c54c7fdfb7f21",
        "buggy_code": "al.](http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf)",
        "fixed_code": "al.](https://github.com/mlresearch/v37/blob/gh-pages/jozefowicz15.pdf)",
        "patch": "@@ -89,7 +89,7 @@ class LSTMCell(DropoutRNNCellMixin, base_layer.BaseRandomLayer):\n       unit_forget_bias: Boolean (default `True`). If True, add 1 to the bias of\n         the forget gate at initialization. Setting it to true will also force\n         `bias_initializer=\"zeros\"`. This is recommended in [Jozefowicz et\n-          al.](http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf)\n+          al.](https://github.com/mlresearch/v37/blob/gh-pages/jozefowicz15.pdf)\n       kernel_regularizer: Regularizer function applied to the `kernel` weights\n         matrix. Default: `None`.\n       recurrent_regularizer: Regularizer function applied to"
    },
    {
        "commit_id": "a4688836a0556d5580f55d463d4e61e6e68e91b2",
        "commit_message": "bug fix in start_from_epoch condition",
        "commit_url": "https://github.com/keras-team/keras/commit/a4688836a0556d5580f55d463d4e61e6e68e91b2",
        "buggy_code": "if current is None or epoch <= self.start_from_epoch:",
        "fixed_code": "if current is None or epoch < self.start_from_epoch:",
        "patch": "@@ -2025,7 +2025,7 @@ def on_train_begin(self, logs=None):\n \n     def on_epoch_end(self, epoch, logs=None):\n         current = self.get_monitor_value(logs)\n-        if current is None or epoch <= self.start_from_epoch:\n+        if current is None or epoch < self.start_from_epoch:\n             # If no monitor value exists or still in initial warm-up stage.\n             return\n         if self.restore_best_weights and self.best_weights is None:"
    },
    {
        "commit_id": "ed7791f06ee58f4b0d12d9aad0b1ee3a7fdbb86b",
        "commit_message": "Merge pull request #16963 from gadagashwini:patch-11\n\nPiperOrigin-RevId: 471580174",
        "commit_url": "https://github.com/keras-team/keras/commit/ed7791f06ee58f4b0d12d9aad0b1ee3a7fdbb86b",
        "buggy_code": "if units < 0:",
        "fixed_code": "if units <= 0:",
        "patch": "@@ -135,7 +135,7 @@ def __init__(\n         reset_after=True,\n         **kwargs,\n     ):\n-        if units < 0:\n+        if units <= 0:\n             raise ValueError(\n                 \"Received an invalid value for argument `units`, \"\n                 f\"expected a positive integer, got {units}.\""
    },
    {
        "commit_id": "6f8ad5b92d54f7b074960222ed7047440bd1e911",
        "commit_message": "Merge pull request #16921 from gadagashwini:patch-8\n\nPiperOrigin-RevId: 470151487",
        "commit_url": "https://github.com/keras-team/keras/commit/6f8ad5b92d54f7b074960222ed7047440bd1e911",
        "buggy_code": "if self.units < 0:",
        "fixed_code": "if self.units <= 0:",
        "patch": "@@ -117,7 +117,7 @@ def __init__(\n         super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n \n         self.units = int(units) if not isinstance(units, int) else units\n-        if self.units < 0:\n+        if self.units <= 0:\n             raise ValueError(\n                 \"Received an invalid value for `units`, expected \"\n                 f\"a positive integer. Received: units={units}\""
    },
    {
        "commit_id": "f0dec5534075f0c6568b4f228a86f7a31cbc2997",
        "commit_message": "Merge pull request #16926 from gadagashwini:patch-9\n\nPiperOrigin-RevId: 469840464",
        "commit_url": "https://github.com/keras-team/keras/commit/f0dec5534075f0c6568b4f228a86f7a31cbc2997",
        "buggy_code": "if units < 0:",
        "fixed_code": "if units <= 0:",
        "patch": "@@ -121,7 +121,7 @@ def __init__(\n         recurrent_dropout=0.0,\n         **kwargs,\n     ):\n-        if units < 0:\n+        if units <= 0:\n             raise ValueError(\n                 \"Received an invalid value for argument `units`, \"\n                 f\"expected a positive integer, got {units}.\""
    },
    {
        "commit_id": "ff78ae0a66aaae4495fdb88e53bd8f68c05e03f7",
        "commit_message": "Merge pull request #16929 from gadagashwini:patch-10\n\nPiperOrigin-RevId: 469840389",
        "commit_url": "https://github.com/keras-team/keras/commit/ff78ae0a66aaae4495fdb88e53bd8f68c05e03f7",
        "buggy_code": "if units < 0:",
        "fixed_code": "if units <= 0:",
        "patch": "@@ -139,7 +139,7 @@ def __init__(\n         recurrent_dropout=0.0,\n         **kwargs,\n     ):\n-        if units < 0:\n+        if units <= 0:\n             raise ValueError(\n                 \"Received an invalid value for argument `units`, \"\n                 f\"expected a positive integer, got {units}.\""
    },
    {
        "commit_id": "a270ddc6fdc1746e25aec2b9f760c57cd17ce35d",
        "commit_message": "Fix Value error of tf.keras.layers.GRU\n\nSimilar #16921",
        "commit_url": "https://github.com/keras-team/keras/commit/a270ddc6fdc1746e25aec2b9f760c57cd17ce35d",
        "buggy_code": "if units < 0:",
        "fixed_code": "if units <= 0:",
        "patch": "@@ -135,7 +135,7 @@ def __init__(\n         reset_after=True,\n         **kwargs,\n     ):\n-        if units < 0:\n+        if units <= 0:\n             raise ValueError(\n                 \"Received an invalid value for argument `units`, \"\n                 f\"expected a positive integer, got {units}.\""
    },
    {
        "commit_id": "d2239e188b61f8d95cd487458dc1ebf3db8697b3",
        "commit_message": "Fix Value Error for Units of tf.keras.layers.LSTM",
        "commit_url": "https://github.com/keras-team/keras/commit/d2239e188b61f8d95cd487458dc1ebf3db8697b3",
        "buggy_code": "if units < 0:",
        "fixed_code": "if units <= 0:",
        "patch": "@@ -139,7 +139,7 @@ def __init__(\n         recurrent_dropout=0.0,\n         **kwargs,\n     ):\n-        if units < 0:\n+        if units <= 0:\n             raise ValueError(\n                 \"Received an invalid value for argument `units`, \"\n                 f\"expected a positive integer, got {units}.\""
    },
    {
        "commit_id": "0142057859208671e2f089214c7b1784778a0da5",
        "commit_message": "Fix Value error for Units of tf.keras.layers.SimpleRNN",
        "commit_url": "https://github.com/keras-team/keras/commit/0142057859208671e2f089214c7b1784778a0da5",
        "buggy_code": "if units < 0:",
        "fixed_code": "if units <= 0:",
        "patch": "@@ -121,7 +121,7 @@ def __init__(\n         recurrent_dropout=0.0,\n         **kwargs,\n     ):\n-        if units < 0:\n+        if units <= 0:\n             raise ValueError(\n                 \"Received an invalid value for argument `units`, \"\n                 f\"expected a positive integer, got {units}.\""
    },
    {
        "commit_id": "13e6a8c2fa5fcad302b04fc1fb0b56d441aa2624",
        "commit_message": "Fix value error for Units of tf.keras.layers.Dense",
        "commit_url": "https://github.com/keras-team/keras/commit/13e6a8c2fa5fcad302b04fc1fb0b56d441aa2624",
        "buggy_code": "if self.units < 0:",
        "fixed_code": "if self.units <= 0:",
        "patch": "@@ -117,7 +117,7 @@ def __init__(\n         super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n \n         self.units = int(units) if not isinstance(units, int) else units\n-        if self.units < 0:\n+        if self.units <= 0:\n             raise ValueError(\n                 \"Received an invalid value for `units`, expected \"\n                 f\"a positive integer. Received: units={units}\""
    },
    {
        "commit_id": "a5f965de22a4c85633d45ce1d287343879f01163",
        "commit_message": "Minor doc fix.\n\nPiperOrigin-RevId: 467823695",
        "commit_url": "https://github.com/keras-team/keras/commit/a5f965de22a4c85633d45ce1d287343879f01163",
        "buggy_code": "```",
        "fixed_code": "```python",
        "patch": "@@ -374,7 +374,7 @@ def load_img(\n \n     Usage:\n \n-    ```\n+    ```python\n     image = tf.keras.utils.load_img(image_path)\n     input_arr = tf.keras.utils.img_to_array(image)\n     input_arr = np.array([input_arr])  # Convert single image to a batch."
    },
    {
        "commit_id": "08350fa3baa6e11a9be0781c9160d8488acecb56",
        "commit_message": "[NumPy] Fix uses of deprecated multidimensional NumPy indexing with a non-tuple index.\n\nNumPy 1.23 removes support for non-tuple indexing of NumPy arrays (https://numpy.org/devdocs/release/1.23.0-notes.html#expired-deprecations). The workaround is to convert multidimensional indices to a tuple.\n\nPiperOrigin-RevId: 465166308",
        "commit_url": "https://github.com/keras-team/keras/commit/08350fa3baa6e11a9be0781c9160d8488acecb56",
        "buggy_code": "mask[p * 2] = True",
        "fixed_code": "mask[tuple(p * 2)] = True",
        "patch": "@@ -326,7 +326,7 @@ def test_conv_kernel_mask_rect_kernel(self, *input_shape):\n             ):\n                 p = list(p)\n                 p[d] = slice(None)\n-                mask[p * 2] = True\n+                mask[tuple(p * 2)] = True\n \n             mask = np.take(mask, range(0, min(1, input_shape[d])), ndims + d)\n "
    },
    {
        "commit_id": "a9475b4b8028771346af33de5513f354914749c4",
        "commit_message": "Fix test to be compatible with new optimizer.\n\nPiperOrigin-RevId: 464588969",
        "commit_url": "https://github.com/keras-team/keras/commit/a9475b4b8028771346af33de5513f354914749c4",
        "buggy_code": "np.ones((10, 1)), np.ones((10, 1)), epochs=0, callbacks=[cbk]",
        "fixed_code": "np.ones((10, 1)), np.ones((10, 1)), epochs=1, callbacks=[cbk]",
        "patch": "@@ -366,7 +366,7 @@ def test_trivial_backup_restore(self):\n             model.compile(\"sgd\", \"mse\")\n             cbk = BackupAndRestore(self.get_temp_dir())\n             model.fit(\n-                np.ones((10, 1)), np.ones((10, 1)), epochs=0, callbacks=[cbk]\n+                np.ones((10, 1)), np.ones((10, 1)), epochs=1, callbacks=[cbk]\n             )\n \n     def test_backup_restore_train_counter(self):"
    },
    {
        "commit_id": "5afd002a958540fb2e5cd9bbc980f746be2eccf8",
        "commit_message": "Merge pull request #16777 from cyai:dtensor-patch\n\nPiperOrigin-RevId: 464317600",
        "commit_url": "https://github.com/keras-team/keras/commit/5afd002a958540fb2e5cd9bbc980f746be2eccf8",
        "buggy_code": "s=[compat.as_bytes(\"loc:@%s\" % handle_name)]",
        "fixed_code": "s=[compat.as_bytes(f\"loc:@{handle_name}\")]",
        "patch": "@@ -42,7 +42,7 @@ def _infer_shape_dtype_and_create_handle(initial_value, shape, dtype, name):\n         device_context_manager = ops.NullContextmanager\n         attr = attr_value_pb2.AttrValue(\n             list=attr_value_pb2.AttrValue.ListValue(\n-                s=[compat.as_bytes(\"loc:@%s\" % handle_name)]\n+                s=[compat.as_bytes(f\"loc:@{handle_name}\")]\n             )\n         )\n         with ops.get_default_graph()._attr_scope({\"_class\": attr}):"
    },
    {
        "commit_id": "d25f091560b3427fdf7534d931a206d977517d1a",
        "commit_message": "Merge pull request #16775 from cyai:benchmarks-patch\n\nPiperOrigin-RevId: 463637462",
        "commit_url": "https://github.com/keras-team/keras/commit/d25f091560b3427fdf7534d931a206d977517d1a",
        "buggy_code": "\"Unrecognized Distribution Strategy: %r\" % distribution_strategy",
        "fixed_code": "f\"Unrecognized Distribution Strategy: {distribution_strategy}\"",
        "patch": "@@ -146,7 +146,7 @@ def get_distribution_strategy(\n         )\n \n     raise ValueError(\n-        \"Unrecognized Distribution Strategy: %r\" % distribution_strategy\n+        f\"Unrecognized Distribution Strategy: {distribution_strategy}\"\n     )\n \n "
    },
    {
        "commit_id": "d25f091560b3427fdf7534d931a206d977517d1a",
        "commit_message": "Merge pull request #16775 from cyai:benchmarks-patch\n\nPiperOrigin-RevId: 463637462",
        "commit_url": "https://github.com/keras-team/keras/commit/d25f091560b3427fdf7534d931a206d977517d1a",
        "buggy_code": "us_per_example = float(\"{0:.3f}\".format(total_time * 1e6 / num_iters_xprof))",
        "fixed_code": "us_per_example = float(f\"{total_time * 1000000.0 / num_iters_xprof:.3f}\")",
        "patch": "@@ -43,5 +43,5 @@ def run_with_xprof(\n         for _ in range(num_iters_xprof):\n             func()\n     total_time = time.time() - start\n-    us_per_example = float(\"{0:.3f}\".format(total_time * 1e6 / num_iters_xprof))\n+    us_per_example = float(f\"{total_time * 1000000.0 / num_iters_xprof:.3f}\")\n     return logdir, us_per_example"
    },
    {
        "commit_id": "e59c9b9bd606da7068bb34272800f2a5e8c1e54b",
        "commit_message": "Merge pull request #16806 from tilakrayal:patch-4\n\nPiperOrigin-RevId: 462657532",
        "commit_url": "https://github.com/keras-team/keras/commit/e59c9b9bd606da7068bb34272800f2a5e8c1e54b",
        "buggy_code": "this [guide](https://www.tensorflow.org/guide/ragged_tensors).",
        "fixed_code": "this [guide](https://www.tensorflow.org/guide/ragged_tensor).",
        "patch": "@@ -1370,7 +1370,7 @@ def placeholder(\n         ragged: Boolean, whether the placeholder should have a ragged type.\n             In this case, values of 'None' in the 'shape' argument represent\n             ragged dimensions. For more information about RaggedTensors, see\n-            this [guide](https://www.tensorflow.org/guide/ragged_tensors).\n+            this [guide](https://www.tensorflow.org/guide/ragged_tensor).\n \n     Raises:\n         ValueError: If called with sparse = True and ragged = True."
    },
    {
        "commit_id": "06521777bdf4419e5e6197e5815ba6a40d4a197f",
        "commit_message": "Update new test so that it fails without the fix",
        "commit_url": "https://github.com/keras-team/keras/commit/06521777bdf4419e5e6197e5815ba6a40d4a197f",
        "buggy_code": "weights=None, include_top=False, input_shape=(224, 224, 3)",
        "fixed_code": "weights='imagenet', include_top=False, input_shape=(224, 224, 3)",
        "patch": "@@ -180,7 +180,7 @@ def test_application_notop(self, app, last_dim):\n     def test_application_notop_custom_input_shape(self, app, last_dim):\n         output_shape = _get_output_shape(\n             lambda: app(\n-                weights=None, include_top=False, input_shape=(224, 224, 3)\n+                weights='imagenet', include_top=False, input_shape=(224, 224, 3)\n             )\n         )\n "
    },
    {
        "commit_id": "4a89bb6ced975a2cf339725af721268cecd94c22",
        "commit_message": "Fix typo in doc",
        "commit_url": "https://github.com/keras-team/keras/commit/4a89bb6ced975a2cf339725af721268cecd94c22",
        "buggy_code": "method to decay weights per the techniques discussed in the paeper,",
        "fixed_code": "method to decay weights per the techniques discussed in the paper,",
        "patch": "@@ -32,7 +32,7 @@ class AdamW(optimizer.Optimizer):\n \n     AdamW optimization is a stochastic gradient descent method that is based on\n     adaptive estimation of first-order and second-order moments with an added\n-    method to decay weights per the techniques discussed in the paeper,\n+    method to decay weights per the techniques discussed in the paper,\n     'Decoupled Weight Decay Regularization' by\n     [Loshchilov, Hutter et al., 2019](https://arxiv.org/abs/1711.05101).\n "
    },
    {
        "commit_id": "d32ff6ce318d53fa16a4acd52ac8a28d1c291f30",
        "commit_message": "Nasnet issue fix - require_flatten IFF include_top",
        "commit_url": "https://github.com/keras-team/keras/commit/d32ff6ce318d53fa16a4acd52ac8a28d1c291f30",
        "buggy_code": "require_flatten=True,",
        "fixed_code": "require_flatten=include_top,",
        "patch": "@@ -188,7 +188,7 @@ def NASNet(\n         default_size=default_size,\n         min_size=32,\n         data_format=backend.image_data_format(),\n-        require_flatten=True,\n+        require_flatten=include_top,\n         weights=weights,\n     )\n "
    },
    {
        "commit_id": "0bc804d2dd4cdeaccd7c6d382bdf15b50f9359a3",
        "commit_message": "Merge pull request #16799 from cyai:optimizers-patch\n\nPiperOrigin-RevId: 461955851",
        "commit_url": "https://github.com/keras-team/keras/commit/0bc804d2dd4cdeaccd7c6d382bdf15b50f9359a3",
        "buggy_code": "\"Could not interpret optimizer identifier: {}\".format(identifier)",
        "fixed_code": "f\"Could not interpret optimizer identifier: {identifier}\"",
        "patch": "@@ -193,5 +193,5 @@ def get(identifier):\n         return deserialize(config)\n     else:\n         raise ValueError(\n-            \"Could not interpret optimizer identifier: {}\".format(identifier)\n+            f\"Could not interpret optimizer identifier: {identifier}\"\n         )"
    },
    {
        "commit_id": "0bc804d2dd4cdeaccd7c6d382bdf15b50f9359a3",
        "commit_message": "Merge pull request #16799 from cyai:optimizers-patch\n\nPiperOrigin-RevId: 461955851",
        "commit_url": "https://github.com/keras-team/keras/commit/0bc804d2dd4cdeaccd7c6d382bdf15b50f9359a3",
        "buggy_code": "\"Expected {} >= 0, received: {}\".format(k, kwargs[k])",
        "fixed_code": "f\"Expected {k} >= 0, received: {kwargs[k]}\"",
        "patch": "@@ -49,7 +49,7 @@ def __init__(self, **kwargs):\n             # checks that clipnorm >= 0 and clipvalue >= 0\n             if kwargs[k] < 0:\n                 raise ValueError(\n-                    \"Expected {} >= 0, received: {}\".format(k, kwargs[k])\n+                    f\"Expected {k} >= 0, received: {kwargs[k]}\"\n                 )\n         self.__dict__.update(kwargs)\n         self.updates = []"
    },
    {
        "commit_id": "2180f3c82a76519f8abbcfe5ff1f7b7da9866bf6",
        "commit_message": "wrong reduction type error message fixed",
        "commit_url": "https://github.com/keras-team/keras/commit/2180f3c82a76519f8abbcfe5ff1f7b7da9866bf6",
        "buggy_code": "'`reduction` must be \"first\" or \"concat\" or \"sum\". Received: '",
        "fixed_code": "'`reduction` must be \"first\", \"concat\", or \"sum\". Received: '",
        "patch": "@@ -3820,7 +3820,7 @@ def _reduce(v):\n             return tf.reduce_sum(values)\n         else:\n             raise ValueError(\n-                '`reduction` must be \"first\" or \"concat\" or \"sum\". Received: '\n+                '`reduction` must be \"first\", \"concat\", or \"sum\". Received: '\n                 f\"reduction={reduction}.\"\n             )\n "
    },
    {
        "commit_id": "6db75928d738420b51058313c1d5db5cd0e67733",
        "commit_message": "docs: Fix a few typos\n\nThere are small typos in:\n- keras/layers/preprocessing/discretization.py\n- keras/layers/preprocessing/image_preprocessing.py\n- keras/saving/pickle_utils_test.py\n\nFixes:\n- Should read `protocol` rather than `protoocol`.\n- Should read `discretized` rather than `discritized`.\n- Should read `augmentation` rather than `augmentaion`.",
        "commit_url": "https://github.com/keras-team/keras/commit/6db75928d738420b51058313c1d5db5cd0e67733",
        "buggy_code": "- `\"int\"`: Return the discritized bin indices directly.",
        "fixed_code": "- `\"int\"`: Return the discretized bin indices directly.",
        "patch": "@@ -167,7 +167,7 @@ class Discretization(base_preprocessing_layer.PreprocessingLayer):\n       output_mode: Specification for the output of the layer. Defaults to\n         `\"int\"`.  Values can be `\"int\"`, `\"one_hot\"`, `\"multi_hot\"`, or\n         `\"count\"` configuring the layer as follows:\n-          - `\"int\"`: Return the discritized bin indices directly.\n+          - `\"int\"`: Return the discretized bin indices directly.\n           - `\"one_hot\"`: Encodes each individual element in the input into an\n             array the same size as `num_bins`, containing a 1 at the input's bin\n             index. If the last dimension is size 1, will encode on that"
    },
    {
        "commit_id": "6db75928d738420b51058313c1d5db5cd0e67733",
        "commit_message": "docs: Fix a few typos\n\nThere are small typos in:\n- keras/layers/preprocessing/discretization.py\n- keras/layers/preprocessing/image_preprocessing.py\n- keras/saving/pickle_utils_test.py\n\nFixes:\n- Should read `protocol` rather than `protoocol`.\n- Should read `discretized` rather than `discritized`.\n- Should read `augmentation` rather than `augmentaion`.",
        "commit_url": "https://github.com/keras-team/keras/commit/6db75928d738420b51058313c1d5db5cd0e67733",
        "buggy_code": "\"\"\"Abstract base layer for image augmentaion.",
        "fixed_code": "\"\"\"Abstract base layer for image augmentation.",
        "patch": "@@ -238,7 +238,7 @@ def get_config(self):\n \n @keras_export(\"keras.__internal__.layers.BaseImageAugmentationLayer\")\n class BaseImageAugmentationLayer(base_layer.BaseRandomLayer):\n-    \"\"\"Abstract base layer for image augmentaion.\n+    \"\"\"Abstract base layer for image augmentation.\n \n     This layer contains base functionalities for preprocessing layers which\n     augment image related data, eg. image and in future, label and bounding"
    },
    {
        "commit_id": "6db75928d738420b51058313c1d5db5cd0e67733",
        "commit_message": "docs: Fix a few typos\n\nThere are small typos in:\n- keras/layers/preprocessing/discretization.py\n- keras/layers/preprocessing/image_preprocessing.py\n- keras/saving/pickle_utils_test.py\n\nFixes:\n- Should read `protocol` rather than `protoocol`.\n- Should read `discretized` rather than `discritized`.\n- Should read `augmentation` rather than `augmentaion`.",
        "commit_url": "https://github.com/keras-team/keras/commit/6db75928d738420b51058313c1d5db5cd0e67733",
        "buggy_code": "\"\"\"Tests pickle protoocol support.\"\"\"",
        "fixed_code": "\"\"\"Tests pickle protocol support.\"\"\"",
        "patch": "@@ -24,7 +24,7 @@\n \n \n class TestPickleProtocol(test_combinations.TestCase):\n-    \"\"\"Tests pickle protoocol support.\"\"\"\n+    \"\"\"Tests pickle protocol support.\"\"\"\n \n     @test_combinations.run_with_all_model_types\n     @test_combinations.parameterized.named_parameters("
    },
    {
        "commit_id": "3c9fff22501b7015bae0f2053c7e2de5ac97fb6a",
        "commit_message": "Merge pull request #16778 from ltiao:patch-2\n\nPiperOrigin-RevId: 460506548",
        "commit_url": "https://github.com/keras-team/keras/commit/3c9fff22501b7015bae0f2053c7e2de5ac97fb6a",
        "buggy_code": "are project to the shape specified by `output_shape`.",
        "fixed_code": "are projected to the shape specified by `output_shape`.",
        "patch": "@@ -225,7 +225,7 @@ class MultiHeadAttention(Layer):\n       attention_output: The result of the computation, of shape `(B, T, E)`,\n         where `T` is for target sequence shapes and `E` is the query input last\n         dimension if `output_shape` is `None`. Otherwise, the multi-head outputs\n-        are project to the shape specified by `output_shape`.\n+        are projected to the shape specified by `output_shape`.\n       attention_scores: [Optional] multi-head attention coefficients over\n         attention axes.\n     \"\"\""
    },
    {
        "commit_id": "65f51ec18cb6d84dc9bdada1c6f7872d9479f867",
        "commit_message": "Merge pull request #16767 from tilakrayal:patch-3\n\nPiperOrigin-RevId: 460505474",
        "commit_url": "https://github.com/keras-team/keras/commit/65f51ec18cb6d84dc9bdada1c6f7872d9479f867",
        "buggy_code": "[this guide](https://www.tensorflow.org/guide/ragged_tensors).",
        "fixed_code": "[this guide](https://www.tensorflow.org/guide/ragged_tensor).",
        "patch": "@@ -331,7 +331,7 @@ def Input(\n             ragged. Only one of 'ragged' and 'sparse' can be True. In this case,\n             values of 'None' in the 'shape' argument represent ragged\n             dimensions.  For more information about RaggedTensors, see\n-            [this guide](https://www.tensorflow.org/guide/ragged_tensors).\n+            [this guide](https://www.tensorflow.org/guide/ragged_tensor).\n         type_spec: A `tf.TypeSpec` object to create the input placeholder from.\n             When provided, all other args except name must be None.\n         **kwargs: deprecated arguments support. Supports `batch_shape` and"
    },
    {
        "commit_id": "ce5497519b6638502146f49fce75d09d431eb9d2",
        "commit_message": "fix error when labels contains brackets when plotting model",
        "commit_url": "https://github.com/keras-team/keras/commit/ce5497519b6638502146f49fce75d09d431eb9d2",
        "buggy_code": "return str(shape).replace(str(None), \"None\")",
        "fixed_code": "return str(shape).replace(str(None), \"None\").replace(\"{\", \"/{\").replace(\"}\", \"/}\")",
        "patch": "@@ -272,7 +272,7 @@ def format_dtype(dtype):\n         if show_shapes:\n \n             def format_shape(shape):\n-                return str(shape).replace(str(None), \"None\")\n+                return str(shape).replace(str(None), \"None\").replace(\"{\", \"/{\").replace(\"}\", \"/}\")\n \n             try:\n                 outputlabels = format_shape(layer.output_shape)"
    },
    {
        "commit_id": "d38de48e5f000247446d375785e0a54dc4c46306",
        "commit_message": "Merge pull request #16689 from haifeng-jin:bug\n\nPiperOrigin-RevId: 455443061",
        "commit_url": "https://github.com/keras-team/keras/commit/d38de48e5f000247446d375785e0a54dc4c46306",
        "buggy_code": "if hasattr(tensor, \"_keras_mask\"):",
        "fixed_code": "if getattr(tensor, \"_keras_mask\", None) is not None:",
        "patch": "@@ -665,7 +665,7 @@ def keras_tensor_from_tensor(tensor):\n \n     out = keras_tensor_cls.from_tensor(tensor)\n \n-    if hasattr(tensor, \"_keras_mask\"):\n+    if getattr(tensor, \"_keras_mask\", None) is not None:\n         out._keras_mask = keras_tensor_from_tensor(tensor._keras_mask)\n     return out\n "
    },
    {
        "commit_id": "acfb52d1f3cde59e1d299d1fdad3d2118a62e2a6",
        "commit_message": "Fix bug for KerasTensor._keras_mask should be None",
        "commit_url": "https://github.com/keras-team/keras/commit/acfb52d1f3cde59e1d299d1fdad3d2118a62e2a6",
        "buggy_code": "if hasattr(tensor, \"_keras_mask\"):",
        "fixed_code": "if getattr(tensor, \"_keras_mask\", None) is not None:",
        "patch": "@@ -665,7 +665,7 @@ def keras_tensor_from_tensor(tensor):\n \n     out = keras_tensor_cls.from_tensor(tensor)\n \n-    if hasattr(tensor, \"_keras_mask\"):\n+    if getattr(tensor, \"_keras_mask\", None) is not None:\n         out._keras_mask = keras_tensor_from_tensor(tensor._keras_mask)\n     return out\n "
    },
    {
        "commit_id": "c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "commit_message": "Merge branch 'keras-team:master' into patch-1",
        "commit_url": "https://github.com/keras-team/keras/commit/c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "buggy_code": "import keras  # pylint: disable=unused-import",
        "fixed_code": "import keras  # noqa: F401",
        "patch": "@@ -23,7 +23,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import keras  # pylint: disable=unused-import\n+import keras  # noqa: F401\n \n # isort: off\n from tensorflow.python.tools.api.generator import ("
    },
    {
        "commit_id": "c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "commit_message": "Merge branch 'keras-team:master' into patch-1",
        "commit_url": "https://github.com/keras-team/keras/commit/c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "buggy_code": "self.maxDiff = None  # pylint: disable=invalid-name",
        "fixed_code": "self.maxDiff = None",
        "patch": "@@ -244,7 +244,7 @@ def _AssertProtoDictEquals(\n                 verbose_diff_message = diff_message\n             else:\n                 # Do not truncate diff\n-                self.maxDiff = None  # pylint: disable=invalid-name\n+                self.maxDiff = None\n                 # Now we can run an actual proto diff.\n                 try:\n                     self.assertProtoEquals(expected_dict[key], actual_dict[key])"
    },
    {
        "commit_id": "c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "commit_message": "Merge branch 'keras-team:master' into patch-1",
        "commit_url": "https://github.com/keras-team/keras/commit/c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "buggy_code": "except Exception:  # pylint: disable=broad-except",
        "fixed_code": "except Exception:",
        "patch": "@@ -183,7 +183,7 @@ def test_application_pretrained_weights_loading(self):\n         for app in apps:\n             try:\n                 model = app(weights=\"imagenet\")\n-            except Exception:  # pylint: disable=broad-except\n+            except Exception:\n                 self.skipTest(\"TODO(b/227700184): Re-enable.\")\n             self.assertShapeEqual(model.output_shape, (None, _IMAGENET_CLASSES))\n             x = _get_elephant(model.input_shape[1:3])"
    },
    {
        "commit_id": "c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "commit_message": "Merge branch 'keras-team:master' into patch-1",
        "commit_url": "https://github.com/keras-team/keras/commit/c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "buggy_code": "class KerasModelCPUBenchmark(  # pylint: disable=undefined-variable",
        "fixed_code": "class KerasModelCPUBenchmark(",
        "patch": "@@ -24,7 +24,7 @@\n _OPTIMIZER = \"rmsprop\"\n \n \n-class KerasModelCPUBenchmark(  # pylint: disable=undefined-variable\n+class KerasModelCPUBenchmark(\n     tf.test.Benchmark, metaclass=tf.__internal__.test.ParameterizedBenchmark\n ):\n     \"\"\"Required Arguments for measure_performance."
    },
    {
        "commit_id": "c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "commit_message": "Merge branch 'keras-team:master' into patch-1",
        "commit_url": "https://github.com/keras-team/keras/commit/c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "buggy_code": "def call(self, inputs):  # pylint: disable=arguments-differ",
        "fixed_code": "def call(self, inputs):",
        "patch": "@@ -169,7 +169,7 @@ def build(self, input_shape):\n             trainable=True,\n         )\n \n-    def call(self, inputs):  # pylint: disable=arguments-differ\n+    def call(self, inputs):\n         inputs -= tf.reduce_mean(inputs, axis=-1, keepdims=True)\n         pos = tf.nn.relu(inputs)\n         neg = tf.nn.relu(-inputs)"
    },
    {
        "commit_id": "c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "commit_message": "Merge branch 'keras-team:master' into patch-1",
        "commit_url": "https://github.com/keras-team/keras/commit/c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "buggy_code": "class KerasLayerBenchmarks(  # pylint: disable=undefined-variable",
        "fixed_code": "class KerasLayerBenchmarks(",
        "patch": "@@ -427,7 +427,7 @@ def _layer_call_backward(layer, x):\n ]\n \n \n-class KerasLayerBenchmarks(  # pylint: disable=undefined-variable\n+class KerasLayerBenchmarks(\n     layer_benchmarks_test_base.LayerBenchmarksBase,\n     metaclass=tf.__internal__.test.ParameterizedBenchmark,\n ):"
    },
    {
        "commit_id": "c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "commit_message": "Merge branch 'keras-team:master' into patch-1",
        "commit_url": "https://github.com/keras-team/keras/commit/c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "buggy_code": "import memory_profiler  # pylint:disable=g-import-not-at-top",
        "fixed_code": "import memory_profiler",
        "patch": "@@ -18,7 +18,7 @@\n import tensorflow.compat.v2 as tf\n \n try:\n-    import memory_profiler  # pylint:disable=g-import-not-at-top\n+    import memory_profiler\n except ImportError:\n     memory_profiler = None\n "
    },
    {
        "commit_id": "c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "commit_message": "Merge branch 'keras-team:master' into patch-1",
        "commit_url": "https://github.com/keras-team/keras/commit/c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "buggy_code": "import memory_profiler  # pylint:disable=g-import-not-at-top",
        "fixed_code": "import memory_profiler",
        "patch": "@@ -27,7 +27,7 @@\n from absl import logging\n \n try:\n-    import memory_profiler  # pylint:disable=g-import-not-at-top\n+    import memory_profiler\n except ImportError:\n     memory_profiler = None\n "
    },
    {
        "commit_id": "c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "commit_message": "Merge branch 'keras-team:master' into patch-1",
        "commit_url": "https://github.com/keras-team/keras/commit/c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "buggy_code": ")  # pylint: disable=protected-access",
        "fixed_code": ")",
        "patch": "@@ -75,7 +75,7 @@ def loss_fn(ctx):\n             optimizer = tf.compat.v1.train.GradientDescentOptimizer(0.25)\n             update_ops = optimizer._distributed_apply(\n                 distribution, grads_and_vars\n-            )  # pylint: disable=protected-access\n+            )\n \n             if not tf.executing_eagerly():\n                 self.evaluate(tf.compat.v1.global_variables_initializer())"
    },
    {
        "commit_id": "c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "commit_message": "Merge branch 'keras-team:master' into patch-1",
        "commit_url": "https://github.com/keras-team/keras/commit/c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "buggy_code": "instance._mesh = mesh  # pylint: disable=protected-access",
        "fixed_code": "instance._mesh = mesh",
        "patch": "@@ -140,7 +140,7 @@ def _wrap_function(instance, *args, **kwargs):\n         # of __init__, since the class might need the mesh to create weights in\n         # the __init__.\n         if mesh is not None:\n-            instance._mesh = mesh  # pylint: disable=protected-access\n+            instance._mesh = mesh\n         init_method(instance, *args, **kwargs)\n \n     return tf.__internal__.decorator.make_decorator("
    },
    {
        "commit_id": "c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "commit_message": "Merge branch 'keras-team:master' into patch-1",
        "commit_url": "https://github.com/keras-team/keras/commit/c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "buggy_code": "def reset_state(self):  # pylint: disable=method-hidden",
        "fixed_code": "def reset_state(self):",
        "patch": "@@ -35,7 +35,7 @@ def build(self, input_shape):\n     def update_state(self, data):\n         self.sum.assign_add(tf.reduce_sum(tf.cast(data, tf.float32)))\n \n-    def reset_state(self):  # pylint: disable=method-hidden\n+    def reset_state(self):\n         self.sum.assign(0.0)\n \n     def set_total(self, sum_value):"
    },
    {
        "commit_id": "c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "commit_message": "Merge branch 'keras-team:master' into patch-1",
        "commit_url": "https://github.com/keras-team/keras/commit/c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "buggy_code": "import h5py  # pylint:disable=g-import-not-at-top",
        "fixed_code": "import h5py",
        "patch": "@@ -25,7 +25,7 @@\n from keras.testing_infra import test_utils\n \n try:\n-    import h5py  # pylint:disable=g-import-not-at-top\n+    import h5py\n except ImportError:\n     h5py = None\n "
    },
    {
        "commit_id": "c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "commit_message": "Merge branch 'keras-team:master' into patch-1",
        "commit_url": "https://github.com/keras-team/keras/commit/c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "buggy_code": "class DenseFeatures(kfc._BaseFeaturesLayer):  # pylint: disable=protected-access",
        "fixed_code": "class DenseFeatures(kfc._BaseFeaturesLayer):",
        "patch": "@@ -31,7 +31,7 @@\n \n \n @keras_export(v1=[\"keras.layers.DenseFeatures\"])\n-class DenseFeatures(kfc._BaseFeaturesLayer):  # pylint: disable=protected-access\n+class DenseFeatures(kfc._BaseFeaturesLayer):\n     \"\"\"A layer that produces a dense `Tensor` based on given `feature_columns`.\n \n     Generally a single example in training data is described with"
    },
    {
        "commit_id": "c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "commit_message": "Merge branch 'keras-team:master' into patch-1",
        "commit_url": "https://github.com/keras-team/keras/commit/c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "buggy_code": "lambda x: (  # pylint: disable=g-long-lambda",
        "fixed_code": "lambda x: (",
        "patch": "@@ -180,7 +180,7 @@ def feature_and_label_gen():\n                 )\n \n                 train_dataset = raw_dataset.map(\n-                    lambda x: (  # pylint: disable=g-long-lambda\n+                    lambda x: (\n                         {\"features\": feature_ps(x[\"features\"])},\n                         label_ps(x[\"label\"]),\n                     )"
    },
    {
        "commit_id": "c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "commit_message": "Merge branch 'keras-team:master' into patch-1",
        "commit_url": "https://github.com/keras-team/keras/commit/c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "buggy_code": "out = _MultiOutput(name=\"out\")(inp)  # pylint: disable=not-callable",
        "fixed_code": "out = _MultiOutput(name=\"out\")(inp)",
        "patch": "@@ -223,7 +223,7 @@ class _MultiOutput(tf.keras.layers.Layer):\n             def call(self, x):\n                 return x + 1.0, x + 2.0\n \n-        out = _MultiOutput(name=\"out\")(inp)  # pylint: disable=not-callable\n+        out = _MultiOutput(name=\"out\")(inp)\n         model = tf.keras.Model(inp, out)\n         loaded = cycle(model, cycles)\n         self.assertAllClose("
    },
    {
        "commit_id": "c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "commit_message": "Merge branch 'keras-team:master' into patch-1",
        "commit_url": "https://github.com/keras-team/keras/commit/c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "buggy_code": "lambda x: (  # pylint: disable=g-long-lambda",
        "fixed_code": "lambda x: (",
        "patch": "@@ -168,7 +168,7 @@ def feature_and_label_gen():\n                 )\n \n                 train_dataset = raw_dataset.map(\n-                    lambda x: (  # pylint: disable=g-long-lambda\n+                    lambda x: (\n                         {\"features\": feature_mapper(x[\"features\"])},\n                         label_mapper(x[\"label\"]),\n                     )"
    },
    {
        "commit_id": "c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "commit_message": "Merge branch 'keras-team:master' into patch-1",
        "commit_url": "https://github.com/keras-team/keras/commit/c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "buggy_code": ")  # pylint:disable=g-complex-comprehension",
        "fixed_code": ")",
        "patch": "@@ -43,7 +43,7 @@ def tensor_gen(batch, num_elements):\n def get_vocab():\n     vocab = list(\n         set([a + b for a in string.ascii_letters for b in string.ascii_letters])\n-    )  # pylint:disable=g-complex-comprehension\n+    )\n     vocab.sort()\n     return vocab\n "
    },
    {
        "commit_id": "c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "commit_message": "Merge branch 'keras-team:master' into patch-1",
        "commit_url": "https://github.com/keras-team/keras/commit/c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "buggy_code": "from scipy import special  # pylint: disable=g-import-not-at-top",
        "fixed_code": "from scipy import special",
        "patch": "@@ -1615,7 +1615,7 @@ def test_invalid_summation_method(self):\n \n     def test_extra_dims(self):\n         try:\n-            from scipy import special  # pylint: disable=g-import-not-at-top\n+            from scipy import special\n \n             self.setup()\n             logits = special.expit("
    },
    {
        "commit_id": "c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "commit_message": "Merge branch 'keras-team:master' into patch-1",
        "commit_url": "https://github.com/keras-team/keras/commit/c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "buggy_code": ")  # pylint: disable=cell-var-from-loop",
        "fixed_code": ")",
        "patch": "@@ -111,7 +111,7 @@ def testMinimizeSparseResourceVariable(self):\n                 def loss():\n                     pred = tf.matmul(\n                         tf.compat.v1.nn.embedding_lookup([var0], [0]), x\n-                    )  # pylint: disable=cell-var-from-loop\n+                    )\n                     return pred * pred\n \n                 sgd_op = ftrl.Ftrl(1.0).minimize(loss, var_list=[var0])"
    },
    {
        "commit_id": "c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "commit_message": "Merge branch 'keras-team:master' into patch-1",
        "commit_url": "https://github.com/keras-team/keras/commit/c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "buggy_code": "from tensorflow.python.training.experimental.loss_scale_optimizer import (",
        "fixed_code": "from tensorflow.python.training.experimental.loss_scale_optimizer import (  # noqa: E501",
        "patch": "@@ -28,7 +28,7 @@\n \n # isort: off\n from tensorflow.python.training.adam import AdamOptimizer\n-from tensorflow.python.training.experimental.loss_scale_optimizer import (\n+from tensorflow.python.training.experimental.loss_scale_optimizer import (  # noqa: E501\n     MixedPrecisionLossScaleOptimizer,\n )\n "
    },
    {
        "commit_id": "c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "commit_message": "Merge branch 'keras-team:master' into patch-1",
        "commit_url": "https://github.com/keras-team/keras/commit/c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "buggy_code": "return self.activation(result)  # pylint: disable=not-callable",
        "fixed_code": "return self.activation(result)",
        "patch": "@@ -192,7 +192,7 @@ def call(self, inputs):\n         if self.use_bias:\n             result = tf.nn.bias_add(result, self.bias)\n         if self.activation is not None:\n-            return self.activation(result)  # pylint: disable=not-callable\n+            return self.activation(result)\n         return result\n \n     def get_config(self):"
    },
    {
        "commit_id": "c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "commit_message": "Merge branch 'keras-team:master' into patch-1",
        "commit_url": "https://github.com/keras-team/keras/commit/c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "buggy_code": "import PIL  # pylint:disable=g-import-not-at-top",
        "fixed_code": "import PIL",
        "patch": "@@ -32,7 +32,7 @@\n from keras.utils import image_utils\n \n try:\n-    import PIL  # pylint:disable=g-import-not-at-top\n+    import PIL\n except ImportError:\n     PIL = None\n "
    },
    {
        "commit_id": "c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "commit_message": "Merge branch 'keras-team:master' into patch-1",
        "commit_url": "https://github.com/keras-team/keras/commit/c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "buggy_code": "if len(g) > 0:  # pylint: disable=g-explicit-length-test",
        "fixed_code": "if len(g) > 0:",
        "patch": "@@ -181,7 +181,7 @@ def test_TimeSeriesGenerator_doesnt_miss_any_sample(self):\n \n             self.assertEqual(expected, actual)\n \n-            if len(g) > 0:  # pylint: disable=g-explicit-length-test\n+            if len(g) > 0:\n                 # All elements in range(length, 10) should be used as current\n                 # step\n                 expected = np.arange(length, 10).reshape(-1, 1)"
    },
    {
        "commit_id": "c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "commit_message": "Merge branch 'keras-team:master' into patch-1",
        "commit_url": "https://github.com/keras-team/keras/commit/c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "buggy_code": "import h5py  # pylint:disable=g-import-not-at-top",
        "fixed_code": "import h5py",
        "patch": "@@ -31,7 +31,7 @@\n from keras.utils import losses_utils\n \n try:\n-    import h5py  # pylint:disable=g-import-not-at-top\n+    import h5py\n except ImportError:\n     h5py = None\n "
    },
    {
        "commit_id": "c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "commit_message": "Merge branch 'keras-team:master' into patch-1",
        "commit_url": "https://github.com/keras-team/keras/commit/c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "buggy_code": "import h5py  # pylint:disable=g-import-not-at-top",
        "fixed_code": "import h5py",
        "patch": "@@ -30,7 +30,7 @@\n from keras.utils import generic_utils\n \n try:\n-    import h5py  # pylint:disable=g-import-not-at-top\n+    import h5py\n except ImportError:\n     h5py = None\n "
    },
    {
        "commit_id": "c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "commit_message": "Merge branch 'keras-team:master' into patch-1",
        "commit_url": "https://github.com/keras-team/keras/commit/c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "buggy_code": "[\"0x12e4\", []],  #  not 12000",
        "fixed_code": "[\"0x12e4\", []],  # not 12000",
        "patch": "@@ -55,7 +55,7 @@ class KerasDoctestOutputCheckerTest(parameterized.TestCase):\n         [\"text1.0 text\", []],\n         [\"text 1.0text\", []],\n         [\"text1.0text\", []],\n-        [\"0x12e4\", []],  #  not 12000\n+        [\"0x12e4\", []],  # not 12000\n         [\"TensorBoard: http://128.0.0.1:8888\", []],\n         # With a newline\n         [\"1.0 text\\n 2.0 3.0 text\", [1.0, 2.0, 3.0]],"
    },
    {
        "commit_id": "c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "commit_message": "Merge branch 'keras-team:master' into patch-1",
        "commit_url": "https://github.com/keras-team/keras/commit/c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "buggy_code": "import h5py  # pylint:disable=g-import-not-at-top",
        "fixed_code": "import h5py",
        "patch": "@@ -25,7 +25,7 @@\n from keras.tests import model_subclassing_test_util as model_util\n \n try:\n-    import h5py  # pylint:disable=g-import-not-at-top\n+    import h5py\n except ImportError:\n     h5py = None\n "
    },
    {
        "commit_id": "c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "commit_message": "Merge branch 'keras-team:master' into patch-1",
        "commit_url": "https://github.com/keras-team/keras/commit/c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "buggy_code": "import PIL  # pylint:disable=g-import-not-at-top",
        "fixed_code": "import PIL",
        "patch": "@@ -26,7 +26,7 @@\n from keras.utils import image_utils\n \n try:\n-    import PIL  # pylint:disable=g-import-not-at-top\n+    import PIL\n except ImportError:\n     PIL = None\n "
    },
    {
        "commit_id": "c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "commit_message": "Merge branch 'keras-team:master' into patch-1",
        "commit_url": "https://github.com/keras-team/keras/commit/c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "buggy_code": "lambda x: (  # pylint: disable=g-long-lambda",
        "fixed_code": "lambda x: (",
        "patch": "@@ -114,7 +114,7 @@ def feature_and_label_gen():\n         )\n \n         train_dataset = raw_dataset.map(\n-            lambda x: (  # pylint: disable=g-long-lambda\n+            lambda x: (\n                 {\"features\": feature_mapper(x[\"features\"])},\n                 label_mapper(x[\"label\"]),\n             )"
    },
    {
        "commit_id": "c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "commit_message": "Merge branch 'keras-team:master' into patch-1",
        "commit_url": "https://github.com/keras-team/keras/commit/c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "buggy_code": "import attr  # pylint:disable=g-import-not-at-top",
        "fixed_code": "import attr",
        "patch": "@@ -23,7 +23,7 @@\n from keras.utils import tf_utils\n \n try:\n-    import attr  # pylint:disable=g-import-not-at-top\n+    import attr\n except ImportError:\n     attr = None\n "
    },
    {
        "commit_id": "c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "commit_message": "Merge branch 'keras-team:master' into patch-1",
        "commit_url": "https://github.com/keras-team/keras/commit/c75789f2ae9b1c9d5dec8ef9812e8c692b493a8b",
        "buggy_code": "AbstractModel()  # pylint: disable=abstract-class-instantiated",
        "fixed_code": "AbstractModel()",
        "patch": "@@ -133,7 +133,7 @@ def call(self, inputs):\n                 return 2 * inputs\n \n         with self.assertRaisesRegex(TypeError, \"instantiate abstract class\"):\n-            AbstractModel()  # pylint: disable=abstract-class-instantiated\n+            AbstractModel()\n \n         model = MyModel()\n         model_class = model.__class__.__bases__[0].__bases__[0]"
    },
    {
        "commit_id": "5cf72f4934f3104ac2378c8b9b3638afea38ba1e",
        "commit_message": "fix the rest",
        "commit_url": "https://github.com/keras-team/keras/commit/5cf72f4934f3104ac2378c8b9b3638afea38ba1e",
        "buggy_code": "except IsADirectoryError as e:  # h5py 3.x",
        "fixed_code": "except IsADirectoryError:  # h5py 3.x",
        "patch": "@@ -1564,7 +1564,7 @@ def _save_model(self, epoch, batch, logs):\n                         )\n \n                 self._maybe_remove_file()\n-            except IsADirectoryError as e:  # h5py 3.x\n+            except IsADirectoryError:  # h5py 3.x\n                 raise IOError(\n                     \"Please specify a non-directory filepath for \"\n                     \"ModelCheckpoint. Filepath used is an existing \""
    },
    {
        "commit_id": "5cf72f4934f3104ac2378c8b9b3638afea38ba1e",
        "commit_message": "fix the rest",
        "commit_url": "https://github.com/keras-team/keras/commit/5cf72f4934f3104ac2378c8b9b3638afea38ba1e",
        "buggy_code": "from keras.saving import *  # noqa: F401",
        "fixed_code": "from keras.saving import *  # noqa: F401,F403",
        "patch": "@@ -18,4 +18,4 @@\n Everything has been moved to keras/saving/. This file will be deleted soon.\n \"\"\"\n \n-from keras.saving import *  # noqa: F401\n+from keras.saving import *  # noqa: F401,F403"
    },
    {
        "commit_id": "5cf72f4934f3104ac2378c8b9b3638afea38ba1e",
        "commit_message": "fix the rest",
        "commit_url": "https://github.com/keras-team/keras/commit/5cf72f4934f3104ac2378c8b9b3638afea38ba1e",
        "buggy_code": "except zipfile.BadZipfile as e:",
        "fixed_code": "except zipfile.BadZipfile:",
        "patch": "@@ -70,7 +70,7 @@ class MultiWorkerTutorialTest(parameterized.TestCase, tf.test.TestCase):\n     def skip_fetch_failure_exception(self):\n         try:\n             yield\n-        except zipfile.BadZipfile as e:\n+        except zipfile.BadZipfile:\n             # There can be a race when multiple processes are downloading the\n             # data.  Skip the test if that results in loading errors.\n             self.skipTest("
    },
    {
        "commit_id": "5cf72f4934f3104ac2378c8b9b3638afea38ba1e",
        "commit_message": "fix the rest",
        "commit_url": "https://github.com/keras-team/keras/commit/5cf72f4934f3104ac2378c8b9b3638afea38ba1e",
        "buggy_code": "self.layer = CustomLayer()",
        "fixed_code": "self.layer = CustomLayer()  # noqa: F821",
        "patch": "@@ -1125,7 +1125,7 @@ def __call__(self, inputs):\n         class Model(keras.models.Model):\n             def __init__(self):\n                 super().__init__()\n-                self.layer = CustomLayer()\n+                self.layer = CustomLayer()  # noqa: F821\n \n             @tf.function(input_signature=[tf.TensorSpec([None, 1])])\n             def call(self, inputs):"
    },
    {
        "commit_id": "5cf72f4934f3104ac2378c8b9b3638afea38ba1e",
        "commit_message": "fix the rest",
        "commit_url": "https://github.com/keras-team/keras/commit/5cf72f4934f3104ac2378c8b9b3638afea38ba1e",
        "buggy_code": "except:  # pylint: disable=bare-except",
        "fixed_code": "except:  # noqa: E722",
        "patch": "@@ -365,7 +365,7 @@ def try_build_compiled_arguments(model):\n                 model.compiled_loss.build(model.outputs)\n             if not model.compiled_metrics.built:\n                 model.compiled_metrics.build(model.outputs, model.outputs)\n-        except:  # pylint: disable=bare-except\n+        except:  # noqa: E722\n             logging.warning(\n                 \"Compiled the loaded model, but the compiled metrics have \"\n                 \"yet to be built. `model.compile_metrics` will be empty \""
    },
    {
        "commit_id": "5cf72f4934f3104ac2378c8b9b3638afea38ba1e",
        "commit_message": "fix the rest",
        "commit_url": "https://github.com/keras-team/keras/commit/5cf72f4934f3104ac2378c8b9b3638afea38ba1e",
        "buggy_code": "[\"0x12e4\", []],  #  not 12000",
        "fixed_code": "[\"0x12e4\", []],  # not 12000",
        "patch": "@@ -55,7 +55,7 @@ class KerasDoctestOutputCheckerTest(parameterized.TestCase):\n         [\"text1.0 text\", []],\n         [\"text 1.0text\", []],\n         [\"text1.0text\", []],\n-        [\"0x12e4\", []],  #  not 12000\n+        [\"0x12e4\", []],  # not 12000\n         [\"TensorBoard: http://128.0.0.1:8888\", []],\n         # With a newline\n         [\"1.0 text\\n 2.0 3.0 text\", [1.0, 2.0, 3.0]],"
    },
    {
        "commit_id": "5cf72f4934f3104ac2378c8b9b3638afea38ba1e",
        "commit_message": "fix the rest",
        "commit_url": "https://github.com/keras-team/keras/commit/5cf72f4934f3104ac2378c8b9b3638afea38ba1e",
        "buggy_code": "import doctest  # pylint: disable=g-import-not-at-top,g-bad-import-order",
        "fixed_code": "import doctest  # noqa: E402",
        "patch": "@@ -32,7 +32,7 @@\n \n # We put doctest after absltest so that it picks up the unittest monkeypatch.\n # Otherwise doctest tests aren't runnable at all.\n-import doctest  # pylint: disable=g-import-not-at-top,g-bad-import-order\n+import doctest  # noqa: E402\n \n FLAGS = flags.FLAGS\n "
    },
    {
        "commit_id": "5cf72f4934f3104ac2378c8b9b3638afea38ba1e",
        "commit_message": "fix the rest",
        "commit_url": "https://github.com/keras-team/keras/commit/5cf72f4934f3104ac2378c8b9b3638afea38ba1e",
        "buggy_code": "except (Exception, KeyboardInterrupt) as e:",
        "fixed_code": "except (Exception, KeyboardInterrupt):",
        "patch": "@@ -298,7 +298,7 @@ def __call__(self, block_num, block_size, total_size):\n                 raise Exception(error_msg.format(origin, e.code, e.msg))\n             except urllib.error.URLError as e:\n                 raise Exception(error_msg.format(origin, e.errno, e.reason))\n-        except (Exception, KeyboardInterrupt) as e:\n+        except (Exception, KeyboardInterrupt):\n             if os.path.exists(fpath):\n                 os.remove(fpath)\n             raise"
    },
    {
        "commit_id": "5cf72f4934f3104ac2378c8b9b3638afea38ba1e",
        "commit_message": "fix the rest",
        "commit_url": "https://github.com/keras-team/keras/commit/5cf72f4934f3104ac2378c8b9b3638afea38ba1e",
        "buggy_code": "from tensorflow.python.saved_model.model_utils.mode_keys import (  # noqa: E501",
        "fixed_code": "from tensorflow.python.saved_model.model_utils.mode_keys import (  # noqa: F401,E501",
        "patch": "@@ -15,6 +15,6 @@\n \"\"\"Keras model mode constants.\"\"\"\n \n # isort: off\n-from tensorflow.python.saved_model.model_utils.mode_keys import (  # noqa: E501\n+from tensorflow.python.saved_model.model_utils.mode_keys import (  # noqa: F401,E501\n     KerasModeKeys as ModeKeys,\n )"
    },
    {
        "commit_id": "53825c7d49c151b0c65c1be1286034c51c60a912",
        "commit_message": "fix F401",
        "commit_url": "https://github.com/keras-team/keras/commit/53825c7d49c151b0c65c1be1286034c51c60a912",
        "buggy_code": "import keras  # pylint: disable=unused-import",
        "fixed_code": "import keras  # noqa: F401",
        "patch": "@@ -23,7 +23,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import keras  # pylint: disable=unused-import\n+import keras  # noqa: F401\n \n # isort: off\n from tensorflow.python.tools.api.generator import ("
    },
    {
        "commit_id": "53825c7d49c151b0c65c1be1286034c51c60a912",
        "commit_message": "fix F401",
        "commit_url": "https://github.com/keras-team/keras/commit/53825c7d49c151b0c65c1be1286034c51c60a912",
        "buggy_code": "from keras.saving import *  # pylint: disable=wildcard-import",
        "fixed_code": "from keras.saving import *  # noqa: F401",
        "patch": "@@ -18,4 +18,4 @@\n Everything has been moved to keras/saving/. This file will be deleted soon.\n \"\"\"\n \n-from keras.saving import *  # pylint: disable=wildcard-import\n+from keras.saving import *  # noqa: F401"
    },
    {
        "commit_id": "e46070f8c184f0e5030050a6982feeda529cc552",
        "commit_message": "Merge pull request #16607 from m-ahmadi:patch-1\n\nPiperOrigin-RevId: 452086489",
        "commit_url": "https://github.com/keras-team/keras/commit/e46070f8c184f0e5030050a6982feeda529cc552",
        "buggy_code": "[Customizing what happends in fit](",
        "fixed_code": "[Customizing what happens in fit](",
        "patch": "@@ -968,7 +968,7 @@ def train_step(self, data):\n \n         This method can be overridden to support custom training logic.\n         For concrete examples of how to override this method see\n-        [Customizing what happends in fit](\n+        [Customizing what happens in fit](\n         https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit).\n         This method is called by `Model.make_train_function`.\n "
    },
    {
        "commit_id": "bb7edcbc84c11b22aa9b885f910d949dd5e10891",
        "commit_message": "Fix typo",
        "commit_url": "https://github.com/keras-team/keras/commit/bb7edcbc84c11b22aa9b885f910d949dd5e10891",
        "buggy_code": "[Customizing what happends in fit](",
        "fixed_code": "[Customizing what happens in fit](",
        "patch": "@@ -966,7 +966,7 @@ def train_step(self, data):\n \n         This method can be overridden to support custom training logic.\n         For concrete examples of how to override this method see\n-        [Customizing what happends in fit](\n+        [Customizing what happens in fit](\n         https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit).\n         This method is called by `Model.make_train_function`.\n "
    },
    {
        "commit_id": "0c7c8d03b5d1451de8ed6233346e5685e8af7e30",
        "commit_message": "Merge pull request #16568 from eltociear:fix-typo\n\nPiperOrigin-RevId: 450984177",
        "commit_url": "https://github.com/keras-team/keras/commit/0c7c8d03b5d1451de8ed6233346e5685e8af7e30",
        "buggy_code": "[github discussion](https://github.com/keras-team/keras/issues/12072)",
        "fixed_code": "[GitHub discussion](https://github.com/keras-team/keras/issues/12072)",
        "patch": "@@ -44,7 +44,7 @@ def load_data(\n     This was originally generated by parsing and preprocessing the classic\n     Reuters-21578 dataset, but the preprocessing code is no longer packaged\n     with Keras. See this\n-    [github discussion](https://github.com/keras-team/keras/issues/12072)\n+    [GitHub discussion](https://github.com/keras-team/keras/issues/12072)\n     for more info.\n \n     Each newswire is encoded as a list of word indexes (integers)."
    },
    {
        "commit_id": "0c7c8d03b5d1451de8ed6233346e5685e8af7e30",
        "commit_message": "Merge pull request #16568 from eltociear:fix-typo\n\nPiperOrigin-RevId: 450984177",
        "commit_url": "https://github.com/keras-team/keras/commit/0c7c8d03b5d1451de8ed6233346e5685e8af7e30",
        "buggy_code": "aware the existance of those variable, we will just give them replicated",
        "fixed_code": "aware the existence of those variable, we will just give them replicated",
        "patch": "@@ -338,7 +338,7 @@ def _init_state_variable_for_rng(model, layout_map):\n     Since the BaseRandomLayer in keras explicitly untrack the tf.random.Generator,\n     the variable in it will stay as LazyInitVariable, which cause runtime error if\n     we don't replace them with proper DVariable. Since user usually are not\n-    aware the existance of those variable, we will just give them replicated\n+    aware the existence of those variable, we will just give them replicated\n     layout since they are tiny.\n \n     Args:"
    },
    {
        "commit_id": "0c7c8d03b5d1451de8ed6233346e5685e8af7e30",
        "commit_message": "Merge pull request #16568 from eltociear:fix-typo\n\nPiperOrigin-RevId: 450984177",
        "commit_url": "https://github.com/keras-team/keras/commit/0c7c8d03b5d1451de8ed6233346e5685e8af7e30",
        "buggy_code": "seen in the dataset, sorted by occurance count, with ties broken by sort",
        "fixed_code": "seen in the dataset, sorted by occurrence count, with ties broken by sort",
        "patch": "@@ -411,7 +411,7 @@ def adapt(self, data, batch_size=None, steps=None):\n         supplied with a vocabulary.\n \n         During `adapt()`, the layer will build a vocabulary of all integer tokens\n-        seen in the dataset, sorted by occurance count, with ties broken by sort\n+        seen in the dataset, sorted by occurrence count, with ties broken by sort\n         order of the tokens (high to low). At the end of `adapt()`, if `max_tokens`\n         is set, the vocabulary wil be truncated to `max_tokens` size. For example,\n         adapting a layer with `max_tokens=1000` will compute the 1000 most frequent"
    },
    {
        "commit_id": "0c7c8d03b5d1451de8ed6233346e5685e8af7e30",
        "commit_message": "Merge pull request #16568 from eltociear:fix-typo\n\nPiperOrigin-RevId: 450984177",
        "commit_url": "https://github.com/keras-team/keras/commit/0c7c8d03b5d1451de8ed6233346e5685e8af7e30",
        "buggy_code": "seen in the dataset, sorted by occurance count, with ties broken by sort",
        "fixed_code": "seen in the dataset, sorted by occurrence count, with ties broken by sort",
        "patch": "@@ -363,7 +363,7 @@ def adapt(self, data, batch_size=None, steps=None):\n         supplied with a vocabulary.\n \n         During `adapt()`, the layer will build a vocabulary of all string tokens\n-        seen in the dataset, sorted by occurance count, with ties broken by sort\n+        seen in the dataset, sorted by occurrence count, with ties broken by sort\n         order of the tokens (high to low). At the end of `adapt()`, if `max_tokens`\n         is set, the vocabulary wil be truncated to `max_tokens` size. For example,\n         adapting a layer with `max_tokens=1000` will compute the 1000 most frequent"
    },
    {
        "commit_id": "0c7c8d03b5d1451de8ed6233346e5685e8af7e30",
        "commit_message": "Merge pull request #16568 from eltociear:fix-typo\n\nPiperOrigin-RevId: 450984177",
        "commit_url": "https://github.com/keras-team/keras/commit/0c7c8d03b5d1451de8ed6233346e5685e8af7e30",
        "buggy_code": "seen in the dataset, sorted by occurance count, with ties broken by sort",
        "fixed_code": "seen in the dataset, sorted by occurrence count, with ties broken by sort",
        "patch": "@@ -416,7 +416,7 @@ def adapt(self, data, batch_size=None, steps=None):\n         dataset or supplied with a vocabulary.\n \n         During `adapt()`, the layer will build a vocabulary of all string tokens\n-        seen in the dataset, sorted by occurance count, with ties broken by sort\n+        seen in the dataset, sorted by occurrence count, with ties broken by sort\n         order of the tokens (high to low). At the end of `adapt()`, if `max_tokens`\n         is set, the vocabulary wil be truncated to `max_tokens` size. For example,\n         adapting a layer with `max_tokens=1000` will compute the 1000 most frequent"
    },
    {
        "commit_id": "751f64d8a20b53ea38c0907510aabe814283445e",
        "commit_message": "Fix typos",
        "commit_url": "https://github.com/keras-team/keras/commit/751f64d8a20b53ea38c0907510aabe814283445e",
        "buggy_code": "[github discussion](https://github.com/keras-team/keras/issues/12072)",
        "fixed_code": "[GitHub discussion](https://github.com/keras-team/keras/issues/12072)",
        "patch": "@@ -44,7 +44,7 @@ def load_data(\n     This was originally generated by parsing and preprocessing the classic\n     Reuters-21578 dataset, but the preprocessing code is no longer packaged\n     with Keras. See this\n-    [github discussion](https://github.com/keras-team/keras/issues/12072)\n+    [GitHub discussion](https://github.com/keras-team/keras/issues/12072)\n     for more info.\n \n     Each newswire is encoded as a list of word indexes (integers)."
    },
    {
        "commit_id": "751f64d8a20b53ea38c0907510aabe814283445e",
        "commit_message": "Fix typos",
        "commit_url": "https://github.com/keras-team/keras/commit/751f64d8a20b53ea38c0907510aabe814283445e",
        "buggy_code": "aware the existance of those variable, we will just give them replicated",
        "fixed_code": "aware the existence of those variable, we will just give them replicated",
        "patch": "@@ -338,7 +338,7 @@ def _init_state_variable_for_rng(model, layout_map):\n     Since the BaseRandomLayer in keras explicitly untrack the tf.random.Generator,\n     the variable in it will stay as LazyInitVariable, which cause runtime error if\n     we don't replace them with proper DVariable. Since user usually are not\n-    aware the existance of those variable, we will just give them replicated\n+    aware the existence of those variable, we will just give them replicated\n     layout since they are tiny.\n \n     Args:"
    },
    {
        "commit_id": "751f64d8a20b53ea38c0907510aabe814283445e",
        "commit_message": "Fix typos",
        "commit_url": "https://github.com/keras-team/keras/commit/751f64d8a20b53ea38c0907510aabe814283445e",
        "buggy_code": "seen in the dataset, sorted by occurance count, with ties broken by sort",
        "fixed_code": "seen in the dataset, sorted by occurrence count, with ties broken by sort",
        "patch": "@@ -411,7 +411,7 @@ def adapt(self, data, batch_size=None, steps=None):\n         supplied with a vocabulary.\n \n         During `adapt()`, the layer will build a vocabulary of all integer tokens\n-        seen in the dataset, sorted by occurance count, with ties broken by sort\n+        seen in the dataset, sorted by occurrence count, with ties broken by sort\n         order of the tokens (high to low). At the end of `adapt()`, if `max_tokens`\n         is set, the vocabulary wil be truncated to `max_tokens` size. For example,\n         adapting a layer with `max_tokens=1000` will compute the 1000 most frequent"
    },
    {
        "commit_id": "751f64d8a20b53ea38c0907510aabe814283445e",
        "commit_message": "Fix typos",
        "commit_url": "https://github.com/keras-team/keras/commit/751f64d8a20b53ea38c0907510aabe814283445e",
        "buggy_code": "seen in the dataset, sorted by occurance count, with ties broken by sort",
        "fixed_code": "seen in the dataset, sorted by occurrence count, with ties broken by sort",
        "patch": "@@ -363,7 +363,7 @@ def adapt(self, data, batch_size=None, steps=None):\n         supplied with a vocabulary.\n \n         During `adapt()`, the layer will build a vocabulary of all string tokens\n-        seen in the dataset, sorted by occurance count, with ties broken by sort\n+        seen in the dataset, sorted by occurrence count, with ties broken by sort\n         order of the tokens (high to low). At the end of `adapt()`, if `max_tokens`\n         is set, the vocabulary wil be truncated to `max_tokens` size. For example,\n         adapting a layer with `max_tokens=1000` will compute the 1000 most frequent"
    },
    {
        "commit_id": "751f64d8a20b53ea38c0907510aabe814283445e",
        "commit_message": "Fix typos",
        "commit_url": "https://github.com/keras-team/keras/commit/751f64d8a20b53ea38c0907510aabe814283445e",
        "buggy_code": "seen in the dataset, sorted by occurance count, with ties broken by sort",
        "fixed_code": "seen in the dataset, sorted by occurrence count, with ties broken by sort",
        "patch": "@@ -416,7 +416,7 @@ def adapt(self, data, batch_size=None, steps=None):\n         dataset or supplied with a vocabulary.\n \n         During `adapt()`, the layer will build a vocabulary of all string tokens\n-        seen in the dataset, sorted by occurance count, with ties broken by sort\n+        seen in the dataset, sorted by occurrence count, with ties broken by sort\n         order of the tokens (high to low). At the end of `adapt()`, if `max_tokens`\n         is set, the vocabulary wil be truncated to `max_tokens` size. For example,\n         adapting a layer with `max_tokens=1000` will compute the 1000 most frequent"
    },
    {
        "commit_id": "68704e2e5b708d45d1f40ef7c14e5a4be68df3d1",
        "commit_message": "move test case to confusion_matrix_test.py\nfix dtype error in update_state()",
        "commit_url": "https://github.com/keras-team/keras/commit/68704e2e5b708d45d1f40ef7c14e5a4be68df3d1",
        "buggy_code": "weights = tf.multiply(sample_weights, label_weights)",
        "fixed_code": "weights = tf.cast(tf.multiply(sample_weights, label_weights), y_true.dtype)",
        "patch": "@@ -373,7 +373,7 @@ def _update_confusion_matrix_variables_optimized(\n                                                             y_pred)\n     if not multi_label:\n       label_weights = tf.reshape(label_weights, [-1])\n-  weights = tf.multiply(sample_weights, label_weights)\n+  weights = tf.cast(tf.multiply(sample_weights, label_weights), y_true.dtype)\n \n   # We shouldn't need this, but in case there are predict value that is out of\n   # the range of [0.0, 1.0]"
    },
    {
        "commit_id": "2a703470e18354c7c4b4c27a2c3846e4471ec54c",
        "commit_message": "Merge pull request #16534 from sushreebarsa:patch-2\n\nPiperOrigin-RevId: 449127894",
        "commit_url": "https://github.com/keras-team/keras/commit/2a703470e18354c7c4b4c27a2c3846e4471ec54c",
        "buggy_code": "The integer size of the voculary, including optional mask and oov indices.",
        "fixed_code": "The integer size of the vocabulary, including optional mask and oov indices.",
        "patch": "@@ -347,7 +347,7 @@ def vocabulary_size(self):\n     \"\"\"Gets the current size of the layer's vocabulary.\n \n     Returns:\n-      The integer size of the voculary, including optional mask and oov indices.\n+      The integer size of the vocabulary, including optional mask and oov indices.\n     \"\"\"\n     return int(self.lookup_table.size().numpy()) + self._token_start_index()\n "
    },
    {
        "commit_id": "2a703470e18354c7c4b4c27a2c3846e4471ec54c",
        "commit_message": "Merge pull request #16534 from sushreebarsa:patch-2\n\nPiperOrigin-RevId: 449127894",
        "commit_url": "https://github.com/keras-team/keras/commit/2a703470e18354c7c4b4c27a2c3846e4471ec54c",
        "buggy_code": "is set, the voculary wil be truncated to `max_tokens` size. For example,",
        "fixed_code": "is set, the vocabulary wil be truncated to `max_tokens` size. For example,",
        "patch": "@@ -393,7 +393,7 @@ def adapt(self, data, batch_size=None, steps=None):\n     During `adapt()`, the layer will build a vocabulary of all integer tokens\n     seen in the dataset, sorted by occurance count, with ties broken by sort\n     order of the tokens (high to low). At the end of `adapt()`, if `max_tokens`\n-    is set, the voculary wil be truncated to `max_tokens` size. For example,\n+    is set, the vocabulary wil be truncated to `max_tokens` size. For example,\n     adapting a layer with `max_tokens=1000` will compute the 1000 most frequent\n     tokens occurring in the input dataset. If `output_mode='tf-idf'`, `adapt()`\n     will also learn the document frequencies of each token in the input dataset."
    },
    {
        "commit_id": "2a703470e18354c7c4b4c27a2c3846e4471ec54c",
        "commit_message": "Merge pull request #16534 from sushreebarsa:patch-2\n\nPiperOrigin-RevId: 449127894",
        "commit_url": "https://github.com/keras-team/keras/commit/2a703470e18354c7c4b4c27a2c3846e4471ec54c",
        "buggy_code": "is set, the voculary wil be truncated to `max_tokens` size. For example,",
        "fixed_code": "is set, the vocabulary wil be truncated to `max_tokens` size. For example,",
        "patch": "@@ -357,7 +357,7 @@ def adapt(self, data, batch_size=None, steps=None):\n     During `adapt()`, the layer will build a vocabulary of all string tokens\n     seen in the dataset, sorted by occurance count, with ties broken by sort\n     order of the tokens (high to low). At the end of `adapt()`, if `max_tokens`\n-    is set, the voculary wil be truncated to `max_tokens` size. For example,\n+    is set, the vocabulary wil be truncated to `max_tokens` size. For example,\n     adapting a layer with `max_tokens=1000` will compute the 1000 most frequent\n     tokens occurring in the input dataset. If `output_mode='tf-idf'`, `adapt()`\n     will also learn the document frequencies of each token in the input dataset."
    },
    {
        "commit_id": "d1eefff16929c0ebf7fcf3f8e40313b51ffc2886",
        "commit_message": "Fix typo in documentation\n\nUpdated 'voculary' to 'vocabulary'.",
        "commit_url": "https://github.com/keras-team/keras/commit/d1eefff16929c0ebf7fcf3f8e40313b51ffc2886",
        "buggy_code": "The integer size of the voculary, including optional mask and oov indices.",
        "fixed_code": "The integer size of the vocabulary, including optional mask and oov indices.",
        "patch": "@@ -347,7 +347,7 @@ def vocabulary_size(self):\n     \"\"\"Gets the current size of the layer's vocabulary.\n \n     Returns:\n-      The integer size of the voculary, including optional mask and oov indices.\n+      The integer size of the vocabulary, including optional mask and oov indices.\n     \"\"\"\n     return int(self.lookup_table.size().numpy()) + self._token_start_index()\n "
    },
    {
        "commit_id": "7e9af6bf4c3d376fd2533aa4bf6edef0dbd972bd",
        "commit_message": "Fix typo in documentation \n\nUpdated 'voculary' to 'vocabulary'.",
        "commit_url": "https://github.com/keras-team/keras/commit/7e9af6bf4c3d376fd2533aa4bf6edef0dbd972bd",
        "buggy_code": "is set, the voculary wil be truncated to `max_tokens` size. For example,",
        "fixed_code": "is set, the vocabulary wil be truncated to `max_tokens` size. For example,",
        "patch": "@@ -393,7 +393,7 @@ def adapt(self, data, batch_size=None, steps=None):\n     During `adapt()`, the layer will build a vocabulary of all integer tokens\n     seen in the dataset, sorted by occurance count, with ties broken by sort\n     order of the tokens (high to low). At the end of `adapt()`, if `max_tokens`\n-    is set, the voculary wil be truncated to `max_tokens` size. For example,\n+    is set, the vocabulary wil be truncated to `max_tokens` size. For example,\n     adapting a layer with `max_tokens=1000` will compute the 1000 most frequent\n     tokens occurring in the input dataset. If `output_mode='tf-idf'`, `adapt()`\n     will also learn the document frequencies of each token in the input dataset."
    },
    {
        "commit_id": "9d104c87dd49771892ba22febcedddeeee2d1baf",
        "commit_message": "Fix typo in documentation\n\nUpdated 'voculary' with 'vocabulary'.",
        "commit_url": "https://github.com/keras-team/keras/commit/9d104c87dd49771892ba22febcedddeeee2d1baf",
        "buggy_code": "is set, the voculary wil be truncated to `max_tokens` size. For example,",
        "fixed_code": "is set, the vocabulary wil be truncated to `max_tokens` size. For example,",
        "patch": "@@ -357,7 +357,7 @@ def adapt(self, data, batch_size=None, steps=None):\n     During `adapt()`, the layer will build a vocabulary of all string tokens\n     seen in the dataset, sorted by occurance count, with ties broken by sort\n     order of the tokens (high to low). At the end of `adapt()`, if `max_tokens`\n-    is set, the voculary wil be truncated to `max_tokens` size. For example,\n+    is set, the vocabulary wil be truncated to `max_tokens` size. For example,\n     adapting a layer with `max_tokens=1000` will compute the 1000 most frequent\n     tokens occurring in the input dataset. If `output_mode='tf-idf'`, `adapt()`\n     will also learn the document frequencies of each token in the input dataset."
    },
    {
        "commit_id": "102d56f76f24ec9a0e8eed77a2cf4ba861ceee59",
        "commit_message": "Merge pull request #1 from Kiwiakos/Kiwiakos-patch-1\n\nFix OrthogonalRegularizer to implement the (1,1) matrix norm",
        "commit_url": "https://github.com/keras-team/keras/commit/102d56f76f24ec9a0e8eed77a2cf4ba861ceee59",
        "buggy_code": "return self.factor * 0.5 * tf.reduce_sum(product_no_diagonal) / num_pairs",
        "fixed_code": "return self.factor * 0.5 * tf.reduce_sum(tf.abs(product_no_diagonal)) / num_pairs",
        "patch": "@@ -368,7 +368,7 @@ def __call__(self, inputs):\n       size = inputs.shape[1]\n     product_no_diagonal = product * (1. - tf.eye(size, dtype=inputs.dtype))\n     num_pairs = size * (size - 1.) / 2.\n-    return self.factor * 0.5 * tf.reduce_sum(product_no_diagonal) / num_pairs\n+    return self.factor * 0.5 * tf.reduce_sum(tf.abs(product_no_diagonal)) / num_pairs\n \n   def get_config(self):\n     return {'factor': float(self.factor), 'mode': self.mode}"
    },
    {
        "commit_id": "2944bc68a9372606c1fd5de2f76e00076b5d26e9",
        "commit_message": "Update regularizers.py\n\nFix OrthogonalRegularizer to implement the (1,1) matrix norm. \r\nIssue: https://github.com/keras-team/keras/issues/16518",
        "commit_url": "https://github.com/keras-team/keras/commit/2944bc68a9372606c1fd5de2f76e00076b5d26e9",
        "buggy_code": "return self.factor * 0.5 * tf.reduce_sum(product_no_diagonal) / num_pairs",
        "fixed_code": "return self.factor * 0.5 * tf.reduce_sum(tf.abs(product_no_diagonal)) / num_pairs",
        "patch": "@@ -368,7 +368,7 @@ def __call__(self, inputs):\n       size = inputs.shape[1]\n     product_no_diagonal = product * (1. - tf.eye(size, dtype=inputs.dtype))\n     num_pairs = size * (size - 1.) / 2.\n-    return self.factor * 0.5 * tf.reduce_sum(product_no_diagonal) / num_pairs\n+    return self.factor * 0.5 * tf.reduce_sum(tf.abs(product_no_diagonal)) / num_pairs\n \n   def get_config(self):\n     return {'factor': float(self.factor), 'mode': self.mode}"
    },
    {
        "commit_id": "ea5f829321cea17bd5d02a7662d79c9f8c4ebdf2",
        "commit_message": "Merge pull request #3 from sayakpaul/feat/convnext-functional\n\nchore: spacing fix/",
        "commit_url": "https://github.com/keras-team/keras/commit/ea5f829321cea17bd5d02a7662d79c9f8c4ebdf2",
        "buggy_code": "\"40a20c5548a5e9202f69735ecc06c990e6b7c9d2de39f0361e27baeb24cb7c45\"),",
        "fixed_code": "\"96f02b6f0753d4f543261bc9d09bed650f24dd6bc02ddde3066135b63d23a1cd\"),",
        "patch": "@@ -48,7 +48,7 @@\n       \"40a20c5548a5e9202f69735ecc06c990e6b7c9d2de39f0361e27baeb24cb7c45\"),\n   \"large\":\n     (\"070c5ed9ed289581e477741d3b34beffa920db8cf590899d6d2c67fba2a198a6\",\n-      \"40a20c5548a5e9202f69735ecc06c990e6b7c9d2de39f0361e27baeb24cb7c45\"),\n+      \"96f02b6f0753d4f543261bc9d09bed650f24dd6bc02ddde3066135b63d23a1cd\"),\n   \"xlarge\":\n     (\"c1f5ccab661354fc3a79a10fa99af82f0fbf10ec65cb894a3ae0815f17a889ee\",\n       \"de3f8a54174130e0cecdc71583354753d557fcf1f4487331558e2a16ba0cfe05\"),"
    },
    {
        "commit_id": "4b24dc05d2bc929c3091a5560ad5d2d0b65db831",
        "commit_message": "chore: spacing fix/",
        "commit_url": "https://github.com/keras-team/keras/commit/4b24dc05d2bc929c3091a5560ad5d2d0b65db831",
        "buggy_code": "\"40a20c5548a5e9202f69735ecc06c990e6b7c9d2de39f0361e27baeb24cb7c45\"),",
        "fixed_code": "\"96f02b6f0753d4f543261bc9d09bed650f24dd6bc02ddde3066135b63d23a1cd\"),",
        "patch": "@@ -48,7 +48,7 @@\n       \"40a20c5548a5e9202f69735ecc06c990e6b7c9d2de39f0361e27baeb24cb7c45\"),\n   \"large\":\n     (\"070c5ed9ed289581e477741d3b34beffa920db8cf590899d6d2c67fba2a198a6\",\n-      \"40a20c5548a5e9202f69735ecc06c990e6b7c9d2de39f0361e27baeb24cb7c45\"),\n+      \"96f02b6f0753d4f543261bc9d09bed650f24dd6bc02ddde3066135b63d23a1cd\"),\n   \"xlarge\":\n     (\"c1f5ccab661354fc3a79a10fa99af82f0fbf10ec65cb894a3ae0815f17a889ee\",\n       \"de3f8a54174130e0cecdc71583354753d557fcf1f4487331558e2a16ba0cfe05\"),"
    },
    {
        "commit_id": "574c7a20b90cf5a1012db504e19877148a3145a9",
        "commit_message": "Fix bug with `save_spec` when there is a `training` positional arg.\n\nPiperOrigin-RevId: 445236065",
        "commit_url": "https://github.com/keras-team/keras/commit/574c7a20b90cf5a1012db504e19877148a3145a9",
        "buggy_code": "return hasattr(spec, 'name') and spec.name is not None",
        "fixed_code": "return spec is None or (hasattr(spec, 'name') and spec.name is not None)",
        "patch": "@@ -299,7 +299,7 @@ def _enforce_names_consistency(specs):\n   \"\"\"Enforces that either all specs have names or none do.\"\"\"\n \n   def _has_name(spec):\n-    return hasattr(spec, 'name') and spec.name is not None\n+    return spec is None or (hasattr(spec, 'name') and spec.name is not None)\n \n   def _clear_name(spec):\n     spec = copy.deepcopy(spec)"
    },
    {
        "commit_id": "babde7f3cf79c3d1e3b09c3c5a1ec22f2c58a0da",
        "commit_message": "Merge pull request #16459 from code-review-doctor:fix-probably-meant-fstring\n\nPiperOrigin-RevId: 444340251",
        "commit_url": "https://github.com/keras-team/keras/commit/babde7f3cf79c3d1e3b09c3c5a1ec22f2c58a0da",
        "buggy_code": "'Received depth_multiplier={depth_multiplier}')",
        "fixed_code": "f'Received depth_multiplier={depth_multiplier}')",
        "patch": "@@ -213,7 +213,7 @@ def MobileNet(input_shape=None,\n     if depth_multiplier != 1:\n       raise ValueError('If imagenet weights are being loaded, '\n                        'depth multiplier must be 1.  '\n-                       'Received depth_multiplier={depth_multiplier}')\n+                       f'Received depth_multiplier={depth_multiplier}')\n \n     if alpha not in [0.25, 0.50, 0.75, 1.0]:\n       raise ValueError('If imagenet weights are being loaded, '"
    },
    {
        "commit_id": "babde7f3cf79c3d1e3b09c3c5a1ec22f2c58a0da",
        "commit_message": "Merge pull request #16459 from code-review-doctor:fix-probably-meant-fstring\n\nPiperOrigin-RevId: 444340251",
        "commit_url": "https://github.com/keras-team/keras/commit/babde7f3cf79c3d1e3b09c3c5a1ec22f2c58a0da",
        "buggy_code": "'and thus has no defined {attr_name}.')",
        "fixed_code": "f'and thus has no defined {attr_name}.')",
        "patch": "@@ -2677,7 +2677,7 @@ def _get_node_attribute_at_index(self, node_index, attr, attr_name):\n     \"\"\"\n     if not self._inbound_nodes:\n       raise RuntimeError(f'The layer {self.name} has never been called '\n-                         'and thus has no defined {attr_name}.')\n+                         f'and thus has no defined {attr_name}.')\n     if not len(self._inbound_nodes) > node_index:\n       raise ValueError(f'Asked to get {attr_name} at node '\n                        f'{node_index}, but the layer has only '"
    },
    {
        "commit_id": "babde7f3cf79c3d1e3b09c3c5a1ec22f2c58a0da",
        "commit_message": "Merge pull request #16459 from code-review-doctor:fix-probably-meant-fstring\n\nPiperOrigin-RevId: 444340251",
        "commit_url": "https://github.com/keras-team/keras/commit/babde7f3cf79c3d1e3b09c3c5a1ec22f2c58a0da",
        "buggy_code": "\"You called `set_weights(weights)` on optimizer {self._name} \"",
        "fixed_code": "f\"You called `set_weights(weights)` on optimizer {self._name} \"",
        "patch": "@@ -1187,7 +1187,7 @@ def set_weights(self, weights):\n     params = self.weights\n     if len(params) != len(weights):\n       raise ValueError(\n-          \"You called `set_weights(weights)` on optimizer {self._name} \"\n+          f\"You called `set_weights(weights)` on optimizer {self._name} \"\n           f\"with a  weight list of length {str(len(weights))}, \"\n           f\"but the optimizer was expecting {str(len(params))} \"\n           f\"weights. Provided weights: {str(weights)[:50]}...\")"
    },
    {
        "commit_id": "babde7f3cf79c3d1e3b09c3c5a1ec22f2c58a0da",
        "commit_message": "Merge pull request #16459 from code-review-doctor:fix-probably-meant-fstring\n\nPiperOrigin-RevId: 444340251",
        "commit_url": "https://github.com/keras-team/keras/commit/babde7f3cf79c3d1e3b09c3c5a1ec22f2c58a0da",
        "buggy_code": "raise ValueError('f{method_name} `inputs` cannot be None or empty.')",
        "fixed_code": "raise ValueError(f'{method_name} `inputs` cannot be None or empty.')",
        "patch": "@@ -58,7 +58,7 @@ def _supervised_signature_def(\n     ValueError: If inputs or outputs is `None`.\n   \"\"\"\n   if inputs is None or not inputs:\n-    raise ValueError('f{method_name} `inputs` cannot be None or empty.')\n+    raise ValueError(f'{method_name} `inputs` cannot be None or empty.')\n \n   signature_inputs = {key: tf.compat.v1.saved_model.build_tensor_info(tensor)\n                       for key, tensor in inputs.items()}"
    },
    {
        "commit_id": "932c53e230b546fd6e0d93766f461ed8e1e2ba5a",
        "commit_message": " Fix issue probably-meant-fstring found at https://codereview.doctor",
        "commit_url": "https://github.com/keras-team/keras/commit/932c53e230b546fd6e0d93766f461ed8e1e2ba5a",
        "buggy_code": "'Received depth_multiplier={depth_multiplier}')",
        "fixed_code": "f'Received depth_multiplier={depth_multiplier}')",
        "patch": "@@ -213,7 +213,7 @@ def MobileNet(input_shape=None,\n     if depth_multiplier != 1:\n       raise ValueError('If imagenet weights are being loaded, '\n                        'depth multiplier must be 1.  '\n-                       'Received depth_multiplier={depth_multiplier}')\n+                       f'Received depth_multiplier={depth_multiplier}')\n \n     if alpha not in [0.25, 0.50, 0.75, 1.0]:\n       raise ValueError('If imagenet weights are being loaded, '"
    },
    {
        "commit_id": "932c53e230b546fd6e0d93766f461ed8e1e2ba5a",
        "commit_message": " Fix issue probably-meant-fstring found at https://codereview.doctor",
        "commit_url": "https://github.com/keras-team/keras/commit/932c53e230b546fd6e0d93766f461ed8e1e2ba5a",
        "buggy_code": "'got {type(layout)}')",
        "fixed_code": "f'got {type(layout)}')",
        "patch": "@@ -113,7 +113,7 @@ def __setitem__(self, key, layout):\n                        'not use duplicated keys.')\n     if not isinstance(layout, dtensor.Layout):\n       raise ValueError(f'{layout} should be a dtensor.Layout type, '\n-                       'got {type(layout)}')\n+                       f'got {type(layout)}')\n \n     self._layout_map[key] = layout\n "
    },
    {
        "commit_id": "932c53e230b546fd6e0d93766f461ed8e1e2ba5a",
        "commit_message": " Fix issue probably-meant-fstring found at https://codereview.doctor",
        "commit_url": "https://github.com/keras-team/keras/commit/932c53e230b546fd6e0d93766f461ed8e1e2ba5a",
        "buggy_code": "\"(Tried to create variable with name='{name}'). \"",
        "fixed_code": "f\"(Tried to create variable with name='{name}'). \"",
        "patch": "@@ -112,7 +112,7 @@ def __init__(\n         initial_value, \"graph\") and initial_value.graph.building_function:\n       raise ValueError(f\"Argument `initial_value` ({initial_value}) could not \"\n                        \"be lifted out of a `tf.function`. \"\n-                       \"(Tried to create variable with name='{name}'). \"\n+                       f\"(Tried to create variable with name='{name}'). \"\n                        \"To avoid this error, when constructing `tf.Variable`s \"\n                        \"inside of `tf.function` you can create the \"\n                        \"`initial_value` tensor in a \""
    },
    {
        "commit_id": "932c53e230b546fd6e0d93766f461ed8e1e2ba5a",
        "commit_message": " Fix issue probably-meant-fstring found at https://codereview.doctor",
        "commit_url": "https://github.com/keras-team/keras/commit/932c53e230b546fd6e0d93766f461ed8e1e2ba5a",
        "buggy_code": "'and thus has no defined {attr_name}.')",
        "fixed_code": "f'and thus has no defined {attr_name}.')",
        "patch": "@@ -2677,7 +2677,7 @@ def _get_node_attribute_at_index(self, node_index, attr, attr_name):\n     \"\"\"\n     if not self._inbound_nodes:\n       raise RuntimeError(f'The layer {self.name} has never been called '\n-                         'and thus has no defined {attr_name}.')\n+                         f'and thus has no defined {attr_name}.')\n     if not len(self._inbound_nodes) > node_index:\n       raise ValueError(f'Asked to get {attr_name} at node '\n                        f'{node_index}, but the layer has only '"
    },
    {
        "commit_id": "932c53e230b546fd6e0d93766f461ed8e1e2ba5a",
        "commit_message": " Fix issue probably-meant-fstring found at https://codereview.doctor",
        "commit_url": "https://github.com/keras-team/keras/commit/932c53e230b546fd6e0d93766f461ed8e1e2ba5a",
        "buggy_code": "\"Received {const_prob}\")",
        "fixed_code": "f\"Received {const_prob}\")",
        "patch": "@@ -233,7 +233,7 @@ def tensor_and_const_value(v):\n           if const_prob < 0 or const_prob > 1:\n             raise ValueError(\n                 f\"Parameter {attr} must be between 0 and 1. \"\n-                \"Received {const_prob}\")\n+                f\"Received {const_prob}\")\n           setattr(self, \"_%s\" % attr, float(const_prob))\n         else:\n           setattr(self, \"_%s\" % attr, tensor_prob)"
    },
    {
        "commit_id": "932c53e230b546fd6e0d93766f461ed8e1e2ba5a",
        "commit_message": " Fix issue probably-meant-fstring found at https://codereview.doctor",
        "commit_url": "https://github.com/keras-team/keras/commit/932c53e230b546fd6e0d93766f461ed8e1e2ba5a",
        "buggy_code": "\"Received {const_prob}\")",
        "fixed_code": "f\"Received {const_prob}\")",
        "patch": "@@ -268,7 +268,7 @@ def tensor_and_const_value(v):\n           if const_prob < 0 or const_prob > 1:\n             raise ValueError(\n                 f\"Parameter {attr} must be between 0 and 1. \"\n-                \"Received {const_prob}\")\n+                f\"Received {const_prob}\")\n           setattr(self, \"_%s\" % attr, float(const_prob))\n         else:\n           setattr(self, \"_%s\" % attr, tensor_prob)"
    },
    {
        "commit_id": "932c53e230b546fd6e0d93766f461ed8e1e2ba5a",
        "commit_message": " Fix issue probably-meant-fstring found at https://codereview.doctor",
        "commit_url": "https://github.com/keras-team/keras/commit/932c53e230b546fd6e0d93766f461ed8e1e2ba5a",
        "buggy_code": "\"received shape: {inputs_shape}\")",
        "fixed_code": "f\"received shape: {inputs_shape}\")",
        "patch": "@@ -940,7 +940,7 @@ def build(self, inputs_shape):\n     if inputs_shape[-1] is None:\n       raise ValueError(\n           \"Expected inputs.shape[-1] to be known, \"\n-          \"received shape: {inputs_shape}\")\n+          f\"received shape: {inputs_shape}\")\n     _check_supported_dtypes(self.dtype)\n     input_depth = inputs_shape[-1]\n     h_depth = self._num_units if self._num_proj is None else self._num_proj"
    },
    {
        "commit_id": "932c53e230b546fd6e0d93766f461ed8e1e2ba5a",
        "commit_message": " Fix issue probably-meant-fstring found at https://codereview.doctor",
        "commit_url": "https://github.com/keras-team/keras/commit/932c53e230b546fd6e0d93766f461ed8e1e2ba5a",
        "buggy_code": "\"You called `set_weights(weights)` on optimizer {self._name} \"",
        "fixed_code": "f\"You called `set_weights(weights)` on optimizer {self._name} \"",
        "patch": "@@ -1187,7 +1187,7 @@ def set_weights(self, weights):\n     params = self.weights\n     if len(params) != len(weights):\n       raise ValueError(\n-          \"You called `set_weights(weights)` on optimizer {self._name} \"\n+          f\"You called `set_weights(weights)` on optimizer {self._name} \"\n           f\"with a  weight list of length {str(len(weights))}, \"\n           f\"but the optimizer was expecting {str(len(params))} \"\n           f\"weights. Provided weights: {str(weights)[:50]}...\")"
    },
    {
        "commit_id": "932c53e230b546fd6e0d93766f461ed8e1e2ba5a",
        "commit_message": " Fix issue probably-meant-fstring found at https://codereview.doctor",
        "commit_url": "https://github.com/keras-team/keras/commit/932c53e230b546fd6e0d93766f461ed8e1e2ba5a",
        "buggy_code": "raise ValueError('f{method_name} `inputs` cannot be None or empty.')",
        "fixed_code": "raise ValueError(f'{method_name} `inputs` cannot be None or empty.')",
        "patch": "@@ -58,7 +58,7 @@ def _supervised_signature_def(\n     ValueError: If inputs or outputs is `None`.\n   \"\"\"\n   if inputs is None or not inputs:\n-    raise ValueError('f{method_name} `inputs` cannot be None or empty.')\n+    raise ValueError(f'{method_name} `inputs` cannot be None or empty.')\n \n   signature_inputs = {key: tf.compat.v1.saved_model.build_tensor_info(tensor)\n                       for key, tensor in inputs.items()}"
    },
    {
        "commit_id": "59b6c70efc09e3119795b321fa46470b4f64c8f3",
        "commit_message": "Fix `reset_states` not working when invoked within a `tf.function` in graph mode.\n\nPiperOrigin-RevId: 440976840",
        "commit_url": "https://github.com/keras-team/keras/commit/59b6c70efc09e3119795b321fa46470b4f64c8f3",
        "buggy_code": "if tf.compat.v1.executing_eagerly_outside_functions():",
        "fixed_code": "if tf.executing_eagerly() or tf.inside_function():",
        "patch": "@@ -4023,7 +4023,7 @@ def batch_set_value(tuples):\n       tuples: a list of tuples `(tensor, value)`.\n           `value` should be a Numpy array.\n   \"\"\"\n-  if tf.compat.v1.executing_eagerly_outside_functions():\n+  if tf.executing_eagerly() or tf.inside_function():\n     for x, value in tuples:\n       x.assign(np.asarray(value, dtype=dtype_numpy(x)))\n   else:"
    },
    {
        "commit_id": "68fef62d2788cea69f75101447af2bcb3405186c",
        "commit_message": "Fix non-float32 efficientnet calls",
        "commit_url": "https://github.com/keras-team/keras/commit/68fef62d2788cea69f75101447af2bcb3405186c",
        "buggy_code": "x = x / tf.math.sqrt(IMAGENET_STDDEV_RGB)",
        "fixed_code": "x = layers.Rescaling(1. / tf.math.sqrt(IMAGENET_STDDEV_RGB))(x)",
        "patch": "@@ -331,7 +331,7 @@ def round_repeats(repeats):\n     # normalize the input, we need to divide another sqrt(var) to match the\n     # original implementation.\n     # See https://github.com/tensorflow/tensorflow/issues/49930 for more details\n-    x = x / tf.math.sqrt(IMAGENET_STDDEV_RGB)\n+    x = layers.Rescaling(1. / tf.math.sqrt(IMAGENET_STDDEV_RGB))(x)\n \n   x = layers.ZeroPadding2D(\n       padding=imagenet_utils.correct_pad(x, 3),"
    },
    {
        "commit_id": "c5e2633190e5eb87654c98622c80c1637aaa0c17",
        "commit_message": "fixed a bug in val prepare_dataset function call",
        "commit_url": "https://github.com/keras-team/keras/commit/c5e2633190e5eb87654c98622c80c1637aaa0c17",
        "buggy_code": "dataset=val_dataset, batch_size=batch_size, shuffle=False, class_names=class_names",
        "fixed_code": "dataset=val_dataset, batch_size=batch_size, shuffle=False, seed=seed, class_names=class_names",
        "patch": "@@ -221,7 +221,7 @@ def audio_dataset_from_directory(\n             class_names=class_names,\n         )\n         val_dataset = prepare_dataset(\n-            dataset=val_dataset, batch_size=batch_size, shuffle=False, class_names=class_names\n+            dataset=val_dataset, batch_size=batch_size, shuffle=False, seed=seed, class_names=class_names\n         )\n         return train_dataset, val_dataset\n "
    },
    {
        "commit_id": "b7aec6378893a3449e6e1987283fe2fdb6eb1686",
        "commit_message": "fixed a bug in keras_export",
        "commit_url": "https://github.com/keras-team/keras/commit/b7aec6378893a3449e6e1987283fe2fdb6eb1686",
        "buggy_code": "@keras_export(\"keras.utils.image_dataset_from_directory\", v1=[])",
        "fixed_code": "@keras_export(\"keras.utils.audio_dataset_from_directory\", v1=[])",
        "patch": "@@ -26,7 +26,7 @@\n ALLOWED_FORMATS = (\".wav\",)\n \n \n-@keras_export(\"keras.utils.image_dataset_from_directory\", v1=[])\n+@keras_export(\"keras.utils.audio_dataset_from_directory\", v1=[])\n def audio_dataset_from_directory(\n     directory,\n     labels=\"inferred\","
    },
    {
        "commit_id": "a954f96e50c76e4cdd338337a4688bd72ee172bf",
        "commit_message": "Nit: Add a space after a period in a ValueError. This improves the error readability slightly.\n\nPiperOrigin-RevId: 440402112",
        "commit_url": "https://github.com/keras-team/keras/commit/a954f96e50c76e4cdd338337a4688bd72ee172bf",
        "buggy_code": "f'Found two metrics with the same name: {m._name}.'",
        "fixed_code": "f'Found two metrics with the same name: {m._name}. '",
        "patch": "@@ -437,7 +437,7 @@ def _set_metric_names(self):\n           m._name = output_name + '_' + m._name\n         if m._name in metric_names:\n           raise ValueError(\n-              f'Found two metrics with the same name: {m._name}.'\n+              f'Found two metrics with the same name: {m._name}. '\n               'All the metrics added to the model need to have unique names.')\n         metric_names.add(m._name)\n "
    },
    {
        "commit_id": "fb507741c88d5614de680920aa97e3f71944a090",
        "commit_message": "Typo fix in LSTM docstring\n\nReplaced a dot with a space.",
        "commit_url": "https://github.com/keras-team/keras/commit/fb507741c88d5614de680920aa97e3f71944a090",
        "buggy_code": "return_sequences: Boolean. Whether to return the last output. in the output",
        "fixed_code": "return_sequences: Boolean. Whether to return the last output in the output",
        "patch": "@@ -419,7 +419,7 @@ class LSTM(DropoutRNNCellMixin, RNN, base_layer.BaseRandomLayer):\n       transformation of the inputs. Default: 0.\n     recurrent_dropout: Float between 0 and 1. Fraction of the units to drop for\n       the linear transformation of the recurrent state. Default: 0.\n-    return_sequences: Boolean. Whether to return the last output. in the output\n+    return_sequences: Boolean. Whether to return the last output in the output\n       sequence, or the full sequence. Default: `False`.\n     return_state: Boolean. Whether to return the last state in addition to the\n       output. Default: `False`."
    },
    {
        "commit_id": "1fa5209dd2af716e8dcc7bfccf37ef7313a00f9b",
        "commit_message": "fix typo",
        "commit_url": "https://github.com/keras-team/keras/commit/1fa5209dd2af716e8dcc7bfccf37ef7313a00f9b",
        "buggy_code": "A tf.dataset.Dataset. Caller might use the dataset in different",
        "fixed_code": "A `tf.data.Dataset`. Caller might use the dataset in different",
        "patch": "@@ -122,7 +122,7 @@ def get_dataset(self):\n     epoch. This behavior might change in the future.\n \n     Returns:\n-      A tf.dataset.Dataset. Caller might use the dataset in different\n+      A `tf.data.Dataset`. Caller might use the dataset in different\n       context, e.g. iter(dataset) in eager to get the value directly, or in graph\n       mode, provide the iterator tensor to Keras model function.\n     \"\"\""
    },
    {
        "commit_id": "4c15bb3f08fdca36c3d9a55fbf6bdac5cd06d48c",
        "commit_message": "fix typo",
        "commit_url": "https://github.com/keras-team/keras/commit/4c15bb3f08fdca36c3d9a55fbf6bdac5cd06d48c",
        "buggy_code": "An tf.dataset.Dataset. Caller might use the dataset in different",
        "fixed_code": "A tf.dataset.Dataset. Caller might use the dataset in different",
        "patch": "@@ -122,7 +122,7 @@ def get_dataset(self):\n     epoch. This behavior might change in the future.\n \n     Returns:\n-      An tf.dataset.Dataset. Caller might use the dataset in different\n+      A tf.dataset.Dataset. Caller might use the dataset in different\n       context, e.g. iter(dataset) in eager to get the value directly, or in graph\n       mode, provide the iterator tensor to Keras model function.\n     \"\"\""
    },
    {
        "commit_id": "143b08ad3aaf9adbc297d4bc17921234677226f6",
        "commit_message": "minor documention fix",
        "commit_url": "https://github.com/keras-team/keras/commit/143b08ad3aaf9adbc297d4bc17921234677226f6",
        "buggy_code": "Note that `jit_compile=True` is",
        "fixed_code": "Note that `jit_compile=True`",
        "patch": "@@ -612,7 +612,7 @@ def compile(self,\n           machine learning.\n           `jit_compile` is not enabled for by default.\n           This option cannot be enabled with `run_eagerly=True`.\n-          Note that `jit_compile=True` is\n+          Note that `jit_compile=True`\n           may not necessarily work for all models.\n           For more information on supported operations please refer to the\n           [XLA documentation](https://www.tensorflow.org/xla)."
    },
    {
        "commit_id": "7d74c9f955c0e56639f9bb6f5caf3332c17d0efc",
        "commit_message": "Fix SAM test's failure.\n\nWe need to set steps_per_epoch in PSS test.\n\nPiperOrigin-RevId: 437850399",
        "commit_url": "https://github.com/keras-team/keras/commit/7d74c9f955c0e56639f9bb6f5caf3332c17d0efc",
        "buggy_code": "sam_model.fit(data, label)",
        "fixed_code": "sam_model.fit(data, label, steps_per_epoch=1)",
        "patch": "@@ -52,7 +52,7 @@ def test_sam_model_fit(self, strategy):\n           loss=keras.losses.BinaryCrossentropy(from_logits=True),\n       )\n \n-      sam_model.fit(data, label)\n+      sam_model.fit(data, label, steps_per_epoch=1)\n \n   def test_save_sam(self):\n     model = keras.Sequential(["
    },
    {
        "commit_id": "ff25e2c98027457e4b3927813f067ad7ef143f6a",
        "commit_message": "Merge pull request #16253 from guberti:fix-image-dataset-from-directory-doc-glitch\n\nPiperOrigin-RevId: 437076552",
        "commit_url": "https://github.com/keras-team/keras/commit/ff25e2c98027457e4b3927813f067ad7ef143f6a",
        "buggy_code": "label_mode:",
        "fixed_code": "label_mode: String describing the encoding of `labels`. Options are:",
        "patch": "@@ -203,7 +203,7 @@ def labels_to_dataset(labels, label_mode, num_classes):\n \n   Args:\n     labels: list/tuple of labels to be converted into a tf.data.Dataset.\n-    label_mode:\n+    label_mode: String describing the encoding of `labels`. Options are:\n     - 'binary' indicates that the labels (there can be only 2) are encoded as\n       `float32` scalars with values 0 or 1 (e.g. for `binary_crossentropy`).\n     - 'categorical' means that the labels are mapped into a categorical vector."
    },
    {
        "commit_id": "ff25e2c98027457e4b3927813f067ad7ef143f6a",
        "commit_message": "Merge pull request #16253 from guberti:fix-image-dataset-from-directory-doc-glitch\n\nPiperOrigin-RevId: 437076552",
        "commit_url": "https://github.com/keras-team/keras/commit/ff25e2c98027457e4b3927813f067ad7ef143f6a",
        "buggy_code": "label_mode:",
        "fixed_code": "label_mode: String describing the encoding of `labels`. Options are:",
        "patch": "@@ -78,7 +78,7 @@ def image_dataset_from_directory(directory,\n         image files found in the directory. Labels should be sorted according\n         to the alphanumeric order of the image file paths\n         (obtained via `os.walk(directory)` in Python).\n-    label_mode:\n+    label_mode: String describing the encoding of `labels`. Options are:\n         - 'int': means that the labels are encoded as integers\n             (e.g. for `sparse_categorical_crossentropy` loss).\n         - 'categorical' means that the labels are"
    },
    {
        "commit_id": "ff25e2c98027457e4b3927813f067ad7ef143f6a",
        "commit_message": "Merge pull request #16253 from guberti:fix-image-dataset-from-directory-doc-glitch\n\nPiperOrigin-RevId: 437076552",
        "commit_url": "https://github.com/keras-team/keras/commit/ff25e2c98027457e4b3927813f067ad7ef143f6a",
        "buggy_code": "label_mode:",
        "fixed_code": "label_mode: String describing the encoding of `labels`. Options are:",
        "patch": "@@ -68,7 +68,7 @@ def text_dataset_from_directory(directory,\n         text files found in the directory. Labels should be sorted according\n         to the alphanumeric order of the text file paths\n         (obtained via `os.walk(directory)` in Python).\n-    label_mode:\n+    label_mode: String describing the encoding of `labels`. Options are:\n         - 'int': means that the labels are encoded as integers\n             (e.g. for `sparse_categorical_crossentropy` loss).\n         - 'categorical' means that the labels are"
    },
    {
        "commit_id": "793620ae1bdda7e37edd485b034e8962fff57f3e",
        "commit_message": "`get_random_tranformation` -> `get_random_transformation`\n\nFix minor typo\n\nPiperOrigin-RevId: 436799072",
        "commit_url": "https://github.com/keras-team/keras/commit/793620ae1bdda7e37edd485b034e8962fff57f3e",
        "buggy_code": "def get_random_tranformation(self):",
        "fixed_code": "def get_random_transformation(self):",
        "patch": "@@ -1872,7 +1872,7 @@ def __init__(self, value_range=(0., 1.0), fixed_value=None, **kwargs):\n     self.value_range = value_range\n     self.fixed_value = fixed_value\n \n-  def get_random_tranformation(self):\n+  def get_random_transformation(self):\n     if self.fixed_value:\n       return self.fixed_value\n     return self._random_generator.random_uniform("
    },
    {
        "commit_id": "0d184e839a7b12ec8ca54b54be740883e00dfd73",
        "commit_message": "Merge remote-tracking branch 'upstream/master' into fix-image-dataset-from-directory-doc-glitch",
        "commit_url": "https://github.com/keras-team/keras/commit/0d184e839a7b12ec8ca54b54be740883e00dfd73",
        "buggy_code": "from keras.optimizers import learning_rate_schedule",
        "fixed_code": "from keras.optimizers.schedules import learning_rate_schedule",
        "patch": "@@ -29,7 +29,7 @@\n from keras import backend\n from keras.distribute import distributed_file_utils\n from keras.distribute import worker_training_state\n-from keras.optimizers import learning_rate_schedule\n+from keras.optimizers.schedules import learning_rate_schedule\n from keras.utils import generic_utils\n from keras.utils import io_utils\n from keras.utils import tf_utils"
    },
    {
        "commit_id": "0d184e839a7b12ec8ca54b54be740883e00dfd73",
        "commit_message": "Merge remote-tracking branch 'upstream/master' into fix-image-dataset-from-directory-doc-glitch",
        "commit_url": "https://github.com/keras-team/keras/commit/0d184e839a7b12ec8ca54b54be740883e00dfd73",
        "buggy_code": "from keras.optimizers import learning_rate_schedule",
        "fixed_code": "from keras.optimizers.schedules import learning_rate_schedule",
        "patch": "@@ -34,8 +34,8 @@\n from keras.engine import sequential\n from keras.layers import Activation\n from keras.layers import Dense\n-from keras.optimizers import learning_rate_schedule\n from keras.optimizers.optimizer_v2 import gradient_descent\n+from keras.optimizers.schedules import learning_rate_schedule\n from keras.testing_infra import test_combinations\n from keras.testing_infra import test_utils\n from keras.utils import io_utils"
    },
    {
        "commit_id": "0d184e839a7b12ec8ca54b54be740883e00dfd73",
        "commit_message": "Merge remote-tracking branch 'upstream/master' into fix-image-dataset-from-directory-doc-glitch",
        "commit_url": "https://github.com/keras-team/keras/commit/0d184e839a7b12ec8ca54b54be740883e00dfd73",
        "buggy_code": "from keras.optimizers import learning_rate_schedule",
        "fixed_code": "from keras.optimizers.schedules import learning_rate_schedule",
        "patch": "@@ -15,13 +15,13 @@\n \"\"\"DTensor specific Keras optimizers.\"\"\"\n \n from keras.dtensor import dtensor_api as dtensor\n-from keras.optimizers import learning_rate_schedule\n from keras.optimizers.optimizer_experimental import adadelta\n from keras.optimizers.optimizer_experimental import adagrad\n from keras.optimizers.optimizer_experimental import adam\n from keras.optimizers.optimizer_experimental import optimizer as optimizer_lib\n from keras.optimizers.optimizer_experimental import rmsprop\n from keras.optimizers.optimizer_experimental import sgd\n+from keras.optimizers.schedules import learning_rate_schedule\n \n import tensorflow.compat.v2 as tf\n "
    },
    {
        "commit_id": "0d184e839a7b12ec8ca54b54be740883e00dfd73",
        "commit_message": "Merge remote-tracking branch 'upstream/master' into fix-image-dataset-from-directory-doc-glitch",
        "commit_url": "https://github.com/keras-team/keras/commit/0d184e839a7b12ec8ca54b54be740883e00dfd73",
        "buggy_code": "from keras.optimizers import learning_rate_schedule",
        "fixed_code": "from keras.optimizers.schedules import learning_rate_schedule",
        "patch": "@@ -17,7 +17,7 @@\n import tensorflow.compat.v2 as tf\n \n import functools\n-from keras.optimizers import learning_rate_schedule\n+from keras.optimizers.schedules import learning_rate_schedule\n from tensorflow.python.util.tf_export import tf_export\n \n "
    },
    {
        "commit_id": "0d184e839a7b12ec8ca54b54be740883e00dfd73",
        "commit_message": "Merge remote-tracking branch 'upstream/master' into fix-image-dataset-from-directory-doc-glitch",
        "commit_url": "https://github.com/keras-team/keras/commit/0d184e839a7b12ec8ca54b54be740883e00dfd73",
        "buggy_code": "from keras.optimizers import learning_rate_schedule",
        "fixed_code": "from keras.optimizers.schedules import learning_rate_schedule",
        "patch": "@@ -22,8 +22,8 @@\n \n from keras import backend\n from keras import initializers\n-from keras.optimizers import learning_rate_schedule\n from keras.optimizers.optimizer_v2 import utils as optimizer_utils\n+from keras.optimizers.schedules import learning_rate_schedule\n import tensorflow.compat.v2 as tf\n # pylint: disable=g-direct-tensorflow-import\n from tensorflow.python.util.tf_export import keras_export"
    },
    {
        "commit_id": "0d184e839a7b12ec8ca54b54be740883e00dfd73",
        "commit_message": "Merge remote-tracking branch 'upstream/master' into fix-image-dataset-from-directory-doc-glitch",
        "commit_url": "https://github.com/keras-team/keras/commit/0d184e839a7b12ec8ca54b54be740883e00dfd73",
        "buggy_code": "from keras.optimizers import learning_rate_schedule",
        "fixed_code": "from keras.optimizers.schedules import learning_rate_schedule",
        "patch": "@@ -9,7 +9,6 @@\n from absl import logging\n from absl.testing import parameterized\n import keras\n-from keras.optimizers import learning_rate_schedule\n from keras.optimizers.optimizer_experimental import adadelta as adadelta_new\n from keras.optimizers.optimizer_experimental import adagrad as adagrad_new\n from keras.optimizers.optimizer_experimental import adam as adam_new\n@@ -25,6 +24,7 @@\n from keras.optimizers.optimizer_v2 import ftrl as ftrl_old\n from keras.optimizers.optimizer_v2 import gradient_descent as sgd_old\n from keras.optimizers.optimizer_v2 import rmsprop as rmsprop_old\n+from keras.optimizers.schedules import learning_rate_schedule\n from keras.utils import losses_utils\n import numpy as np\n import tensorflow.compat.v2 as tf"
    },
    {
        "commit_id": "0d184e839a7b12ec8ca54b54be740883e00dfd73",
        "commit_message": "Merge remote-tracking branch 'upstream/master' into fix-image-dataset-from-directory-doc-glitch",
        "commit_url": "https://github.com/keras-team/keras/commit/0d184e839a7b12ec8ca54b54be740883e00dfd73",
        "buggy_code": "from keras.optimizers import learning_rate_schedule",
        "fixed_code": "from keras.optimizers.schedules import learning_rate_schedule",
        "patch": "@@ -22,7 +22,7 @@\n import numpy as np\n from keras.testing_infra import test_combinations\n from keras.optimizers.optimizer_v2 import adagrad\n-from keras.optimizers import learning_rate_schedule\n+from keras.optimizers.schedules import learning_rate_schedule\n \n _DATA_TYPES = [\n     tf.half, tf.float32, tf.float64, tf.complex64,"
    },
    {
        "commit_id": "0d184e839a7b12ec8ca54b54be740883e00dfd73",
        "commit_message": "Merge remote-tracking branch 'upstream/master' into fix-image-dataset-from-directory-doc-glitch",
        "commit_url": "https://github.com/keras-team/keras/commit/0d184e839a7b12ec8ca54b54be740883e00dfd73",
        "buggy_code": "from keras.optimizers import learning_rate_schedule",
        "fixed_code": "from keras.optimizers.schedules import learning_rate_schedule",
        "patch": "@@ -21,7 +21,7 @@\n from keras.testing_infra import test_combinations\n from keras.optimizers import optimizer_v1\n from keras.optimizers.optimizer_v2 import adam\n-from keras.optimizers import learning_rate_schedule\n+from keras.optimizers.schedules import learning_rate_schedule\n \n \n def adam_update_numpy(param,"
    },
    {
        "commit_id": "0d184e839a7b12ec8ca54b54be740883e00dfd73",
        "commit_message": "Merge remote-tracking branch 'upstream/master' into fix-image-dataset-from-directory-doc-glitch",
        "commit_url": "https://github.com/keras-team/keras/commit/0d184e839a7b12ec8ca54b54be740883e00dfd73",
        "buggy_code": "from keras.optimizers import learning_rate_schedule",
        "fixed_code": "from keras.optimizers.schedules import learning_rate_schedule",
        "patch": "@@ -20,7 +20,7 @@\n import numpy as np\n from keras.testing_infra import test_combinations\n from keras.optimizers.optimizer_v2 import gradient_descent\n-from keras.optimizers import learning_rate_schedule\n+from keras.optimizers.schedules import learning_rate_schedule\n \n \n class GradientDescentOptimizerTest(tf.test.TestCase, parameterized.TestCase):"
    },
    {
        "commit_id": "0d184e839a7b12ec8ca54b54be740883e00dfd73",
        "commit_message": "Merge remote-tracking branch 'upstream/master' into fix-image-dataset-from-directory-doc-glitch",
        "commit_url": "https://github.com/keras-team/keras/commit/0d184e839a7b12ec8ca54b54be740883e00dfd73",
        "buggy_code": "from keras.optimizers import learning_rate_schedule",
        "fixed_code": "from keras.optimizers.schedules import learning_rate_schedule",
        "patch": "@@ -16,7 +16,7 @@\n \n import tensorflow.compat.v2 as tf\n from keras import backend_config\n-from keras.optimizers import learning_rate_schedule\n+from keras.optimizers.schedules import learning_rate_schedule\n from keras.optimizers.optimizer_v2 import optimizer_v2\n from tensorflow.python.util.tf_export import keras_export\n "
    },
    {
        "commit_id": "0d184e839a7b12ec8ca54b54be740883e00dfd73",
        "commit_message": "Merge remote-tracking branch 'upstream/master' into fix-image-dataset-from-directory-doc-glitch",
        "commit_url": "https://github.com/keras-team/keras/commit/0d184e839a7b12ec8ca54b54be740883e00dfd73",
        "buggy_code": "from keras.optimizers import learning_rate_schedule",
        "fixed_code": "from keras.optimizers.schedules import learning_rate_schedule",
        "patch": "@@ -23,8 +23,8 @@\n from keras import backend\n from keras import initializers\n from keras.engine import base_layer_utils\n-from keras.optimizers import learning_rate_schedule\n from keras.optimizers.optimizer_v2 import utils as optimizer_utils\n+from keras.optimizers.schedules import learning_rate_schedule\n from keras.utils import generic_utils\n from keras.utils import layer_utils\n from keras.utils import tf_inspect"
    },
    {
        "commit_id": "0d184e839a7b12ec8ca54b54be740883e00dfd73",
        "commit_message": "Merge remote-tracking branch 'upstream/master' into fix-image-dataset-from-directory-doc-glitch",
        "commit_url": "https://github.com/keras-team/keras/commit/0d184e839a7b12ec8ca54b54be740883e00dfd73",
        "buggy_code": "from keras.optimizers import learning_rate_schedule",
        "fixed_code": "from keras.optimizers.schedules import learning_rate_schedule",
        "patch": "@@ -26,7 +26,6 @@\n from keras.engine import training\n from keras.layers import core\n from keras.layers import regularization\n-from keras.optimizers import learning_rate_schedule\n from keras.optimizers import optimizer_v1\n from keras.optimizers.optimizer_v2 import adadelta\n from keras.optimizers.optimizer_v2 import adagrad\n@@ -37,6 +36,7 @@\n from keras.optimizers.optimizer_v2 import nadam\n from keras.optimizers.optimizer_v2 import optimizer_v2\n from keras.optimizers.optimizer_v2 import rmsprop\n+from keras.optimizers.schedules import learning_rate_schedule\n from keras.testing_infra import test_combinations\n from keras.testing_infra import test_utils\n from keras.utils import np_utils"
    },
    {
        "commit_id": "0d184e839a7b12ec8ca54b54be740883e00dfd73",
        "commit_message": "Merge remote-tracking branch 'upstream/master' into fix-image-dataset-from-directory-doc-glitch",
        "commit_url": "https://github.com/keras-team/keras/commit/0d184e839a7b12ec8ca54b54be740883e00dfd73",
        "buggy_code": "from keras.optimizers import learning_rate_schedule",
        "fixed_code": "from keras.optimizers.schedules import learning_rate_schedule",
        "patch": "@@ -25,7 +25,7 @@\n from tensorflow.python.framework import test_util as tf_test_utils  # pylint: disable=g-direct-tensorflow-import\n from keras.testing_infra import test_combinations\n from keras.testing_infra import test_utils\n-from keras.optimizers import learning_rate_schedule\n+from keras.optimizers.schedules import learning_rate_schedule\n from keras.optimizers.optimizer_v2 import rmsprop\n \n _DATA_TYPES = ["
    },
    {
        "commit_id": "0d184e839a7b12ec8ca54b54be740883e00dfd73",
        "commit_message": "Merge remote-tracking branch 'upstream/master' into fix-image-dataset-from-directory-doc-glitch",
        "commit_url": "https://github.com/keras-team/keras/commit/0d184e839a7b12ec8ca54b54be740883e00dfd73",
        "buggy_code": "\"\"\"Various learning rate decay functions.\"\"\"",
        "fixed_code": "\"\"\"Various learning rate schedule functions.\"\"\"",
        "patch": "@@ -12,7 +12,7 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n # ==============================================================================\n-\"\"\"Various learning rate decay functions.\"\"\"\n+\"\"\"Various learning rate schedule functions.\"\"\"\n \n import tensorflow.compat.v2 as tf\n "
    },
    {
        "commit_id": "0d184e839a7b12ec8ca54b54be740883e00dfd73",
        "commit_message": "Merge remote-tracking branch 'upstream/master' into fix-image-dataset-from-directory-doc-glitch",
        "commit_url": "https://github.com/keras-team/keras/commit/0d184e839a7b12ec8ca54b54be740883e00dfd73",
        "buggy_code": "from keras.utils import all_utils as utils",
        "fixed_code": "from keras import utils",
        "patch": "@@ -26,7 +26,7 @@\n from keras.testing_infra import test_utils\n from keras.layers.rnn import legacy_cells\n from keras.legacy_tf_layers import base as base_layer\n-from keras.utils import all_utils as utils\n+from keras import utils\n \n \n class KerasIntegrationTest(test_combinations.TestCase):"
    },
    {
        "commit_id": "0d184e839a7b12ec8ca54b54be740883e00dfd73",
        "commit_message": "Merge remote-tracking branch 'upstream/master' into fix-image-dataset-from-directory-doc-glitch",
        "commit_url": "https://github.com/keras-team/keras/commit/0d184e839a7b12ec8ca54b54be740883e00dfd73",
        "buggy_code": "from keras.preprocessing import image_dataset",
        "fixed_code": "from keras.utils import image_dataset",
        "patch": "@@ -23,7 +23,7 @@\n from keras.testing_infra import test_combinations\n from keras.testing_infra import test_utils\n from keras.preprocessing import image as image_preproc\n-from keras.preprocessing import image_dataset\n+from keras.utils import image_dataset\n \n try:\n   import PIL  # pylint:disable=g-import-not-at-top"
    },
    {
        "commit_id": "0d184e839a7b12ec8ca54b54be740883e00dfd73",
        "commit_message": "Merge remote-tracking branch 'upstream/master' into fix-image-dataset-from-directory-doc-glitch",
        "commit_url": "https://github.com/keras-team/keras/commit/0d184e839a7b12ec8ca54b54be740883e00dfd73",
        "buggy_code": "from keras.preprocessing import dataset_utils",
        "fixed_code": "from keras.utils import dataset_utils",
        "patch": "@@ -17,7 +17,7 @@\n import tensorflow.compat.v2 as tf\n \n import numpy as np\n-from keras.preprocessing import dataset_utils\n+from keras.utils import dataset_utils\n from tensorflow.python.util.tf_export import keras_export\n \n "
    },
    {
        "commit_id": "0d184e839a7b12ec8ca54b54be740883e00dfd73",
        "commit_message": "Merge remote-tracking branch 'upstream/master' into fix-image-dataset-from-directory-doc-glitch",
        "commit_url": "https://github.com/keras-team/keras/commit/0d184e839a7b12ec8ca54b54be740883e00dfd73",
        "buggy_code": "from keras.preprocessing import text_dataset",
        "fixed_code": "from keras.utils import text_dataset",
        "patch": "@@ -22,7 +22,7 @@\n import string\n from keras.testing_infra import test_combinations\n from keras.testing_infra import test_utils\n-from keras.preprocessing import text_dataset\n+from keras.utils import text_dataset\n \n \n @test_utils.run_v2_only"
    },
    {
        "commit_id": "4352f38b114552f15d8e067fd2f029287b908488",
        "commit_message": "Proactive fix for upcoming experimental_relax_shapes update\n\nPiperOrigin-RevId: 435755459",
        "commit_url": "https://github.com/keras-team/keras/commit/4352f38b114552f15d8e067fd2f029287b908488",
        "buggy_code": "predict_function, experimental_relax_shapes=False)",
        "fixed_code": "predict_function, experimental_relax_shapes=True)",
        "patch": "@@ -1861,7 +1861,7 @@ def predict_function(iterator):\n \n     if not self.run_eagerly:\n       predict_function = tf.function(\n-          predict_function, experimental_relax_shapes=False)\n+          predict_function, experimental_relax_shapes=True)\n     self.predict_function = predict_function\n \n     return self.predict_function"
    },
    {
        "commit_id": "9dc9a78cc6502226775a99725c654fab3298aa5f",
        "commit_message": "Expose all utilities in `keras.utils.__init__.py`, and resolve the hourglass import issues that led to the creation of an extraneous `all_utils.py` file / library.\n\nPiperOrigin-RevId: 435725558",
        "commit_url": "https://github.com/keras-team/keras/commit/9dc9a78cc6502226775a99725c654fab3298aa5f",
        "buggy_code": "from keras.utils import all_utils as utils",
        "fixed_code": "from keras import utils",
        "patch": "@@ -26,7 +26,7 @@\n from keras.testing_infra import test_utils\n from keras.layers.rnn import legacy_cells\n from keras.legacy_tf_layers import base as base_layer\n-from keras.utils import all_utils as utils\n+from keras import utils\n \n \n class KerasIntegrationTest(test_combinations.TestCase):"
    },
    {
        "commit_id": "802ef25756089cc55dd49c0b47377a76edf8958c",
        "commit_message": "- Refactor learning rate schedule code to live in `keras/optimizers/schedules` (to match the API namespace).\n- Export optimizers to `keras.optimizers.__init__` to resolve discrepancy between tf.keras and keras packages.\n- Export schedules to `keras.optimizers.schedules.__init__` to resolve discrepancy between tf.keras and keras packages.\n\nPiperOrigin-RevId: 435722952",
        "commit_url": "https://github.com/keras-team/keras/commit/802ef25756089cc55dd49c0b47377a76edf8958c",
        "buggy_code": "from keras.optimizers import learning_rate_schedule",
        "fixed_code": "from keras.optimizers.schedules import learning_rate_schedule",
        "patch": "@@ -29,7 +29,7 @@\n from keras import backend\n from keras.distribute import distributed_file_utils\n from keras.distribute import worker_training_state\n-from keras.optimizers import learning_rate_schedule\n+from keras.optimizers.schedules import learning_rate_schedule\n from keras.utils import generic_utils\n from keras.utils import io_utils\n from keras.utils import tf_utils"
    },
    {
        "commit_id": "802ef25756089cc55dd49c0b47377a76edf8958c",
        "commit_message": "- Refactor learning rate schedule code to live in `keras/optimizers/schedules` (to match the API namespace).\n- Export optimizers to `keras.optimizers.__init__` to resolve discrepancy between tf.keras and keras packages.\n- Export schedules to `keras.optimizers.schedules.__init__` to resolve discrepancy between tf.keras and keras packages.\n\nPiperOrigin-RevId: 435722952",
        "commit_url": "https://github.com/keras-team/keras/commit/802ef25756089cc55dd49c0b47377a76edf8958c",
        "buggy_code": "from keras.optimizers import learning_rate_schedule",
        "fixed_code": "from keras.optimizers.schedules import learning_rate_schedule",
        "patch": "@@ -34,8 +34,8 @@\n from keras.engine import sequential\n from keras.layers import Activation\n from keras.layers import Dense\n-from keras.optimizers import learning_rate_schedule\n from keras.optimizers.optimizer_v2 import gradient_descent\n+from keras.optimizers.schedules import learning_rate_schedule\n from keras.testing_infra import test_combinations\n from keras.testing_infra import test_utils\n from keras.utils import io_utils"
    },
    {
        "commit_id": "802ef25756089cc55dd49c0b47377a76edf8958c",
        "commit_message": "- Refactor learning rate schedule code to live in `keras/optimizers/schedules` (to match the API namespace).\n- Export optimizers to `keras.optimizers.__init__` to resolve discrepancy between tf.keras and keras packages.\n- Export schedules to `keras.optimizers.schedules.__init__` to resolve discrepancy between tf.keras and keras packages.\n\nPiperOrigin-RevId: 435722952",
        "commit_url": "https://github.com/keras-team/keras/commit/802ef25756089cc55dd49c0b47377a76edf8958c",
        "buggy_code": "from keras.optimizers import learning_rate_schedule",
        "fixed_code": "from keras.optimizers.schedules import learning_rate_schedule",
        "patch": "@@ -15,13 +15,13 @@\n \"\"\"DTensor specific Keras optimizers.\"\"\"\n \n from keras.dtensor import dtensor_api as dtensor\n-from keras.optimizers import learning_rate_schedule\n from keras.optimizers.optimizer_experimental import adadelta\n from keras.optimizers.optimizer_experimental import adagrad\n from keras.optimizers.optimizer_experimental import adam\n from keras.optimizers.optimizer_experimental import optimizer as optimizer_lib\n from keras.optimizers.optimizer_experimental import rmsprop\n from keras.optimizers.optimizer_experimental import sgd\n+from keras.optimizers.schedules import learning_rate_schedule\n \n import tensorflow.compat.v2 as tf\n "
    },
    {
        "commit_id": "802ef25756089cc55dd49c0b47377a76edf8958c",
        "commit_message": "- Refactor learning rate schedule code to live in `keras/optimizers/schedules` (to match the API namespace).\n- Export optimizers to `keras.optimizers.__init__` to resolve discrepancy between tf.keras and keras packages.\n- Export schedules to `keras.optimizers.schedules.__init__` to resolve discrepancy between tf.keras and keras packages.\n\nPiperOrigin-RevId: 435722952",
        "commit_url": "https://github.com/keras-team/keras/commit/802ef25756089cc55dd49c0b47377a76edf8958c",
        "buggy_code": "from keras.optimizers import learning_rate_schedule",
        "fixed_code": "from keras.optimizers.schedules import learning_rate_schedule",
        "patch": "@@ -17,7 +17,7 @@\n import tensorflow.compat.v2 as tf\n \n import functools\n-from keras.optimizers import learning_rate_schedule\n+from keras.optimizers.schedules import learning_rate_schedule\n from tensorflow.python.util.tf_export import tf_export\n \n "
    },
    {
        "commit_id": "802ef25756089cc55dd49c0b47377a76edf8958c",
        "commit_message": "- Refactor learning rate schedule code to live in `keras/optimizers/schedules` (to match the API namespace).\n- Export optimizers to `keras.optimizers.__init__` to resolve discrepancy between tf.keras and keras packages.\n- Export schedules to `keras.optimizers.schedules.__init__` to resolve discrepancy between tf.keras and keras packages.\n\nPiperOrigin-RevId: 435722952",
        "commit_url": "https://github.com/keras-team/keras/commit/802ef25756089cc55dd49c0b47377a76edf8958c",
        "buggy_code": "from keras.optimizers import learning_rate_schedule",
        "fixed_code": "from keras.optimizers.schedules import learning_rate_schedule",
        "patch": "@@ -22,8 +22,8 @@\n \n from keras import backend\n from keras import initializers\n-from keras.optimizers import learning_rate_schedule\n from keras.optimizers.optimizer_v2 import utils as optimizer_utils\n+from keras.optimizers.schedules import learning_rate_schedule\n import tensorflow.compat.v2 as tf\n # pylint: disable=g-direct-tensorflow-import\n from tensorflow.python.util.tf_export import keras_export"
    },
    {
        "commit_id": "802ef25756089cc55dd49c0b47377a76edf8958c",
        "commit_message": "- Refactor learning rate schedule code to live in `keras/optimizers/schedules` (to match the API namespace).\n- Export optimizers to `keras.optimizers.__init__` to resolve discrepancy between tf.keras and keras packages.\n- Export schedules to `keras.optimizers.schedules.__init__` to resolve discrepancy between tf.keras and keras packages.\n\nPiperOrigin-RevId: 435722952",
        "commit_url": "https://github.com/keras-team/keras/commit/802ef25756089cc55dd49c0b47377a76edf8958c",
        "buggy_code": "from keras.optimizers import learning_rate_schedule",
        "fixed_code": "from keras.optimizers.schedules import learning_rate_schedule",
        "patch": "@@ -9,7 +9,6 @@\n from absl import logging\n from absl.testing import parameterized\n import keras\n-from keras.optimizers import learning_rate_schedule\n from keras.optimizers.optimizer_experimental import adadelta as adadelta_new\n from keras.optimizers.optimizer_experimental import adagrad as adagrad_new\n from keras.optimizers.optimizer_experimental import adam as adam_new\n@@ -25,6 +24,7 @@\n from keras.optimizers.optimizer_v2 import ftrl as ftrl_old\n from keras.optimizers.optimizer_v2 import gradient_descent as sgd_old\n from keras.optimizers.optimizer_v2 import rmsprop as rmsprop_old\n+from keras.optimizers.schedules import learning_rate_schedule\n from keras.utils import losses_utils\n import numpy as np\n import tensorflow.compat.v2 as tf"
    },
    {
        "commit_id": "802ef25756089cc55dd49c0b47377a76edf8958c",
        "commit_message": "- Refactor learning rate schedule code to live in `keras/optimizers/schedules` (to match the API namespace).\n- Export optimizers to `keras.optimizers.__init__` to resolve discrepancy between tf.keras and keras packages.\n- Export schedules to `keras.optimizers.schedules.__init__` to resolve discrepancy between tf.keras and keras packages.\n\nPiperOrigin-RevId: 435722952",
        "commit_url": "https://github.com/keras-team/keras/commit/802ef25756089cc55dd49c0b47377a76edf8958c",
        "buggy_code": "from keras.optimizers import learning_rate_schedule",
        "fixed_code": "from keras.optimizers.schedules import learning_rate_schedule",
        "patch": "@@ -22,7 +22,7 @@\n import numpy as np\n from keras.testing_infra import test_combinations\n from keras.optimizers.optimizer_v2 import adagrad\n-from keras.optimizers import learning_rate_schedule\n+from keras.optimizers.schedules import learning_rate_schedule\n \n _DATA_TYPES = [\n     tf.half, tf.float32, tf.float64, tf.complex64,"
    },
    {
        "commit_id": "802ef25756089cc55dd49c0b47377a76edf8958c",
        "commit_message": "- Refactor learning rate schedule code to live in `keras/optimizers/schedules` (to match the API namespace).\n- Export optimizers to `keras.optimizers.__init__` to resolve discrepancy between tf.keras and keras packages.\n- Export schedules to `keras.optimizers.schedules.__init__` to resolve discrepancy between tf.keras and keras packages.\n\nPiperOrigin-RevId: 435722952",
        "commit_url": "https://github.com/keras-team/keras/commit/802ef25756089cc55dd49c0b47377a76edf8958c",
        "buggy_code": "from keras.optimizers import learning_rate_schedule",
        "fixed_code": "from keras.optimizers.schedules import learning_rate_schedule",
        "patch": "@@ -21,7 +21,7 @@\n from keras.testing_infra import test_combinations\n from keras.optimizers import optimizer_v1\n from keras.optimizers.optimizer_v2 import adam\n-from keras.optimizers import learning_rate_schedule\n+from keras.optimizers.schedules import learning_rate_schedule\n \n \n def adam_update_numpy(param,"
    },
    {
        "commit_id": "802ef25756089cc55dd49c0b47377a76edf8958c",
        "commit_message": "- Refactor learning rate schedule code to live in `keras/optimizers/schedules` (to match the API namespace).\n- Export optimizers to `keras.optimizers.__init__` to resolve discrepancy between tf.keras and keras packages.\n- Export schedules to `keras.optimizers.schedules.__init__` to resolve discrepancy between tf.keras and keras packages.\n\nPiperOrigin-RevId: 435722952",
        "commit_url": "https://github.com/keras-team/keras/commit/802ef25756089cc55dd49c0b47377a76edf8958c",
        "buggy_code": "from keras.optimizers import learning_rate_schedule",
        "fixed_code": "from keras.optimizers.schedules import learning_rate_schedule",
        "patch": "@@ -20,7 +20,7 @@\n import numpy as np\n from keras.testing_infra import test_combinations\n from keras.optimizers.optimizer_v2 import gradient_descent\n-from keras.optimizers import learning_rate_schedule\n+from keras.optimizers.schedules import learning_rate_schedule\n \n \n class GradientDescentOptimizerTest(tf.test.TestCase, parameterized.TestCase):"
    },
    {
        "commit_id": "802ef25756089cc55dd49c0b47377a76edf8958c",
        "commit_message": "- Refactor learning rate schedule code to live in `keras/optimizers/schedules` (to match the API namespace).\n- Export optimizers to `keras.optimizers.__init__` to resolve discrepancy between tf.keras and keras packages.\n- Export schedules to `keras.optimizers.schedules.__init__` to resolve discrepancy between tf.keras and keras packages.\n\nPiperOrigin-RevId: 435722952",
        "commit_url": "https://github.com/keras-team/keras/commit/802ef25756089cc55dd49c0b47377a76edf8958c",
        "buggy_code": "from keras.optimizers import learning_rate_schedule",
        "fixed_code": "from keras.optimizers.schedules import learning_rate_schedule",
        "patch": "@@ -16,7 +16,7 @@\n \n import tensorflow.compat.v2 as tf\n from keras import backend_config\n-from keras.optimizers import learning_rate_schedule\n+from keras.optimizers.schedules import learning_rate_schedule\n from keras.optimizers.optimizer_v2 import optimizer_v2\n from tensorflow.python.util.tf_export import keras_export\n "
    },
    {
        "commit_id": "802ef25756089cc55dd49c0b47377a76edf8958c",
        "commit_message": "- Refactor learning rate schedule code to live in `keras/optimizers/schedules` (to match the API namespace).\n- Export optimizers to `keras.optimizers.__init__` to resolve discrepancy between tf.keras and keras packages.\n- Export schedules to `keras.optimizers.schedules.__init__` to resolve discrepancy between tf.keras and keras packages.\n\nPiperOrigin-RevId: 435722952",
        "commit_url": "https://github.com/keras-team/keras/commit/802ef25756089cc55dd49c0b47377a76edf8958c",
        "buggy_code": "from keras.optimizers import learning_rate_schedule",
        "fixed_code": "from keras.optimizers.schedules import learning_rate_schedule",
        "patch": "@@ -23,8 +23,8 @@\n from keras import backend\n from keras import initializers\n from keras.engine import base_layer_utils\n-from keras.optimizers import learning_rate_schedule\n from keras.optimizers.optimizer_v2 import utils as optimizer_utils\n+from keras.optimizers.schedules import learning_rate_schedule\n from keras.utils import generic_utils\n from keras.utils import layer_utils\n from keras.utils import tf_inspect"
    },
    {
        "commit_id": "802ef25756089cc55dd49c0b47377a76edf8958c",
        "commit_message": "- Refactor learning rate schedule code to live in `keras/optimizers/schedules` (to match the API namespace).\n- Export optimizers to `keras.optimizers.__init__` to resolve discrepancy between tf.keras and keras packages.\n- Export schedules to `keras.optimizers.schedules.__init__` to resolve discrepancy between tf.keras and keras packages.\n\nPiperOrigin-RevId: 435722952",
        "commit_url": "https://github.com/keras-team/keras/commit/802ef25756089cc55dd49c0b47377a76edf8958c",
        "buggy_code": "from keras.optimizers import learning_rate_schedule",
        "fixed_code": "from keras.optimizers.schedules import learning_rate_schedule",
        "patch": "@@ -26,7 +26,6 @@\n from keras.engine import training\n from keras.layers import core\n from keras.layers import regularization\n-from keras.optimizers import learning_rate_schedule\n from keras.optimizers import optimizer_v1\n from keras.optimizers.optimizer_v2 import adadelta\n from keras.optimizers.optimizer_v2 import adagrad\n@@ -37,6 +36,7 @@\n from keras.optimizers.optimizer_v2 import nadam\n from keras.optimizers.optimizer_v2 import optimizer_v2\n from keras.optimizers.optimizer_v2 import rmsprop\n+from keras.optimizers.schedules import learning_rate_schedule\n from keras.testing_infra import test_combinations\n from keras.testing_infra import test_utils\n from keras.utils import np_utils"
    },
    {
        "commit_id": "802ef25756089cc55dd49c0b47377a76edf8958c",
        "commit_message": "- Refactor learning rate schedule code to live in `keras/optimizers/schedules` (to match the API namespace).\n- Export optimizers to `keras.optimizers.__init__` to resolve discrepancy between tf.keras and keras packages.\n- Export schedules to `keras.optimizers.schedules.__init__` to resolve discrepancy between tf.keras and keras packages.\n\nPiperOrigin-RevId: 435722952",
        "commit_url": "https://github.com/keras-team/keras/commit/802ef25756089cc55dd49c0b47377a76edf8958c",
        "buggy_code": "from keras.optimizers import learning_rate_schedule",
        "fixed_code": "from keras.optimizers.schedules import learning_rate_schedule",
        "patch": "@@ -25,7 +25,7 @@\n from tensorflow.python.framework import test_util as tf_test_utils  # pylint: disable=g-direct-tensorflow-import\n from keras.testing_infra import test_combinations\n from keras.testing_infra import test_utils\n-from keras.optimizers import learning_rate_schedule\n+from keras.optimizers.schedules import learning_rate_schedule\n from keras.optimizers.optimizer_v2 import rmsprop\n \n _DATA_TYPES = ["
    },
    {
        "commit_id": "802ef25756089cc55dd49c0b47377a76edf8958c",
        "commit_message": "- Refactor learning rate schedule code to live in `keras/optimizers/schedules` (to match the API namespace).\n- Export optimizers to `keras.optimizers.__init__` to resolve discrepancy between tf.keras and keras packages.\n- Export schedules to `keras.optimizers.schedules.__init__` to resolve discrepancy between tf.keras and keras packages.\n\nPiperOrigin-RevId: 435722952",
        "commit_url": "https://github.com/keras-team/keras/commit/802ef25756089cc55dd49c0b47377a76edf8958c",
        "buggy_code": "\"\"\"Various learning rate decay functions.\"\"\"",
        "fixed_code": "\"\"\"Various learning rate schedule functions.\"\"\"",
        "patch": "@@ -12,7 +12,7 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n # ==============================================================================\n-\"\"\"Various learning rate decay functions.\"\"\"\n+\"\"\"Various learning rate schedule functions.\"\"\"\n \n import tensorflow.compat.v2 as tf\n "
    },
    {
        "commit_id": "0523fc3e6bfc5aa86bbc214247061c8cc3ea2ccd",
        "commit_message": "Proactive fix for upcoming experimental_relax_shapes update\n\nPiperOrigin-RevId: 435517780",
        "commit_url": "https://github.com/keras-team/keras/commit/0523fc3e6bfc5aa86bbc214247061c8cc3ea2ccd",
        "buggy_code": "predict_function, experimental_relax_shapes=True)",
        "fixed_code": "predict_function, experimental_relax_shapes=False)",
        "patch": "@@ -1861,7 +1861,7 @@ def predict_function(iterator):\n \n     if not self.run_eagerly:\n       predict_function = tf.function(\n-          predict_function, experimental_relax_shapes=True)\n+          predict_function, experimental_relax_shapes=False)\n     self.predict_function = predict_function\n \n     return self.predict_function"
    },
    {
        "commit_id": "3073e00912838454359079a35f1638ccf06e855f",
        "commit_message": "Fix the issue in the other two places it occurs",
        "commit_url": "https://github.com/keras-team/keras/commit/3073e00912838454359079a35f1638ccf06e855f",
        "buggy_code": "label_mode:",
        "fixed_code": "label_mode: String describing the encoding of `labels`. Options are:",
        "patch": "@@ -203,7 +203,7 @@ def labels_to_dataset(labels, label_mode, num_classes):\n \n   Args:\n     labels: list/tuple of labels to be converted into a tf.data.Dataset.\n-    label_mode:\n+    label_mode: String describing the encoding of `labels`. Options are:\n     - 'binary' indicates that the labels (there can be only 2) are encoded as\n       `float32` scalars with values 0 or 1 (e.g. for `binary_crossentropy`).\n     - 'categorical' means that the labels are mapped into a categorical vector."
    },
    {
        "commit_id": "3073e00912838454359079a35f1638ccf06e855f",
        "commit_message": "Fix the issue in the other two places it occurs",
        "commit_url": "https://github.com/keras-team/keras/commit/3073e00912838454359079a35f1638ccf06e855f",
        "buggy_code": "label_mode:",
        "fixed_code": "label_mode: String describing the encoding of `labels`. Options are:",
        "patch": "@@ -68,7 +68,7 @@ def text_dataset_from_directory(directory,\n         text files found in the directory. Labels should be sorted according\n         to the alphanumeric order of the text file paths\n         (obtained via `os.walk(directory)` in Python).\n-    label_mode:\n+    label_mode: String describing the encoding of `labels`. Options are:\n         - 'int': means that the labels are encoded as integers\n             (e.g. for `sparse_categorical_crossentropy` loss).\n         - 'categorical' means that the labels are"
    },
    {
        "commit_id": "5c11e767a7312a80f70fa5100b7df8b4e391c4e2",
        "commit_message": "Fix first element in list being displayed as code\n\nit's kinda a hack, but eh?",
        "commit_url": "https://github.com/keras-team/keras/commit/5c11e767a7312a80f70fa5100b7df8b4e391c4e2",
        "buggy_code": "label_mode:",
        "fixed_code": "label_mode: String describing the encoding of `labels`. Options are:",
        "patch": "@@ -79,7 +79,7 @@ def image_dataset_from_directory(directory,\n         image files found in the directory. Labels should be sorted according\n         to the alphanumeric order of the image file paths\n         (obtained via `os.walk(directory)` in Python).\n-    label_mode:\n+    label_mode: String describing the encoding of `labels`. Options are:\n         - 'int': means that the labels are encoded as integers\n             (e.g. for `sparse_categorical_crossentropy` loss).\n         - 'categorical' means that the labels are"
    },
    {
        "commit_id": "cb5ef400671833ac895fbd058d6be906693c8aaa",
        "commit_message": "Merge pull request #16073 from code-review-doctor:fix-avoid-misusing-assert-true\n\nPiperOrigin-RevId: 433762193",
        "commit_url": "https://github.com/keras-team/keras/commit/cb5ef400671833ac895fbd058d6be906693c8aaa",
        "buggy_code": "self.assertTrue(opt.dynamic, 4.)",
        "fixed_code": "self.assertTrue(opt.dynamic)",
        "patch": "@@ -1024,7 +1024,7 @@ def testSerializationWithBuiltInOptimizer(self, lso_type):\n     self.assertEqual(self._eval_if_tensor(opt.inner_optimizer.momentum), 0.5)\n     self.assertEqual(self.evaluate(opt.loss_scale), 2.)\n     self.assertEqual(opt.dynamic_growth_steps, 3.)\n-    self.assertTrue(opt.dynamic, 4.)\n+    self.assertTrue(opt.dynamic)\n     if lso_type in ('v1', 'v2'):\n       self.assertEqual(type(opt), loss_scale_optimizer.LossScaleOptimizer)\n     else:"
    },
    {
        "commit_id": "56841780ca4cf25d1dec47add854834cd380ad91",
        "commit_message": "Merge pull request #16165 from gadagashwini:patch-1\n\nPiperOrigin-RevId: 433015293",
        "commit_url": "https://github.com/keras-team/keras/commit/56841780ca4cf25d1dec47add854834cd380ad91",
        "buggy_code": "tf.feature_column.categorical_column_with_hash_bucket(\"keywords\", 10K),",
        "fixed_code": "tf.feature_column.categorical_column_with_hash_bucket(\"keywords\", 10000),",
        "patch": "@@ -44,7 +44,7 @@ class DenseFeatures(dense_features.DenseFeatures):\n   ```python\n   price = tf.feature_column.numeric_column('price')\n   keywords_embedded = tf.feature_column.embedding_column(\n-      tf.feature_column.categorical_column_with_hash_bucket(\"keywords\", 10K),\n+      tf.feature_column.categorical_column_with_hash_bucket(\"keywords\", 10000),\n       dimensions=16)\n   columns = [price, keywords_embedded, ...]\n   feature_layer = tf.keras.layers.DenseFeatures(columns)"
    },
    {
        "commit_id": "7b0a05f5013f03b4897e3aac462352fa6b0e26c6",
        "commit_message": "Fix typo in documentation\n\nUpdated `voculary` with `vocabulary`",
        "commit_url": "https://github.com/keras-team/keras/commit/7b0a05f5013f03b4897e3aac462352fa6b0e26c6",
        "buggy_code": "The integer size of the voculary, including optional mask and oov indices.",
        "fixed_code": "The integer size of the vocabulary, including optional mask and oov indices.",
        "patch": "@@ -451,7 +451,7 @@ def vocabulary_size(self):\n     \"\"\"Gets the current size of the layer's vocabulary.\n \n     Returns:\n-      The integer size of the voculary, including optional mask and oov indices.\n+      The integer size of the vocabulary, including optional mask and oov indices.\n     \"\"\"\n     return self._lookup_layer.vocabulary_size()\n "
    },
    {
        "commit_id": "18935312a1a08f1f3bdcb50b402256bd7289b66a",
        "commit_message": "Fix input_shape validation in Concatenate.build.\n\nPiperOrigin-RevId: 432901838",
        "commit_url": "https://github.com/keras-team/keras/commit/18935312a1a08f1f3bdcb50b402256bd7289b66a",
        "buggy_code": "if not isinstance(input_shape[0], tuple) or len(input_shape) < 1:",
        "fixed_code": "if len(input_shape) < 1 or not isinstance(input_shape[0], tuple):",
        "patch": "@@ -92,7 +92,7 @@ def __init__(self, axis=-1, **kwargs):\n   @tf_utils.shape_type_conversion\n   def build(self, input_shape):\n     # Used purely for shape validation.\n-    if not isinstance(input_shape[0], tuple) or len(input_shape) < 1:\n+    if len(input_shape) < 1 or not isinstance(input_shape[0], tuple):\n       raise ValueError(\n           'A `Concatenate` layer should be called on a list of '\n           f'at least 1 input. Received: input_shape={input_shape}')"
    },
    {
        "commit_id": "550dea8da84ddd37f3d293437f6aee172d95e156",
        "commit_message": "Fix the MutableMapping issue when used in python 3.10.\n\nThe collections.MutableMapping is fully removed in 3.10.\n\nPiperOrigin-RevId: 432577789",
        "commit_url": "https://github.com/keras-team/keras/commit/550dea8da84ddd37f3d293437f6aee172d95e156",
        "buggy_code": "class LayoutMap(collections.MutableMapping):",
        "fixed_code": "class LayoutMap(collections.abc.MutableMapping):",
        "patch": "@@ -41,7 +41,7 @@ def get_current_layout_map():\n   return getattr(_LAYOUT_MAP, 'layout_map', None)\n \n \n-class LayoutMap(collections.MutableMapping):\n+class LayoutMap(collections.abc.MutableMapping):\n \n   def __init__(self, mesh=None):\n     \"\"\"A dict like object that maps between string name and dtensor.Layout."
    },
    {
        "commit_id": "e0a970d08ddba7f700876439c44b379e19d3cc33",
        "commit_message": "Fix the corner case for dtensor model layout map.\n\nPiperOrigin-RevId: 432548534",
        "commit_url": "https://github.com/keras-team/keras/commit/e0a970d08ddba7f700876439c44b379e19d3cc33",
        "buggy_code": "if self._layout_map and not self.built:",
        "fixed_code": "if self._layout_map is not None and not self.built:",
        "patch": "@@ -459,7 +459,7 @@ def build(self, input_shape):\n \n   @traceback_utils.filter_traceback\n   def __call__(self, *args, **kwargs):\n-    if self._layout_map and not self.built:\n+    if self._layout_map is not None and not self.built:\n       # Note that this method is only overridden for DTensor and layout\n       # injection purpose.\n       # Capture the inputs and create graph input as replacement for model"
    },
    {
        "commit_id": "fc00d58f810553a177400e441b903263db96c1e1",
        "commit_message": "Fix typo in docstring for `DenseFeatures`",
        "commit_url": "https://github.com/keras-team/keras/commit/fc00d58f810553a177400e441b903263db96c1e1",
        "buggy_code": "tf.feature_column.categorical_column_with_hash_bucket(\"keywords\", 10K),",
        "fixed_code": "tf.feature_column.categorical_column_with_hash_bucket(\"keywords\", 10000),",
        "patch": "@@ -44,7 +44,7 @@ class DenseFeatures(dense_features.DenseFeatures):\n   ```python\n   price = tf.feature_column.numeric_column('price')\n   keywords_embedded = tf.feature_column.embedding_column(\n-      tf.feature_column.categorical_column_with_hash_bucket(\"keywords\", 10K),\n+      tf.feature_column.categorical_column_with_hash_bucket(\"keywords\", 10000),\n       dimensions=16)\n   columns = [price, keywords_embedded, ...]\n   feature_layer = tf.keras.layers.DenseFeatures(columns)"
    },
    {
        "commit_id": "39ffc7ad09f8877ad90773a7390a1ede6c4a6cbb",
        "commit_message": "Export Adamax and fix some exporting issues.\n\nPreviously the __init__py in optimizers/ folder does not include rmsprop, adamax and adamw, so they are not caught when updating golden. This CL fixes this issue.\n\nPiperOrigin-RevId: 431736718",
        "commit_url": "https://github.com/keras-team/keras/commit/39ffc7ad09f8877ad90773a7390a1ede6c4a6cbb",
        "buggy_code": "\"\"\"This is under development, and subject to interface/implementation changes.\"\"\"",
        "fixed_code": "\"\"\"Experimental optimizer package.\"\"\"",
        "patch": "@@ -12,4 +12,4 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n # ==============================================================================\n-\"\"\"This is under development, and subject to interface/implementation changes.\"\"\"\n+\"\"\"Experimental optimizer package.\"\"\""
    },
    {
        "commit_id": "ca76d905659d31e002e04714a74f5bb4b156da72",
        "commit_message": "Issue #16090: Split input_shapes horizontally and not vertically in keras.utils.vis_utils.plot_model when show_shapes=True",
        "commit_url": "https://github.com/keras-team/keras/commit/ca76d905659d31e002e04714a74f5bb4b156da72",
        "buggy_code": "label = '{%s}|{input:|output:}|{{%s}}|{{%s}}' % (label, inputlabels,",
        "fixed_code": "label = '{%s}|{input:|output:}|{{%s}|{%s}}' % (label, inputlabels,",
        "patch": "@@ -290,7 +290,7 @@ def format_shape(shape):\n             [format_shape(ishape) for ishape in layer.input_shapes])\n       else:\n         inputlabels = '?'\n-      label = '{%s}|{input:|output:}|{{%s}}|{{%s}}' % (label, inputlabels,\n+      label = '{%s}|{input:|output:}|{{%s}|{%s}}' % (label, inputlabels,\n                                                        outputlabels)\n     if not expand_nested or not isinstance(\n         layer, functional.Functional):"
    },
    {
        "commit_id": "4a41ec57b763568a4f1545b878819eb67ac27963",
        "commit_message": "Merge pull request #16082 from futtetennista:patch-1\n\nPiperOrigin-RevId: 429602933",
        "commit_url": "https://github.com/keras-team/keras/commit/4a41ec57b763568a4f1545b878819eb67ac27963",
        "buggy_code": "is set, the voculary wil be truncated to `max_tokens` size. For example,",
        "fixed_code": "is set, the vocabulary wil be truncated to `max_tokens` size. For example,",
        "patch": "@@ -389,7 +389,7 @@ def adapt(self, data, batch_size=None, steps=None):\n     During `adapt()`, the layer will build a vocabulary of all string tokens\n     seen in the dataset, sorted by occurance count, with ties broken by sort\n     order of the tokens (high to low). At the end of `adapt()`, if `max_tokens`\n-    is set, the voculary wil be truncated to `max_tokens` size. For example,\n+    is set, the vocabulary wil be truncated to `max_tokens` size. For example,\n     adapting a layer with `max_tokens=1000` will compute the 1000 most frequent\n     tokens occurring in the input dataset. If `output_mode='tf-idf'`, `adapt()`\n     will also learn the document frequencies of each token in the input dataset."
    },
    {
        "commit_id": "e71cbf258c718739d5c57ab8b0b09c882eac6239",
        "commit_message": "Fix typo in documentation",
        "commit_url": "https://github.com/keras-team/keras/commit/e71cbf258c718739d5c57ab8b0b09c882eac6239",
        "buggy_code": "is set, the voculary wil be truncated to `max_tokens` size. For example,",
        "fixed_code": "is set, the vocabulary wil be truncated to `max_tokens` size. For example,",
        "patch": "@@ -389,7 +389,7 @@ def adapt(self, data, batch_size=None, steps=None):\n     During `adapt()`, the layer will build a vocabulary of all string tokens\n     seen in the dataset, sorted by occurance count, with ties broken by sort\n     order of the tokens (high to low). At the end of `adapt()`, if `max_tokens`\n-    is set, the voculary wil be truncated to `max_tokens` size. For example,\n+    is set, the vocabulary wil be truncated to `max_tokens` size. For example,\n     adapting a layer with `max_tokens=1000` will compute the 1000 most frequent\n     tokens occurring in the input dataset. If `output_mode='tf-idf'`, `adapt()`\n     will also learn the document frequencies of each token in the input dataset."
    },
    {
        "commit_id": "b879229cf3ac36d961989c2e4e3761661c5467c0",
        "commit_message": " Fix issue avoid-misusing-assert-true found at https://codereview.doctor",
        "commit_url": "https://github.com/keras-team/keras/commit/b879229cf3ac36d961989c2e4e3761661c5467c0",
        "buggy_code": "self.assertTrue(opt.dynamic, 4.)",
        "fixed_code": "self.assertEqual(opt.dynamic, 4.)",
        "patch": "@@ -1167,7 +1167,7 @@ def testSerializationWithBuiltInOptimizer(self, lso_type):\n     self.assertEqual(self._eval_if_tensor(opt.inner_optimizer.momentum), 0.5)\n     self.assertEqual(self.evaluate(opt.loss_scale), 2.)\n     self.assertEqual(opt.dynamic_growth_steps, 3.)\n-    self.assertTrue(opt.dynamic, 4.)\n+    self.assertEqual(opt.dynamic, 4.)\n     if lso_type in ('v1', 'v2'):\n       # Deserializing a LossScaleOptimizerV1 results in a V2 LossScaleOptimizer.\n       self.assertEqual(type(opt), loss_scale_optimizer.LossScaleOptimizer)"
    },
    {
        "commit_id": "ef293fdb46994b0bca2571eb3d8d66aad2cfc4ad",
        "commit_message": "Fixed Typo: categorial -> categorical\n\nRelated to issue #16058",
        "commit_url": "https://github.com/keras-team/keras/commit/ef293fdb46994b0bca2571eb3d8d66aad2cfc4ad",
        "buggy_code": "- if `label_mode` is `categorial`, the labels are a `float32` tensor",
        "fixed_code": "- if `label_mode` is `categorical`, the labels are a `float32` tensor",
        "patch": "@@ -111,7 +111,7 @@ def text_dataset_from_directory(directory,\n       `(batch_size,)`.\n     - if `label_mode` is `binary`, the labels are a `float32` tensor of\n       1s and 0s of shape `(batch_size, 1)`.\n-    - if `label_mode` is `categorial`, the labels are a `float32` tensor\n+    - if `label_mode` is `categorical`, the labels are a `float32` tensor\n       of shape `(batch_size, num_classes)`, representing a one-hot\n       encoding of the class index.\n   \"\"\""
    },
    {
        "commit_id": "86209dc46a58d6fe3ec25ca69947a26d227c3e38",
        "commit_message": "Fix typo: categorial -> categorical\n\nPiperOrigin-RevId: 428542266",
        "commit_url": "https://github.com/keras-team/keras/commit/86209dc46a58d6fe3ec25ca69947a26d227c3e38",
        "buggy_code": "- if `label_mode` is `categorial`, the labels are a `float32` tensor",
        "fixed_code": "- if `label_mode` is `categorical`, the labels are a `float32` tensor",
        "patch": "@@ -138,7 +138,7 @@ def image_dataset_from_directory(directory,\n       `(batch_size,)`.\n     - if `label_mode` is `binary`, the labels are a `float32` tensor of\n       1s and 0s of shape `(batch_size, 1)`.\n-    - if `label_mode` is `categorial`, the labels are a `float32` tensor\n+    - if `label_mode` is `categorical`, the labels are a `float32` tensor\n       of shape `(batch_size, num_classes)`, representing a one-hot\n       encoding of the class index.\n "
    },
    {
        "commit_id": "163ae9681e4ec19de40be444ebf4cdcbca759307",
        "commit_message": "Fix typo in test",
        "commit_url": "https://github.com/keras-team/keras/commit/163ae9681e4ec19de40be444ebf4cdcbca759307",
        "buggy_code": "keras.layers.Conv2D(3, 5, padding='same', activation='softmax'),",
        "fixed_code": "keras.layers.Conv1D(3, 5, padding='same', activation='softmax'),",
        "patch": "@@ -344,7 +344,7 @@ def densify(x, y):\n         keras.layers.Conv1D(4, 5, padding='same', activation='relu'),\n         keras.layers.Conv1D(8, 5, padding='same'),\n         keras.layers.BatchNormalization(),\n-        keras.layers.Conv2D(3, 5, padding='same', activation='softmax'),\n+        keras.layers.Conv1D(3, 5, padding='same', activation='softmax'),\n     ]\n     model = test_utils.get_model_from_layers(\n         layers, input_shape=(None,))"
    },
    {
        "commit_id": "7482fa2a3fe18af56cfaabbfd3efc57ca7cb58fc",
        "commit_message": "fix docstring typo.\n\nPiperOrigin-RevId: 427495375",
        "commit_url": "https://github.com/keras-team/keras/commit/7482fa2a3fe18af56cfaabbfd3efc57ca7cb58fc",
        "buggy_code": "amount in the range `[-20%, +30%]. `factor=0.2` results in an output with",
        "fixed_code": "amount in the range `[-20%, +30%]`. `factor=0.2` results in an output with",
        "patch": "@@ -1240,7 +1240,7 @@ class RandomHeight(base_layer.BaseRandomLayer):\n       lower bound. For instance, `factor=(0.2, 0.3)` results in an output with\n       height changed by a random amount in the range `[20%, 30%]`.\n       `factor=(-0.2, 0.3)` results in an output with height changed by a random\n-      amount in the range `[-20%, +30%]. `factor=0.2` results in an output with\n+      amount in the range `[-20%, +30%]`. `factor=0.2` results in an output with\n       height changed by a random amount in the range `[-20%, +20%]`.\n     interpolation: String, the interpolation method. Defaults to `\"bilinear\"`.\n       Supports `\"bilinear\"`, `\"nearest\"`, `\"bicubic\"`, `\"area\"`,"
    },
    {
        "commit_id": "2cdfbd18a750cabaff1499fad7473dd91f3c7fa7",
        "commit_message": "Previously, many unit test files started with `enable_v2_behavior`, which would have caused them to run in V2 mode when executing with a V1 test flag. The correct behavior would in fact be to skip such tests when executing with a V1 test flag.\n\nThis fix significantly reduces the total V1 + V2 test load by eliminating redundancy.\n\nPiperOrigin-RevId: 424734850",
        "commit_url": "https://github.com/keras-team/keras/commit/2cdfbd18a750cabaff1499fad7473dd91f3c7fa7",
        "buggy_code": "tf.compat.v1.enable_v2_behavior()",
        "fixed_code": "@testing_utils.run_v2_only",
        "patch": "@@ -30,6 +30,7 @@\n   h5py = None\n \n \n+@testing_utils.run_v2_only\n class TestDeferredSequential(keras_parameterized.TestCase):\n \n   @keras_parameterized.run_all_keras_modes(always_skip_v1=True)\n@@ -213,5 +214,4 @@ def get_model():\n \n \n if __name__ == '__main__':\n-  tf.compat.v1.enable_v2_behavior()\n   tf.test.main()"
    },
    {
        "commit_id": "2cdfbd18a750cabaff1499fad7473dd91f3c7fa7",
        "commit_message": "Previously, many unit test files started with `enable_v2_behavior`, which would have caused them to run in V2 mode when executing with a V1 test flag. The correct behavior would in fact be to skip such tests when executing with a V1 test flag.\n\nThis fix significantly reduces the total V1 + V2 test load by eliminating redundancy.\n\nPiperOrigin-RevId: 424734850",
        "commit_url": "https://github.com/keras-team/keras/commit/2cdfbd18a750cabaff1499fad7473dd91f3c7fa7",
        "buggy_code": "tf.compat.v1.enable_v2_behavior()",
        "fixed_code": "@testing_utils.run_v2_only",
        "patch": "@@ -26,6 +26,7 @@ def squared_l2_norm(x):\n   return tf.reduce_sum(x ** 2)\n \n \n+@testing_utils.run_v2_only\n class UnitNormalizationTest(keras_parameterized.TestCase):\n \n   @keras_parameterized.run_all_keras_modes\n@@ -74,5 +75,4 @@ def testInvalidAxis(self):\n \n \n if __name__ == '__main__':\n-  tf.compat.v1.enable_v2_behavior()\n   tf.test.main()"
    },
    {
        "commit_id": "89879e2c76e86c685e44c47a6cdb82f7e645c142",
        "commit_message": "Fix keras docstrings\n\nPiperOrigin-RevId: 424275818",
        "commit_url": "https://github.com/keras-team/keras/commit/89879e2c76e86c685e44c47a6cdb82f7e645c142",
        "buggy_code": "[0. , 0.2, 0. , 0.4]])>",
        "fixed_code": "[0. , 0.2, 0. , 0.4]], dtype=float32)>",
        "patch": "@@ -80,7 +80,7 @@ class CategoryEncoding(base_layer.Layer):\n     array([[0.1, 0.2, 0. , 0. ],\n            [0.2, 0. , 0. , 0. ],\n            [0. , 0.2, 0.3, 0. ],\n-           [0. , 0.2, 0. , 0.4]])>\n+           [0. , 0.2, 0. , 0.4]], dtype=float32)>\n \n   Args:\n     num_tokens: The total number of tokens the layer should support. All inputs"
    },
    {
        "commit_id": "89879e2c76e86c685e44c47a6cdb82f7e645c142",
        "commit_message": "Fix keras docstrings\n\nPiperOrigin-RevId: 424275818",
        "commit_url": "https://github.com/keras-team/keras/commit/89879e2c76e86c685e44c47a6cdb82f7e645c142",
        "buggy_code": "array([0., 0., 0.], dtype=float32)>",
        "fixed_code": "array([-1., -1., -1.], dtype=float32)>",
        "patch": "@@ -85,7 +85,7 @@ class Normalization(base_preprocessing_layer.PreprocessingLayer):\n   >>> layer.adapt(adapt_data)\n   >>> layer(input_data)\n   <tf.Tensor: shape=(1, 3), dtype=float32, numpy=\n-  array([0., 0., 0.], dtype=float32)>\n+  array([-1., -1., -1.], dtype=float32)>\n \n   Pass the mean and variance directly.\n "
    },
    {
        "commit_id": "89879e2c76e86c685e44c47a6cdb82f7e645c142",
        "commit_message": "Fix keras docstrings\n\nPiperOrigin-RevId: 424275818",
        "commit_url": "https://github.com/keras-team/keras/commit/89879e2c76e86c685e44c47a6cdb82f7e645c142",
        "buggy_code": "...     np.mean(x + np.log(np.exp(-2. * x) + 1.) - math_ops.log(2.), axis=-1),",
        "fixed_code": "...     np.mean(x + np.log(np.exp(-2. * x) + 1.) - tf.math.log(2.), axis=-1),",
        "patch": "@@ -1720,7 +1720,7 @@ def log_cosh(y_true, y_pred):\n   >>> x = y_pred - y_true\n   >>> assert np.allclose(\n   ...     loss.numpy(),\n-  ...     np.mean(x + np.log(np.exp(-2. * x) + 1.) - math_ops.log(2.), axis=-1),\n+  ...     np.mean(x + np.log(np.exp(-2. * x) + 1.) - tf.math.log(2.), axis=-1),\n   ...     atol=1e-5)\n \n   Args:"
    },
    {
        "commit_id": "326cf80085a9d7d980b968ea1ca235490e32833b",
        "commit_message": "fix: parameter score to score_mode",
        "commit_url": "https://github.com/keras-team/keras/commit/326cf80085a9d7d980b968ea1ca235490e32833b",
        "buggy_code": "attention_layer = dense_attention.Attention(score='concat')",
        "fixed_code": "attention_layer = dense_attention.Attention(score_mode='concat')",
        "patch": "@@ -341,7 +341,7 @@ def test_shape_with_key_concat(self):\n         dtype=np.float32)\n     # Value mask tensor of shape [1, 3]\n     v_mask = np.array([[True, True, False]], dtype=np.bool_)\n-    attention_layer = dense_attention.Attention(score='concat')\n+    attention_layer = dense_attention.Attention(score_mode='concat')\n     attention_layer.concat_score_weight = 1\n     actual = attention_layer([q, v, k], mask=[None, v_mask])\n "
    },
    {
        "commit_id": "f1e9c76675981ee6683f54a3ce569212d551d12d",
        "commit_message": "Fix test failures caused by a NumPy 1.21 upgrade\n\nPiperOrigin-RevId: 418955634",
        "commit_url": "https://github.com/keras-team/keras/commit/f1e9c76675981ee6683f54a3ce569212d551d12d",
        "buggy_code": "self.assertAllEqual(previous_losses, model.losses)",
        "fixed_code": "self.assertEqual(previous_losses, model.losses)",
        "patch": "@@ -253,7 +253,7 @@ def test_maintains_losses(self):\n     with previous_losses[0].graph.as_default():\n       # If we try to compare symbolic Tensors in eager mode assertAllEqual will\n       # return False even if they are the same Tensor.\n-      self.assertAllEqual(previous_losses, model.losses)\n+      self.assertEqual(previous_losses, model.losses)\n \n     if tf.executing_eagerly():\n       # Test that eager losses are maintained."
    },
    {
        "commit_id": "e9edff0311452b4b2e1266b2e264635bc488ebd0",
        "commit_message": "Merge pull request #15773 from lgeiger:patch-1\n\nPiperOrigin-RevId: 418380712",
        "commit_url": "https://github.com/keras-team/keras/commit/e9edff0311452b4b2e1266b2e264635bc488ebd0",
        "buggy_code": "return x.assign(x * momentum + value * (1 - momentum))",
        "fixed_code": "return x.assign_sub((x - value) * (1 - momentum))",
        "patch": "@@ -2147,7 +2147,7 @@ def moving_average_update(x, value, momentum):\n   if tf.__internal__.tf2.enabled():\n     momentum = tf.cast(momentum, x.dtype)\n     value = tf.cast(value, x.dtype)\n-    return x.assign(x * momentum + value * (1 - momentum))\n+    return x.assign_sub((x - value) * (1 - momentum))\n   else:\n     return tf.__internal__.train.assign_moving_average(\n         x, value, momentum, zero_debias=True)"
    },
    {
        "commit_id": "4383429e8e5e7d41198c5ce4f5f63c38f26794b7",
        "commit_message": "Minor error in BASE_DOCSTRING",
        "commit_url": "https://github.com/keras-team/keras/commit/4383429e8e5e7d41198c5ce4f5f63c38f26794b7",
        "buggy_code": "The naming of models is as follows: `RegNet{block_type}{flops}` where",
        "fixed_code": "The naming of models is as follows: `RegNet<block_type><flops>` where",
        "patch": "@@ -237,7 +237,7 @@\n   RegNet models expect their inputs to be float or uint8 tensors of pixels with \n   values in the [0-255] range.\n \n-  The naming of models is as follows: `RegNet{block_type}{flops}` where \n+  The naming of models is as follows: `RegNet<block_type><flops>` where \n   `block_type` is one of `(Y, Z)` and `flops` signifies hundred million \n   floating point operations. For example RegNetY64 corresponds to RegNet with \n   Y block and 6.4 giga flops (64 hundred million flops). "
    },
    {
        "commit_id": "6a02df3aa882ae3468ead98829ef177025b3b8ab",
        "commit_message": "Fix bug in get_or_create_layer migration utility that produced regularization losses of the wrong rank, causing failures on model fit.\n\nPiperOrigin-RevId: 414066868",
        "commit_url": "https://github.com/keras-team/keras/commit/6a02df3aa882ae3468ead98829ef177025b3b8ab",
        "buggy_code": "self._regularizers[name] = lambda: layer.losses",
        "fixed_code": "self._regularizers[name] = lambda: tf.math.reduce_sum(layer.losses)",
        "patch": "@@ -526,7 +526,7 @@ def get_or_create_layer(self, name, create_layer_method):\n       layer = create_layer_method()\n       self._layers[name] = layer\n       if isinstance(layer, base_layer.Layer):\n-        self._regularizers[name] = lambda: layer.losses\n+        self._regularizers[name] = lambda: tf.math.reduce_sum(layer.losses)\n     return self._layers[name]\n \n   def add_regularizer(self, var, regularizer):"
    },
    {
        "commit_id": "1559a7617a23554ebd1408913d37fdeb5e6e888b",
        "commit_message": "Merge pull request #15683 from kykim0:patch-1\n\nPiperOrigin-RevId: 413701903",
        "commit_url": "https://github.com/keras-team/keras/commit/1559a7617a23554ebd1408913d37fdeb5e6e888b",
        "buggy_code": "are used for create a sample sequence.",
        "fixed_code": "are used for creating a sample sequence.",
        "patch": "@@ -59,7 +59,7 @@ def timeseries_dataset_from_array(\n     sampling_rate: Period between successive individual timesteps\n       within sequences. For rate `r`, timesteps\n       `data[i], data[i + r], ... data[i + sequence_length]`\n-      are used for create a sample sequence.\n+      are used for creating a sample sequence.\n     batch_size: Number of timeseries samples in each batch\n       (except maybe the last one). If `None`, the data will not be batched\n       (the dataset will yield individual samples)."
    },
    {
        "commit_id": "69a439d3794fb5cdd0bd1ceb2bee9b45c5d629ba",
        "commit_message": "fix: add space before = sign",
        "commit_url": "https://github.com/keras-team/keras/commit/69a439d3794fb5cdd0bd1ceb2bee9b45c5d629ba",
        "buggy_code": "self.best= initial_value_threshold",
        "fixed_code": "self.best = initial_value_threshold",
        "patch": "@@ -1282,7 +1282,7 @@ def __init__(self,\n     self.epochs_since_last_save = 0\n     self._batches_seen_since_last_saving = 0\n     self._last_batch_seen = 0\n-    self.best= initial_value_threshold\n+    self.best = initial_value_threshold\n \n     if save_weights_only:\n       if options is None or isinstance("
    },
    {
        "commit_id": "e61436934cd39bfd5a07f95943ae99c957c13fad",
        "commit_message": "fix: rename in docstring",
        "commit_url": "https://github.com/keras-team/keras/commit/e61436934cd39bfd5a07f95943ae99c957c13fad",
        "buggy_code": "initial_best: Initial \"best\" value of the metric to be monitored.",
        "fixed_code": "initial_value_threshold: Initial \"best\" value of the metric to be monitored.",
        "patch": "@@ -1253,7 +1253,7 @@ class ModelCheckpoint(Callback):\n       options: Optional `tf.train.CheckpointOptions` object if\n         `save_weights_only` is true or optional `tf.saved_model.SaveOptions`\n         object if `save_weights_only` is false.\n-      initial_best: Initial \"best\" value of the metric to be monitored.\n+      initial_value_threshold: Initial \"best\" value of the metric to be monitored.\n         Only overwrites the model weights already saved if the\n         performance of current model is better than this value.\n       **kwargs: Additional arguments for backwards compatibility. Possible key"
    },
    {
        "commit_id": "8d06a12d90cbcfcde64a7776752fd050cc19af39",
        "commit_message": "LearningRateScheduler: Fix the error message \"LearningRateScheduler setting learning rate to {lr}.\" where `lr` is not populated.\n\nPiperOrigin-RevId: 411908609",
        "commit_url": "https://github.com/keras-team/keras/commit/8d06a12d90cbcfcde64a7776752fd050cc19af39",
        "buggy_code": "'rate to {lr}.')",
        "fixed_code": "f'rate to {lr}.')",
        "patch": "@@ -1984,7 +1984,7 @@ def on_epoch_begin(self, epoch, logs=None):\n     if self.verbose > 0:\n       io_utils.print_msg(\n           f'\\nEpoch {epoch + 1}: LearningRateScheduler setting learning '\n-          'rate to {lr}.')\n+          f'rate to {lr}.')\n \n   def on_epoch_end(self, epoch, logs=None):\n     logs = logs or {}"
    },
    {
        "commit_id": "b1876404713e6d157d1dd05d0d74e510b53442f4",
        "commit_message": "Fix utility for checking if under a load context\n\nPiperOrigin-RevId: 411601386",
        "commit_url": "https://github.com/keras-team/keras/commit/b1876404713e6d157d1dd05d0d74e510b53442f4",
        "buggy_code": "return _load_context.in_load_context",
        "fixed_code": "return _load_context.in_load_context()",
        "patch": "@@ -60,4 +60,4 @@ def get_load_options():\n \n def in_load_context():\n   \"\"\"Returns whether under a load context.\"\"\"\n-  return _load_context.in_load_context\n+  return _load_context.in_load_context()"
    },
    {
        "commit_id": "fdf220c4212f0743afabd7ff0bafcd3f0edc5ef9",
        "commit_message": "Fix a minor typo in the docstring",
        "commit_url": "https://github.com/keras-team/keras/commit/fdf220c4212f0743afabd7ff0bafcd3f0edc5ef9",
        "buggy_code": "are used for create a sample sequence.",
        "fixed_code": "are used for creating a sample sequence.",
        "patch": "@@ -59,7 +59,7 @@ def timeseries_dataset_from_array(\n     sampling_rate: Period between successive individual timesteps\n       within sequences. For rate `r`, timesteps\n       `data[i], data[i + r], ... data[i + sequence_length]`\n-      are used for create a sample sequence.\n+      are used for creating a sample sequence.\n     batch_size: Number of timeseries samples in each batch\n       (except maybe the last one). If `None`, the data will not be batched\n       (the dataset will yield individual samples)."
    },
    {
        "commit_id": "94373fefce87226db29f8270eca75408aa085996",
        "commit_message": "Fix various typos in error messages.\n\nPiperOrigin-RevId: 410160508",
        "commit_url": "https://github.com/keras-team/keras/commit/94373fefce87226db29f8270eca75408aa085996",
        "buggy_code": "with self.assertRaisesRegex(TypeError, 'keys in axes must be integers'):",
        "fixed_code": "with self.assertRaisesRegex(TypeError, 'Argument `axes` must be a dict'):",
        "patch": "@@ -29,7 +29,7 @@ def test_axes_initialization(self):\n     input_spec.InputSpec(shape=[1, None, 2, 3], axes={3: 5, '2': 2})\n     with self.assertRaisesRegex(ValueError, 'Axis 4 is greater than'):\n       input_spec.InputSpec(shape=[1, None, 2, 3], axes={4: 5})\n-    with self.assertRaisesRegex(TypeError, 'keys in axes must be integers'):\n+    with self.assertRaisesRegex(TypeError, 'Argument `axes` must be a dict'):\n       input_spec.InputSpec(shape=[1, None, 2, 3], axes={'string': 5})\n \n "
    },
    {
        "commit_id": "47526f18249658c460e3a9d22efa00dffd940c9d",
        "commit_message": "Fix typo",
        "commit_url": "https://github.com/keras-team/keras/commit/47526f18249658c460e3a9d22efa00dffd940c9d",
        "buggy_code": "pointwise losses your must include a dummy axis so that `[batch, W, H, 1]`",
        "fixed_code": "pointwise losses you must include a dummy axis so that `[batch, W, H, 1]`",
        "patch": "@@ -43,7 +43,7 @@ class ReductionV2:\n      `Reduction.NONE` just means that no **additional** reduction is applied by\n      the class wrapper. For categorical losses with an example input shape of\n      `[batch, W, H, n_classes]` the `n_classes` dimension is reduced. For\n-     pointwise losses your must include a dummy axis so that `[batch, W, H, 1]`\n+     pointwise losses you must include a dummy axis so that `[batch, W, H, 1]`\n      is reduced to `[batch, W, H]`. Without the dummy axis `[batch, W, H]`\n      will be incorrectly reduced to `[batch, W]`.\n "
    },
    {
        "commit_id": "6be9dcfa320cb4856d5ce0e4e9353bebab58c839",
        "commit_message": "Remove stray comma causing a tuple to be created instead of a string.\n\nThis block looks like it's meant to be an implicit string-concatenation block (i.e. `('foo ' 'bar.')` => `foo bar.`, but the extra comma means it is a tuple.\n\nThe failure is causing `plot_model` to throw an error when `pydot` is not installed.\n\nPiperOrigin-RevId: 408777016",
        "commit_url": "https://github.com/keras-team/keras/commit/6be9dcfa320cb4856d5ce0e4e9353bebab58c839",
        "buggy_code": "'(see instructions at https://graphviz.gitlab.io/download/) ',",
        "fixed_code": "'(see instructions at https://graphviz.gitlab.io/download/) '",
        "patch": "@@ -152,7 +152,7 @@ def model_to_dot(model,\n     message = (\n         'You must install pydot (`pip install pydot`) '\n         'and install graphviz '\n-        '(see instructions at https://graphviz.gitlab.io/download/) ',\n+        '(see instructions at https://graphviz.gitlab.io/download/) '\n         'for plot_model/model_to_dot to work.')\n     if 'IPython.core.magics.namespace' in sys.modules:\n       # We don't raise an exception here in order to avoid crashing notebook"
    },
    {
        "commit_id": "863e385bcb1977ce497cff16478f3a8f9fc3fd88",
        "commit_message": "Merge pull request #15543 from kianmeng:fix-typos\n\nPiperOrigin-RevId: 407106182",
        "commit_url": "https://github.com/keras-team/keras/commit/863e385bcb1977ce497cff16478f3a8f9fc3fd88",
        "buggy_code": "\"\"\"Build simple custome layer.\"\"\"",
        "fixed_code": "\"\"\"Build simple custom layer.\"\"\"",
        "patch": "@@ -128,7 +128,7 @@ def benchmark_antirectifier_bs_512_gpu_2(self):\n \n \n class Antirectifier(tf.keras.layers.Layer):\n-  \"\"\"Build simple custome layer.\"\"\"\n+  \"\"\"Build simple custom layer.\"\"\"\n \n   def __init__(self, initializer=\"he_normal\", **kwargs):\n     super(Antirectifier, self).__init__(**kwargs)"
    },
    {
        "commit_id": "863e385bcb1977ce497cff16478f3a8f9fc3fd88",
        "commit_message": "Merge pull request #15543 from kianmeng:fix-typos\n\nPiperOrigin-RevId: 407106182",
        "commit_url": "https://github.com/keras-team/keras/commit/863e385bcb1977ce497cff16478f3a8f9fc3fd88",
        "buggy_code": "multiple input/output, or dictionary of objects when the intput/output are",
        "fixed_code": "multiple input/output, or dictionary of objects when the input/output are",
        "patch": "@@ -74,7 +74,7 @@ def can_handle(x, y=None):\n     \"\"\"Whether the current DataAdapter could handle the input x and y.\n \n     Structure wise, x and y can be single object, or list of objects if there\n-    multiple input/output, or dictionary of objects when the intput/output are\n+    multiple input/output, or dictionary of objects when the input/output are\n     named.\n \n     Args:"
    },
    {
        "commit_id": "863e385bcb1977ce497cff16478f3a8f9fc3fd88",
        "commit_message": "Merge pull request #15543 from kianmeng:fix-typos\n\nPiperOrigin-RevId: 407106182",
        "commit_url": "https://github.com/keras-team/keras/commit/863e385bcb1977ce497cff16478f3a8f9fc3fd88",
        "buggy_code": "tf.constant([\"ironman\", \"ironman\", \"unkonwn\"]))[\"output_0\"]",
        "fixed_code": "tf.constant([\"ironman\", \"ironman\", \"unknown\"]))[\"output_0\"]",
        "patch": "@@ -258,7 +258,7 @@ def serve_fn(raw_features):\n       self.assertIn(prediction0, (\"yes\", \"no\"))\n \n       prediction1 = loaded_serving_fn(\n-          tf.constant([\"ironman\", \"ironman\", \"unkonwn\"]))[\"output_0\"]\n+          tf.constant([\"ironman\", \"ironman\", \"unknown\"]))[\"output_0\"]\n       self.assertIn(prediction1, (\"yes\", \"no\"))\n \n "
    },
    {
        "commit_id": "863e385bcb1977ce497cff16478f3a8f9fc3fd88",
        "commit_message": "Merge pull request #15543 from kianmeng:fix-typos\n\nPiperOrigin-RevId: 407106182",
        "commit_url": "https://github.com/keras-team/keras/commit/863e385bcb1977ce497cff16478f3a8f9fc3fd88",
        "buggy_code": "tf.constant([\"ironman\", \"ironman\", \"unkonwn\"]))[\"output_0\"]",
        "fixed_code": "tf.constant([\"ironman\", \"ironman\", \"unknown\"]))[\"output_0\"]",
        "patch": "@@ -232,7 +232,7 @@ def serve_fn(raw_features):\n     self.assertIn(prediction1, (\"yes\", \"no\"))\n \n     prediction2 = loaded_serving_fn(\n-        tf.constant([\"ironman\", \"ironman\", \"unkonwn\"]))[\"output_0\"]\n+        tf.constant([\"ironman\", \"ironman\", \"unknown\"]))[\"output_0\"]\n     self.assertIn(prediction2, (\"yes\", \"no\"))\n \n "
    },
    {
        "commit_id": "863e385bcb1977ce497cff16478f3a8f9fc3fd88",
        "commit_message": "Merge pull request #15543 from kianmeng:fix-typos\n\nPiperOrigin-RevId: 407106182",
        "commit_url": "https://github.com/keras-team/keras/commit/863e385bcb1977ce497cff16478f3a8f9fc3fd88",
        "buggy_code": "calls, and consquently this behavior is disallowed for safety. Lambda",
        "fixed_code": "calls, and consequently this behavior is disallowed for safety. Lambda",
        "patch": "@@ -215,7 +215,7 @@ def _check_variables(self, created_variables, accessed_variables):\n           but are not tracked by said layer:\n           {variable_str}\n           The layer cannot safely ensure proper Variable reuse across multiple\n-          calls, and consquently this behavior is disallowed for safety. Lambda\n+          calls, and consequently this behavior is disallowed for safety. Lambda\n           layers are not well suited to stateful computation; instead, writing a\n           subclassed Layer is the recommend way to define layers with\n           Variables.\"\"\").format("
    },
    {
        "commit_id": "863e385bcb1977ce497cff16478f3a8f9fc3fd88",
        "commit_message": "Merge pull request #15543 from kianmeng:fix-typos\n\nPiperOrigin-RevId: 407106182",
        "commit_url": "https://github.com/keras-team/keras/commit/863e385bcb1977ce497cff16478f3a8f9fc3fd88",
        "buggy_code": "'across multiple calls, and consquently this behavior is disallowed '",
        "fixed_code": "'across multiple calls, and consequently this behavior is disallowed '",
        "patch": "@@ -279,7 +279,7 @@ def _check_variables(self, created_variables, accessed_variables):\n           'The following Variables were created within a Lambda layer '\n           f'({self.name}) but are not tracked by said layer: {variable_str}\\n'\n           'The layer cannot safely ensure proper Variable reuse '\n-          'across multiple calls, and consquently this behavior is disallowed '\n+          'across multiple calls, and consequently this behavior is disallowed '\n           'for safety reasons. Lambda layers are not well suited for stateful '\n           'computation; instead, writing a subclassed Layer is the recommend '\n           'way to define layers with Variables.')"
    },
    {
        "commit_id": "863e385bcb1977ce497cff16478f3a8f9fc3fd88",
        "commit_message": "Merge pull request #15543 from kianmeng:fix-typos\n\nPiperOrigin-RevId: 407106182",
        "commit_url": "https://github.com/keras-team/keras/commit/863e385bcb1977ce497cff16478f3a8f9fc3fd88",
        "buggy_code": "a dict, or a nested strcture of input tensors.",
        "fixed_code": "a dict, or a nested structure of input tensors.",
        "patch": "@@ -123,7 +123,7 @@ class FunctionalPreprocessingStage(functional.Functional,\n \n   Args:\n     inputs: An input tensor (must be created via `tf.keras.Input()`), or a list,\n-      a dict, or a nested strcture of input tensors.\n+      a dict, or a nested structure of input tensors.\n     outputs: An output tensor, or a list, a dict or a nested structure of output\n       tensors.\n     name: String, optional. Name of the preprocessing stage."
    },
    {
        "commit_id": "863e385bcb1977ce497cff16478f3a8f9fc3fd88",
        "commit_message": "Merge pull request #15543 from kianmeng:fix-typos\n\nPiperOrigin-RevId: 407106182",
        "commit_url": "https://github.com/keras-team/keras/commit/863e385bcb1977ce497cff16478f3a8f9fc3fd88",
        "buggy_code": "has 2 batches with [2, 1] values respectivly the resulting loss is",
        "fixed_code": "has 2 batches with [2, 1] values respectively the resulting loss is",
        "patch": "@@ -1695,7 +1695,7 @@ def _ragged_tensor_categorical_crossentropy(y_true,\n   When used by CategoricalCrossentropy() with the default reduction\n   (SUM_OVER_BATCH_SIZE), the reduction averages the loss over the\n   number of elements independent of the batch. E.g. if the RaggedTensor\n-  has 2 batches with [2, 1] values respectivly the resulting loss is\n+  has 2 batches with [2, 1] values respectively the resulting loss is\n   the sum of the individual loss values divided by 3.\n   \"\"\"\n   fn = functools.partial("
    },
    {
        "commit_id": "863e385bcb1977ce497cff16478f3a8f9fc3fd88",
        "commit_message": "Merge pull request #15543 from kianmeng:fix-typos\n\nPiperOrigin-RevId: 407106182",
        "commit_url": "https://github.com/keras-team/keras/commit/863e385bcb1977ce497cff16478f3a8f9fc3fd88",
        "buggy_code": "'an infinity nubmer or NaN are not valid value')",
        "fixed_code": "'an infinity number or NaN are not valid value')",
        "patch": "@@ -35,7 +35,7 @@ def _check_penalty_number(x):\n   if math.isinf(x) or math.isnan(x):\n     raise ValueError(\n         f'Value: {x} is not a valid regularization penalty number, '\n-        'an infinity nubmer or NaN are not valid value')\n+        'an infinity number or NaN are not valid value')\n \n \n def _none_to_default(inputs, default):"
    },
    {
        "commit_id": "863e385bcb1977ce497cff16478f3a8f9fc3fd88",
        "commit_message": "Merge pull request #15543 from kianmeng:fix-typos\n\nPiperOrigin-RevId: 407106182",
        "commit_url": "https://github.com/keras-team/keras/commit/863e385bcb1977ce497cff16478f3a8f9fc3fd88",
        "buggy_code": "presist a property to the layer indicating it was constructed with a vocab.",
        "fixed_code": "persist a property to the layer indicating it was constructed with a vocab.",
        "patch": "@@ -170,7 +170,7 @@ class VocabularySavedModelSaver(LayerSavedModelSaver):\n   vocab as part of the config until saving, when we need to clear it to avoid\n   initializing a StaticHashTable twice (once when restoring the config and once\n   when restoring restoring module resources). After clearing the vocab, we\n-  presist a property to the layer indicating it was constructed with a vocab.\n+  persist a property to the layer indicating it was constructed with a vocab.\n   \"\"\"\n \n   @property"
    },
    {
        "commit_id": "863e385bcb1977ce497cff16478f3a8f9fc3fd88",
        "commit_message": "Merge pull request #15543 from kianmeng:fix-typos\n\nPiperOrigin-RevId: 407106182",
        "commit_url": "https://github.com/keras-team/keras/commit/863e385bcb1977ce497cff16478f3a8f9fc3fd88",
        "buggy_code": "The `enqueuer.get()` should be an infinite stream of datas.",
        "fixed_code": "The `enqueuer.get()` should be an infinite stream of data.",
        "patch": "@@ -584,7 +584,7 @@ class SequenceEnqueuer:\n       enqueuer.stop()\n   ```\n \n-  The `enqueuer.get()` should be an infinite stream of datas.\n+  The `enqueuer.get()` should be an infinite stream of data.\n   \"\"\"\n \n   def __init__(self, sequence,"
    },
    {
        "commit_id": "863e385bcb1977ce497cff16478f3a8f9fc3fd88",
        "commit_message": "Merge pull request #15543 from kianmeng:fix-typos\n\nPiperOrigin-RevId: 407106182",
        "commit_url": "https://github.com/keras-team/keras/commit/863e385bcb1977ce497cff16478f3a8f9fc3fd88",
        "buggy_code": "tf.constant([\"ironman\", \"ironman\", \"unkonwn\"]))[\"output_0\"]",
        "fixed_code": "tf.constant([\"ironman\", \"ironman\", \"unknown\"]))[\"output_0\"]",
        "patch": "@@ -176,5 +176,5 @@ def test_save_load_serving_model(self, model, feature_mapper,\n     self.assertIn(prediction0.numpy().decode(\"UTF-8\"), (\"yes\", \"no\"))\n \n     prediction1 = loaded_serving_fn(\n-        tf.constant([\"ironman\", \"ironman\", \"unkonwn\"]))[\"output_0\"]\n+        tf.constant([\"ironman\", \"ironman\", \"unknown\"]))[\"output_0\"]\n     self.assertIn(prediction1.numpy().decode(\"UTF-8\"), (\"yes\", \"no\"))"
    },
    {
        "commit_id": "863e385bcb1977ce497cff16478f3a8f9fc3fd88",
        "commit_message": "Merge pull request #15543 from kianmeng:fix-typos\n\nPiperOrigin-RevId: 407106182",
        "commit_url": "https://github.com/keras-team/keras/commit/863e385bcb1977ce497cff16478f3a8f9fc3fd88",
        "buggy_code": "evaluted.",
        "fixed_code": "evaluated.",
        "patch": "@@ -466,7 +466,7 @@ def is_evenly_distributed_thresholds(thresholds):\n \n   We could leverage evenly distributed thresholds to use less memory when\n   calculate metrcis like AUC where each individual threshold need to be\n-  evaluted.\n+  evaluated.\n \n   Args:\n     thresholds: A python list or tuple, or 1D numpy array whose value is ranged"
    },
    {
        "commit_id": "d67a43aa8cf2a6618bbd103869c477e449e7428d",
        "commit_message": "Fix typos",
        "commit_url": "https://github.com/keras-team/keras/commit/d67a43aa8cf2a6618bbd103869c477e449e7428d",
        "buggy_code": "\"\"\"Build simple custome layer.\"\"\"",
        "fixed_code": "\"\"\"Build simple custom layer.\"\"\"",
        "patch": "@@ -128,7 +128,7 @@ def benchmark_antirectifier_bs_512_gpu_2(self):\n \n \n class Antirectifier(tf.keras.layers.Layer):\n-  \"\"\"Build simple custome layer.\"\"\"\n+  \"\"\"Build simple custom layer.\"\"\"\n \n   def __init__(self, initializer=\"he_normal\", **kwargs):\n     super(Antirectifier, self).__init__(**kwargs)"
    },
    {
        "commit_id": "d67a43aa8cf2a6618bbd103869c477e449e7428d",
        "commit_message": "Fix typos",
        "commit_url": "https://github.com/keras-team/keras/commit/d67a43aa8cf2a6618bbd103869c477e449e7428d",
        "buggy_code": "multiple input/output, or dictionary of objects when the intput/output are",
        "fixed_code": "multiple input/output, or dictionary of objects when the input/output are",
        "patch": "@@ -74,7 +74,7 @@ def can_handle(x, y=None):\n     \"\"\"Whether the current DataAdapter could handle the input x and y.\n \n     Structure wise, x and y can be single object, or list of objects if there\n-    multiple input/output, or dictionary of objects when the intput/output are\n+    multiple input/output, or dictionary of objects when the input/output are\n     named.\n \n     Args:"
    },
    {
        "commit_id": "d67a43aa8cf2a6618bbd103869c477e449e7428d",
        "commit_message": "Fix typos",
        "commit_url": "https://github.com/keras-team/keras/commit/d67a43aa8cf2a6618bbd103869c477e449e7428d",
        "buggy_code": "tf.constant([\"ironman\", \"ironman\", \"unkonwn\"]))[\"output_0\"]",
        "fixed_code": "tf.constant([\"ironman\", \"ironman\", \"unknown\"]))[\"output_0\"]",
        "patch": "@@ -258,7 +258,7 @@ def serve_fn(raw_features):\n       self.assertIn(prediction0, (\"yes\", \"no\"))\n \n       prediction1 = loaded_serving_fn(\n-          tf.constant([\"ironman\", \"ironman\", \"unkonwn\"]))[\"output_0\"]\n+          tf.constant([\"ironman\", \"ironman\", \"unknown\"]))[\"output_0\"]\n       self.assertIn(prediction1, (\"yes\", \"no\"))\n \n "
    },
    {
        "commit_id": "d67a43aa8cf2a6618bbd103869c477e449e7428d",
        "commit_message": "Fix typos",
        "commit_url": "https://github.com/keras-team/keras/commit/d67a43aa8cf2a6618bbd103869c477e449e7428d",
        "buggy_code": "tf.constant([\"ironman\", \"ironman\", \"unkonwn\"]))[\"output_0\"]",
        "fixed_code": "tf.constant([\"ironman\", \"ironman\", \"unknown\"]))[\"output_0\"]",
        "patch": "@@ -232,7 +232,7 @@ def serve_fn(raw_features):\n     self.assertIn(prediction1, (\"yes\", \"no\"))\n \n     prediction2 = loaded_serving_fn(\n-        tf.constant([\"ironman\", \"ironman\", \"unkonwn\"]))[\"output_0\"]\n+        tf.constant([\"ironman\", \"ironman\", \"unknown\"]))[\"output_0\"]\n     self.assertIn(prediction2, (\"yes\", \"no\"))\n \n "
    },
    {
        "commit_id": "d67a43aa8cf2a6618bbd103869c477e449e7428d",
        "commit_message": "Fix typos",
        "commit_url": "https://github.com/keras-team/keras/commit/d67a43aa8cf2a6618bbd103869c477e449e7428d",
        "buggy_code": "calls, and consquently this behavior is disallowed for safety. Lambda",
        "fixed_code": "calls, and consequently this behavior is disallowed for safety. Lambda",
        "patch": "@@ -215,7 +215,7 @@ def _check_variables(self, created_variables, accessed_variables):\n           but are not tracked by said layer:\n           {variable_str}\n           The layer cannot safely ensure proper Variable reuse across multiple\n-          calls, and consquently this behavior is disallowed for safety. Lambda\n+          calls, and consequently this behavior is disallowed for safety. Lambda\n           layers are not well suited to stateful computation; instead, writing a\n           subclassed Layer is the recommend way to define layers with\n           Variables.\"\"\").format("
    },
    {
        "commit_id": "d67a43aa8cf2a6618bbd103869c477e449e7428d",
        "commit_message": "Fix typos",
        "commit_url": "https://github.com/keras-team/keras/commit/d67a43aa8cf2a6618bbd103869c477e449e7428d",
        "buggy_code": "'across multiple calls, and consquently this behavior is disallowed '",
        "fixed_code": "'across multiple calls, and consequently this behavior is disallowed '",
        "patch": "@@ -279,7 +279,7 @@ def _check_variables(self, created_variables, accessed_variables):\n           'The following Variables were created within a Lambda layer '\n           f'({self.name}) but are not tracked by said layer: {variable_str}\\n'\n           'The layer cannot safely ensure proper Variable reuse '\n-          'across multiple calls, and consquently this behavior is disallowed '\n+          'across multiple calls, and consequently this behavior is disallowed '\n           'for safety reasons. Lambda layers are not well suited for stateful '\n           'computation; instead, writing a subclassed Layer is the recommend '\n           'way to define layers with Variables.')"
    },
    {
        "commit_id": "d67a43aa8cf2a6618bbd103869c477e449e7428d",
        "commit_message": "Fix typos",
        "commit_url": "https://github.com/keras-team/keras/commit/d67a43aa8cf2a6618bbd103869c477e449e7428d",
        "buggy_code": "a dict, or a nested strcture of input tensors.",
        "fixed_code": "a dict, or a nested structure of input tensors.",
        "patch": "@@ -123,7 +123,7 @@ class FunctionalPreprocessingStage(functional.Functional,\n \n   Args:\n     inputs: An input tensor (must be created via `tf.keras.Input()`), or a list,\n-      a dict, or a nested strcture of input tensors.\n+      a dict, or a nested structure of input tensors.\n     outputs: An output tensor, or a list, a dict or a nested structure of output\n       tensors.\n     name: String, optional. Name of the preprocessing stage."
    },
    {
        "commit_id": "d67a43aa8cf2a6618bbd103869c477e449e7428d",
        "commit_message": "Fix typos",
        "commit_url": "https://github.com/keras-team/keras/commit/d67a43aa8cf2a6618bbd103869c477e449e7428d",
        "buggy_code": "has 2 batches with [2, 1] values respectivly the resulting loss is",
        "fixed_code": "has 2 batches with [2, 1] values respectively the resulting loss is",
        "patch": "@@ -1695,7 +1695,7 @@ def _ragged_tensor_categorical_crossentropy(y_true,\n   When used by CategoricalCrossentropy() with the default reduction\n   (SUM_OVER_BATCH_SIZE), the reduction averages the loss over the\n   number of elements independent of the batch. E.g. if the RaggedTensor\n-  has 2 batches with [2, 1] values respectivly the resulting loss is\n+  has 2 batches with [2, 1] values respectively the resulting loss is\n   the sum of the individual loss values divided by 3.\n   \"\"\"\n   fn = functools.partial("
    },
    {
        "commit_id": "d67a43aa8cf2a6618bbd103869c477e449e7428d",
        "commit_message": "Fix typos",
        "commit_url": "https://github.com/keras-team/keras/commit/d67a43aa8cf2a6618bbd103869c477e449e7428d",
        "buggy_code": "'an infinity nubmer or NaN are not valid value')",
        "fixed_code": "'an infinity number or NaN are not valid value')",
        "patch": "@@ -35,7 +35,7 @@ def _check_penalty_number(x):\n   if math.isinf(x) or math.isnan(x):\n     raise ValueError(\n         f'Value: {x} is not a valid regularization penalty number, '\n-        'an infinity nubmer or NaN are not valid value')\n+        'an infinity number or NaN are not valid value')\n \n \n def _none_to_default(inputs, default):"
    },
    {
        "commit_id": "d67a43aa8cf2a6618bbd103869c477e449e7428d",
        "commit_message": "Fix typos",
        "commit_url": "https://github.com/keras-team/keras/commit/d67a43aa8cf2a6618bbd103869c477e449e7428d",
        "buggy_code": "presist a property to the layer indicating it was constructed with a vocab.",
        "fixed_code": "persist a property to the layer indicating it was constructed with a vocab.",
        "patch": "@@ -170,7 +170,7 @@ class VocabularySavedModelSaver(LayerSavedModelSaver):\n   vocab as part of the config until saving, when we need to clear it to avoid\n   initializing a StaticHashTable twice (once when restoring the config and once\n   when restoring restoring module resources). After clearing the vocab, we\n-  presist a property to the layer indicating it was constructed with a vocab.\n+  persist a property to the layer indicating it was constructed with a vocab.\n   \"\"\"\n \n   @property"
    },
    {
        "commit_id": "d67a43aa8cf2a6618bbd103869c477e449e7428d",
        "commit_message": "Fix typos",
        "commit_url": "https://github.com/keras-team/keras/commit/d67a43aa8cf2a6618bbd103869c477e449e7428d",
        "buggy_code": "The `enqueuer.get()` should be an infinite stream of datas.",
        "fixed_code": "The `enqueuer.get()` should be an infinite stream of data.",
        "patch": "@@ -584,7 +584,7 @@ class SequenceEnqueuer:\n       enqueuer.stop()\n   ```\n \n-  The `enqueuer.get()` should be an infinite stream of datas.\n+  The `enqueuer.get()` should be an infinite stream of data.\n   \"\"\"\n \n   def __init__(self, sequence,"
    },
    {
        "commit_id": "d67a43aa8cf2a6618bbd103869c477e449e7428d",
        "commit_message": "Fix typos",
        "commit_url": "https://github.com/keras-team/keras/commit/d67a43aa8cf2a6618bbd103869c477e449e7428d",
        "buggy_code": "tf.constant([\"ironman\", \"ironman\", \"unkonwn\"]))[\"output_0\"]",
        "fixed_code": "tf.constant([\"ironman\", \"ironman\", \"unknown\"]))[\"output_0\"]",
        "patch": "@@ -176,5 +176,5 @@ def test_save_load_serving_model(self, model, feature_mapper,\n     self.assertIn(prediction0.numpy().decode(\"UTF-8\"), (\"yes\", \"no\"))\n \n     prediction1 = loaded_serving_fn(\n-        tf.constant([\"ironman\", \"ironman\", \"unkonwn\"]))[\"output_0\"]\n+        tf.constant([\"ironman\", \"ironman\", \"unknown\"]))[\"output_0\"]\n     self.assertIn(prediction1.numpy().decode(\"UTF-8\"), (\"yes\", \"no\"))"
    },
    {
        "commit_id": "d67a43aa8cf2a6618bbd103869c477e449e7428d",
        "commit_message": "Fix typos",
        "commit_url": "https://github.com/keras-team/keras/commit/d67a43aa8cf2a6618bbd103869c477e449e7428d",
        "buggy_code": "evaluted.",
        "fixed_code": "evaluated.",
        "patch": "@@ -466,7 +466,7 @@ def is_evenly_distributed_thresholds(thresholds):\n \n   We could leverage evenly distributed thresholds to use less memory when\n   calculate metrcis like AUC where each individual threshold need to be\n-  evaluted.\n+  evaluated.\n \n   Args:\n     thresholds: A python list or tuple, or 1D numpy array whose value is ranged"
    },
    {
        "commit_id": "0b1d504ba21cf917a4f42055aba6bdf91fa5e5d6",
        "commit_message": "Add missing space to error message.\n\nPiperOrigin-RevId: 404392831",
        "commit_url": "https://github.com/keras-team/keras/commit/0b1d504ba21cf917a4f42055aba6bdf91fa5e5d6",
        "buggy_code": "f'incompatible with the layer: expected axis {axis}'",
        "fixed_code": "f'incompatible with the layer: expected axis {axis} '",
        "patch": "@@ -246,7 +246,7 @@ def assert_input_compatibility(input_spec, inputs, layer_name):\n         if value is not None and shape_as_list[int(axis)] not in {value, None}:\n           raise ValueError(\n               f'Input {input_index} of layer \"{layer_name}\" is '\n-              f'incompatible with the layer: expected axis {axis}'\n+              f'incompatible with the layer: expected axis {axis} '\n               f'of input shape to have value {value}, '\n               f'but received input with shape {display_shape(x.shape)}')\n     # Check shape."
    },
    {
        "commit_id": "f5171d521acbf2ebbb6414352d5792163c41479f",
        "commit_message": "Fix TF1 saved model compatibility for Discretization and Hashing\n\nIn TF1, before the dypte refacotring we need to deal with explicit\nNone dtypes in the config.\n\nPiperOrigin-RevId: 403221018",
        "commit_url": "https://github.com/keras-team/keras/commit/f5171d521acbf2ebbb6414352d5792163c41479f",
        "buggy_code": "if \"dtype\" not in kwargs:",
        "fixed_code": "if \"dtype\" not in kwargs or kwargs[\"dtype\"] is None:",
        "patch": "@@ -215,7 +215,7 @@ def __init__(self,\n       del kwargs[\"bins\"]\n \n     # By default, output int64 when output_mode='int' and floats otherwise.\n-    if \"dtype\" not in kwargs:\n+    if \"dtype\" not in kwargs or kwargs[\"dtype\"] is None:\n       kwargs[\"dtype\"] = tf.int64 if output_mode == INT else backend.floatx()\n     elif output_mode == \"int\" and not tf.as_dtype(kwargs[\"dtype\"]).is_integer:\n       # Compat for when dtype was alwyas floating and ingored by the layer."
    },
    {
        "commit_id": "f5171d521acbf2ebbb6414352d5792163c41479f",
        "commit_message": "Fix TF1 saved model compatibility for Discretization and Hashing\n\nIn TF1, before the dypte refacotring we need to deal with explicit\nNone dtypes in the config.\n\nPiperOrigin-RevId: 403221018",
        "commit_url": "https://github.com/keras-team/keras/commit/f5171d521acbf2ebbb6414352d5792163c41479f",
        "buggy_code": "if 'dtype' not in kwargs:",
        "fixed_code": "if 'dtype' not in kwargs or kwargs['dtype'] is None:",
        "patch": "@@ -165,7 +165,7 @@ def __init__(self,\n           f'values. Received: num_bins={num_bins}.')\n \n     # By default, output int64 when output_mode='int' and floats otherwise.\n-    if 'dtype' not in kwargs:\n+    if 'dtype' not in kwargs or kwargs['dtype'] is None:\n       kwargs['dtype'] = tf.int64 if output_mode == INT else backend.floatx()\n     elif output_mode == 'int' and not tf.as_dtype(kwargs['dtype']).is_integer:\n       # Compat for when dtype was alwyas floating and ingored by the layer."
    },
    {
        "commit_id": "a38a5ab069ffbd4a1d96b0c24eeecb02a3a4632b",
        "commit_message": "fix a bug, here need to compare strings for equality not string memory addresses",
        "commit_url": "https://github.com/keras-team/keras/commit/a38a5ab069ffbd4a1d96b0c24eeecb02a3a4632b",
        "buggy_code": "if self._output_mode is not INT:",
        "fixed_code": "if self._output_mode != INT:",
        "patch": "@@ -513,7 +513,7 @@ def call(self, inputs):\n     lookup_data = self._lookup_layer(inputs)\n \n     # For any non-int output, we can return directly from the underlying layer.\n-    if self._output_mode is not INT:\n+    if self._output_mode != INT:\n       return lookup_data\n \n     if self._ragged:"
    },
    {
        "commit_id": "228ce89b56f1be222ae0deb6e744b0f4d0daad54",
        "commit_message": "Fix and extra tests relating to PR #15233",
        "commit_url": "https://github.com/keras-team/keras/commit/228ce89b56f1be222ae0deb6e744b0f4d0daad54",
        "buggy_code": "label = '%s\\n|{input:|output:}|{{%s}|{%s}}' % (label,",
        "fixed_code": "label = '%s|{input:|output:}|{{%s}|{%s}}' % (label,",
        "patch": "@@ -290,7 +290,7 @@ def format_shape(shape):\n             [format_shape(ishape) for ishape in layer.input_shapes])\n       else:\n         inputlabels = '?'\n-      label = '%s\\n|{input:|output:}|{{%s}|{%s}}' % (label,\n+      label = '%s|{input:|output:}|{{%s}|{%s}}' % (label,\n                                                      inputlabels,\n                                                      outputlabels)\n "
    },
    {
        "commit_id": "639afd1276db8e9821c79569faa73061563001ed",
        "commit_message": "fix: typo in SeparableConv1D\n\nFixed typo in SeparableConv1D docstring (tensor number of dimensions).",
        "commit_url": "https://github.com/keras-team/keras/commit/639afd1276db8e9821c79569faa73061563001ed",
        "buggy_code": "or 5D tensor with shape:",
        "fixed_code": "or 3D tensor with shape:",
        "patch": "@@ -1984,7 +1984,7 @@ class SeparableConv1D(SeparableConv):\n   Input shape:\n     3D tensor with shape:\n     `(batch_size, channels, steps)` if data_format='channels_first'\n-    or 5D tensor with shape:\n+    or 3D tensor with shape:\n     `(batch_size, steps, channels)` if data_format='channels_last'.\n \n   Output shape:"
    },
    {
        "commit_id": "519430bb8fa354d2c6c2552ca87010b8e0931570",
        "commit_message": "Merge pull request #15321 from Rishit-dagli:Rishit-dagli-patch-1\n\nPiperOrigin-RevId: 395505151",
        "commit_url": "https://github.com/keras-team/keras/commit/519430bb8fa354d2c6c2552ca87010b8e0931570",
        "buggy_code": "(10000, 32, 32, 3), containing the test data. Pixel values range",
        "fixed_code": "`(10000, 32, 32, 3)`, containing the test data. Pixel values range",
        "patch": "@@ -58,7 +58,7 @@ def load_data():\n     with shape `(50000, 1)` for the training data.\n \n   **x_test**: uint8 NumPy array of grayscale image data with shapes\n-    (10000, 32, 32, 3), containing the test data. Pixel values range\n+    `(10000, 32, 32, 3)`, containing the test data. Pixel values range\n     from 0 to 255.\n \n   **y_test**: uint8 NumPy array of labels (integers in range 0-9)"
    },
    {
        "commit_id": "519430bb8fa354d2c6c2552ca87010b8e0931570",
        "commit_message": "Merge pull request #15321 from Rishit-dagli:Rishit-dagli-patch-1\n\nPiperOrigin-RevId: 395505151",
        "commit_url": "https://github.com/keras-team/keras/commit/519430bb8fa354d2c6c2552ca87010b8e0931570",
        "buggy_code": "(10000, 32, 32, 3), containing the test data. Pixel values range",
        "fixed_code": "`(10000, 32, 32, 3)`, containing the test data. Pixel values range",
        "patch": "@@ -49,7 +49,7 @@ def load_data(label_mode='fine'):\n     with shape `(50000, 1)` for the training data.\n \n   **x_test**: uint8 NumPy array of grayscale image data with shapes\n-    (10000, 32, 32, 3), containing the test data. Pixel values range\n+    `(10000, 32, 32, 3)`, containing the test data. Pixel values range\n     from 0 to 255.\n \n   **y_test**: uint8 NumPy array of labels (integers in range 0-99)"
    },
    {
        "commit_id": "59d53eddaa7ec5afb648e6ec4429bb33985d5679",
        "commit_message": "Fix a minor typo in CIFAR-100 README",
        "commit_url": "https://github.com/keras-team/keras/commit/59d53eddaa7ec5afb648e6ec4429bb33985d5679",
        "buggy_code": "(10000, 32, 32, 3), containing the test data. Pixel values range",
        "fixed_code": "`(10000, 32, 32, 3)`, containing the test data. Pixel values range",
        "patch": "@@ -49,7 +49,7 @@ def load_data(label_mode='fine'):\n     with shape `(50000, 1)` for the training data.\n \n   **x_test**: uint8 NumPy array of grayscale image data with shapes\n-    (10000, 32, 32, 3), containing the test data. Pixel values range\n+    `(10000, 32, 32, 3)`, containing the test data. Pixel values range\n     from 0 to 255.\n \n   **y_test**: uint8 NumPy array of labels (integers in range 0-99)"
    },
    {
        "commit_id": "8b824e8bc7538091d50d5cc07e92a25100bf2785",
        "commit_message": "Fix a minor typo in CIFAR-10 README",
        "commit_url": "https://github.com/keras-team/keras/commit/8b824e8bc7538091d50d5cc07e92a25100bf2785",
        "buggy_code": "(10000, 32, 32, 3), containing the test data. Pixel values range",
        "fixed_code": "`(10000, 32, 32, 3)`, containing the test data. Pixel values range",
        "patch": "@@ -58,7 +58,7 @@ def load_data():\n     with shape `(50000, 1)` for the training data.\n \n   **x_test**: uint8 NumPy array of grayscale image data with shapes\n-    (10000, 32, 32, 3), containing the test data. Pixel values range\n+    `(10000, 32, 32, 3)`, containing the test data. Pixel values range\n     from 0 to 255.\n \n   **y_test**: uint8 NumPy array of labels (integers in range 0-9)"
    },
    {
        "commit_id": "e24262ab08d7eaa5405c39281a38439b699d7e3d",
        "commit_message": "Fix  for subclass models in  and added a unit test case",
        "commit_url": "https://github.com/keras-team/keras/commit/e24262ab08d7eaa5405c39281a38439b699d7e3d",
        "buggy_code": "if expand_nested and isinstance(layer, type(model)) and layer.layers:",
        "fixed_code": "if expand_nested and hasattr(layer, 'layers') and layer.layers:",
        "patch": "@@ -284,7 +284,7 @@ def print_layer(layer,\n     else:\n       print_layer_summary_with_connections(layer, nested_level)\n \n-    if expand_nested and isinstance(layer, type(model)) and layer.layers:\n+    if expand_nested and hasattr(layer, 'layers') and layer.layers:\n       print_fn('|' * (nested_level + 1) +\n                '\u00af' * (line_length - 2 * nested_level - 2) +\n                '|' * (nested_level + 1))"
    },
    {
        "commit_id": "f1e1ba94f3fcb6ace6cf9ca6362e7ef12bdd753a",
        "commit_message": "Fix error message for `sparse` setting in IndexLookup layer when `output_mode = \"int\"`.\n\nPiperOrigin-RevId: 393195894",
        "commit_url": "https://github.com/keras-team/keras/commit/f1e1ba94f3fcb6ace6cf9ca6362e7ef12bdd753a",
        "buggy_code": "raise ValueError(f\"`sparse` must not be true if `output_mode` is \"",
        "fixed_code": "raise ValueError(f\"`sparse` may only be true if `output_mode` is \"",
        "patch": "@@ -192,7 +192,7 @@ def __init__(self,\n                        f\"Received: output_mode={output_mode}\")\n \n     if sparse and output_mode == INT:\n-      raise ValueError(f\"`sparse` must not be true if `output_mode` is \"\n+      raise ValueError(f\"`sparse` may only be true if `output_mode` is \"\n                        f\"`'one_hot'`, `'multi_hot'`, `'count'` or `'tf_idf'`. \"\n                        f\"Received: sparse={sparse} and \"\n                        f\"output_mode={output_mode}\")"
    },
    {
        "commit_id": "f1e1ba94f3fcb6ace6cf9ca6362e7ef12bdd753a",
        "commit_message": "Fix error message for `sparse` setting in IndexLookup layer when `output_mode = \"int\"`.\n\nPiperOrigin-RevId: 393195894",
        "commit_url": "https://github.com/keras-team/keras/commit/f1e1ba94f3fcb6ace6cf9ca6362e7ef12bdd753a",
        "buggy_code": "with self.assertRaisesRegex(ValueError, \"`sparse` must not be true if\"):",
        "fixed_code": "with self.assertRaisesRegex(ValueError, \"`sparse` may only be true if\"):",
        "patch": "@@ -1588,7 +1588,7 @@ def test_ragged_true_fails_if_output_mode_not_int(self):\n           ragged=True, output_mode=text_vectorization.MULTI_HOT)\n \n   def test_sparse_true_fails_if_output_mode_is_int(self):\n-    with self.assertRaisesRegex(ValueError, \"`sparse` must not be true if\"):\n+    with self.assertRaisesRegex(ValueError, \"`sparse` may only be true if\"):\n       _ = text_vectorization.TextVectorization(\n           sparse=True, output_mode=text_vectorization.INT)\n "
    },
    {
        "commit_id": "d3e67af9c958260a1e88f5879cc010542305bc90",
        "commit_message": "fix test_cropping_1d to be addapted to new parameters",
        "commit_url": "https://github.com/keras-team/keras/commit/d3e67af9c958260a1e88f5879cc010542305bc90",
        "buggy_code": "kwargs={'cropping': (2, 2)},",
        "fixed_code": "kwargs={'cropping': (1, 1)},",
        "patch": "@@ -1005,7 +1005,7 @@ def test_cropping_1d(self):\n     with self.cached_session():\n       testing_utils.layer_test(\n           keras.layers.Cropping1D,\n-          kwargs={'cropping': (2, 2)},\n+          kwargs={'cropping': (1, 1)},\n           input_shape=inputs.shape)\n \n     # test incorrect use"
    },
    {
        "commit_id": "6638ce76b1d414b33393f00cdde13b78c3774a43",
        "commit_message": "Fix small mistake `optimizer` to `optimizers`",
        "commit_url": "https://github.com/keras-team/keras/commit/6638ce76b1d414b33393f00cdde13b78c3774a43",
        "buggy_code": "model.compile(optimizer=tf.keras.optimizer.Adam(learning_rate=1e-3),",
        "fixed_code": "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),",
        "patch": "@@ -462,7 +462,7 @@ def compile(self,\n     Example:\n \n     ```python\n-    model.compile(optimizer=tf.keras.optimizer.Adam(learning_rate=1e-3),\n+    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n                   loss=tf.keras.losses.BinaryCrossentropy(),\n                   metrics=[tf.keras.metrics.BinaryAccuracy(),\n                            tf.keras.metrics.FalseNegatives()])"
    },
    {
        "commit_id": "9554eed59cec929c71a0b91dc0f57f5a77824bac",
        "commit_message": "Fix for bug causing failing test keras/utils/vis_utils_test.py test_layer_range_value_fail second value (empty list).",
        "commit_url": "https://github.com/keras-team/keras/commit/9554eed59cec929c71a0b91dc0f57f5a77824bac",
        "buggy_code": "if layer_range:",
        "fixed_code": "if layer_range is not None:",
        "patch": "@@ -162,7 +162,7 @@ def model_to_dot(model,\n     dot.set('dpi', dpi)\n     dot.set_node_defaults(shape='record')\n \n-  if layer_range:\n+  if layer_range is not None:\n     if len(layer_range) != 2:\n       raise ValueError(\n           'layer_range must be of shape (2,). Received: '"
    },
    {
        "commit_id": "79e9e20d8b95f043cd8a3a240b70928d468a60ac",
        "commit_message": "fix __array__ for numpy support",
        "commit_url": "https://github.com/keras-team/keras/commit/79e9e20d8b95f043cd8a3a240b70928d468a60ac",
        "buggy_code": "def __array__(self):",
        "fixed_code": "def __array__(self, dtype=None):",
        "patch": "@@ -240,7 +240,7 @@ def __hash__(self):\n   # with ndarrays.\n   __array_priority__ = 100\n \n-  def __array__(self):\n+  def __array__(self, dtype=None):\n     raise TypeError(\n         'Cannot convert a symbolic Keras input/output to a numpy array. '\n         'This error may indicate that you\\'re trying to pass a symbolic value '"
    },
    {
        "commit_id": "fe9452a658b1c0e75226b467192586e0ab081d43",
        "commit_message": "Merge pull request #15177 from YoniChechik:patch-1\n\nPiperOrigin-RevId: 391561552",
        "commit_url": "https://github.com/keras-team/keras/commit/fe9452a658b1c0e75226b467192586e0ab081d43",
        "buggy_code": "'`color_mode` must be one of {\"rbg\", \"rgba\", \"grayscale\"}. '",
        "fixed_code": "'`color_mode` must be one of {\"rgb\", \"rgba\", \"grayscale\"}. '",
        "patch": "@@ -179,7 +179,7 @@ def image_dataset_from_directory(directory,\n     num_channels = 1\n   else:\n     raise ValueError(\n-        '`color_mode` must be one of {\"rbg\", \"rgba\", \"grayscale\"}. '\n+        '`color_mode` must be one of {\"rgb\", \"rgba\", \"grayscale\"}. '\n         f'Received: color_mode={color_mode}')\n   interpolation = image_preprocessing.get_interpolation(interpolation)\n   dataset_utils.check_validation_split_arg("
    },
    {
        "commit_id": "a23d4ed1fea66c9cb4b6aeb272481c5482042b09",
        "commit_message": "fix \"rbg\" -> \"rgb\" in image_dataset_from_directory in field color_mode in case of ValueError",
        "commit_url": "https://github.com/keras-team/keras/commit/a23d4ed1fea66c9cb4b6aeb272481c5482042b09",
        "buggy_code": "'`color_mode` must be one of {\"rbg\", \"rgba\", \"grayscale\"}. '",
        "fixed_code": "'`color_mode` must be one of {\"rgb\", \"rgba\", \"grayscale\"}. '",
        "patch": "@@ -179,7 +179,7 @@ def image_dataset_from_directory(directory,\n     num_channels = 1\n   else:\n     raise ValueError(\n-        '`color_mode` must be one of {\"rbg\", \"rgba\", \"grayscale\"}. '\n+        '`color_mode` must be one of {\"rgb\", \"rgba\", \"grayscale\"}. '\n         f'Received: color_mode={color_mode}')\n   interpolation = image_preprocessing.get_interpolation(interpolation)\n   dataset_utils.check_validation_split_arg("
    },
    {
        "commit_id": "36e0a33d85e0ab30ca2f7220a437e80e66e87f18",
        "commit_message": "fix None tensor check #14970",
        "commit_url": "https://github.com/keras-team/keras/commit/36e0a33d85e0ab30ca2f7220a437e80e66e87f18",
        "buggy_code": "if tf.not_equal(tf.size(inputs), 0) and sum(self.cropping) >= inputs.shape[1]:",
        "fixed_code": "if inputs.shape[1] is not None and sum(self.cropping) >= inputs.shape[1]:",
        "patch": "@@ -3409,7 +3409,7 @@ def compute_output_shape(self, input_shape):\n     return tf.TensorShape([input_shape[0], length, input_shape[2]])\n \n   def call(self, inputs):\n-    if tf.not_equal(tf.size(inputs), 0) and sum(self.cropping) >= inputs.shape[1]:\n+    if inputs.shape[1] is not None and sum(self.cropping) >= inputs.shape[1]:\n       raise ValueError('cropping parameter of Cropping layer must be '\n                        'greater than the input shape. Recieved: inputs.shape='\n                        f'{inputs.shape}, and cropping={self.cropping}')"
    },
    {
        "commit_id": "d8f79581504e793660a053acb2e3246efe24d3ee",
        "commit_message": "Improve a number of error messages for keras layer\n\nPiperOrigin-RevId: 390304623",
        "commit_url": "https://github.com/keras-team/keras/commit/d8f79581504e793660a053acb2e3246efe24d3ee",
        "buggy_code": "raise ValueError(\"`num_bins` must be must be greater than or equal to 0. \"",
        "fixed_code": "raise ValueError(\"`num_bins` must be greater than or equal to 0. \"",
        "patch": "@@ -184,7 +184,7 @@ def __init__(self,\n     base_preprocessing_layer.keras_kpl_gauge.get_cell(\"Discretization\").set(\n         True)\n     if num_bins is not None and num_bins < 0:\n-      raise ValueError(\"`num_bins` must be must be greater than or equal to 0. \"\n+      raise ValueError(\"`num_bins` must be greater than or equal to 0. \"\n                        \"You passed `num_bins={}`\".format(num_bins))\n     if num_bins is not None and bin_boundaries is not None:\n       raise ValueError(\"Both `num_bins` and `bin_boundaries` should not be \""
    },
    {
        "commit_id": "02ec19c88ba756b470c80fae7db74160fca25de5",
        "commit_message": "Improve error messages in tensorflow/python/saved_model.\n\nPiperOrigin-RevId: 390034770",
        "commit_url": "https://github.com/keras-team/keras/commit/02ec19c88ba756b470c80fae7db74160fca25de5",
        "buggy_code": "raise ValueError('{} inputs cannot be None or empty.'.format(method_name))",
        "fixed_code": "raise ValueError('f{method_name} `inputs` cannot be None or empty.')",
        "patch": "@@ -58,7 +58,7 @@ def _supervised_signature_def(\n     ValueError: If inputs or outputs is `None`.\n   \"\"\"\n   if inputs is None or not inputs:\n-    raise ValueError('{} inputs cannot be None or empty.'.format(method_name))\n+    raise ValueError('f{method_name} `inputs` cannot be None or empty.')\n \n   signature_inputs = {key: tf.compat.v1.saved_model.build_tensor_info(tensor)\n                       for key, tensor in inputs.items()}"
    },
    {
        "commit_id": "d9680f61c81d70de0687e38dd52a0338c2a75931",
        "commit_message": "fix empty tensor and create test",
        "commit_url": "https://github.com/keras-team/keras/commit/d9680f61c81d70de0687e38dd52a0338c2a75931",
        "buggy_code": "if sum(self.cropping) >= inputs.shape[1]:",
        "fixed_code": "if tf.not_equal(tf.size(inputs), 0) and sum(self.cropping) >= inputs.shape[1]:",
        "patch": "@@ -3400,7 +3400,7 @@ def compute_output_shape(self, input_shape):\n     return tf.TensorShape([input_shape[0], length, input_shape[2]])\n \n   def call(self, inputs):\n-    if sum(self.cropping) >= inputs.shape[1]:\n+    if tf.not_equal(tf.size(inputs), 0) and sum(self.cropping) >= inputs.shape[1]:\n       raise ValueError(\n         'cropping parameter of Cropping layer is too high,' +\n         'the result of crop' + str(inputs.shape) + ' with cropping ' +"
    },
    {
        "commit_id": "20c8480a3fdbfc6f6c090f4f37aeed75f82c0496",
        "commit_message": "Improve error messages for keras SavedModel\n\nPiperOrigin-RevId: 389234253",
        "commit_url": "https://github.com/keras-team/keras/commit/20c8480a3fdbfc6f6c090f4f37aeed75f82c0496",
        "buggy_code": "'Maybe you meant to use '",
        "fixed_code": "f'Received: config={config}. Did you meant to use '",
        "patch": "@@ -46,7 +46,7 @@ def model_from_config(config, custom_objects=None):\n   \"\"\"\n   if isinstance(config, list):\n     raise TypeError('`model_from_config` expects a dictionary, not a list. '\n-                    'Maybe you meant to use '\n+                    f'Received: config={config}. Did you meant to use '\n                     '`Sequential.from_config(config)`?')\n   from keras.layers import deserialize  # pylint: disable=g-import-not-at-top\n   return deserialize(config, custom_objects=custom_objects)"
    },
    {
        "commit_id": "20c8480a3fdbfc6f6c090f4f37aeed75f82c0496",
        "commit_message": "Improve error messages for keras SavedModel\n\nPiperOrigin-RevId: 389234253",
        "commit_url": "https://github.com/keras-team/keras/commit/20c8480a3fdbfc6f6c090f4f37aeed75f82c0496",
        "buggy_code": "'available) or SavedModel.')",
        "fixed_code": "f'available) or SavedModel. Received: filepath={filepath}')",
        "patch": "@@ -209,7 +209,7 @@ def load_model(filepath, custom_objects=None, compile=True, options=None):  # py\n \n   raise IOError(\n       'Unable to load model. Filepath is not an hdf5 file (or h5py is not '\n-      'available) or SavedModel.')\n+      f'available) or SavedModel. Received: filepath={filepath}')\n \n # Inject the load_model function to keras_deps to remove the dependency\n # from TFLite to Keras."
    },
    {
        "commit_id": "edebe0f3b44714b30b8d3390da4fafa4df878651",
        "commit_message": "Update error messages several keras/utils module.\n\nPiperOrigin-RevId: 389045697",
        "commit_url": "https://github.com/keras-team/keras/commit/edebe0f3b44714b30b8d3390da4fafa4df878651",
        "buggy_code": "\"Found instead: %s\" % type(pred))",
        "fixed_code": "f\"Received: {type(pred)}\")",
        "patch": "@@ -129,4 +129,4 @@ def constant_value(pred):  # pylint: disable=invalid-name\n   if isinstance(pred, tf.Variable):\n     return None\n   raise TypeError(\"`pred` must be a Tensor, or a Python bool, or 1 or 0. \"\n-                  \"Found instead: %s\" % type(pred))\n+                  f\"Received: {type(pred)}\")"
    },
    {
        "commit_id": "e19c5069ae4c10ef403f8d22a64a460f78a80728",
        "commit_message": "TF error message fixit: keras/datasets/reuters.\n\nPiperOrigin-RevId: 389017077",
        "commit_url": "https://github.com/keras-team/keras/commit/e19c5069ae4c10ef403f8d22a64a460f78a80728",
        "buggy_code": "raise TypeError('Unrecognized keyword arguments: ' + str(kwargs))",
        "fixed_code": "raise TypeError(f'Unrecognized keyword arguments: {str(kwargs)}')",
        "patch": "@@ -103,7 +103,7 @@ def load_data(path='reuters.npz',\n                     'has been renamed `num_words`.')\n     num_words = kwargs.pop('nb_words')\n   if kwargs:\n-    raise TypeError('Unrecognized keyword arguments: ' + str(kwargs))\n+    raise TypeError(f'Unrecognized keyword arguments: {str(kwargs)}')\n \n   origin_folder = 'https://storage.googleapis.com/tensorflow/tf-keras-datasets/'\n   path = get_file("
    },
    {
        "commit_id": "f717f8cf0978b5e2fa3560870681e49dda248ef3",
        "commit_message": "GRU: Fix a typo in doc comment about reset_after.\n\n`reset_after` is a named argument, not string.",
        "commit_url": "https://github.com/keras-team/keras/commit/f717f8cf0978b5e2fa3560870681e49dda248ef3",
        "buggy_code": "`recurrent_kernel`. To use this variant, set `'reset_after'=True` and",
        "fixed_code": "`recurrent_kernel`. To use this variant, set `reset_after=True` and",
        "patch": "@@ -231,7 +231,7 @@ class GRU(recurrent.DropoutRNNCellMixin, recurrent.GRU):\n \n   The second variant is compatible with CuDNNGRU (GPU-only) and allows\n   inference on CPU. Thus it has separate biases for `kernel` and\n-  `recurrent_kernel`. To use this variant, set `'reset_after'=True` and\n+  `recurrent_kernel`. To use this variant, set `reset_after=True` and\n   `recurrent_activation='sigmoid'`.\n \n   For example:"
    },
    {
        "commit_id": "fdf91ec03325eb2900d87ccaf572815968779404",
        "commit_message": "Improve a number of error messages in Keras layers.\n\nPiperOrigin-RevId: 387883278",
        "commit_url": "https://github.com/keras-team/keras/commit/fdf91ec03325eb2900d87ccaf572815968779404",
        "buggy_code": "ValueError, \".*is not a part of the output specification.*\"):",
        "fixed_code": "ValueError, \".*is not part of the output spec.*\"):",
        "patch": "@@ -280,7 +280,7 @@ def test_unspecified_bias_dim_fails(self):\n     layer = einsum_dense.EinsumDense(\n         equation=\"ab,bc->ac\", output_shape=64, bias_axes=\"y\")\n     with self.assertRaisesRegex(\n-        ValueError, \".*is not a part of the output specification.*\"):\n+        ValueError, \".*is not part of the output spec.*\"):\n       _ = layer(input_tensor)\n \n   def test_incompatible_input_output_shape_fails(self):"
    },
    {
        "commit_id": "b693bb84200d70aa736f2491ff83509fd1b1b6fb",
        "commit_message": "Improve error messages in Keras activations / constraints / metrics.\n\nPiperOrigin-RevId: 387713769",
        "commit_url": "https://github.com/keras-team/keras/commit/b693bb84200d70aa736f2491ff83509fd1b1b6fb",
        "buggy_code": "with self.assertRaisesRegex(ValueError, 'does not have any result yet'):",
        "fixed_code": "with self.assertRaisesRegex(ValueError, 'does not have any value yet'):",
        "patch": "@@ -1379,7 +1379,7 @@ def test_config(self):\n       self.assertEqual(m.dtype, tf.float32)\n       self.assertEmpty(m.variables)\n \n-      with self.assertRaisesRegex(ValueError, 'does not have any result yet'):\n+      with self.assertRaisesRegex(ValueError, 'does not have any value yet'):\n         m.result()\n \n       self.evaluate(m([[3], [5], [3]]))"
    },
    {
        "commit_id": "eef3ad0626c6cbedc92c998828671f0d6b766058",
        "commit_message": "Improve a number of error messages related to functional & sequential model construction.\n\nPiperOrigin-RevId: 387700563",
        "commit_url": "https://github.com/keras-team/keras/commit/eef3ad0626c6cbedc92c998828671f0d6b766058",
        "buggy_code": "'Found incompatiable static batch sizes among all the inputs. '",
        "fixed_code": "'Found incompatiable static batch sizes among the inputs. '",
        "patch": "@@ -1099,7 +1099,7 @@ def call(self, inputs):\n       training_module.Model([input1, input2], outputs)\n       self.assertEqual(\n           mock_warn.call_args_list[0][0][0],\n-          'Found incompatiable static batch sizes among all the inputs. '\n+          'Found incompatiable static batch sizes among the inputs. '\n           'Batch sizes: [2, 3]')\n \n   @combinations.generate(combinations.combine(mode=['graph', 'eager']))"
    },
    {
        "commit_id": "777ed83e4f85f0e24af7ee3d14fb1b1eb098b28d",
        "commit_message": "fix: typo spelling, fixed indentation",
        "commit_url": "https://github.com/keras-team/keras/commit/777ed83e4f85f0e24af7ee3d14fb1b1eb098b28d",
        "buggy_code": "\"\"\"Common utilities for our Keras preprocessing intergration tests.\"\"\"",
        "fixed_code": "\"\"\"Common utilities for our Keras preprocessing integration tests.\"\"\"",
        "patch": "@@ -12,7 +12,7 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n # ==============================================================================\n-\"\"\"Common utilities for our Keras preprocessing intergration tests.\"\"\"\n+\"\"\"Common utilities for our Keras preprocessing integration tests.\"\"\"\n \n import os\n "
    },
    {
        "commit_id": "777ed83e4f85f0e24af7ee3d14fb1b1eb098b28d",
        "commit_message": "fix: typo spelling, fixed indentation",
        "commit_url": "https://github.com/keras-team/keras/commit/777ed83e4f85f0e24af7ee3d14fb1b1eb098b28d",
        "buggy_code": "\"\"\"Intializes a Merge layer.",
        "fixed_code": "\"\"\"Initializes a Merge layer.",
        "patch": "@@ -32,7 +32,7 @@ class _Merge(Layer):\n   \"\"\"\n \n   def __init__(self, **kwargs):\n-    \"\"\"Intializes a Merge layer.\n+    \"\"\"Initializes a Merge layer.\n \n     Args:\n       **kwargs: standard layer keyword arguments."
    },
    {
        "commit_id": "777ed83e4f85f0e24af7ee3d14fb1b1eb098b28d",
        "commit_message": "fix: typo spelling, fixed indentation",
        "commit_url": "https://github.com/keras-team/keras/commit/777ed83e4f85f0e24af7ee3d14fb1b1eb098b28d",
        "buggy_code": "attention_scores: [Optional] multi-head attention coeffients over",
        "fixed_code": "attention_scores: [Optional] multi-head attention coefficients over",
        "patch": "@@ -207,7 +207,7 @@ class MultiHeadAttention(Layer):\n       where `T` is for target sequence shapes and `E` is the query input last\n       dimension if `output_shape` is `None`. Otherwise, the multi-head outputs\n       are project to the shape specified by `output_shape`.\n-    attention_scores: [Optional] multi-head attention coeffients over\n+    attention_scores: [Optional] multi-head attention coefficients over\n       attention axes.\n   \"\"\"\n "
    },
    {
        "commit_id": "777ed83e4f85f0e24af7ee3d14fb1b1eb098b28d",
        "commit_message": "fix: typo spelling, fixed indentation",
        "commit_url": "https://github.com/keras-team/keras/commit/777ed83e4f85f0e24af7ee3d14fb1b1eb098b28d",
        "buggy_code": "class_names: Only valid if \"labels\" is \"inferred\". This is the explict",
        "fixed_code": "class_names: Only valid if \"labels\" is \"inferred\". This is the explicit",
        "patch": "@@ -42,7 +42,7 @@ def index_directory(directory,\n         to the alphanumeric order of the image file paths\n         (obtained via `os.walk(directory)` in Python).\n     formats: Allowlist of file extensions to index (e.g. \".jpg\", \".txt\").\n-    class_names: Only valid if \"labels\" is \"inferred\". This is the explict\n+    class_names: Only valid if \"labels\" is \"inferred\". This is the explicit\n         list of class names (must match names of subdirectories). Used\n         to control the order of the classes\n         (otherwise alphanumerical order is used)."
    },
    {
        "commit_id": "10b165f06ec9385ed7251b46eef22836bd04ad55",
        "commit_message": "fix: typo spelling",
        "commit_url": "https://github.com/keras-team/keras/commit/10b165f06ec9385ed7251b46eef22836bd04ad55",
        "buggy_code": "raise ValueError(\"Please specificy either `input_shape` or `input`\"",
        "fixed_code": "raise ValueError(\"Please specify either `input_shape` or `input`\"",
        "patch": "@@ -46,7 +46,7 @@ def _get_input_data(inputs):\n   elif \"input\" in inputs:\n     return inputs[\"input\"]\n   else:\n-    raise ValueError(\"Please specificy either `input_shape` or `input`\"\n+    raise ValueError(\"Please specify either `input_shape` or `input`\"\n                      \"for the benchmark test\")\n \n "
    },
    {
        "commit_id": "10b165f06ec9385ed7251b46eef22836bd04ad55",
        "commit_message": "fix: typo spelling",
        "commit_url": "https://github.com/keras-team/keras/commit/10b165f06ec9385ed7251b46eef22836bd04ad55",
        "buggy_code": "\"\"\"Utilites for `Model.compile`.\"\"\"",
        "fixed_code": "\"\"\"Utilities for `Model.compile`.\"\"\"",
        "patch": "@@ -12,7 +12,7 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n # ==============================================================================\n-\"\"\"Utilites for `Model.compile`.\"\"\"\n+\"\"\"Utilities for `Model.compile`.\"\"\"\n \n import tensorflow.compat.v2 as tf\n "
    },
    {
        "commit_id": "10b165f06ec9385ed7251b46eef22836bd04ad55",
        "commit_message": "fix: typo spelling",
        "commit_url": "https://github.com/keras-team/keras/commit/10b165f06ec9385ed7251b46eef22836bd04ad55",
        "buggy_code": "restore the values before returing from said endpoint. This scope checks if",
        "fixed_code": "restore the values before returning from said endpoint. This scope checks if",
        "patch": "@@ -122,7 +122,7 @@ class RespectCompiledTrainableState(object):\n   at `Model.compile` time will be used when training that model. In order to\n   respect this requirement, it may be necessary to set the trainable value of\n   layers to their compile time values before beginning a training endpoint and\n-  restore the values before returing from said endpoint. This scope checks if\n+  restore the values before returning from said endpoint. This scope checks if\n   any layer's trainable state has changed since Model compile, and performs this\n   set and un-set bookkeeping.\n "
    },
    {
        "commit_id": "10b165f06ec9385ed7251b46eef22836bd04ad55",
        "commit_message": "fix: typo spelling",
        "commit_url": "https://github.com/keras-team/keras/commit/10b165f06ec9385ed7251b46eef22836bd04ad55",
        "buggy_code": "\"\"\"Common utilities for our Keras preprocessing intergration tests.\"\"\"",
        "fixed_code": "\"\"\"Common utilities for our Keras preprocessing integration tests.\"\"\"",
        "patch": "@@ -12,7 +12,7 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n # ==============================================================================\n-\"\"\"Common utilities for our Keras preprocessing intergration tests.\"\"\"\n+\"\"\"Common utilities for our Keras preprocessing integration tests.\"\"\"\n \n import os\n "
    },
    {
        "commit_id": "10b165f06ec9385ed7251b46eef22836bd04ad55",
        "commit_message": "fix: typo spelling",
        "commit_url": "https://github.com/keras-team/keras/commit/10b165f06ec9385ed7251b46eef22836bd04ad55",
        "buggy_code": "\"\"\"Intializes a Merge layer.",
        "fixed_code": "\"\"\"Initializes a Merge layer.",
        "patch": "@@ -32,7 +32,7 @@ class _Merge(Layer):\n   \"\"\"\n \n   def __init__(self, **kwargs):\n-    \"\"\"Intializes a Merge layer.\n+    \"\"\"Initializes a Merge layer.\n \n     Args:\n       **kwargs: standard layer keyword arguments."
    },
    {
        "commit_id": "10b165f06ec9385ed7251b46eef22836bd04ad55",
        "commit_message": "fix: typo spelling",
        "commit_url": "https://github.com/keras-team/keras/commit/10b165f06ec9385ed7251b46eef22836bd04ad55",
        "buggy_code": "attention_scores: [Optional] multi-head attention coeffients over",
        "fixed_code": "attention_scores: [Optional] multi-head attention coefficients over",
        "patch": "@@ -207,7 +207,7 @@ class MultiHeadAttention(Layer):\n       where `T` is for target sequence shapes and `E` is the query input last\n       dimension if `output_shape` is `None`. Otherwise, the multi-head outputs\n       are project to the shape specified by `output_shape`.\n-    attention_scores: [Optional] multi-head attention coeffients over\n+    attention_scores: [Optional] multi-head attention coefficients over\n       attention axes.\n   \"\"\"\n "
    },
    {
        "commit_id": "10b165f06ec9385ed7251b46eef22836bd04ad55",
        "commit_message": "fix: typo spelling",
        "commit_url": "https://github.com/keras-team/keras/commit/10b165f06ec9385ed7251b46eef22836bd04ad55",
        "buggy_code": "replicas in the presense of `tf.distribute.Strategy`. If False, it's",
        "fixed_code": "replicas in the presence of `tf.distribute.Strategy`. If False, it's",
        "patch": "@@ -607,7 +607,7 @@ def apply_gradients(self,\n       name: Optional name for the returned operation. Default to the name passed\n         to the `Optimizer` constructor.\n       experimental_aggregate_gradients: Whether to sum gradients from different\n-        replicas in the presense of `tf.distribute.Strategy`. If False, it's\n+        replicas in the presence of `tf.distribute.Strategy`. If False, it's\n         user responsibility to aggregate the gradients. Default to True.\n \n     Returns:"
    },
    {
        "commit_id": "10b165f06ec9385ed7251b46eef22836bd04ad55",
        "commit_message": "fix: typo spelling",
        "commit_url": "https://github.com/keras-team/keras/commit/10b165f06ec9385ed7251b46eef22836bd04ad55",
        "buggy_code": "class_names: Only valid if \"labels\" is \"inferred\". This is the explict",
        "fixed_code": "class_names: Only valid if \"labels\" is \"inferred\". This is the explicit",
        "patch": "@@ -42,7 +42,7 @@ def index_directory(directory,\n         to the alphanumeric order of the image file paths\n         (obtained via `os.walk(directory)` in Python).\n     formats: Allowlist of file extensions to index (e.g. \".jpg\", \".txt\").\n-    class_names: Only valid if \"labels\" is \"inferred\". This is the explict\n+    class_names: Only valid if \"labels\" is \"inferred\". This is the explicit\n         list of class names (must match names of subdirectories). Used\n         to control the order of the classes\n         (otherwise alphanumerical order is used)."
    },
    {
        "commit_id": "10b165f06ec9385ed7251b46eef22836bd04ad55",
        "commit_message": "fix: typo spelling",
        "commit_url": "https://github.com/keras-team/keras/commit/10b165f06ec9385ed7251b46eef22836bd04ad55",
        "buggy_code": "class_names: Only valid if \"labels\" is \"inferred\". This is the explict",
        "fixed_code": "class_names: Only valid if \"labels\" is \"inferred\". This is the explicit",
        "patch": "@@ -89,7 +89,7 @@ def image_dataset_from_directory(directory,\n             are encoded as `float32` scalars with values 0 or 1\n             (e.g. for `binary_crossentropy`).\n         - None (no labels).\n-    class_names: Only valid if \"labels\" is \"inferred\". This is the explict\n+    class_names: Only valid if \"labels\" is \"inferred\". This is the explicit\n         list of class names (must match names of subdirectories). Used\n         to control the order of the classes\n         (otherwise alphanumerical order is used)."
    },
    {
        "commit_id": "10b165f06ec9385ed7251b46eef22836bd04ad55",
        "commit_message": "fix: typo spelling",
        "commit_url": "https://github.com/keras-team/keras/commit/10b165f06ec9385ed7251b46eef22836bd04ad55",
        "buggy_code": "class_names: Only valid if \"labels\" is \"inferred\". This is the explict",
        "fixed_code": "class_names: Only valid if \"labels\" is \"inferred\". This is the explicit",
        "patch": "@@ -78,7 +78,7 @@ def text_dataset_from_directory(directory,\n             are encoded as `float32` scalars with values 0 or 1\n             (e.g. for `binary_crossentropy`).\n         - None (no labels).\n-    class_names: Only valid if \"labels\" is \"inferred\". This is the explict\n+    class_names: Only valid if \"labels\" is \"inferred\". This is the explicit\n         list of class names (must match names of subdirectories). Used\n         to control the order of the classes\n         (otherwise alphanumerical order is used)."
    },
    {
        "commit_id": "304c2d06dc7ab25d7e9bb236e2f514f94bbeb4cb",
        "commit_message": "Fix clone_model to consider input_tensors",
        "commit_url": "https://github.com/keras-team/keras/commit/304c2d06dc7ab25d7e9bb236e2f514f94bbeb4cb",
        "buggy_code": "new_input_layers[original_input_layer] = original_input_layer",
        "fixed_code": "new_input_layers[original_input_layer] = input_tensor._keras_history.layer",
        "patch": "@@ -183,7 +183,7 @@ def _clone_functional_model(model, input_tensors=None, layer_fn=_clone_layer):\n         newly_created_input_layer = input_tensor._keras_history.layer\n         new_input_layers[original_input_layer] = newly_created_input_layer\n       else:\n-        new_input_layers[original_input_layer] = original_input_layer\n+        new_input_layers[original_input_layer] = input_tensor._keras_history.layer\n \n   if not callable(layer_fn):\n     raise ValueError('Expected `layer_fn` argument to be a callable.')"
    },
    {
        "commit_id": "cb7cf4c255593fe773c9387787c9d232ceb88739",
        "commit_message": "PR #50068: Change profiler dir to non-temporary in Keras TensorBoard callback\n\nImported from GitHub PR https://github.com/tensorflow/tensorflow/pull/50068\n\nThis is to fix the issue https://github.com/tensorflow/tensorflow/issues/49852.\nWithout the fix, the profiler dir will always be deleted for non-chief node under MWMS mode when Keras TensorBoard callback(https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard) is used.\n\nPiperOrigin-RevId: 385910950",
        "commit_url": "https://github.com/keras-team/keras/commit/cb7cf4c255593fe773c9387787c9d232ceb88739",
        "buggy_code": "self._start_profiler(logdir=self._train_dir)",
        "fixed_code": "self._start_profiler(logdir=self.log_dir)",
        "patch": "@@ -2452,7 +2452,7 @@ def on_epoch_end(self, epoch, logs=None):\n \n   def _start_trace(self):\n     tf.summary.trace_on(graph=True, profiler=False)\n-    self._start_profiler(logdir=self._train_dir)\n+    self._start_profiler(logdir=self.log_dir)\n     self._is_tracing = True\n \n   def _stop_trace(self, batch=None):"
    },
    {
        "commit_id": "f6e8d5b910aa8afca0f9c4b5b9435cc356adb78c",
        "commit_message": "Fix typo in the PIP package creation script.\n\nPiperOrigin-RevId: 385838285",
        "commit_url": "https://github.com/keras-team/keras/commit/f6e8d5b910aa8afca0f9c4b5b9435cc356adb78c",
        "buggy_code": "'keras/saving/saved_model/create_test_saved_model.py'",
        "fixed_code": "'keras/saving/saved_model/create_test_saved_model.py',",
        "patch": "@@ -26,7 +26,7 @@\n     'keras/api/create_python_api_wrapper.py',\n     'keras/applications/efficientnet_weight_update_util.py',\n     'keras/distribute/tpu_strategy_test_utils.py',\n-    'keras/saving/saved_model/create_test_saved_model.py'\n+    'keras/saving/saved_model/create_test_saved_model.py',\n     'keras/tools/pip_package/setup.py',\n     'keras/tools/pip_package/create_pip_helper.py',\n ])"
    },
    {
        "commit_id": "7b52fde67845760db98e6fd2a1ef5950ffb10baf",
        "commit_message": "Merge pull request #14946 from seanmor5:patch-1\n\nPiperOrigin-RevId: 385584224",
        "commit_url": "https://github.com/keras-team/keras/commit/7b52fde67845760db98e6fd2a1ef5950ffb10baf",
        "buggy_code": "return_sequences: Boolean. Whether to return the last output.",
        "fixed_code": "return_sequences: Boolean. Whether to return the last output",
        "patch": "@@ -2706,7 +2706,7 @@ class LSTM(RNN):\n     recurrent_dropout: Float between 0 and 1.\n       Fraction of the units to drop for\n       the linear transformation of the recurrent state.\n-    return_sequences: Boolean. Whether to return the last output.\n+    return_sequences: Boolean. Whether to return the last output\n       in the output sequence, or the full sequence.\n     return_state: Boolean. Whether to return the last state\n       in addition to the output."
    },
    {
        "commit_id": "b4da9c94739f9832115a84c0f22098c47f29e533",
        "commit_message": "Fix typo in docs",
        "commit_url": "https://github.com/keras-team/keras/commit/b4da9c94739f9832115a84c0f22098c47f29e533",
        "buggy_code": "return_sequences: Boolean. Whether to return the last output.",
        "fixed_code": "return_sequences: Boolean. Whether to return the last output",
        "patch": "@@ -2706,7 +2706,7 @@ class LSTM(RNN):\n     recurrent_dropout: Float between 0 and 1.\n       Fraction of the units to drop for\n       the linear transformation of the recurrent state.\n-    return_sequences: Boolean. Whether to return the last output.\n+    return_sequences: Boolean. Whether to return the last output\n       in the output sequence, or the full sequence.\n     return_state: Boolean. Whether to return the last state\n       in addition to the output."
    },
    {
        "commit_id": "82fa47a377e4790bc9de0834d8923626829ac55f",
        "commit_message": "Merge pull request #14917 from anth2o:fix-imagenet-preprocessing-within-lambda-layer-mixed-precision\n\nPiperOrigin-RevId: 384836708",
        "commit_url": "https://github.com/keras-team/keras/commit/82fa47a377e4790bc9de0834d8923626829ac55f",
        "buggy_code": "std_tensor = backend.constant(np.array(std))",
        "fixed_code": "std_tensor = backend.constant(np.array(std), dtype=backend.dtype(x))",
        "patch": "@@ -286,7 +286,7 @@ def _preprocess_symbolic_input(x, data_format, mode):\n   else:\n     x = backend.bias_add(x, mean_tensor, data_format)\n   if std is not None:\n-    std_tensor = backend.constant(np.array(std))\n+    std_tensor = backend.constant(np.array(std), dtype=backend.dtype(x))\n     if data_format == 'channels_first':\n       std_tensor = backend.reshape(std_tensor, (-1, 1, 1))\n     x /= std_tensor"
    },
    {
        "commit_id": "c883c0a0e0c0fef186a7028861a24641ec2d214a",
        "commit_message": "Fix typo in docstrings.\n\nPiperOrigin-RevId: 384321649",
        "commit_url": "https://github.com/keras-team/keras/commit/c883c0a0e0c0fef186a7028861a24641ec2d214a",
        "buggy_code": "approximation sof the following two RBF kernels:",
        "fixed_code": "approximations of the following two RBF kernels:",
        "patch": "@@ -45,7 +45,7 @@ class RandomFourierFeatures(base_layer.Layer):\n   are sampled determines which shift-invariant kernel the layer approximates\n   (see paper for more details). You can use the distribution of your\n   choice. The layer supports out-of-the-box\n-  approximation sof the following two RBF kernels:\n+  approximations of the following two RBF kernels:\n \n   - Gaussian: `K(x, y) == exp(- square(x - y) / (2 * square(scale)))`\n   - Laplacian: `K(x, y) = exp(-abs(x - y) / scale))`"
    },
    {
        "commit_id": "26545d652488edaa0f3591635ccb436ea3ffad12",
        "commit_message": "Merge pull request #14901 from hirobf10:patch-1\n\nPiperOrigin-RevId: 384281052",
        "commit_url": "https://github.com/keras-team/keras/commit/26545d652488edaa0f3591635ccb436ea3ffad12",
        "buggy_code": "https://www.tensorflow.org/guide/estimators#creating_estimators_from_keras_models).",
        "fixed_code": "https://www.tensorflow.org/guide/estimator#create_an_estimator_from_a_keras_model).",
        "patch": "@@ -46,7 +46,7 @@ def model_to_estimator(\n \n   For usage example, please see:\n   [Creating estimators from Keras Models](\n-    https://www.tensorflow.org/guide/estimators#creating_estimators_from_keras_models).\n+    https://www.tensorflow.org/guide/estimator#create_an_estimator_from_a_keras_model).\n \n   Sample Weights:\n   Estimators returned by `model_to_estimator` are configured so that they can"
    },
    {
        "commit_id": "a1cc01da4392729bf379904ffdf6bb1706076867",
        "commit_message": "[keras/{engine/training_v1,layers/advanced_activations}.py] Fix `int` given for `float` args",
        "commit_url": "https://github.com/keras-team/keras/commit/a1cc01da4392729bf379904ffdf6bb1706076867",
        "buggy_code": "def __init__(self, max_value=None, negative_slope=0, threshold=0, **kwargs):",
        "fixed_code": "def __init__(self, max_value=None, negative_slope=.0, threshold=.0, **kwargs):",
        "patch": "@@ -406,7 +406,7 @@ class ReLU(Layer):\n       to 0.\n   \"\"\"\n \n-  def __init__(self, max_value=None, negative_slope=0, threshold=0, **kwargs):\n+  def __init__(self, max_value=None, negative_slope=.0, threshold=.0, **kwargs):\n     super(ReLU, self).__init__(**kwargs)\n     if max_value is not None and max_value < 0.:\n       raise ValueError('max_value of a ReLU layer cannot be a negative '"
    },
    {
        "commit_id": "6325142d655bac2724187fa426cb8728563c92f1",
        "commit_message": "[keras/{backend,losses,distribute/keras_premade_models_test,mixed_precision/policy_test,premade/linear_test,premade/wide_deep_test}.py] Fix `int` given for `float` args",
        "commit_url": "https://github.com/keras-team/keras/commit/6325142d655bac2724187fa426cb8728563c92f1",
        "buggy_code": ">>> x = tf.keras.backend.random_uniform_variable(shape=(2, 3), low=0, high=1)",
        "fixed_code": ">>> x = tf.keras.backend.random_uniform_variable(shape=(2, 3), low=.0, high=1.)",
        "patch": "@@ -1945,7 +1945,7 @@ def dot(x, y):\n \n   If `x` is an N-D array and `y` is an M-D array (where M>=2), it is a sum\n   product over the last axis of `x` and the second-to-last axis of `y`.\n-  >>> x = tf.keras.backend.random_uniform_variable(shape=(2, 3), low=0, high=1)\n+  >>> x = tf.keras.backend.random_uniform_variable(shape=(2, 3), low=.0, high=1.)\n   >>> y = tf.keras.backend.ones((4, 3, 5))\n   >>> xy = tf.keras.backend.dot(x, y)\n   >>> tf.keras.backend.int_shape(xy)"
    },
    {
        "commit_id": "6325142d655bac2724187fa426cb8728563c92f1",
        "commit_message": "[keras/{backend,losses,distribute/keras_premade_models_test,mixed_precision/policy_test,premade/linear_test,premade/wide_deep_test}.py] Fix `int` given for `float` args",
        "commit_url": "https://github.com/keras-team/keras/commit/6325142d655bac2724187fa426cb8728563c92f1",
        "buggy_code": "inputs = np.random.uniform(low=-5, high=5, size=(64, 2)).astype(np.float32)",
        "fixed_code": "inputs = np.random.uniform(low=-5., high=5., size=(64, 2)).astype(np.float32)",
        "patch": "@@ -46,7 +46,7 @@ def strategy_combinations_eager_data_fn():\n \n \n def get_numpy():\n-  inputs = np.random.uniform(low=-5, high=5, size=(64, 2)).astype(np.float32)\n+  inputs = np.random.uniform(low=-5., high=5., size=(64, 2)).astype(np.float32)\n   output = .3 * inputs[:, 0] + .2 * inputs[:, 1]\n   return inputs, output\n "
    },
    {
        "commit_id": "6325142d655bac2724187fa426cb8728563c92f1",
        "commit_message": "[keras/{backend,losses,distribute/keras_premade_models_test,mixed_precision/policy_test,premade/linear_test,premade/wide_deep_test}.py] Fix `int` given for `float` args",
        "commit_url": "https://github.com/keras-team/keras/commit/6325142d655bac2724187fa426cb8728563c92f1",
        "buggy_code": "self.assertEqual(repr(mp_policy.PolicyV1('float16', loss_scale=2)),",
        "fixed_code": "self.assertEqual(repr(mp_policy.PolicyV1('float16', loss_scale=2.)),",
        "patch": "@@ -60,7 +60,7 @@ def test_repr(self):\n     for policy in ('float32', 'int8', 'mixed_bfloat16', '_infer'):\n       self.assertEqual(repr(mp_policy.PolicyV1(policy)),\n                        '<PolicyV1 \"%s\", loss_scale=None>' % policy)\n-    self.assertEqual(repr(mp_policy.PolicyV1('float16', loss_scale=2)),\n+    self.assertEqual(repr(mp_policy.PolicyV1('float16', loss_scale=2.)),\n                      '<PolicyV1 \"float16\", loss_scale=FixedLossScale(2.0)>')\n     self.assertStartsWith(\n         repr(mp_policy.PolicyV1('mixed_float16')),"
    },
    {
        "commit_id": "5a61ffc52b231325eda91d2f01c7df2a99d91222",
        "commit_message": "[{activations,backend,backend_test}.py] Fix `int` given for `float` args",
        "commit_url": "https://github.com/keras-team/keras/commit/5a61ffc52b231325eda91d2f01c7df2a99d91222",
        "buggy_code": "def relu(x, alpha=0., max_value=None, threshold=0):",
        "fixed_code": "def relu(x, alpha=0., max_value=None, threshold=.0):",
        "patch": "@@ -4667,7 +4667,7 @@ def in_test_phase(x, alt, training=None):\n @keras_export('keras.backend.relu')\n @tf.__internal__.dispatch.add_dispatch_support\n @doc_controls.do_not_generate_docs\n-def relu(x, alpha=0., max_value=None, threshold=0):\n+def relu(x, alpha=0., max_value=None, threshold=.0):\n   \"\"\"Rectified linear unit.\n \n   With default values, it returns element-wise `max(x, 0)`."
    },
    {
        "commit_id": "f4254fb496508778edb7edb92342b6fe1babefc5",
        "commit_message": "Fix edge cases with class name conversion to snake case.\n\nPiperOrigin-RevId: 383939498",
        "commit_url": "https://github.com/keras-team/keras/commit/f4254fb496508778edb7edb92342b6fe1babefc5",
        "buggy_code": "intermediate = re.sub('(.)([A-Z][a-z0-9]+)', r'\\1_\\2', name)",
        "fixed_code": "intermediate = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', name)",
        "patch": "@@ -1108,7 +1108,7 @@ def to_list(x):\n \n \n def to_snake_case(name):\n-  intermediate = re.sub('(.)([A-Z][a-z0-9]+)', r'\\1_\\2', name)\n+  intermediate = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', name)\n   insecure = re.sub('([a-z])([A-Z])', r'\\1_\\2', intermediate).lower()\n   # If the class is private the name starts with \"_\" which is not secure\n   # for creating scopes. We prefix the name with \"private\" in this case."
    },
    {
        "commit_id": "7fe04bf89f94c7175c4ab4bc389e8220ff70c49d",
        "commit_message": "Add format list to image_data_from_directory \"no images found\" error.\n\nPiperOrigin-RevId: 383622099",
        "commit_url": "https://github.com/keras-team/keras/commit/7fe04bf89f94c7175c4ab4bc389e8220ff70c49d",
        "buggy_code": "raise ValueError('No images found.')",
        "fixed_code": "raise ValueError(f'No images found. Allowed formats: {ALLOWLIST_FORMATS}')",
        "patch": "@@ -204,7 +204,7 @@ def image_dataset_from_directory(directory,\n   image_paths, labels = dataset_utils.get_training_or_validation_split(\n       image_paths, labels, validation_split, subset)\n   if not image_paths:\n-    raise ValueError('No images found.')\n+    raise ValueError(f'No images found. Allowed formats: {ALLOWLIST_FORMATS}')\n \n   dataset = paths_and_labels_to_dataset(\n       image_paths=image_paths,"
    },
    {
        "commit_id": "16608a98ec2cf02476393f221c86383f10b518ed",
        "commit_message": "Fix model to estimator breakage caused by recent change.\n\nPiperOrigin-RevId: 380894633",
        "commit_url": "https://github.com/keras-team/keras/commit/16608a98ec2cf02476393f221c86383f10b518ed",
        "buggy_code": "from tensorflow_estimator.python.estimator import keras as keras_lib  # pylint: disable=g-import-not-at-top",
        "fixed_code": "from tensorflow_estimator.python.estimator import keras_lib  # pylint: disable=g-import-not-at-top",
        "patch": "@@ -160,7 +160,7 @@ def input_fn():\n   \"\"\"\n \n   try:\n-    from tensorflow_estimator.python.estimator import keras as keras_lib  # pylint: disable=g-import-not-at-top\n+    from tensorflow_estimator.python.estimator import keras_lib  # pylint: disable=g-import-not-at-top\n   except ImportError:\n     raise NotImplementedError(\n         'tf.keras.estimator.model_to_estimator function not available in your '"
    },
    {
        "commit_id": "472877be4e2f348527053e302e415913d20baf28",
        "commit_message": "fix build",
        "commit_url": "https://github.com/keras-team/keras/commit/472877be4e2f348527053e302e415913d20baf28",
        "buggy_code": "return (deserialize_model_from_bytecode, *serialize_model_as_bytecode(self))",
        "fixed_code": "return (deserialize_model_from_bytecode, serialize_model_as_bytecode(self))",
        "patch": "@@ -323,7 +323,7 @@ def __setattr__(self, name, value):\n     super(Model, self).__setattr__(name, value)\n \n   def __reduce__(self):\n-    return (deserialize_model_from_bytecode, *serialize_model_as_bytecode(self))\n+    return (deserialize_model_from_bytecode, serialize_model_as_bytecode(self))\n \n   def __deepcopy__(self, memo):\n     if self.built:"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import six\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl import flags\n from absl.testing import parameterized"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -23,7 +23,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from keras import backend\n from keras.applications import imagenet_utils"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -24,7 +24,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import copy\n import math"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -41,7 +41,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import argparse\n import warnings"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -25,7 +25,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from keras import backend\n from keras.applications import imagenet_utils"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -23,7 +23,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from keras import backend\n from keras.applications import imagenet_utils"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -65,7 +65,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from keras import backend\n from keras.applications import imagenet_utils"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -77,7 +77,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from keras import backend\n from keras.applications import imagenet_utils"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -19,7 +19,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n \n from keras import backend"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -41,7 +41,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from keras import backend\n from keras.applications import imagenet_utils"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -23,7 +23,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from keras import backend\n from keras.applications import imagenet_utils"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -23,7 +23,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from keras import backend\n from keras.applications import imagenet_utils"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -23,7 +23,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from keras import backend\n from keras.applications import imagenet_utils"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -27,7 +27,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from keras import backend\n from keras.applications import imagenet_utils"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -21,7 +21,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import collections\n import itertools"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from tensorflow.python.util.tf_export import keras_export\n \n # The type of float to use throughout a session."
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from keras import backend\n from keras import backend_config"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import gc\n import warnings"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import timeit\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from keras.benchmarks import benchmark_util\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -22,7 +22,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import time\n import six"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n import six"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from keras.benchmarks import benchmark_util\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from keras.benchmarks import benchmark_util\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from keras.benchmarks import benchmark_util\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import timeit\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from keras.benchmarks import benchmark_util\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from keras.benchmarks import benchmark_util\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from keras.benchmarks import benchmark_util\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import functools\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import time\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import time\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -23,7 +23,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl import app\n from absl import flags"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from keras.benchmarks import benchmark_util\n from keras.optimizer_v2 import adam"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras.benchmarks.saved_model_benchmarks import saved_model_benchmark_util\n \n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras.benchmarks.saved_model_benchmarks import saved_model_benchmark_util\n \n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras.benchmarks.saved_model_benchmarks import saved_model_benchmark_util\n \n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras.benchmarks.saved_model_benchmarks import saved_model_benchmark_util\n \n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras.benchmarks.saved_model_benchmarks import saved_model_benchmark_util\n \n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras.benchmarks.saved_model_benchmarks import saved_model_benchmark_util\n \n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import tempfile\n import time"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras.benchmarks.saved_model_benchmarks import saved_model_benchmark_util\n \n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras.benchmarks.saved_model_benchmarks import saved_model_benchmark_util\n \n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -20,7 +20,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import collections\n import copy"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import collections\n import csv"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -19,7 +19,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n import shutil"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import functools\n from keras import testing_utils"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import unittest\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -19,7 +19,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import six\n from keras import backend as K"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import math\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n from keras import layers"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -19,7 +19,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n from tensorflow.python.distribute import values"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -48,7 +48,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras import backend\n \n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from keras import callbacks\n from keras.distribute import distributed_training_utils_v1"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import functools\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import functools\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n import keras"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n import keras"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n from keras import metrics"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n import keras"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras import testing_utils\n from keras.distribute import saved_model_test_base as test_base\n from keras.saving import save"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n import keras"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import collections\n import tempfile"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n import numpy"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from tensorflow.python.distribute import combinations as ds_combinations\n from tensorflow.python.distribute import distribute_utils\n from keras.layers import core"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras.distribute import simple_models\n \n simple_functional_model = tf.__internal__.test.combinations.NamedObject("
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import json\n import os"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import collections\n import copy"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n import keras\n from keras.optimizer_v2 import gradient_descent\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras.optimizer_v2 import adadelta as adadelta_keras_v2\n from keras.optimizer_v2 import adagrad as adagrad_keras_v2\n from keras.optimizer_v2 import adam as adam_keras_v2"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -19,7 +19,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import random\n import tempfile"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -24,7 +24,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras import testing_utils\n from keras.distribute import saved_model_test_base as test_base\n from keras.saving import save"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n from keras import testing_utils"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from tensorflow.python.distribute import sharded_variable\n from keras.engine import base_layer\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -19,7 +19,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import re\n from tensorflow.python.platform import tf_logging as logging"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -19,7 +19,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -13,7 +13,7 @@\n # limitations under the License.\n # ==============================================================================\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \"\"\"Strategy combinations for combinations.combine().\"\"\"\n \n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras.optimizer_v2 import optimizer_v2\n \n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -19,7 +19,7 @@\n from __future__ import google_type_annotations\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl import flags\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n from keras import backend as K"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n import os\n import sys\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import collections\n import copy"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import copy\n import os"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import functools\n import threading"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -16,7 +16,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import collections\n import functools"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import abc\n import collections"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import json\n import os"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n from keras import backend as K"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import copy\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras import backend as K\n from keras import keras_parameterized\n from keras import losses as losses_mod"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import abc\n import contextlib"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import math\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n import unittest"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -19,7 +19,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import collections\n import copy"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import warnings\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -19,7 +19,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras import backend\n from keras.distribute import distributed_training_utils\n from keras.engine import base_layer"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from tensorflow.python.framework import type_spec\n from keras import combinations\n from keras import keras_parameterized"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from six.moves import zip  # pylint: disable=redefined-builtin\n from keras import backend"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from keras.engine import input_spec\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras.utils import object_identity\n \n # pylint: disable=g-classes-have-attributes"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras import layers\n from keras.engine import keras_tensor\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import collections\n import copy"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from keras import keras_parameterized\n from keras.engine import base_layer"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n import six"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n from keras import keras_parameterized"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -19,7 +19,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import copy\n import warnings"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import copy\n import itertools"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import sys\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -19,7 +19,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import functools\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import sys\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -19,7 +19,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -19,7 +19,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import itertools\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -19,7 +19,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import functools\n import math"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import collections\n import itertools"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import collections\n import io"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n from keras.utils import generic_utils"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import abc\n import atexit"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import functools\n import multiprocessing.pool"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import collections\n import warnings"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from tensorflow.python.util.tf_export import keras_export\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -21,7 +21,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n \n from tensorflow.python.feature_column import feature_column_v2"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from tensorflow.python.feature_column import feature_column_v2 as fc\n from keras.feature_column import base_feature_layer as kfc"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n from tensorflow.python.eager import backprop"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -21,7 +21,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from tensorflow.python.feature_column import feature_column_v2 as fc\n from keras import backend"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n \n from google.protobuf import text_format"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n \n from absl.testing import parameterized"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import threading\n import six"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from tensorflow.python.util.tf_export import keras_export\n \n keras_export(v1=['keras.initializers.Zeros', 'keras.initializers.zeros'], allow_multiple_exports=True)("
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -19,7 +19,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import math\n from keras import backend"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import collections.abc as collections_abc\n import functools"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import unittest\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from tensorflow.python import tf2\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras import backend as K\n from keras import constraints\n from keras import initializers"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -19,7 +19,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import functools\n import six"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -19,7 +19,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import copy\n import functools"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import textwrap\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import collections\n from keras import backend as K"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n import tempfile"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -22,7 +22,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras import backend as K\n from keras.engine.base_layer import Layer\n from keras.utils import control_flow_util"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import re\n from keras import activations"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from tensorflow.python.distribute import sharded_variable\n from keras import backend as K"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import copy\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import copy\n import os"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -19,7 +19,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n import six"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import functools\n import math"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -19,7 +19,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras import layers\n \n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -24,7 +24,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import collections\n import warnings"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import hashlib\n import numbers"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import copy\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import copy\n import os"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -20,7 +20,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from keras import backend as K\n from keras.engine import base_layer_utils"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -19,7 +19,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import collections\n import math"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from tensorflow.python.framework import ops\n from tensorflow.python.framework import tensor_shape\n from keras import backend as K"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras import backend\n from keras.layers import normalization\n from tensorflow.python.util.tf_export import keras_export"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n \n # TODO(b/157913406): Expose this publicly."
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import functools\n from keras import backend"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import itertools\n import time"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import time\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import time\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import itertools\n import random"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import functools\n import time"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import collections\n import itertools"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n import random"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import time\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import itertools\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n from keras import keras_parameterized"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n from keras import backend as K"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n \n from absl.testing import parameterized"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import collections\n import json"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import functools\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n from keras import keras_parameterized"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n from keras import backend as K"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import collections\n import json"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import itertools\n import os"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n \n from keras.engine import base_preprocessing_layer_v1"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras.engine import base_preprocessing_layer\n from keras.layers.preprocessing import index_lookup\n from keras.layers.preprocessing import table_utils"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import itertools\n import os"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n from keras import backend as K"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import json\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n from keras.engine import base_preprocessing_layer"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import time\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import time\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import collections.abc as collections_abc\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -19,7 +19,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from keras.engine.base_layer import Layer\n from tensorflow.python.platform import tf_logging as logging"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras.engine import base_preprocessing_layer\n from keras.layers.preprocessing import index_lookup\n from keras.layers.preprocessing import table_utils"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import collections\n import os"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n import tempfile"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n from keras import backend as K"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -19,7 +19,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import collections\n import warnings"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -21,7 +21,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import collections\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import uuid\n from tensorflow.python.eager import function"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -21,7 +21,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n from absl.testing import parameterized"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -21,7 +21,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import threading\n from keras.engine import base_layer"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import copy\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import keras\n from keras import keras_parameterized"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import time\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -19,7 +19,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import copy\n from keras import backend as K"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import copy\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import copy\n import functools"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import copy\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -19,7 +19,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import warnings\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n from keras.legacy_tf_layers import convolutional as conv_layers"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -21,7 +21,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import warnings\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import collections\n import platform"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -19,7 +19,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import warnings\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from tensorflow.python.framework import test_util\n from keras.legacy_tf_layers import pooling as pooling_layers"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import abc\n import functools"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -20,7 +20,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import abc\n import types"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import json\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import json\n import math"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import threading\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n import threading"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import itertools\n from tensorflow.python.platform import tf_logging"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import re\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from keras.engine import base_layer_utils\n from keras.layers import core"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -21,7 +21,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import six\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import time\n from keras.mixed_precision import loss_scale_optimizer"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from tensorflow.python.framework import ops\n from tensorflow.python.framework import smart_cond\n from keras import backend"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n from keras import combinations"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import contextlib\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n from keras import combinations"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras import regularizers\n from keras.engine import base_layer\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -19,7 +19,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras import backend as K\n from keras import metrics as metrics_module\n from keras import optimizer_v1"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import functools\n import os"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -22,7 +22,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from six.moves import zip  # pylint: disable=redefined-builtin\n from keras import backend as K"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n from keras import backend_config"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n from keras import backend_config"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import copy\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras import backend_config\n from keras.optimizer_v2 import optimizer_v2\n from tensorflow.python.util.tf_export import keras_export"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras import backend_config\n from keras.optimizer_v2 import optimizer_v2\n from tensorflow.python.util.tf_export import keras_export"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from keras.optimizer_v2 import optimizer_v2\n from tensorflow.python.util.tf_export import keras_export"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n from keras.optimizer_v2 import ftrl"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras.optimizer_v2 import optimizer_v2\n from tensorflow.python.util.tf_export import keras_export\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import abc\n import math"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import math\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import functools\n from keras.optimizer_v2 import learning_rate_schedule"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import math\n from keras import combinations"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras import backend_config\n from keras.optimizer_v2 import learning_rate_schedule\n from keras.optimizer_v2 import optimizer_v2"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n from keras.optimizer_v2 import nadam"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -19,7 +19,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import abc\n import contextlib"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import collections\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n from keras import backend_config"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import copy\n import itertools"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from tensorflow.python.platform import tf_logging as logging\n \n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -21,7 +21,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import six\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import gc\n import weakref"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras import activations\n from keras import initializers\n from keras import regularizers"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n from keras import backend"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras import activations\n from keras import backend as K\n from keras import layers as layer_module"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n from keras import keras_parameterized"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import multiprocessing\n import os"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -21,7 +21,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from keras_preprocessing import image\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n from keras.layers.preprocessing import image_preprocessing"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n import shutil"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n import shutil"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from math import ceil\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n from keras.preprocessing import dataset_utils"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n import random"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -19,7 +19,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n from tensorflow.python.util.tf_export import keras_export"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n from keras.preprocessing import timeseries"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -19,7 +19,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import math\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -19,7 +19,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import json\n import os"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n import shutil"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n import shutil"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import six\n from keras.saving import hdf5_format"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import collections\n import os"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n import shutil"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import abc\n import six"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -25,7 +25,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import collections.abc as collections_abc\n import enum"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -19,7 +19,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import enum\n from keras.saving.saved_model import json_utils"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from keras.mixed_precision import policy\n from keras.saving.saved_model import base_serialization"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n import re"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -24,7 +24,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import shutil\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -21,7 +21,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import functools\n import weakref"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -24,7 +24,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n import shutil"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from tensorflow.python.eager import def_function\n from tensorflow.python.eager import function as defun"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import itertools\n import threading"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n import warnings"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n import shutil"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import collections.abc as collections_abc\n import copy"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import collections\n import contextlib"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n from keras import Input"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n import numpy as np"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from keras import keras_parameterized\n from keras.engine import sequential"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n from tensorflow.core.protobuf import meta_graph_pb2"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n import random"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import keras\n from tensorflow.python.framework.memory_checker import MemoryChecker"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -24,7 +24,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import keras\n from tensorflow.python.eager.memory_tests import memory_test_util"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n import shutil"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import copy\n import os"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n import sys"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import functools\n import os"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import json\n from keras import combinations"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -16,7 +16,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -16,7 +16,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import functools\n import os"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import functools\n import os"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -16,7 +16,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from tensorflow.compiler.tests import xla_test\n from keras.engine import training"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -22,7 +22,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from tensorflow.python.framework import smart_cond as smart_module\n \n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import itertools\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import itertools\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -19,7 +19,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from abc import abstractmethod\n from contextlib import closing"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from itertools import cycle\n import os"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n \n class DatasetCreator(object):"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from tensorflow.python.distribute import multi_worker_test_base\n from tensorflow.python.distribute.cluster_resolver import SimpleClusterResolver\n from keras.engine import sequential"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import binascii\n import codecs"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from functools import partial\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import sys\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n \n def _to_matrix(u):"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import functools\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import random\n import tempfile"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -19,7 +19,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import functools\n import weakref"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import collections\n import contextlib"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras import backend as K\n from keras.engine import keras_tensor\n from tensorflow.python.util.tf_export import keras_export"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras import combinations\n from keras.utils import losses_utils\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -19,7 +19,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import functools\n import weakref"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n from keras import combinations"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras import backend as K\n from keras.engine.training import Model\n from keras.layers.core import Lambda"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n import keras"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import contextlib as _contextlib\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import collections\n import functools"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -17,7 +17,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import collections\n import copy"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl.testing import parameterized\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras.utils.generic_utils import LazyLoader\n \n # TODO(b/134426265): Switch back to single-quotes once the issue"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import abc\n "
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -19,7 +19,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n import sys"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import keras\n from keras.utils import vis_utils"
    },
    {
        "commit_id": "0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "commit_message": "Update keras to import tensorflow.compat.v2 as tf.\n\nThis is to avoid issue when tf is build with tf_api_version=1.\n\nThe existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.\n\nPiperOrigin-RevId: 358446889",
        "commit_url": "https://github.com/keras-team/keras/commit/0f8da5a7b814cb37baba868fc11fe8b10b3d4cf8",
        "buggy_code": "import tensorflow as tf",
        "fixed_code": "import tensorflow.compat.v2 as tf",
        "patch": "@@ -18,7 +18,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n "
    },
    {
        "commit_id": "1a3ee8441933fc007be6b2beb47af67998d50737",
        "commit_message": "Bump version number for patch release",
        "commit_url": "https://github.com/keras-team/keras/commit/1a3ee8441933fc007be6b2beb47af67998d50737",
        "buggy_code": "__version__ = '2.4.2'",
        "fixed_code": "__version__ = '2.4.3'",
        "patch": "@@ -29,4 +29,4 @@\n from .models import Model\r\n from .models import Sequential\r\n \r\n-__version__ = '2.4.2'\r\n+__version__ = '2.4.3'\r"
    },
    {
        "commit_id": "7a39b6c62d43c25472b2c2476bd2a8983ae4f682",
        "commit_message": "Fix too many values to unpack error (#13511)\n\n* fix too many values to unpack error\r\n\r\nIn the example script lstm_seq2seq_restore.py and lstm_seq2seq.py, when\r\nparse the data using line.split(\"\\t\"), it will return 3 values rather than\r\n2, a simple modification can fix it.\r\n\r\n* add blankspace around operator",
        "commit_url": "https://github.com/keras-team/keras/commit/7a39b6c62d43c25472b2c2476bd2a8983ae4f682",
        "buggy_code": "input_text, target_text = line.split('\\t')",
        "fixed_code": "input_text, target_text, _ = line.split('\\t')",
        "patch": "@@ -70,7 +70,7 @@\n with open(data_path, 'r', encoding='utf-8') as f:\n     lines = f.read().split('\\n')\n for line in lines[: min(num_samples, len(lines) - 1)]:\n-    input_text, target_text = line.split('\\t')\n+    input_text, target_text, _ = line.split('\\t')\n     # We use \"tab\" as the \"start sequence\" character\n     # for the targets, and \"\\n\" as \"end sequence\" character.\n     target_text = '\\t' + target_text + '\\n'"
    },
    {
        "commit_id": "7a39b6c62d43c25472b2c2476bd2a8983ae4f682",
        "commit_message": "Fix too many values to unpack error (#13511)\n\n* fix too many values to unpack error\r\n\r\nIn the example script lstm_seq2seq_restore.py and lstm_seq2seq.py, when\r\nparse the data using line.split(\"\\t\"), it will return 3 values rather than\r\n2, a simple modification can fix it.\r\n\r\n* add blankspace around operator",
        "commit_url": "https://github.com/keras-team/keras/commit/7a39b6c62d43c25472b2c2476bd2a8983ae4f682",
        "buggy_code": "input_text, target_text = line.split('\\t')",
        "fixed_code": "input_text, target_text, _ = line.split('\\t')",
        "patch": "@@ -33,7 +33,7 @@\n with open(data_path, 'r', encoding='utf-8') as f:\n     lines = f.read().split('\\n')\n for line in lines[: min(num_samples, len(lines) - 1)]:\n-    input_text, target_text = line.split('\\t')\n+    input_text, target_text, _ = line.split('\\t')\n     # We use \"tab\" as the \"start sequence\" character\n     # for the targets, and \"\\n\" as \"end sequence\" character.\n     target_text = '\\t' + target_text + '\\n'"
    },
    {
        "commit_id": "ecac367b2372b5f2326fcd3ddd11718323427f4e",
        "commit_message": "Fix h5py group naming while model saving (#13477)",
        "commit_url": "https://github.com/keras-team/keras/commit/ecac367b2372b5f2326fcd3ddd11718323427f4e",
        "buggy_code": "@pytest.mark.skipif(K.backend() != 'tensorflow', reason='requires tensorflow')",
        "fixed_code": "@pytest.mark.skipif(True, reason='It is a flaky test, see #13477 for more context.')",
        "patch": "@@ -80,7 +80,7 @@ def test_sensitivity_metrics():\n     model.evaluate(x, y)\n \n \n-@pytest.mark.skipif(K.backend() != 'tensorflow', reason='requires tensorflow')\n+@pytest.mark.skipif(True, reason='It is a flaky test, see #13477 for more context.')\n def test_mean_iou():\n     import tensorflow as tf\n     if not tf.__version__.startswith('2.'):"
    },
    {
        "commit_id": "f2bbf98b1b48213c16c8e94807d5435817d797ad",
        "commit_message": "Fix issue where the disable_tracking decorator obfuscates layer constructors.",
        "commit_url": "https://github.com/keras-team/keras/commit/f2bbf98b1b48213c16c8e94807d5435817d797ad",
        "buggy_code": "from ..engine.base_layer import Layer, InputSpec, disable_tracking",
        "fixed_code": "from ..engine.base_layer import Layer, InputSpec",
        "patch": "@@ -5,7 +5,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-from ..engine.base_layer import Layer, InputSpec, disable_tracking\n+from ..engine.base_layer import Layer, InputSpec\n from .. import initializers\n from .. import regularizers\n from .. import constraints"
    },
    {
        "commit_id": "04cbccc8038c105374eef6eb2ce96d6746999860",
        "commit_message": "fix #13341 math_ops to K (#13342)",
        "commit_url": "https://github.com/keras-team/keras/commit/04cbccc8038c105374eef6eb2ce96d6746999860",
        "buggy_code": "mask = math_ops.cast(mask, y_pred.dtype)",
        "fixed_code": "mask = K.cast(mask, y_pred.dtype)",
        "patch": "@@ -1019,7 +1019,7 @@ def call_metric_function(metric_fn,\n                          mask=None):\n     \"\"\"Invokes metric function and returns the metric result tensor.\"\"\"\n     if mask is not None:\n-        mask = math_ops.cast(mask, y_pred.dtype)\n+        mask = K.cast(mask, y_pred.dtype)\n         if weights is None:\n             # Use mask as sample weight.\n             weights = mask"
    },
    {
        "commit_id": "1eac861262d00618e490d50a9db9f69572bd3300",
        "commit_message": "fix in \"Layer.compute_output_shape\" description (#13210)",
        "commit_url": "https://github.com/keras-team/keras/commit/1eac861262d00618e490d50a9db9f69572bd3300",
        "buggy_code": "An input shape tuple.",
        "fixed_code": "An output shape tuple.",
        "patch": "@@ -618,7 +618,7 @@ def compute_output_shape(self, input_shape):\n                 instead of an integer.\n \n         # Returns\n-            An input shape tuple.\n+            An output shape tuple.\n         \"\"\"\n         return input_shape\n "
    },
    {
        "commit_id": "da289bb337ea2639cb03d162574aaeb94f58e928",
        "commit_message": "Fix py2 test",
        "commit_url": "https://github.com/keras-team/keras/commit/da289bb337ea2639cb03d162574aaeb94f58e928",
        "buggy_code": "assert np.allclose(K.eval(result), expected_result, atol=1e-3)",
        "fixed_code": "assert np.allclose(K.eval(result), float(expected_result), atol=1e-3)",
        "patch": "@@ -917,7 +917,7 @@ def test_unweighted(self):\n         # sum_row = [2, 2], sum_col = [2, 2], true_positives = [1, 1]\n         # iou = true_positives / (sum_row + sum_col - true_positives))\n         expected_result = (1 / (2 + 2 - 1) + 1 / (2 + 2 - 1)) / 2\n-        assert np.allclose(K.eval(result), expected_result, atol=1e-3)\n+        assert np.allclose(K.eval(result), float(expected_result), atol=1e-3)\n \n     def test_weighted(self):\n         y_pred = K.constant([0, 1, 0, 1], dtype='float32')"
    },
    {
        "commit_id": "388cbf171d79933522560296368ff1b64cf60537",
        "commit_message": "Fix Theano tests.",
        "commit_url": "https://github.com/keras-team/keras/commit/388cbf171d79933522560296368ff1b64cf60537",
        "buggy_code": "assert history.history['val_accuracy'][-1] > 0.75",
        "fixed_code": "assert history.history['val_accuracy'][-1] > 0.70",
        "patch": "@@ -72,7 +72,7 @@ def test_image_data_generator_training():\n                                   validation_data=img_gen.flow(x_test, y_test,\n                                                                batch_size=16),\n                                   verbose=0)\n-    assert history.history['val_accuracy'][-1] > 0.75\n+    assert history.history['val_accuracy'][-1] > 0.70\n     model.evaluate_generator(img_gen.flow(x_train, y_train, batch_size=16))\n \n "
    },
    {
        "commit_id": "6bb3fb7c9d853dec1c4dc8564debeb426b13cd30",
        "commit_message": "Fix some bugs",
        "commit_url": "https://github.com/keras-team/keras/commit/6bb3fb7c9d853dec1c4dc8564debeb426b13cd30",
        "buggy_code": "mask, _, weights = tf_losses_utils.squeeze_or_expand_dimensions(",
        "fixed_code": "mask, _, weights = losses_utils.squeeze_or_expand_dimensions(",
        "patch": "@@ -1025,7 +1025,7 @@ def call_metric_function(metric_fn,\n             weights = mask\n         else:\n             # Update dimensions of weights to match with mask.\n-            mask, _, weights = tf_losses_utils.squeeze_or_expand_dimensions(\n+            mask, _, weights = losses_utils.squeeze_or_expand_dimensions(\n                 mask, sample_weight=weights)\n             weights *= mask\n "
    },
    {
        "commit_id": "8de897a0f448757f96a5e6417180d3b9ae9227c0",
        "commit_message": "Fix metrics reporting /  accumulation with fit_generator and evaluate_generator.",
        "commit_url": "https://github.com/keras-team/keras/commit/8de897a0f448757f96a5e6417180d3b9ae9227c0",
        "buggy_code": "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)",
        "fixed_code": "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)",
        "patch": "@@ -56,7 +56,7 @@\n model.add(Activation('softmax'))\n \n # initiate RMSprop optimizer\n-opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n+opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n \n # Let's train the model using RMSprop\n model.compile(loss='categorical_crossentropy',"
    },
    {
        "commit_id": "655cfd33494ee45c80bcac4d57c41e7b516f5e4c",
        "commit_message": "Fix theano backend",
        "commit_url": "https://github.com/keras-team/keras/commit/655cfd33494ee45c80bcac4d57c41e7b516f5e4c",
        "buggy_code": "return isinstance(x, (T.TensorVariable, T.TensorSharedVariable))",
        "fixed_code": "return isinstance(x, theano.tensor.sharedvar.TensorSharedVariable)",
        "patch": "@@ -155,7 +155,7 @@ def variable(value, dtype=None, name=None, constraint=None):\n \n \n def is_variable(x):\n-    return isinstance(x, (T.TensorVariable, T.TensorSharedVariable))\n+    return isinstance(x, theano.tensor.sharedvar.TensorSharedVariable)\n \n \n def constant(value, dtype=None, shape=None, name=None):"
    },
    {
        "commit_id": "d4fe07cbf4b3633670db0991ff4cb9d845235bc2",
        "commit_message": "Fix docs test",
        "commit_url": "https://github.com/keras-team/keras/commit/d4fe07cbf4b3633670db0991ff4cb9d845235bc2",
        "buggy_code": "MIN_CODE_SIZE = 12",
        "fixed_code": "MIN_CODE_SIZE = 15",
        "patch": "@@ -19,7 +19,7 @@\n accepted_module = ['keras.legacy.layers', 'keras.utils.generic_utils']\n \n # Functions or classes with less than 'MIN_CODE_SIZE' lines can be ignored\n-MIN_CODE_SIZE = 12\n+MIN_CODE_SIZE = 15\n \n \n def handle_class_init(name, member):"
    },
    {
        "commit_id": "2ccb69dfb46688feed5a06f19fef526f2d8bc884",
        "commit_message": "Fix",
        "commit_url": "https://github.com/keras-team/keras/commit/2ccb69dfb46688feed5a06f19fef526f2d8bc884",
        "buggy_code": "with K.control_dependencies([update_op]):  # For TF",
        "fixed_code": "with K.control_dependencies(update_op):  # For TF",
        "patch": "@@ -79,7 +79,7 @@ def __call__(self, *args, **kwargs):\n             raise RuntimeError(\n                 'Metric calling only supported with TensorFlow backend.')\n         update_op = self.update_state(*args, **kwargs)\n-        with K.control_dependencies([update_op]):  # For TF\n+        with K.control_dependencies(update_op):  # For TF\n             return self.result()\n \n     def get_config(self):"
    },
    {
        "commit_id": "ebe3f30f1122a97d4d88855ab5a73618332d81b2",
        "commit_message": "Fix integration tests",
        "commit_url": "https://github.com/keras-team/keras/commit/ebe3f30f1122a97d4d88855ab5a73618332d81b2",
        "buggy_code": "assert history.history['val_acc'][-1] >= target",
        "fixed_code": "assert history.history['val_accuracy'][-1] >= target",
        "patch": "@@ -41,7 +41,7 @@ def test_tf_optimizer():\n                   metrics=['accuracy'])\n     history = model.fit(x_train, y_train, epochs=8, batch_size=16,\n                         validation_data=(x_test, y_test), verbose=2)\n-    assert history.history['val_acc'][-1] >= target\n+    assert history.history['val_accuracy'][-1] >= target\n \n     # Test saving.\n     _, fname = tempfile.mkstemp('.h5')"
    },
    {
        "commit_id": "c714efa31658ef43eaddc7b9c4340cb915bf8211",
        "commit_message": "Fix a number of tests.",
        "commit_url": "https://github.com/keras-team/keras/commit/c714efa31658ef43eaddc7b9c4340cb915bf8211",
        "buggy_code": "MIN_CODE_SIZE = 10",
        "fixed_code": "MIN_CODE_SIZE = 12",
        "patch": "@@ -15,7 +15,7 @@\n accepted_module = ['keras.legacy.layers', 'keras.utils.generic_utils']\n \n # Functions or classes with less than 'MIN_CODE_SIZE' lines can be ignored\n-MIN_CODE_SIZE = 10\n+MIN_CODE_SIZE = 12\n \n \n def handle_class_init(name, member):"
    },
    {
        "commit_id": "c714efa31658ef43eaddc7b9c4340cb915bf8211",
        "commit_message": "Fix a number of tests.",
        "commit_url": "https://github.com/keras-team/keras/commit/c714efa31658ef43eaddc7b9c4340cb915bf8211",
        "buggy_code": "np.random.seed(1338)",
        "fixed_code": "np.random.seed(1337)",
        "patch": "@@ -180,7 +180,7 @@ def test_masked_temporal():\n     The ground-truth best cross-entropy loss should, then be -log(0.5) = 0.69\n \n     '''\n-    np.random.seed(1338)\n+    np.random.seed(1337)\n \n     model = Sequential()\n     model.add(layers.Embedding(10, 10, mask_zero=True))"
    },
    {
        "commit_id": "eab1b5bcdf105746ede02d2eb8a5cb3ca359b1b5",
        "commit_message": "Fix CNTK test.",
        "commit_url": "https://github.com/keras-team/keras/commit/eab1b5bcdf105746ede02d2eb8a5cb3ca359b1b5",
        "buggy_code": "@pytest.mark.skipif(K.backend() == 'ctnk',",
        "fixed_code": "@pytest.mark.skipif(K.backend() == 'cntk',",
        "patch": "@@ -840,7 +840,7 @@ def test_constant_initializer_with_numpy():\n     model_from_yaml(yaml_str).summary()\n \n \n-@pytest.mark.skipif(K.backend() == 'ctnk',\n+@pytest.mark.skipif(K.backend() == 'cntk',\n                     reason='Float64 not supported with CNTK.')\n def test_initialization_dtype():\n     class TestLayer(Layer):"
    },
    {
        "commit_id": "510f9f0b1d97ca3567c858e0300c913a4bc2bf53",
        "commit_message": "Fix conv_rnn bug with cntk/theano",
        "commit_url": "https://github.com/keras-team/keras/commit/510f9f0b1d97ca3567c858e0300c913a4bc2bf53",
        "buggy_code": "K.zeros(tuple(shape))",
        "fixed_code": "kernel = K.zeros(tuple(shape))",
        "patch": "@@ -254,7 +254,7 @@ def get_initial_state(self, inputs):\n             import tensorflow as tf\n             kernel = tf.zeros(tuple(shape))\n         else:\n-            K.zeros(tuple(shape))\n+            kernel = K.zeros(tuple(shape))\n         initial_state = self.cell.input_conv(initial_state,\n                                              kernel,\n                                              padding=self.cell.padding)"
    },
    {
        "commit_id": "47e1b18c0b7e3ddeef4e9fcded409a55d0479a4f",
        "commit_message": "fix doc (#12836)",
        "commit_url": "https://github.com/keras-team/keras/commit/47e1b18c0b7e3ddeef4e9fcded409a55d0479a4f",
        "buggy_code": ">>> from keras.data_utils import _hash_file",
        "fixed_code": ">>> from keras.utils.data_utils import _hash_file",
        "patch": "@@ -250,7 +250,7 @@ def _hash_file(fpath, algorithm='sha256', chunk_size=65535):\n     # Example\n \n     ```python\n-        >>> from keras.data_utils import _hash_file\n+        >>> from keras.utils.data_utils import _hash_file\n         >>> _hash_file('/path/to/file.zip')\n         'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855'\n     ```"
    },
    {
        "commit_id": "34231971fa47cb2477b357c1a368978de4128294",
        "commit_message": "Fix datasets.",
        "commit_url": "https://github.com/keras-team/keras/commit/34231971fa47cb2477b357c1a368978de4128294",
        "buggy_code": "with np.load(path) as f:",
        "fixed_code": "with np.load(path, allow_pickle=True) as f:",
        "patch": "@@ -26,7 +26,7 @@ def load_data(path='boston_housing.npz', test_split=0.2, seed=113):\n         path,\n         origin='https://s3.amazonaws.com/keras-datasets/boston_housing.npz',\n         file_hash='f553886a1f8d56431e820c5b82552d9d95cfcb96d1e678153f8839538947dff5')\n-    with np.load(path) as f:\n+    with np.load(path, allow_pickle=True) as f:\n         x = f['x']\n         y = f['y']\n "
    },
    {
        "commit_id": "34231971fa47cb2477b357c1a368978de4128294",
        "commit_message": "Fix datasets.",
        "commit_url": "https://github.com/keras-team/keras/commit/34231971fa47cb2477b357c1a368978de4128294",
        "buggy_code": "with np.load(path) as f:",
        "fixed_code": "with np.load(path, allow_pickle=True) as f:",
        "patch": "@@ -21,7 +21,7 @@ def load_data(path='mnist.npz'):\n     path = get_file(path,\n                     origin='https://s3.amazonaws.com/img-datasets/mnist.npz',\n                     file_hash='8a61469f7ea1b51cbae51d4f78837e45')\n-    with np.load(path) as f:\n+    with np.load(path, allow_pickle=True) as f:\n         x_train, y_train = f['x_train'], f['y_train']\n         x_test, y_test = f['x_test'], f['y_test']\n     return (x_train, y_train), (x_test, y_test)"
    },
    {
        "commit_id": "34231971fa47cb2477b357c1a368978de4128294",
        "commit_message": "Fix datasets.",
        "commit_url": "https://github.com/keras-team/keras/commit/34231971fa47cb2477b357c1a368978de4128294",
        "buggy_code": "with np.load(path) as f:",
        "fixed_code": "with np.load(path, allow_pickle=True) as f:",
        "patch": "@@ -53,7 +53,7 @@ def load_data(path='reuters.npz', num_words=None, skip_top=0,\n     path = get_file(path,\n                     origin='https://s3.amazonaws.com/text-datasets/reuters.npz',\n                     file_hash='87aedbeb0cb229e378797a632c1997b6')\n-    with np.load(path) as f:\n+    with np.load(path, allow_pickle=True) as f:\n         xs, labels = f['x'], f['y']\n \n     rng = np.random.RandomState(seed)"
    },
    {
        "commit_id": "9416f3647ac4c9ec0c57575a66d66aeac077d56c",
        "commit_message": "Fix np.load call for np v1.16.3 (#12714)\n\nNumpy 1.16.3 changed the default value for the allow_pickle flag.\r\n\r\nSo this load call breaks.\r\n\r\nhttps://nvd.nist.gov/vuln/detail/CVE-2019-6446\r\n\r\nhttps://github.com/numpy/numpy/blob/v1.16.2/numpy/lib/npyio.py#L288\r\nhttps://github.com/numpy/numpy/blob/v1.16.3/numpy/lib/npyio.py#L292\r\n\r\nnp.__version__ = 1.16.3\r\nkeras.version = 2.2.4\r\nkeras.datasets.imdb.load_data()          \r\n\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-2-154d5969a0d5> in <module>\r\n----> 1 k.datasets.imdb.load_data()\r\n\r\n~/venv3/lib/python3.6/site-packages/keras/datasets/imdb.py in load_data(path, num_words, skip_top, maxlen, seed, start_char, oov_char, index_from, **kwargs)\r\n     57                     file_hash='599dadb1135973df5b59232a0e9a887c')\r\n     58     with np.load(path) as f:\r\n---> 59         x_train, labels_train = f['x_train'], f['y_train']\r\n     60         x_test, labels_test = f['x_test'], f['y_test']\r\n     61 \r\n\r\n~/venv3/lib/python3.6/site-packages/numpy/lib/npyio.py in __getitem__(self, key)\r\n    260                 return format.read_array(bytes,\r\n    261                                          allow_pickle=self.allow_pickle,\r\n--> 262                                          pickle_kwargs=self.pickle_kwargs)\r\n    263             else:\r\n    264                 return self.zip.read(key)\r\n\r\n~/venv3/lib/python3.6/site-packages/numpy/lib/format.py in read_array(fp, allow_pickle, pickle_kwargs)\r\n    690         # The array contained Python objects. We need to unpickle the data.\r\n    691         if not allow_pickle:\r\n--> 692             raise ValueError(\"Object arrays cannot be loaded when \"\r\n    693                              \"allow_pickle=False\")\r\n    694         if pickle_kwargs is None:\r\n\r\nValueError: Object arrays cannot be loaded when allow_pickle=False\r\n```",
        "commit_url": "https://github.com/keras-team/keras/commit/9416f3647ac4c9ec0c57575a66d66aeac077d56c",
        "buggy_code": "with np.load(path) as f:",
        "fixed_code": "with np.load(path, allow_pickle=True) as f:",
        "patch": "@@ -55,7 +55,7 @@ def load_data(path='imdb.npz', num_words=None, skip_top=0,\n     path = get_file(path,\n                     origin='https://s3.amazonaws.com/text-datasets/imdb.npz',\n                     file_hash='599dadb1135973df5b59232a0e9a887c')\n-    with np.load(path) as f:\n+    with np.load(path, allow_pickle=True) as f:\n         x_train, labels_train = f['x_train'], f['y_train']\n         x_test, labels_test = f['x_test'], f['y_test']\n "
    },
    {
        "commit_id": "35093bc9bb14a66d09fe6ea26e302df8ffad64f4",
        "commit_message": "Add missing bracket to error string. (#12661)",
        "commit_url": "https://github.com/keras-team/keras/commit/35093bc9bb14a66d09fe6ea26e302df8ffad64f4",
        "buggy_code": "'(got ' + str(input_shape[1:]) + '. '",
        "fixed_code": "'(got ' + str(input_shape[1:]) + '). '",
        "patch": "@@ -498,7 +498,7 @@ def compute_output_shape(self, input_shape):\n         if not all(input_shape[1:]):\n             raise ValueError('The shape of the input to \"Flatten\" '\n                              'is not fully defined '\n-                             '(got ' + str(input_shape[1:]) + '. '\n+                             '(got ' + str(input_shape[1:]) + '). '\n                              'Make sure to pass a complete \"input_shape\" '\n                              'or \"batch_input_shape\" argument to the first '\n                              'layer in your model.')"
    },
    {
        "commit_id": "f1e14ef9c57da498f37b8fe9ac7fe86bff0b3f76",
        "commit_message": "fix a comment error for MaxNorm constraint (#12658)",
        "commit_url": "https://github.com/keras-team/keras/commit/f1e14ef9c57da498f37b8fe9ac7fe86bff0b3f76",
        "buggy_code": "m: the maximum norm for the incoming weights.",
        "fixed_code": "max_value: the maximum norm for the incoming weights.",
        "patch": "@@ -26,7 +26,7 @@ class MaxNorm(Constraint):\n     to have a norm less than or equal to a desired value.\n \n     # Arguments\n-        m: the maximum norm for the incoming weights.\n+        max_value: the maximum norm for the incoming weights.\n         axis: integer, axis along which to calculate weight norms.\n             For instance, in a `Dense` layer the weight matrix\n             has shape `(input_dim, output_dim)`,"
    },
    {
        "commit_id": "ed144aa1299d6876263420a45460ed638a575903",
        "commit_message": "Fix convrnn tests.",
        "commit_url": "https://github.com/keras-team/keras/commit/ed144aa1299d6876263420a45460ed638a575903",
        "buggy_code": "def test_missing_inputs():",
        "fixed_code": "def DISABLED_test_missing_inputs():",
        "patch": "@@ -430,7 +430,7 @@ def test_finite_generator_enqueuer_processes():\n \n @pytest.mark.skipif('TRAVIS_PYTHON_VERSION' in os.environ,\n                     reason='Takes 150s to run')\n-def test_missing_inputs():\n+def DISABLED_test_missing_inputs():\n     missing_idx = 10\n \n     class TimeOutSequence(DummySequence):"
    },
    {
        "commit_id": "d7ea34fcc87159ec7d3b5a802b34629f756dd923",
        "commit_message": "Fix a bug (#12618)\n\nThis makes `len(pixel_range) == len(sample_range_x) == len(sample_range_y) == 30`.",
        "commit_url": "https://github.com/keras-team/keras/commit/d7ea34fcc87159ec7d3b5a802b34629f756dd923",
        "buggy_code": "end_range = n * digit_size + start_range + 1",
        "fixed_code": "end_range = (n - 1) * digit_size + start_range + 1",
        "patch": "@@ -100,7 +100,7 @@ def plot_results(models,\n \n     plt.figure(figsize=(10, 10))\n     start_range = digit_size // 2\n-    end_range = n * digit_size + start_range + 1\n+    end_range = (n - 1) * digit_size + start_range + 1\n     pixel_range = np.arange(start_range, end_range, digit_size)\n     sample_range_x = np.round(grid_x, 1)\n     sample_range_y = np.round(grid_y, 1)"
    },
    {
        "commit_id": "e8ec47aa7b76f8817561d087be4141c403951d09",
        "commit_message": "Fix test_model_with_external_loss",
        "commit_url": "https://github.com/keras-team/keras/commit/e8ec47aa7b76f8817561d087be4141c403951d09",
        "buggy_code": "val_inputs = [0.]",
        "fixed_code": "val_inputs = [0]",
        "patch": "@@ -1017,7 +1017,7 @@ def fit(self,\n         elif validation_steps:\n             do_validation = True\n             if self._uses_dynamic_learning_phase():\n-                val_inputs = [0.]\n+                val_inputs = [0]\n \n         # Prepare input arrays and training function.\n         if self._uses_dynamic_learning_phase():"
    },
    {
        "commit_id": "5b653e2577abf2691479bd2bfb69bad6bdf3382b",
        "commit_message": "Fix v1 tests.",
        "commit_url": "https://github.com/keras-team/keras/commit/5b653e2577abf2691479bd2bfb69bad6bdf3382b",
        "buggy_code": "return sp.misc.logsumexp(x, axis=axis, keepdims=keepdims)",
        "fixed_code": "return sp.special.logsumexp(x, axis=axis, keepdims=keepdims)",
        "patch": "@@ -366,7 +366,7 @@ def std(x, axis=None, keepdims=False):\n def logsumexp(x, axis=None, keepdims=False):\n     if isinstance(axis, list):\n         axis = tuple(axis)\n-    return sp.misc.logsumexp(x, axis=axis, keepdims=keepdims)\n+    return sp.special.logsumexp(x, axis=axis, keepdims=keepdims)\n \n \n def sum(x, axis=None, keepdims=False):"
    },
    {
        "commit_id": "5b653e2577abf2691479bd2bfb69bad6bdf3382b",
        "commit_message": "Fix v1 tests.",
        "commit_url": "https://github.com/keras-team/keras/commit/5b653e2577abf2691479bd2bfb69bad6bdf3382b",
        "buggy_code": "tsb = callbacks.TensorBoard(histogram_freq=1)",
        "fixed_code": "tsb = callbacks.TensorBoard(filepath, histogram_freq=1)",
        "patch": "@@ -292,7 +292,7 @@ def test_TensorBoard_convnet(tmpdir):\n     model.compile(loss='categorical_crossentropy',\n                   optimizer='rmsprop',\n                   metrics=['accuracy'])\n-    tsb = callbacks.TensorBoard(histogram_freq=1)\n+    tsb = callbacks.TensorBoard(filepath, histogram_freq=1)\n     cbks = [tsb]\n     model.summary()\n     history = model.fit(x_train, y_train, epochs=2, batch_size=16,"
    },
    {
        "commit_id": "435cf42e24419b60acda6f24e828d59cabe65a2e",
        "commit_message": "Docs fix for Model (#12425)",
        "commit_url": "https://github.com/keras-team/keras/commit/435cf42e24419b60acda6f24e828d59cabe65a2e",
        "buggy_code": "to the model's outputs. If a tensor, it is expected to map",
        "fixed_code": "to the model's outputs. If a dict, it is expected to map",
        "patch": "@@ -66,7 +66,7 @@ def compile(self, optimizer,\n                 will then be the *weighted sum* of all individual losses,\n                 weighted by the `loss_weights` coefficients.\n                 If a list, it is expected to have a 1:1 mapping\n-                to the model's outputs. If a tensor, it is expected to map\n+                to the model's outputs. If a dict, it is expected to map\n                 output names (strings) to scalar coefficients.\n             sample_weight_mode: If you need to do timestep-wise\n                 sample weighting (2D weights), set this to `\"temporal\"`."
    },
    {
        "commit_id": "e59570ae26670f788d6c649191031e4a8824f955",
        "commit_message": "Fix grammar in README, backend docs and initializers docs (#12133)\n\n* Update README.md\r\n\r\n* Update backend.md\r\n\r\n* Update initializers.py\r\n\r\n* Update backend.md",
        "commit_url": "https://github.com/keras-team/keras/commit/e59570ae26670f788d6c649191031e4a8824f955",
        "buggy_code": "are discarded and re-drawn. This is the recommended initializer for",
        "fixed_code": "are discarded and redrawn. This is the recommended initializer for",
        "patch": "@@ -124,7 +124,7 @@ class TruncatedNormal(Initializer):\n \n     These values are similar to values from a `RandomNormal`\n     except that values more than two standard deviations from the mean\n-    are discarded and re-drawn. This is the recommended initializer for\n+    are discarded and redrawn. This is the recommended initializer for\n     neural network weights and filters.\n \n     # Arguments"
    },
    {
        "commit_id": "aac5391c984feda699f270c3757fcbed47749ad4",
        "commit_message": "Fix documentation rendering issue (#12171)",
        "commit_url": "https://github.com/keras-team/keras/commit/aac5391c984feda699f270c3757fcbed47749ad4",
        "buggy_code": "result += snippet + '\\n'",
        "fixed_code": "result += snippet.encode('unicode_escape').decode('utf8') + '\\n'",
        "patch": "@@ -106,7 +106,7 @@ def class_to_source_link(cls):\n \n def code_snippet(snippet):\n     result = '```python\\n'\n-    result += snippet + '\\n'\n+    result += snippet.encode('unicode_escape').decode('utf8') + '\\n'\n     result += '```\\n'\n     return result\n "
    },
    {
        "commit_id": "f42d9e0179f11871179bc9ee4e8c138cd016612b",
        "commit_message": "Cleaned the namespace of keras.backend. (#12076)\n\n* Cleaned the namespace of keras.backend.\r\n\r\n* Fixing some errors.\r\n\r\n* Added a clear_session to theano.\r\n\r\n* Fixed usage of private variable.\r\n\r\n* Removed use of K._config_path\r\n\r\n* Fixed the reloading issue\r\n\r\n* Fixed the cannot import name.\r\n\r\n* Changed the way of using th_sparse_module usage.\r\n\r\n* Fixed the cntk error.\r\n\r\n* Fixed the issue of pattern_broadcast.\r\n\r\n* Added small info in docstring.\r\n\r\n* Forgot import\r\n\r\n* Removed empty line.\r\n\r\n* Removed pattern broadcast and some other functions.\r\n\r\n* Added clear session only for specific backends.\r\n\r\n* Removed useless functions.",
        "commit_url": "https://github.com/keras-team/keras/commit/f42d9e0179f11871179bc9ee4e8c138cd016612b",
        "buggy_code": "from keras.backend import floatx",
        "fixed_code": "from .common import floatx",
        "patch": "@@ -6,7 +6,7 @@\n import numpy as np\n import scipy.signal as signal\n import scipy as sp\n-from keras.backend import floatx\n+from .common import floatx\n from keras.utils.generic_utils import transpose_shape\n from keras.utils import to_categorical\n "
    },
    {
        "commit_id": "86ce3cdd7d87d84532d08b0d6b65b3918a10ba5e",
        "commit_message": "Fix spelling mistake in SELU docs (#12123)\n\n### Summary\r\nFixed a spelling mistake in SELU documentation in activations.py. (pre-defined --> predefined)\r\n\r\n### Related Issues\r\nNone\r\n\r\n### PR Overview\r\nFix spelling error in docs.\r\n\r\n- [n] This PR requires new unit tests [y/n] (make sure tests are included)\r\n- [y] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)\r\n- [y] This PR is backwards compatible [y/n]\r\n- [n] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)",
        "commit_url": "https://github.com/keras-team/keras/commit/86ce3cdd7d87d84532d08b0d6b65b3918a10ba5e",
        "buggy_code": "are pre-defined constants. The values of `alpha` and `scale` are",
        "fixed_code": "are predefined constants. The values of `alpha` and `scale` are",
        "patch": "@@ -58,7 +58,7 @@ def selu(x):\n     \"\"\"Scaled Exponential Linear Unit (SELU).\n \n     SELU is equal to: `scale * elu(x, alpha)`, where alpha and scale\n-    are pre-defined constants. The values of `alpha` and `scale` are\n+    are predefined constants. The values of `alpha` and `scale` are\n     chosen so that the mean and variance of the inputs are preserved\n     between two consecutive layers as long as the weights are initialized\n     correctly (see `lecun_normal` initialization) and the number of inputs"
    },
    {
        "commit_id": "4185cbb50bfcae9cc30b0fc7b67e81d67a50a8ac",
        "commit_message": "Use var_list argument in TFOptimizer wrapper (#12106)\n\n* Update optimizers.py\r\n\r\nfix bug in TFOptimizer, this optimizer should call tensorflow native optimizer with the named param var_list\r\n\r\n* add test_tfoptimizer_pass_correct_named_params_to_compute_gradient\r\n\r\n* fix formating\r\n\r\n* fix test\r\n\r\n* fix test\r\n\r\n* fix formating\r\n\r\n* fix test",
        "commit_url": "https://github.com/keras-team/keras/commit/4185cbb50bfcae9cc30b0fc7b67e81d67a50a8ac",
        "buggy_code": "grads = self.optimizer.compute_gradients(loss, params)",
        "fixed_code": "grads = self.optimizer.compute_gradients(loss, var_list=params)",
        "patch": "@@ -703,7 +703,7 @@ def __init__(self, optimizer):\n \n     @interfaces.legacy_get_updates_support\n     def get_updates(self, loss, params):\n-        grads = self.optimizer.compute_gradients(loss, params)\n+        grads = self.optimizer.compute_gradients(loss, var_list=params)\n         self.updates = [K.update_add(self.iterations, 1)]\n         opt_update = self.optimizer.apply_gradients(\n             grads, global_step=self.iterations)"
    },
    {
        "commit_id": "ae30f36fbde83beb122a1eb1c3bf3cea2d490d5a",
        "commit_message": "[P] Bump TF version to 1.12 (#11984)\n\n* rebase gabrieldem branch on master\r\n\r\n* bump to 1.12\r\n\r\n* fix beam search decoder\r\n\r\n* fix tests",
        "commit_url": "https://github.com/keras-team/keras/commit/ae30f36fbde83beb122a1eb1c3bf3cea2d490d5a",
        "buggy_code": "top_paths=top_paths)",
        "fixed_code": "top_paths=top_paths, merge_repeated=False)",
        "patch": "@@ -4512,7 +4512,7 @@ def ctc_decode(y_pred, input_length, greedy=True, beam_width=100,\n         (decoded, log_prob) = ctc.ctc_beam_search_decoder(\n             inputs=y_pred,\n             sequence_length=input_length, beam_width=beam_width,\n-            top_paths=top_paths)\n+            top_paths=top_paths, merge_repeated=False)\n \n     decoded_dense = []\n     for st in decoded:"
    },
    {
        "commit_id": "5a8c85f1261e926a7f4bb52fb72935c574476ac3",
        "commit_message": "Fix typos (#11997)",
        "commit_url": "https://github.com/keras-team/keras/commit/5a8c85f1261e926a7f4bb52fb72935c574476ac3",
        "buggy_code": "the smaller the updates.",
        "fixed_code": "the smaller the learning rate.",
        "patch": "@@ -291,7 +291,7 @@ class Adagrad(Optimizer):\n     Adagrad is an optimizer with parameter-specific learning rates,\n     which are adapted relative to how frequently a parameter gets\n     updated during training. The more updates a parameter receives,\n-    the smaller the updates.\n+    the smaller the learning rate.\n \n     It is recommended to leave the parameters of this optimizer\n     at their default values."
    },
    {
        "commit_id": "425e99a9e3d00c7d505d585e00e85ee716e3c350",
        "commit_message": "Fix DeprecationWarning: invalid escape sequence in examples and tests (#11974)\n\n* Fix 2 DeprecationWarning: invlid escape sequence in examples\r\n\r\nSigned-off-by: Micka\u00ebl Schoentgen <contact@tiger-222.fr>\r\n\r\n* Fix 2 DeprecationWarning: invlid escape sequence in tests\r\n\r\nSigned-off-by: Micka\u00ebl Schoentgen <contact@tiger-222.fr>",
        "commit_url": "https://github.com/keras-team/keras/commit/425e99a9e3d00c7d505d585e00e85ee716e3c350",
        "buggy_code": "return [x.strip() for x in re.split('(\\W+)?', sent) if x.strip()]",
        "fixed_code": "return [x.strip() for x in re.split(r'(\\W+)?', sent) if x.strip()]",
        "patch": "@@ -34,7 +34,7 @@ def tokenize(sent):\n     >>> tokenize('Bob dropped the apple. Where is the apple?')\n     ['Bob', 'dropped', 'the', 'apple', '.', 'Where', 'is', 'the', 'apple', '?']\n     '''\n-    return [x.strip() for x in re.split('(\\W+)?', sent) if x.strip()]\n+    return [x.strip() for x in re.split(r'(\\W+)?', sent) if x.strip()]\n \n \n def parse_stories(lines, only_supporting=False):"
    },
    {
        "commit_id": "425e99a9e3d00c7d505d585e00e85ee716e3c350",
        "commit_message": "Fix DeprecationWarning: invalid escape sequence in examples and tests (#11974)\n\n* Fix 2 DeprecationWarning: invlid escape sequence in examples\r\n\r\nSigned-off-by: Micka\u00ebl Schoentgen <contact@tiger-222.fr>\r\n\r\n* Fix 2 DeprecationWarning: invlid escape sequence in tests\r\n\r\nSigned-off-by: Micka\u00ebl Schoentgen <contact@tiger-222.fr>",
        "commit_url": "https://github.com/keras-team/keras/commit/425e99a9e3d00c7d505d585e00e85ee716e3c350",
        "buggy_code": "return [x.strip() for x in re.split('(\\W+)?', sent) if x.strip()]",
        "fixed_code": "return [x.strip() for x in re.split(r'(\\W+)?', sent) if x.strip()]",
        "patch": "@@ -78,7 +78,7 @@ def tokenize(sent):\n     >>> tokenize('Bob dropped the apple. Where is the apple?')\n     ['Bob', 'dropped', 'the', 'apple', '.', 'Where', 'is', 'the', 'apple', '?']\n     '''\n-    return [x.strip() for x in re.split('(\\W+)?', sent) if x.strip()]\n+    return [x.strip() for x in re.split(r'(\\W+)?', sent) if x.strip()]\n \n \n def parse_stories(lines, only_supporting=False):"
    },
    {
        "commit_id": "fca79866f4dd8df054d1643774175358f057d097",
        "commit_message": "Typo fix (#11949)",
        "commit_url": "https://github.com/keras-team/keras/commit/fca79866f4dd8df054d1643774175358f057d097",
        "buggy_code": "in the interval [-1.0, +1.0).",
        "fixed_code": "in the interval [-1.0, +1.0].",
        "patch": "@@ -262,7 +262,7 @@ class ImageDataGenerator(image.ImageDataGenerator):\n                 are integers `[-1, 0, +1]`,\n                 same as with `height_shift_range=[-1, 0, +1]`,\n                 while with `height_shift_range=1.0` possible values are floats\n-                in the interval [-1.0, +1.0).\n+                in the interval [-1.0, +1.0].\n         brightness_range: Tuple or list of two floats. Range for picking\n             a brightness shift value from.\n         shear_range: Float. Shear Intensity"
    },
    {
        "commit_id": "8a73aec637a853f0fccb544dcb61dfe170db1277",
        "commit_message": "typo fix (#11760)",
        "commit_url": "https://github.com/keras-team/keras/commit/8a73aec637a853f0fccb544dcb61dfe170db1277",
        "buggy_code": "The softplus activation: `x / (abs(x) + 1)`.",
        "fixed_code": "The softsign activation: `x / (abs(x) + 1)`.",
        "patch": "@@ -101,7 +101,7 @@ def softsign(x):\n         x: Input tensor.\n \n     # Returns\n-        The softplus activation: `x / (abs(x) + 1)`.\n+        The softsign activation: `x / (abs(x) + 1)`.\n     \"\"\"\n     return K.softsign(x)\n "
    },
    {
        "commit_id": "2b831d5bf8d64f7009697c367cfa034060ae540f",
        "commit_message": "Fixing a confusing URL faliure error message in get_file() exception handler (#11696)",
        "commit_url": "https://github.com/keras-team/keras/commit/2b831d5bf8d64f7009697c367cfa034060ae540f",
        "buggy_code": "error_msg = 'URL fetch failure on {}: {} -- {}'",
        "fixed_code": "error_msg = 'URL fetch failure on {} : {} -- {}'",
        "patch": "@@ -216,7 +216,7 @@ def dl_progress(count, block_size, total_size):\n             else:\n                 ProgressTracker.progbar.update(count * block_size)\n \n-        error_msg = 'URL fetch failure on {}: {} -- {}'\n+        error_msg = 'URL fetch failure on {} : {} -- {}'\n         try:\n             try:\n                 urlretrieve(origin, fpath, dl_progress)"
    },
    {
        "commit_id": "8b59e31d2b1d854a1eae585db7bd1582ef95c978",
        "commit_message": "Fix the timeout error on Travis (#11640)",
        "commit_url": "https://github.com/keras-team/keras/commit/8b59e31d2b1d854a1eae585db7bd1582ef95c978",
        "buggy_code": "K.backend() == 'tensorflow' and 'TRAVIS_PYTHON_VERSION' in os.environ,",
        "fixed_code": "K.backend() in {'tensorflow', 'cntk'} and 'TRAVIS_PYTHON_VERSION' in os.environ,",
        "patch": "@@ -23,7 +23,7 @@\n from keras import backend as K\n \n pytestmark = pytest.mark.skipif(\n-    K.backend() == 'tensorflow' and 'TRAVIS_PYTHON_VERSION' in os.environ,\n+    K.backend() in {'tensorflow', 'cntk'} and 'TRAVIS_PYTHON_VERSION' in os.environ,\n     reason='Temporarily disabled until the use_multiprocessing problem is solved')\n \n if sys.version_info < (3,):"
    },
    {
        "commit_id": "8b59e31d2b1d854a1eae585db7bd1582ef95c978",
        "commit_message": "Fix the timeout error on Travis (#11640)",
        "commit_url": "https://github.com/keras-team/keras/commit/8b59e31d2b1d854a1eae585db7bd1582ef95c978",
        "buggy_code": "K.backend() == 'tensorflow' and 'TRAVIS_PYTHON_VERSION' in os.environ,",
        "fixed_code": "K.backend() in {'tensorflow', 'cntk'} and 'TRAVIS_PYTHON_VERSION' in os.environ,",
        "patch": "@@ -9,7 +9,7 @@\n from keras import backend as K\n \n pytestmark = pytest.mark.skipif(\n-    K.backend() == 'tensorflow' and 'TRAVIS_PYTHON_VERSION' in os.environ,\n+    K.backend() in {'tensorflow', 'cntk'} and 'TRAVIS_PYTHON_VERSION' in os.environ,\n     reason='Temporarily disabled until the use_multiprocessing problem is solved')\n \n STEPS_PER_EPOCH = 100"
    },
    {
        "commit_id": "7c90c378d428ee80dd85d9a2bf404458e2672c2f",
        "commit_message": "Fixed typo in training_utils.py (#11566)\n\nThe error message didn't have a space between words, so it looked like \"we expect thetensors to have a static batch size.\" \r\nWith this change we add a space between \"the\" and \"tensors\"",
        "commit_url": "https://github.com/keras-team/keras/commit/7c90c378d428ee80dd85d9a2bf404458e2672c2f",
        "buggy_code": "'When feeding symbolic tensors to a model, we expect the'",
        "fixed_code": "'When feeding symbolic tensors to a model, we expect the '",
        "patch": "@@ -21,7 +21,7 @@ def standardize_single_array(x):\n         shape = K.int_shape(x)\n         if shape is None or shape[0] is None:\n             raise ValueError(\n-                'When feeding symbolic tensors to a model, we expect the'\n+                'When feeding symbolic tensors to a model, we expect the '\n                 'tensors to have a static batch size. '\n                 'Got tensor with shape: %s' % str(shape))\n         return x"
    },
    {
        "commit_id": "8ef5dcfd3dfa385e00e7d2654825f7f79d2dec57",
        "commit_message": "Add the numpy implementation in the keras backend documentation (#11507)\n\n* Added the numpy implementation in the documentation.\r\n\r\n* Changed the name of the numpy backend.\r\n\r\nChanged the tag for detecting where to put the numpy implementation.\r\n\r\n* Added the footer and header automatically.\r\n\r\n* Automatically add a `Show the numpy implementation` if the code is more than 10 lines long.\r\n\r\n* Fix pep8",
        "commit_url": "https://github.com/keras-team/keras/commit/8ef5dcfd3dfa385e00e7d2654825f7f79d2dec57",
        "buggy_code": "import reference_operations as KNP",
        "fixed_code": "from keras.backend import numpy_backend as KNP",
        "patch": "@@ -7,7 +7,7 @@\n from keras import backend as K\n from keras.backend import floatx, set_floatx, variable\n from keras.utils.conv_utils import convert_kernel\n-import reference_operations as KNP\n+from keras.backend import numpy_backend as KNP\n \n \n BACKENDS = []  # Holds a list of all available back-ends"
    },
    {
        "commit_id": "dd9109d152aea0e45d414edd3f4768b872807048",
        "commit_message": "Fix issues related to keras_preprocessing.",
        "commit_url": "https://github.com/keras-team/keras/commit/dd9109d152aea0e45d414edd3f4768b872807048",
        "buggy_code": "'keras_preprocessing>=1.0.4'],",
        "fixed_code": "'keras_preprocessing>=1.0.5'],",
        "patch": "@@ -38,7 +38,7 @@\n                         'pyyaml',\n                         'h5py',\n                         'keras_applications>=1.0.6',\n-                        'keras_preprocessing>=1.0.4'],\n+                        'keras_preprocessing>=1.0.5'],\n       extras_require={\n           'visualize': ['pydot>=1.2.4'],\n           'tests': ['pytest',"
    },
    {
        "commit_id": "b9ee83cc227ac0719a0de937ae65392473fe007f",
        "commit_message": "Fix h5py error \"Unable to create attribute (object header message is too large)\" (#11242)\n\n* Save np data only as dataset\r\n\r\n* Fix docs\r\n\r\n* Update test for saving large np.array objects\r\n\r\n* Update tests for saving large np.array objects",
        "commit_url": "https://github.com/keras-team/keras/commit/b9ee83cc227ac0719a0de937ae65392473fe007f",
        "buggy_code": "f: keras.utils.hdf5.HD5Dict instance.",
        "fixed_code": "f: keras.utils.io_utils.HD5Dict instance.",
        "patch": "@@ -34,7 +34,7 @@ def _serialize_model(model, f, include_optimizer=True):\n \n     # Arguments\n         model: Keras model instance to be serialized.\n-        f: keras.utils.hdf5.HD5Dict instance.\n+        f: keras.utils.io_utils.HD5Dict instance.\n         include_optimizer: If True, serialize optimizer's state together.\n \n     \"\"\""
    },
    {
        "commit_id": "b9ee83cc227ac0719a0de937ae65392473fe007f",
        "commit_message": "Fix h5py error \"Unable to create attribute (object header message is too large)\" (#11242)\n\n* Save np data only as dataset\r\n\r\n* Fix docs\r\n\r\n* Update test for saving large np.array objects\r\n\r\n* Update tests for saving large np.array objects",
        "commit_url": "https://github.com/keras-team/keras/commit/b9ee83cc227ac0719a0de937ae65392473fe007f",
        "buggy_code": "if isinstance(val, list):",
        "fixed_code": "elif isinstance(val, list):",
        "patch": "@@ -219,7 +219,7 @@ def __setitem__(self, attr, val):\n                 dataset[()] = val\n             else:\n                 dataset[:] = val\n-        if isinstance(val, list):\n+        elif isinstance(val, list):\n             # Check that no item in `data` is larger than `HDF5_OBJECT_HEADER_LIMIT`\n             # because in that case even chunking the array would not make the saving\n             # possible."
    },
    {
        "commit_id": "ff89e2de51e5ccdb7a68510d5539365002881b61",
        "commit_message": "Fix error messages related to model saving.",
        "commit_url": "https://github.com/keras-team/keras/commit/ff89e2de51e5ccdb7a68510d5539365002881b61",
        "buggy_code": "raise TypeError('Not JSON Serializable:', obj)",
        "fixed_code": "raise TypeError('Not JSON Serializable: %s' % (obj,))",
        "patch": "@@ -71,7 +71,7 @@ def get_json_type(obj):\n         if type(obj).__name__ == type.__name__:\n             return obj.__name__\n \n-        raise TypeError('Not JSON Serializable:', obj)\n+        raise TypeError('Not JSON Serializable: %s' % (obj,))\n \n     from .. import __version__ as keras_version\n "
    },
    {
        "commit_id": "06c3a804e7d56cc77f76a28ee34aa67a34daedee",
        "commit_message": "Fix bug when channel=1 (#11123)",
        "commit_url": "https://github.com/keras-team/keras/commit/06c3a804e7d56cc77f76a28ee34aa67a34daedee",
        "buggy_code": "input_shape=(3, 4, 2))",
        "fixed_code": "input_shape=(1, 4, 1))",
        "patch": "@@ -28,7 +28,7 @@ def test_basic_batchnorm():\n                kwargs={'momentum': 0.9,\n                        'epsilon': 0.1,\n                        'axis': 1},\n-               input_shape=(3, 4, 2))\n+               input_shape=(1, 4, 1))\n     layer_test(normalization.BatchNormalization,\n                kwargs={'gamma_initializer': 'ones',\n                        'beta_initializer': 'ones',"
    },
    {
        "commit_id": "66f8cc7ac4942f7f9fe0164a2a854a6264b87735",
        "commit_message": "Update the RNN cell API to be explicit about output_size. (#11021)\n\n* Update the RNN cell API to be explicit about output_size.\r\n\r\nThe existing contract of state_size[0] to be output size is bit\r\nweird and might cause unnecessary contrain for supporting higher\r\ndimension input/output/states. Adding explicit output_size to cell\r\nso that the contract is not inferred by state_size anymore.\r\n\r\nFor backward compat reason, if a cell does not implement\r\noutput_size, the state_size[0] will be used as output_size.\r\n\r\nThe stackedRNNCells is also updated to by default return natural\r\norder state_size as the cells' state, instead of reverse order.\r\nFor any user who rely on the states of the RNN, eg\r\nRNN(return_state=True), please add the extra param\r\nreverse_state_order=True while constructing the StackedRNNCells.\r\n\r\n* Update warning message for keywords.\r\n\r\n* Fix unit test.\r\n\r\n* Fix the cntk backend for RNN, and update test case.\r\n\r\n* Update comment and tests.",
        "commit_url": "https://github.com/keras-team/keras/commit/66f8cc7ac4942f7f9fe0164a2a854a6264b87735",
        "buggy_code": "new_output = n_s[0]",
        "fixed_code": "new_output = n_s[-1]",
        "patch": "@@ -1439,7 +1439,7 @@ def _recurrence(x, states, m):\n             for o, p in zip(new_states, place_holders):\n                 n_s.append(o.replace_placeholders({p: o.output}))\n             if len(n_s) > 0:\n-                new_output = n_s[0]\n+                new_output = n_s[-1]\n             return new_output, n_s\n \n         final_output, final_states = _recurrence(rnn_inputs, states, mask)"
    },
    {
        "commit_id": "cc380c48f842c2bfb4c4a124b7b567f0ee5a148d",
        "commit_message": "fix a bug, load_weights doesn't return anything (#11031)",
        "commit_url": "https://github.com/keras-team/keras/commit/cc380c48f842c2bfb4c4a124b7b567f0ee5a148d",
        "buggy_code": "vae = vae.load_weights(args.weights)",
        "fixed_code": "vae.load_weights(args.weights)",
        "patch": "@@ -192,7 +192,7 @@ def plot_results(models,\n                show_shapes=True)\n \n     if args.weights:\n-        vae = vae.load_weights(args.weights)\n+        vae.load_weights(args.weights)\n     else:\n         # train the autoencoder\n         vae.fit(x_train,"
    },
    {
        "commit_id": "d88f2006af35179b986479ac6ad5a20dac8ac9d1",
        "commit_message": "Fix dilated convolution for CNTK backend. (#10967)",
        "commit_url": "https://github.com/keras-team/keras/commit/d88f2006af35179b986479ac6ad5a20dac8ac9d1",
        "buggy_code": "reason=\"cntk does not support dilated conv\")",
        "fixed_code": "reason=\"cntk only supports dilated conv on GPU\")",
        "patch": "@@ -139,7 +139,7 @@ def test_averagepooling_1d():\n \n @keras_test\n @pytest.mark.skipif((K.backend() == 'cntk'),\n-                    reason=\"cntk does not support dilated conv\")\n+                    reason=\"cntk only supports dilated conv on GPU\")\n def test_convolution_2d():\n     num_samples = 2\n     filters = 2"
    },
    {
        "commit_id": "6746bda3dcda273580fef2d911c6cc333c8a626c",
        "commit_message": "Fix val_step in fit_generator with Sequence (#10946)\n\n* Keep the right val_steps\r\n\r\n* Add tests",
        "commit_url": "https://github.com/keras-team/keras/commit/6746bda3dcda273580fef2d911c6cc333c8a626c",
        "buggy_code": "validation_steps = len(val_data)",
        "fixed_code": "validation_steps = validation_steps or len(val_data)",
        "patch": "@@ -111,7 +111,7 @@ def fit_generator(model,\n                 if isinstance(val_data, Sequence):\n                     val_enqueuer = OrderedEnqueuer(val_data,\n                                                    use_multiprocessing=use_multiprocessing)\n-                    validation_steps = len(val_data)\n+                    validation_steps = validation_steps or len(val_data)\n                 else:\n                     val_enqueuer = GeneratorEnqueuer(val_data,\n                                                      use_multiprocessing=use_multiprocessing)"
    },
    {
        "commit_id": "4ba641806b4afcf95bece96c3b15e646fc092161",
        "commit_message": "Fix doc (#10812)\n\n* Fix doc\r\n\r\n* Fix doc\r\n\r\n* Update convolutional_recurrent.py",
        "commit_url": "https://github.com/keras-team/keras/commit/4ba641806b4afcf95bece96c3b15e646fc092161",
        "buggy_code": "padding: one of `'valid'` or `'same'` (case-insensitive).",
        "fixed_code": "padding: one of `\"valid\"` or `\"same\"` (case-insensitive).",
        "patch": "@@ -1680,7 +1680,7 @@ class DepthwiseConv2D(Conv2D):\n             all spatial dimensions.\n             Specifying any stride value != 1 is incompatible with specifying\n             any `dilation_rate` value != 1.\n-        padding: one of `'valid'` or `'same'` (case-insensitive).\n+        padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n         depth_multiplier: The number of depthwise convolution output channels\n             for each input channel.\n             The total number of depthwise convolution output"
    },
    {
        "commit_id": "da9ce7d8f2e4212cebdacc80f6252b4ae1e68773",
        "commit_message": "Fix Stateful Metrics in fit_generator with TensorBoard (#10673)\n\n* Fix casting validate generator with stateful metrics.\r\n\r\n* Add a stateful metric to Tensboard tests",
        "commit_url": "https://github.com/keras-team/keras/commit/da9ce7d8f2e4212cebdacc80f6252b4ae1e68773",
        "buggy_code": "averages.append(float(outs_per_batch[-1][i]))",
        "fixed_code": "averages.append(np.float64(outs_per_batch[-1][i]))",
        "patch": "@@ -375,7 +375,7 @@ def evaluate_generator(model, generator,\n             averages.append(np.average([out[i] for out in outs_per_batch],\n                                        weights=batch_sizes))\n         else:\n-            averages.append(float(outs_per_batch[-1][i]))\n+            averages.append(np.float64(outs_per_batch[-1][i]))\n     return unpack_singleton(averages)\n \n "
    },
    {
        "commit_id": "75114feeac5ee6aa7679802ce7e5172c63565e2c",
        "commit_message": "Removed some unused variables and fixed a formatting error. (#10688)\n\n* Removed some unused variables.\r\n\r\n* Fixed the formatting of an error message.",
        "commit_url": "https://github.com/keras-team/keras/commit/75114feeac5ee6aa7679802ce7e5172c63565e2c",
        "buggy_code": "% (len(cntk_shape, dynamic_axis_num)))",
        "fixed_code": "% (len(cntk_shape), dynamic_axis_num))",
        "patch": "@@ -270,7 +270,7 @@ def placeholder(\n         raise ValueError('CNTK backend: creating placeholder with '\n                          '%d dimension is not supported, at least '\n                          '%d dimensions are needed.'\n-                         % (len(cntk_shape, dynamic_axis_num)))\n+                         % (len(cntk_shape), dynamic_axis_num))\n \n     if name is None:\n         name = ''"
    },
    {
        "commit_id": "75114feeac5ee6aa7679802ce7e5172c63565e2c",
        "commit_message": "Removed some unused variables and fixed a formatting error. (#10688)\n\n* Removed some unused variables.\r\n\r\n* Fixed the formatting of an error message.",
        "commit_url": "https://github.com/keras-team/keras/commit/75114feeac5ee6aa7679802ce7e5172c63565e2c",
        "buggy_code": "except (Exception, KeyboardInterrupt) as e:",
        "fixed_code": "except (Exception, KeyboardInterrupt):",
        "patch": "@@ -224,7 +224,7 @@ def dl_progress(count, block_size, total_size):\n                 raise Exception(error_msg.format(origin, e.errno, e.reason))\n             except HTTPError as e:\n                 raise Exception(error_msg.format(origin, e.code, e.msg))\n-        except (Exception, KeyboardInterrupt) as e:\n+        except (Exception, KeyboardInterrupt):\n             if os.path.exists(fpath):\n                 os.remove(fpath)\n             raise"
    },
    {
        "commit_id": "d2803c0fb7d0ba9361dcba8eb9bcebbf2f774958",
        "commit_message": "PEP8 fixed line length examples/ (#10724)\n\n* PEP8 fixed line length examples/\r\n\r\n* revert addition_rnn\r\n\r\n* Fix PEP8 in babi_memnn",
        "commit_url": "https://github.com/keras-team/keras/commit/d2803c0fb7d0ba9361dcba8eb9bcebbf2f774958",
        "buggy_code": "'''",
        "fixed_code": "'''  # noqa",
        "patch": "@@ -24,7 +24,7 @@\n \n Five digits reversed:\n + One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs\n-'''\n+'''  # noqa\n \n from __future__ import print_function\n from keras.models import Sequential"
    },
    {
        "commit_id": "354bd35ff47aab7834c3576829dab5d3802fd41a",
        "commit_message": "DOC: Fix IMDB get_word_index documentation (#10576)\n\n* DOC: Fix IMDB get_word_index documentation\r\n\r\n* DOC: Fix reuters get_word_index documentation",
        "commit_url": "https://github.com/keras-team/keras/commit/354bd35ff47aab7834c3576829dab5d3802fd41a",
        "buggy_code": "\"\"\"Retrieves the dictionary mapping word indices back to words.",
        "fixed_code": "\"\"\"Retrieves the dictionary mapping words to word indices.",
        "patch": "@@ -103,7 +103,7 @@ def load_data(path='imdb.npz', num_words=None, skip_top=0,\n \n \n def get_word_index(path='imdb_word_index.json'):\n-    \"\"\"Retrieves the dictionary mapping word indices back to words.\n+    \"\"\"Retrieves the dictionary mapping words to word indices.\n \n     # Arguments\n         path: where to cache the data (relative to `~/.keras/dataset`)."
    },
    {
        "commit_id": "354bd35ff47aab7834c3576829dab5d3802fd41a",
        "commit_message": "DOC: Fix IMDB get_word_index documentation (#10576)\n\n* DOC: Fix IMDB get_word_index documentation\r\n\r\n* DOC: Fix reuters get_word_index documentation",
        "commit_url": "https://github.com/keras-team/keras/commit/354bd35ff47aab7834c3576829dab5d3802fd41a",
        "buggy_code": "\"\"\"Retrieves the dictionary mapping word indices back to words.",
        "fixed_code": "\"\"\"Retrieves the dictionary mapping words to word indices.",
        "patch": "@@ -89,7 +89,7 @@ def load_data(path='reuters.npz', num_words=None, skip_top=0,\n \n \n def get_word_index(path='reuters_word_index.json'):\n-    \"\"\"Retrieves the dictionary mapping word indices back to words.\n+    \"\"\"Retrieves the dictionary mapping words to word indices.\n \n     # Arguments\n         path: where to cache the data (relative to `~/.keras/dataset`)."
    },
    {
        "commit_id": "86a683540504c6f6ecd44d03941ba4d0a97ad08c",
        "commit_message": "Fix Dense layer bias_add bug when ndim > 2. (#10562)\n\n* Fix Dense layer bias_add bug when ndim > 2.\r\n\r\n* Address comment",
        "commit_url": "https://github.com/keras-team/keras/commit/86a683540504c6f6ecd44d03941ba4d0a97ad08c",
        "buggy_code": "output = K.bias_add(output, self.bias)",
        "fixed_code": "output = K.bias_add(output, self.bias, data_format='channels_last')",
        "patch": "@@ -884,7 +884,7 @@ def build(self, input_shape):\n     def call(self, inputs):\n         output = K.dot(inputs, self.kernel)\n         if self.use_bias:\n-            output = K.bias_add(output, self.bias)\n+            output = K.bias_add(output, self.bias, data_format='channels_last')\n         if self.activation is not None:\n             output = self.activation(output)\n         return output"
    },
    {
        "commit_id": "a2d11d4724d3cf4a0b18a7fe8448723d92e1c716",
        "commit_message": "Fix several typos (#10468)",
        "commit_url": "https://github.com/keras-team/keras/commit/a2d11d4724d3cf4a0b18a7fe8448723d92e1c716",
        "buggy_code": "and correspding target sequences from another domain",
        "fixed_code": "and corresponding target sequences from another domain",
        "patch": "@@ -10,7 +10,7 @@\n # Summary of the algorithm\n \n - We start with input sequences from a domain (e.g. English sentences)\n-    and correspding target sequences from another domain\n+    and corresponding target sequences from another domain\n     (e.g. French sentences).\n - An encoder LSTM turns input sequences to 2 state vectors\n     (we keep the last LSTM state and discard the outputs)."
    },
    {
        "commit_id": "a2d11d4724d3cf4a0b18a7fe8448723d92e1c716",
        "commit_message": "Fix several typos (#10468)",
        "commit_url": "https://github.com/keras-team/keras/commit/a2d11d4724d3cf4a0b18a7fe8448723d92e1c716",
        "buggy_code": "new_states: Tist of tensors, same length and shapes",
        "fixed_code": "new_states: List of tensors, same length and shapes",
        "patch": "@@ -2736,7 +2736,7 @@ def rnn(step_function, inputs, initial_states,\n                 states: List of tensors.\n             Returns:\n                 outputs: Tensor with shape (samples, ...) (no time dimension),\n-                new_states: Tist of tensors, same length and shapes\n+                new_states: List of tensors, same length and shapes\n                     as 'states'.\n         inputs: Tensor of temporal data of shape (samples, time, ...)\n             (at least 3D)."
    },
    {
        "commit_id": "a2d11d4724d3cf4a0b18a7fe8448723d92e1c716",
        "commit_message": "Fix several typos (#10468)",
        "commit_url": "https://github.com/keras-team/keras/commit/a2d11d4724d3cf4a0b18a7fe8448723d92e1c716",
        "buggy_code": "new_states: Tist of tensors, same length and shapes",
        "fixed_code": "new_states: List of tensors, same length and shapes",
        "patch": "@@ -1323,7 +1323,7 @@ def rnn(step_function, inputs, initial_states,\n                 states: List of tensors.\n             Returns:\n                 outputs: Tensor with shape (samples, ...) (no time dimension),\n-                new_states: Tist of tensors, same length and shapes\n+                new_states: List of tensors, same length and shapes\n                     as 'states'.\n         inputs: Tensor of temporal data of shape (samples, time, ...)\n             (at least 3D)."
    },
    {
        "commit_id": "a2d11d4724d3cf4a0b18a7fe8448723d92e1c716",
        "commit_message": "Fix several typos (#10468)",
        "commit_url": "https://github.com/keras-team/keras/commit/a2d11d4724d3cf4a0b18a7fe8448723d92e1c716",
        "buggy_code": "or vice verca. However, there's no conversion required between TF and CNTK.",
        "fixed_code": "or vice versa. However, there's no conversion required between TF and CNTK.",
        "patch": "@@ -833,7 +833,7 @@ def _need_convert_kernel(original_backend):\n     The convolution operation is implemented differently in different backends.\n     While TH implements convolution, TF and CNTK implement the correlation operation.\n     So the channel axis needs to be flipped when we're loading TF weights onto a TH model,\n-    or vice verca. However, there's no conversion required between TF and CNTK.\n+    or vice versa. However, there's no conversion required between TF and CNTK.\n \n     # Arguments\n         original_backend: Keras backend the weights were trained with, as a string."
    },
    {
        "commit_id": "5fcd832b5c5025b164c99f0bd46cb94d707b93d3",
        "commit_message": "Fix small doc error (#10453)",
        "commit_url": "https://github.com/keras-team/keras/commit/5fcd832b5c5025b164c99f0bd46cb94d707b93d3",
        "buggy_code": "(or list of Numpy arrays if the model has multiple outputs).",
        "fixed_code": "(or list of Numpy arrays if the model has multiple inputs).",
        "patch": "@@ -1125,7 +1125,7 @@ def predict(self, x,\n \n         # Arguments\n             x: The input data, as a Numpy array\n-                (or list of Numpy arrays if the model has multiple outputs).\n+                (or list of Numpy arrays if the model has multiple inputs).\n             batch_size: Integer. If unspecified, it will default to 32.\n             verbose: Verbosity mode, 0 or 1.\n             steps: Total number of steps (batches of samples)"
    },
    {
        "commit_id": "56b255cc043f57e712a95a90819e5c005a2fee8a",
        "commit_message": "Update to Keras Applications 1.0.2 (fixes NASNet issue).",
        "commit_url": "https://github.com/keras-team/keras/commit/56b255cc043f57e712a95a90819e5c005a2fee8a",
        "buggy_code": "'keras_applications==1.0.1',",
        "fixed_code": "'keras_applications==1.0.2',",
        "patch": "@@ -37,7 +37,7 @@\n                         'six>=1.9.0',\n                         'pyyaml',\n                         'h5py',\n-                        'keras_applications==1.0.1',\n+                        'keras_applications==1.0.2',\n                         'keras_preprocessing==1.0.1'],\n       extras_require={\n           'visualize': ['pydot>=1.2.4'],"
    },
    {
        "commit_id": "9bff5b1a55f51ad974c3a3489d7ca2d80f26f770",
        "commit_message": "Typo fix (#10293)",
        "commit_url": "https://github.com/keras-team/keras/commit/9bff5b1a55f51ad974c3a3489d7ca2d80f26f770",
        "buggy_code": "'will be removed, use `min_delta` insted.')",
        "fixed_code": "'will be removed, use `min_delta` instead.')",
        "patch": "@@ -938,7 +938,7 @@ def __init__(self, monitor='val_loss', factor=0.1, patience=10,\n         if 'epsilon' in kwargs:\n             min_delta = kwargs.pop('epsilon')\n             warnings.warn('`epsilon` argument is deprecated and '\n-                          'will be removed, use `min_delta` insted.')\n+                          'will be removed, use `min_delta` instead.')\n         self.factor = factor\n         self.min_lr = min_lr\n         self.min_delta = min_delta"
    },
    {
        "commit_id": "84aa7b5f4167afaa8e4b24f2449ac76c11d5e8df",
        "commit_message": "Non training Batch Norm operator has bad performance for it running into tensorflow's non fused batch norm API (#10207)\n\n* When use tensorflow as backend, let batch norm run into fused batch norm as much as possible, which has better performance.\r\n\r\nfix issue: http://github.com/keras-team/keras/issues/10058\r\n\r\n* In Tensorflow backend, let batch norm call to FusedBatchNorm only NHWC format, also gamma and beta are not None.\r\n\r\nTest result:\r\ntest env: with Tensorflow(commit a543d9471047ca3f6881c87105fcbe2cdff9207d Date:   Thu May 10 17:43:30 2018, local build), python3.4, centos7.4\r\ntest cases:\r\n  \"pytest  ./tests/keras/layers/normalization_test.py\"  <all passed>\r\n  \"pytest  ./tests\"      <keep same result as without this commit's modification on BN>\r\n\r\n* fix code sytle.\r\n\r\n* 1. Add axis parameter in backend's batch_normalization functions.\r\n2. Refine the batch_normalization function in tensorflow backend, Let's it call to fused batch norm as much as possible.\r\n\r\nThanks the coments from fchollet.\r\n\r\n* Trigger\r\n\r\n* 1. add default value -1 for parameter axis in batch_normalization function in backend.\r\n2. fix some code style.\r\nThanks the comments from fchollet.",
        "commit_url": "https://github.com/keras-team/keras/commit/84aa7b5f4167afaa8e4b24f2449ac76c11d5e8df",
        "buggy_code": "def batch_normalization(x, mean, var, beta, gamma, epsilon=1e-3):",
        "fixed_code": "def batch_normalization(x, mean, var, beta, gamma, axis=-1, epsilon=1e-3):",
        "patch": "@@ -1063,7 +1063,7 @@ def _moments(x, axes=None, shift=None, keep_dims=False):\n     return mean, variance\n \n \n-def batch_normalization(x, mean, var, beta, gamma, epsilon=1e-3):\n+def batch_normalization(x, mean, var, beta, gamma, axis=-1, epsilon=1e-3):\n     # The mean / var / beta / gamma may be processed by broadcast\n     # so it may have an extra batch axis with 1, it is not needed\n     # in cntk, need to remove those dummy axis."
    },
    {
        "commit_id": "84aa7b5f4167afaa8e4b24f2449ac76c11d5e8df",
        "commit_message": "Non training Batch Norm operator has bad performance for it running into tensorflow's non fused batch norm API (#10207)\n\n* When use tensorflow as backend, let batch norm run into fused batch norm as much as possible, which has better performance.\r\n\r\nfix issue: http://github.com/keras-team/keras/issues/10058\r\n\r\n* In Tensorflow backend, let batch norm call to FusedBatchNorm only NHWC format, also gamma and beta are not None.\r\n\r\nTest result:\r\ntest env: with Tensorflow(commit a543d9471047ca3f6881c87105fcbe2cdff9207d Date:   Thu May 10 17:43:30 2018, local build), python3.4, centos7.4\r\ntest cases:\r\n  \"pytest  ./tests/keras/layers/normalization_test.py\"  <all passed>\r\n  \"pytest  ./tests\"      <keep same result as without this commit's modification on BN>\r\n\r\n* fix code sytle.\r\n\r\n* 1. Add axis parameter in backend's batch_normalization functions.\r\n2. Refine the batch_normalization function in tensorflow backend, Let's it call to fused batch norm as much as possible.\r\n\r\nThanks the coments from fchollet.\r\n\r\n* Trigger\r\n\r\n* 1. add default value -1 for parameter axis in batch_normalization function in backend.\r\n2. fix some code style.\r\nThanks the comments from fchollet.",
        "commit_url": "https://github.com/keras-team/keras/commit/84aa7b5f4167afaa8e4b24f2449ac76c11d5e8df",
        "buggy_code": "def batch_normalization(x, mean, var, beta, gamma, epsilon=1e-3):",
        "fixed_code": "def batch_normalization(x, mean, var, beta, gamma, axis=-1, epsilon=1e-3):",
        "patch": "@@ -731,7 +731,7 @@ def normalize_batch_in_training(x, gamma, beta,\n     return normed, mean, T.inv(stdinv ** 2)\n \n \n-def batch_normalization(x, mean, var, beta, gamma, epsilon=1e-3):\n+def batch_normalization(x, mean, var, beta, gamma, axis=-1, epsilon=1e-3):\n     \"\"\"Apply batch normalization on x given mean, var, beta and gamma.\n     \"\"\"\n     # TODO remove this if statement when Theano without"
    },
    {
        "commit_id": "b8ac7e07b97c82f4870758fd5ee28ea64af4ee6b",
        "commit_message": "Fix duplicated argname: num_gpus === parts (#10228)\n\nSigned-off-by: CUI Wei <ghostplant@qq.com>",
        "commit_url": "https://github.com/keras-team/keras/commit/b8ac7e07b97c82f4870758fd5ee28ea64af4ee6b",
        "buggy_code": "if i == num_gpus - 1:",
        "fixed_code": "if i == parts - 1:",
        "patch": "@@ -184,7 +184,7 @@ def get_slice(data, i, parts):\n         batch_size = shape[:1]\n         input_shape = shape[1:]\n         step = batch_size // parts\n-        if i == num_gpus - 1:\n+        if i == parts - 1:\n             size = batch_size - step * i\n         else:\n             size = step"
    },
    {
        "commit_id": "4f1ea9affa135121ee2336cd2be541aa2ffa150e",
        "commit_message": "Grammatical error - \"inputs channels\" rather than \"input\". (#10217)",
        "commit_url": "https://github.com/keras-team/keras/commit/4f1ea9affa135121ee2336cd2be541aa2ffa150e",
        "buggy_code": "It should have exactly 3 inputs channels,",
        "fixed_code": "It should have exactly 3 input channels,",
        "patch": "@@ -89,7 +89,7 @@ def NASNet(input_shape=None,\n         input_shape: Optional shape tuple, the input shape\n             is by default `(331, 331, 3)` for NASNetLarge and\n             `(224, 224, 3)` for NASNetMobile.\n-            It should have exactly 3 inputs channels,\n+            It should have exactly 3 input channels,\n             and width and height should be no smaller than 32.\n             E.g. `(224, 224, 3)` would be one valid value.\n         penultimate_filters: Number of filters in the penultimate layer."
    },
    {
        "commit_id": "d7884570b10951d156aa086ee29a4df9eab79cf3",
        "commit_message": "Allow dynamic backends in _need_convert_kernel (#10111)\n\n* Fix _need_convert_kernel for external backends\r\n\r\n* Don't assume external backend won't support NASNet\r\n\r\n* Update from review comments",
        "commit_url": "https://github.com/keras-team/keras/commit/d7884570b10951d156aa086ee29a4df9eab79cf3",
        "buggy_code": "if K.backend() != 'tensorflow':",
        "fixed_code": "if K.backend() in ['cntk', 'theano']:",
        "patch": "@@ -143,7 +143,7 @@ def NASNet(input_shape=None,\n         RuntimeError: If attempting to run this model with a\n             backend that does not support separable convolutions.\n     '''\n-    if K.backend() != 'tensorflow':\n+    if K.backend() in ['cntk', 'theano']:\n         raise RuntimeError('Only TensorFlow backend is currently supported, '\n                            'as other backends do not support '\n                            'separable convolution.')"
    },
    {
        "commit_id": "f0e197e7ff42b9b096b81a9449f8cb90c6bc7922",
        "commit_message": "fix typo (#10078)",
        "commit_url": "https://github.com/keras-team/keras/commit/f0e197e7ff42b9b096b81a9449f8cb90c6bc7922",
        "buggy_code": "Every `Sequence` must implements the `__getitem__` and the `__len__` methods.",
        "fixed_code": "Every `Sequence` must implement the `__getitem__` and the `__len__` methods.",
        "patch": "@@ -302,7 +302,7 @@ def validate_file(fpath, file_hash, algorithm='auto', chunk_size=65535):\n class Sequence(object):\n     \"\"\"Base object for fitting to a sequence of data, such as a dataset.\n \n-    Every `Sequence` must implements the `__getitem__` and the `__len__` methods.\n+    Every `Sequence` must implement the `__getitem__` and the `__len__` methods.\n     If you want to modify your dataset between epochs you may implement `on_epoch_end`.\n     The method `__getitem__` should return a complete batch.\n "
    },
    {
        "commit_id": "a637960fab61b66848a36e6a5caf0204c155af01",
        "commit_message": "[RELNOTES] Simplify implementation of Sequential and remove legacy Merge support (#10077)\n\n* Refactor topological part of Keras engine.\r\n\r\n* Fix imports\r\n\r\n* Fix merge mixup.\r\n\r\n* Refactor training part of the Keras engine.\r\n\r\n* Fix unit tests.\r\n\r\n* Refactor Network to prepare support for Model subclassing\r\n\r\n* Finish enabling Model subclassing.\r\n\r\n* Simplify Sequential implementation.\r\n\r\nRELNOTES: This breaks weight loading and model loading/saving for models from Keras 0.* that used Merge layers. The Merge layer has been deprecated for 2 years.\r\n\r\n* [RELNOTES] Remove support for Keras 0.* Merge layer and associated functionality, which was scheduled for 08/2017.",
        "commit_url": "https://github.com/keras-team/keras/commit/a637960fab61b66848a36e6a5caf0204c155af01",
        "buggy_code": "model.model._make_train_function()",
        "fixed_code": "model._make_train_function()",
        "patch": "@@ -226,7 +226,7 @@ def test_saving_right_after_compilation():\n     model.add(Dense(2, input_shape=(3,)))\n     model.add(Dense(3))\n     model.compile(loss='mse', optimizer='sgd', metrics=['acc'])\n-    model.model._make_train_function()\n+    model._make_train_function()\n \n     _, fname = tempfile.mkstemp('.h5')\n     save_model(model, fname)"
    },
    {
        "commit_id": "3b440235e237ef59ec5763c413e7f4292dab5d79",
        "commit_message": "Enable Model subclassing API (#10046)\n\n* Refactor topological part of Keras engine.\r\n\r\n* Fix imports\r\n\r\n* Fix merge mixup.\r\n\r\n* Refactor training part of the Keras engine.\r\n\r\n* Fix unit tests.\r\n\r\n* Refactor Network to prepare support for Model subclassing\r\n\r\n* Finish enabling Model subclassing.",
        "commit_url": "https://github.com/keras-team/keras/commit/3b440235e237ef59ec5763c413e7f4292dab5d79",
        "buggy_code": "if include_optimizer and hasattr(model, 'optimizer'):",
        "fixed_code": "if include_optimizer and model.optimizer:",
        "patch": "@@ -125,7 +125,7 @@ def get_json_type(obj):\n             model_layers = model.layers\n         save_weights_to_hdf5_group(model_weights_group, model_layers)\n \n-        if include_optimizer and hasattr(model, 'optimizer'):\n+        if include_optimizer and model.optimizer:\n             if isinstance(model.optimizer, optimizers.TFOptimizer):\n                 warnings.warn(\n                     'TensorFlow optimizers do not '"
    },
    {
        "commit_id": "49f5b931410bc2e56378f20a15e8ac919e0efb88",
        "commit_message": "Refactor topological part of `engine` module (#10023)\n\n* Refactor topological part of Keras engine.\r\n\r\n* Fix imports\r\n\r\n* Fix merge mixup.",
        "commit_url": "https://github.com/keras-team/keras/commit/49f5b931410bc2e56378f20a15e8ac919e0efb88",
        "buggy_code": "from keras.engine.topology import Layer",
        "fixed_code": "from keras.layers import Layer",
        "patch": "@@ -14,7 +14,7 @@\n \n from __future__ import print_function\n from keras import backend as K\n-from keras.engine.topology import Layer\n+from keras.layers import Layer\n from keras import activations\n from keras import utils\n from keras.datasets import cifar10"
    },
    {
        "commit_id": "49f5b931410bc2e56378f20a15e8ac919e0efb88",
        "commit_message": "Refactor topological part of `engine` module (#10023)\n\n* Refactor topological part of Keras engine.\r\n\r\n* Fix imports\r\n\r\n* Fix merge mixup.",
        "commit_url": "https://github.com/keras-team/keras/commit/49f5b931410bc2e56378f20a15e8ac919e0efb88",
        "buggy_code": "from ..engine.topology import get_source_inputs",
        "fixed_code": "from ..engine import get_source_inputs",
        "patch": "@@ -33,7 +33,7 @@\n from ..layers import MaxPooling2D\n from ..layers import ZeroPadding2D\n from ..utils.data_utils import get_file\n-from ..engine.topology import get_source_inputs\n+from ..engine import get_source_inputs\n from . import imagenet_utils\n from .imagenet_utils import decode_predictions\n from .imagenet_utils import _obtain_input_shape"
    },
    {
        "commit_id": "49f5b931410bc2e56378f20a15e8ac919e0efb88",
        "commit_message": "Refactor topological part of `engine` module (#10023)\n\n* Refactor topological part of Keras engine.\r\n\r\n* Fix imports\r\n\r\n* Fix merge mixup.",
        "commit_url": "https://github.com/keras-team/keras/commit/49f5b931410bc2e56378f20a15e8ac919e0efb88",
        "buggy_code": "from ..engine.topology import get_source_inputs",
        "fixed_code": "from ..engine import get_source_inputs",
        "patch": "@@ -33,7 +33,7 @@\n from ..layers import Lambda\n from ..layers import MaxPooling2D\n from ..utils.data_utils import get_file\n-from ..engine.topology import get_source_inputs\n+from ..engine import get_source_inputs\n from . import imagenet_utils\n from .imagenet_utils import _obtain_input_shape\n from .imagenet_utils import decode_predictions"
    },
    {
        "commit_id": "49f5b931410bc2e56378f20a15e8ac919e0efb88",
        "commit_message": "Refactor topological part of `engine` module (#10023)\n\n* Refactor topological part of Keras engine.\r\n\r\n* Fix imports\r\n\r\n* Fix merge mixup.",
        "commit_url": "https://github.com/keras-team/keras/commit/49f5b931410bc2e56378f20a15e8ac919e0efb88",
        "buggy_code": "from ..engine.topology import get_source_inputs",
        "fixed_code": "from ..engine import get_source_inputs",
        "patch": "@@ -28,7 +28,7 @@\n from ..layers import AveragePooling2D\n from ..layers import GlobalAveragePooling2D\n from ..layers import GlobalMaxPooling2D\n-from ..engine.topology import get_source_inputs\n+from ..engine import get_source_inputs\n from ..utils.data_utils import get_file\n from .. import backend as K\n from . import imagenet_utils"
    },
    {
        "commit_id": "49f5b931410bc2e56378f20a15e8ac919e0efb88",
        "commit_message": "Refactor topological part of `engine` module (#10023)\n\n* Refactor topological part of Keras engine.\r\n\r\n* Fix imports\r\n\r\n* Fix merge mixup.",
        "commit_url": "https://github.com/keras-team/keras/commit/49f5b931410bc2e56378f20a15e8ac919e0efb88",
        "buggy_code": "from ..engine.topology import get_source_inputs",
        "fixed_code": "from ..engine import get_source_inputs",
        "patch": "@@ -54,7 +54,7 @@\n from ..layers import concatenate\n from ..layers import add\n from ..utils.data_utils import get_file\n-from ..engine.topology import get_source_inputs\n+from ..engine import get_source_inputs\n from ..applications.imagenet_utils import _obtain_input_shape\n from ..applications.inception_v3 import preprocess_input\n from ..applications.imagenet_utils import decode_predictions"
    },
    {
        "commit_id": "49f5b931410bc2e56378f20a15e8ac919e0efb88",
        "commit_message": "Refactor topological part of `engine` module (#10023)\n\n* Refactor topological part of Keras engine.\r\n\r\n* Fix imports\r\n\r\n* Fix merge mixup.",
        "commit_url": "https://github.com/keras-team/keras/commit/49f5b931410bc2e56378f20a15e8ac919e0efb88",
        "buggy_code": "from ..engine.topology import get_source_inputs",
        "fixed_code": "from ..engine import get_source_inputs",
        "patch": "@@ -28,7 +28,7 @@\n from ..layers import BatchNormalization\n from ..models import Model\n from .. import backend as K\n-from ..engine.topology import get_source_inputs\n+from ..engine import get_source_inputs\n from ..utils import layer_utils\n from ..utils.data_utils import get_file\n from .imagenet_utils import decode_predictions"
    },
    {
        "commit_id": "49f5b931410bc2e56378f20a15e8ac919e0efb88",
        "commit_message": "Refactor topological part of `engine` module (#10023)\n\n* Refactor topological part of Keras engine.\r\n\r\n* Fix imports\r\n\r\n* Fix merge mixup.",
        "commit_url": "https://github.com/keras-team/keras/commit/49f5b931410bc2e56378f20a15e8ac919e0efb88",
        "buggy_code": "from ..engine.topology import get_source_inputs",
        "fixed_code": "from ..engine import get_source_inputs",
        "patch": "@@ -21,7 +21,7 @@\n from ..layers import MaxPooling2D\n from ..layers import GlobalAveragePooling2D\n from ..layers import GlobalMaxPooling2D\n-from ..engine.topology import get_source_inputs\n+from ..engine import get_source_inputs\n from ..utils import layer_utils\n from ..utils.data_utils import get_file\n from .. import backend as K"
    },
    {
        "commit_id": "49f5b931410bc2e56378f20a15e8ac919e0efb88",
        "commit_message": "Refactor topological part of `engine` module (#10023)\n\n* Refactor topological part of Keras engine.\r\n\r\n* Fix imports\r\n\r\n* Fix merge mixup.",
        "commit_url": "https://github.com/keras-team/keras/commit/49f5b931410bc2e56378f20a15e8ac919e0efb88",
        "buggy_code": "from ..engine.topology import get_source_inputs",
        "fixed_code": "from ..engine import get_source_inputs",
        "patch": "@@ -21,7 +21,7 @@\n from ..layers import MaxPooling2D\n from ..layers import GlobalAveragePooling2D\n from ..layers import GlobalMaxPooling2D\n-from ..engine.topology import get_source_inputs\n+from ..engine import get_source_inputs\n from ..utils import layer_utils\n from ..utils.data_utils import get_file\n from .. import backend as K"
    },
    {
        "commit_id": "49f5b931410bc2e56378f20a15e8ac919e0efb88",
        "commit_message": "Refactor topological part of `engine` module (#10023)\n\n* Refactor topological part of Keras engine.\r\n\r\n* Fix imports\r\n\r\n* Fix merge mixup.",
        "commit_url": "https://github.com/keras-team/keras/commit/49f5b931410bc2e56378f20a15e8ac919e0efb88",
        "buggy_code": "from ..engine.topology import get_source_inputs",
        "fixed_code": "from ..engine import get_source_inputs",
        "patch": "@@ -35,7 +35,7 @@\n from ..layers import MaxPooling2D\n from ..layers import GlobalAveragePooling2D\n from ..layers import GlobalMaxPooling2D\n-from ..engine.topology import get_source_inputs\n+from ..engine import get_source_inputs\n from ..utils.data_utils import get_file\n from .. import backend as K\n from . import imagenet_utils"
    },
    {
        "commit_id": "49f5b931410bc2e56378f20a15e8ac919e0efb88",
        "commit_message": "Refactor topological part of `engine` module (#10023)\n\n* Refactor topological part of Keras engine.\r\n\r\n* Fix imports\r\n\r\n* Fix merge mixup.",
        "commit_url": "https://github.com/keras-team/keras/commit/49f5b931410bc2e56378f20a15e8ac919e0efb88",
        "buggy_code": "from ..engine import InputSpec, Layer",
        "fixed_code": "from ..engine.base_layer import InputSpec, Layer",
        "patch": "@@ -15,7 +15,7 @@\n \n import numpy as np\n import warnings\n-from ..engine import InputSpec, Layer\n+from ..engine.base_layer import InputSpec, Layer\n from ..utils import conv_utils\n from ..legacy import interfaces\n from ..legacy.layers import Recurrent, ConvRecurrent2D"
    },
    {
        "commit_id": "49f5b931410bc2e56378f20a15e8ac919e0efb88",
        "commit_message": "Refactor topological part of `engine` module (#10023)\n\n* Refactor topological part of Keras engine.\r\n\r\n* Fix imports\r\n\r\n* Fix merge mixup.",
        "commit_url": "https://github.com/keras-team/keras/commit/49f5b931410bc2e56378f20a15e8ac919e0efb88",
        "buggy_code": "from ..engine import Layer",
        "fixed_code": "from ..engine.base_layer import Layer",
        "patch": "@@ -8,7 +8,7 @@\n from .. import initializers\n from .. import regularizers\n from .. import constraints\n-from ..engine import Layer\n+from ..engine.base_layer import Layer\n from ..legacy import interfaces\n \n "
    },
    {
        "commit_id": "49f5b931410bc2e56378f20a15e8ac919e0efb88",
        "commit_message": "Refactor topological part of `engine` module (#10023)\n\n* Refactor topological part of Keras engine.\r\n\r\n* Fix imports\r\n\r\n* Fix merge mixup.",
        "commit_url": "https://github.com/keras-team/keras/commit/49f5b931410bc2e56378f20a15e8ac919e0efb88",
        "buggy_code": "from ..engine.topology import Layer",
        "fixed_code": "from ..engine.base_layer import Layer",
        "patch": "@@ -4,7 +4,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-from ..engine.topology import Layer\n+from ..engine.base_layer import Layer\n from .. import backend as K\n \n "
    },
    {
        "commit_id": "49f5b931410bc2e56378f20a15e8ac919e0efb88",
        "commit_message": "Refactor topological part of `engine` module (#10023)\n\n* Refactor topological part of Keras engine.\r\n\r\n* Fix imports\r\n\r\n* Fix merge mixup.",
        "commit_url": "https://github.com/keras-team/keras/commit/49f5b931410bc2e56378f20a15e8ac919e0efb88",
        "buggy_code": "from ..engine import Layer",
        "fixed_code": "from ..engine.base_layer import Layer",
        "patch": "@@ -5,7 +5,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-from ..engine import Layer\n+from ..engine.base_layer import Layer\n from .. import backend as K\n import numpy as np\n from ..legacy import interfaces"
    },
    {
        "commit_id": "49f5b931410bc2e56378f20a15e8ac919e0efb88",
        "commit_message": "Refactor topological part of `engine` module (#10023)\n\n* Refactor topological part of Keras engine.\r\n\r\n* Fix imports\r\n\r\n* Fix merge mixup.",
        "commit_url": "https://github.com/keras-team/keras/commit/49f5b931410bc2e56378f20a15e8ac919e0efb88",
        "buggy_code": "from ..engine import Layer, InputSpec",
        "fixed_code": "from ..engine.base_layer import Layer, InputSpec",
        "patch": "@@ -5,7 +5,7 @@\n from __future__ import division\n from __future__ import print_function\n \n-from ..engine import Layer, InputSpec\n+from ..engine.base_layer import Layer, InputSpec\n from .. import initializers\n from .. import regularizers\n from .. import constraints"
    },
    {
        "commit_id": "49f5b931410bc2e56378f20a15e8ac919e0efb88",
        "commit_message": "Refactor topological part of `engine` module (#10023)\n\n* Refactor topological part of Keras engine.\r\n\r\n* Fix imports\r\n\r\n* Fix merge mixup.",
        "commit_url": "https://github.com/keras-team/keras/commit/49f5b931410bc2e56378f20a15e8ac919e0efb88",
        "buggy_code": "from ..engine.topology import Layer, InputSpec",
        "fixed_code": "from ..engine import Layer, InputSpec",
        "patch": "@@ -6,7 +6,7 @@\n import types as python_types\n import warnings\n \n-from ..engine.topology import Layer, InputSpec\n+from ..engine import Layer, InputSpec\n from .. import backend as K\n from ..utils.generic_utils import func_dump, func_load, has_arg\n from ..utils import conv_utils"
    },
    {
        "commit_id": "49f5b931410bc2e56378f20a15e8ac919e0efb88",
        "commit_message": "Refactor topological part of `engine` module (#10023)\n\n* Refactor topological part of Keras engine.\r\n\r\n* Fix imports\r\n\r\n* Fix merge mixup.",
        "commit_url": "https://github.com/keras-team/keras/commit/49f5b931410bc2e56378f20a15e8ac919e0efb88",
        "buggy_code": "if node_key in model._container_nodes:",
        "fixed_code": "if node_key in model._network_nodes:",
        "patch": "@@ -106,7 +106,7 @@ def model_to_dot(model,\n         layer_id = str(id(layer))\n         for i, node in enumerate(layer._inbound_nodes):\n             node_key = layer.name + '_ib-' + str(i)\n-            if node_key in model._container_nodes:\n+            if node_key in model._network_nodes:\n                 for inbound_layer in node.inbound_layers:\n                     inbound_layer_id = str(id(inbound_layer))\n                     layer_id = str(id(layer))"
    },
    {
        "commit_id": "49f5b931410bc2e56378f20a15e8ac919e0efb88",
        "commit_message": "Refactor topological part of `engine` module (#10023)\n\n* Refactor topological part of Keras engine.\r\n\r\n* Fix imports\r\n\r\n* Fix merge mixup.",
        "commit_url": "https://github.com/keras-team/keras/commit/49f5b931410bc2e56378f20a15e8ac919e0efb88",
        "buggy_code": "from keras.engine.topology import Input",
        "fixed_code": "from keras.engine import Input",
        "patch": "@@ -8,7 +8,7 @@\n import keras\n from keras import losses\n from keras.layers import Dense, Dropout\n-from keras.engine.topology import Input\n+from keras.engine import Input\n from keras.engine.training import Model\n from keras.engine.training import _check_loss_and_target_compatibility\n from keras.engine.training import _weighted_masked_objective"
    },
    {
        "commit_id": "a8ca67f281bdc5d751204e3b2bf6e98731513a27",
        "commit_message": "Chenta/cntk bn (#9952)\n\n* fix cntk static learning phase issue; add a test\r\n\r\n* fix code style;add more comments\r\n\r\n* add boolean support\r\n\r\n* fix code style issue",
        "commit_url": "https://github.com/keras-team/keras/commit/a8ca67f281bdc5d751204e3b2bf6e98731513a27",
        "buggy_code": "if K.backend() == 'tensorflow':",
        "fixed_code": "if K.backend() == 'tensorflow' or K.backend() == 'cntk':",
        "patch": "@@ -159,7 +159,7 @@ def keras_test(func):\n     @six.wraps(func)\n     def wrapper(*args, **kwargs):\n         output = func(*args, **kwargs)\n-        if K.backend() == 'tensorflow':\n+        if K.backend() == 'tensorflow' or K.backend() == 'cntk':\n             K.clear_session()\n         return output\n     return wrapper"
    },
    {
        "commit_id": "946a3b371567af143e13c159f00051353f161c56",
        "commit_message": "import `pydot`, improve error messages about `pydot` and GraphViz, bump to `pydot >= 1.2.4` (#9904)\n\n* REL: bump to `pydot >= 1.2.4` in `extras_require`\r\n\r\n* MAI: import pydot (as required in `extras_require`)\r\n\r\n* MAI: refine error messages for `pydot` and GraphViz\r\n\r\ndistinguish between absence of `pydot` and failure to find\r\nthe executables of GraphViz in the $PATH.\r\n\r\n* DEV: ignore `.pytest_cache`",
        "commit_url": "https://github.com/keras-team/keras/commit/946a3b371567af143e13c159f00051353f161c56",
        "buggy_code": "'visualize': ['pydot>=1.2.0'],",
        "fixed_code": "'visualize': ['pydot>=1.2.4'],",
        "patch": "@@ -16,7 +16,7 @@\n                         'pyyaml',\n                         'h5py'],\n       extras_require={\n-          'visualize': ['pydot>=1.2.0'],\n+          'visualize': ['pydot>=1.2.4'],\n           'tests': ['pytest',\n                     'pytest-pep8',\n                     'pytest-xdist',"
    },
    {
        "commit_id": "e85d3dc15072f774736eb0e3c216eb0b7da1db9a",
        "commit_message": "Fix error in ImageDataGenerator documentation (#9798)\n\nThe documentation says \"direction as radians\". However, on line 846, deg2rad() is applied to the argument, implying that the argument should be given in degrees.",
        "commit_url": "https://github.com/keras-team/keras/commit/e85d3dc15072f774736eb0e3c216eb0b7da1db9a",
        "buggy_code": "shear_range: Float. Shear Intensity (Shear angle in counter-clockwise direction as radians)",
        "fixed_code": "shear_range: Float. Shear Intensity (Shear angle in counter-clockwise direction in degrees)",
        "patch": "@@ -425,7 +425,7 @@ class ImageDataGenerator(object):\n         rotation_range: Int. Degree range for random rotations.\n         width_shift_range: Float (fraction of total width). Range for random horizontal shifts.\n         height_shift_range: Float (fraction of total height). Range for random vertical shifts.\n-        shear_range: Float. Shear Intensity (Shear angle in counter-clockwise direction as radians)\n+        shear_range: Float. Shear Intensity (Shear angle in counter-clockwise direction in degrees)\n         zoom_range: Float or [lower, upper]. Range for random zoom. If a float, `[lower, upper] = [1-zoom_range, 1+zoom_range]`.\n         channel_shift_range: Float. Range for random channel shifts.\n         fill_mode: One of {\"constant\", \"nearest\", \"reflect\" or \"wrap\"}.  Default is 'nearest'."
    },
    {
        "commit_id": "99c61ebd50912ec0981a11116b03265cb7cfaa3f",
        "commit_message": "fix typo (#9792)\n\n* Fix typo",
        "commit_url": "https://github.com/keras-team/keras/commit/99c61ebd50912ec0981a11116b03265cb7cfaa3f",
        "buggy_code": "This is seful to reserve part of the data for test or validation.",
        "fixed_code": "This is useful to reserve part of the data for test or validation.",
        "patch": "@@ -270,7 +270,7 @@ class TimeseriesGenerator(Sequence):\n             be centered around `data[i]`, `data[i+s]`, `data[i+2*s]`, etc.\n         start_index, end_index: Data points earlier than `start_index`\n             or later than `end_index` will not be used in the output sequences.\n-            This is seful to reserve part of the data for test or validation.\n+            This is useful to reserve part of the data for test or validation.\n         shuffle: Whether to shuffle output samples,\n             or instead draw them in chronological order.\n         reverse: Boolean: if `true`, timesteps in each output sample will be"
    },
    {
        "commit_id": "9f8f520767a322165b01303f84943e59be342beb",
        "commit_message": "Fixes type error in Sequence example (#9703)",
        "commit_url": "https://github.com/keras-team/keras/commit/9f8f520767a322165b01303f84943e59be342beb",
        "buggy_code": "return np.ceil(len(self.x) / float(self.batch_size))",
        "fixed_code": "return int(np.ceil(len(self.x) / float(self.batch_size)))",
        "patch": "@@ -328,7 +328,7 @@ def __init__(self, x_set, y_set, batch_size):\n                 self.batch_size = batch_size\n \n             def __len__(self):\n-                return np.ceil(len(self.x) / float(self.batch_size))\n+                return int(np.ceil(len(self.x) / float(self.batch_size)))\n \n             def __getitem__(self, idx):\n                 batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]"
    },
    {
        "commit_id": "a82ad3a617b6c8192688c022c7df3fde71fe91f7",
        "commit_message": "Fix tensorflow_backend  deprecation warning (#9488)\n\nWARNING:tensorflow:From .../lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3148: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\ndim is deprecated, use axis instead",
        "commit_url": "https://github.com/keras-team/keras/commit/a82ad3a617b6c8192688c022c7df3fde71fe91f7",
        "buggy_code": "return tf.nn.l2_normalize(x, dim=axis)",
        "fixed_code": "return tf.nn.l2_normalize(x, axis=axis)",
        "patch": "@@ -3148,7 +3148,7 @@ def l2_normalize(x, axis=None):\n     # Returns\n         A tensor.\n     \"\"\"\n-    return tf.nn.l2_normalize(x, dim=axis)\n+    return tf.nn.l2_normalize(x, axis=axis)\n \n \n def in_top_k(predictions, targets, k):"
    },
    {
        "commit_id": "4b9ba1b3fa99755910971bd75a87f3d6824d2be8",
        "commit_message": "Fixing minor bug in pretrained_word_embeddings example (#9438)",
        "commit_url": "https://github.com/keras-team/keras/commit/4b9ba1b3fa99755910971bd75a87f3d6824d2be8",
        "buggy_code": "num_words = min(MAX_NUM_WORDS, len(word_index))",
        "fixed_code": "num_words = min(MAX_NUM_WORDS, len(word_index) + 1)",
        "patch": "@@ -101,7 +101,7 @@\n print('Preparing embedding matrix.')\n \n # prepare embedding matrix\n-num_words = min(MAX_NUM_WORDS, len(word_index))\n+num_words = min(MAX_NUM_WORDS, len(word_index) + 1)\n embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n for word, i in word_index.items():\n     if i >= MAX_NUM_WORDS:"
    },
    {
        "commit_id": "ffb8b813818221a9b43d51e251d489a40b116607",
        "commit_message": "typo fix (#9432)",
        "commit_url": "https://github.com/keras-team/keras/commit/ffb8b813818221a9b43d51e251d489a40b116607",
        "buggy_code": "If unspecified, `workers` will default to False.",
        "fixed_code": "If unspecified, `use_multiprocessing` will default to False.",
        "patch": "@@ -2034,7 +2034,7 @@ def fit_generator(self,\n                 If unspecified, `workers` will default to 1. If 0, will\n                 execute the generator on the main thread.\n             use_multiprocessing: Boolean. If True, use process based threading.\n-                If unspecified, `workers` will default to False.\n+                If unspecified, `use_multiprocessing` will default to False.\n                 Note that because\n                 this implementation relies on multiprocessing,\n                 you should not pass"
    },
    {
        "commit_id": "b6596a56992ea7902b255c61f46c1f5fa8ac5e98",
        "commit_message": "Fix description of epoch (#9415)",
        "commit_url": "https://github.com/keras-team/keras/commit/b6596a56992ea7902b255c61f46c1f5fa8ac5e98",
        "buggy_code": "epoch epochs is reached.",
        "fixed_code": "epoch of index `epochs` is reached.",
        "patch": "@@ -1181,7 +1181,7 @@ def fit_generator(self, generator,\n                 Note that in conjunction with initial_epoch, the parameter\n                 epochs is to be understood as \"final epoch\". The model is\n                 not trained for n steps given by epochs, but until the\n-                epoch epochs is reached.\n+                epoch of index `epochs` is reached.\n             verbose: Verbosity mode, 0, 1, or 2.\n             callbacks: List of callbacks to be called during training.\n             validation_data: This can be either"
    },
    {
        "commit_id": "ed204e116d6e8f8dc1f700a6f6f2026c6437c420",
        "commit_message": "fix typo (#9391)",
        "commit_url": "https://github.com/keras-team/keras/commit/ed204e116d6e8f8dc1f700a6f6f2026c6437c420",
        "buggy_code": "so the probelm becomes a 10 two-classification problems",
        "fixed_code": "so the problem becomes a 10 two-classification problem.",
        "patch": "@@ -171,7 +171,7 @@ def compute_output_shape(self, input_shape):\n the output of final model is the lengths of 10 Capsule, whose dim=16.\n \n the length of Capsule is the proba,\n-so the probelm becomes a 10 two-classification problems\n+so the problem becomes a 10 two-classification problem.\n \"\"\"\n \n x = Reshape((-1, 128))(x)"
    },
    {
        "commit_id": "4c79e3e16c88b2714c894f0e73f6b2e536d74123",
        "commit_message": "The type of list keys was float (#9324)\n\nIn my env, the error shown below occured, and it would be fixed by this change.  \r\nThe error is similer to [this thread](https://stackoverflow.com/questions/34952651/only-integers-slices-ellipsis-numpy-newaxis-none-and-intege) and I fixed it.\r\n\r\n## error occured\r\n```\r\n---------------------------------------------------------------------------\r\nIndexError                                Traceback (most recent call last)\r\n<ipython-input-2-c38539c7e5b8> in <module>()\r\n    385 # run the experiments\r\n    386 net2wider_experiment()\r\n--> 387 net2deeper_experiment()\r\n\r\n<ipython-input-2-c38539c7e5b8> in net2deeper_experiment()\r\n    375                               x_test, y_test,\r\n    376                               init='net2deeper',\r\n--> 377                               epochs=epochs)\r\n    378 \r\n    379 \r\n\r\n<ipython-input-2-c38539c7e5b8> in make_deeper_student_model(teacher_model, x_train, y_train, x_test, y_test, init, epochs)\r\n    301     if init == 'net2deeper':\r\n    302         prev_w, _ = model.get_layer('conv2').get_weights()\r\n--> 303         new_weights = deeper2net_conv2d(prev_w)\r\n    304         model.add(Conv2D(64, 3, padding='same',\r\n    305                          name='conv2-deeper', weights=new_weights))\r\n\r\n<ipython-input-2-c38539c7e5b8> in deeper2net_conv2d(teacher_w)\r\n    196     student_w = np.zeros_like(teacher_w)\r\n    197     for i in range(filters):\r\n--> 198         student_w[(kh - 1) / 2, (kw - 1) / 2, i, i] = 1.\r\n    199     student_b = np.zeros(filters)\r\n    200     return student_w, student_b\r\n\r\nIndexError: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices\r\n```\r\n\r\n## my environment\r\n```\r\n# python -V\r\nPython 3.6.2\r\n# pip freeze | grep Keras\r\nKeras==2.0.9\r\n# pip freeze | grep numpy\r\nnumpy==1.13.3\r\n```",
        "commit_url": "https://github.com/keras-team/keras/commit/4c79e3e16c88b2714c894f0e73f6b2e536d74123",
        "buggy_code": "student_w[(kh - 1) / 2, (kw - 1) / 2, i, i] = 1.",
        "fixed_code": "student_w[(kh - 1) // 2, (kw - 1) // 2, i, i] = 1.",
        "patch": "@@ -208,7 +208,7 @@ def deeper2net_conv2d(teacher_w):\n     kh, kw, num_channel, filters = teacher_w.shape\n     student_w = np.zeros_like(teacher_w)\n     for i in range(filters):\n-        student_w[(kh - 1) / 2, (kw - 1) / 2, i, i] = 1.\n+        student_w[(kh - 1) // 2, (kw - 1) // 2, i, i] = 1.\n     student_b = np.zeros(filters)\n     return student_w, student_b\n "
    },
    {
        "commit_id": "45e478a5c0bf3e43bc178e14c470c9831e0a3383",
        "commit_message": "fix issue 9267",
        "commit_url": "https://github.com/keras-team/keras/commit/45e478a5c0bf3e43bc178e14c470c9831e0a3383",
        "buggy_code": "regularization_losses = [layer.activity_regularizer(x) for x in computed_tensors]",
        "fixed_code": "regularization_losses = [layer.activity_regularizer(x) for x in output_tensors]",
        "patch": "@@ -2246,7 +2246,7 @@ def run_internal_graph(self, inputs, masks=None):\n \n                         # Apply activity regularizer if any:\n                         if hasattr(layer, 'activity_regularizer') and layer.activity_regularizer is not None:\n-                            regularization_losses = [layer.activity_regularizer(x) for x in computed_tensors]\n+                            regularization_losses = [layer.activity_regularizer(x) for x in output_tensors]\n                             layer.add_loss(regularization_losses, computed_tensors)\n \n                     # Update model updates and losses:"
    },
    {
        "commit_id": "5822ee2b95ab2fff640abcc7233c0ee67620cdf6",
        "commit_message": "Regularization bug. Tests and fix. (#9098)\n\n* Added tests showing regularization bug.\r\n\r\n* Fixed bug using the 'is' operator in losses(self).\r\n\r\n* The check is only performed for tensors that are associated with weight regularization.\r\n\r\n* Improved tests. Created id for weights.\r\n\r\n* Used set() only for tensors.\r\n\r\n* Changed seed for random_normal.",
        "commit_url": "https://github.com/keras-team/keras/commit/5822ee2b95ab2fff640abcc7233c0ee67620cdf6",
        "buggy_code": "return random_normal_variable(shape=shape, mean=mean, scale=1.0)",
        "fixed_code": "return random_normal_variable(shape=shape, mean=mean, scale=1.0, seed=seed)",
        "patch": "@@ -447,7 +447,7 @@ def random_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n                              'Please provide fixed dimension '\n                              'instead of `None`.')\n     # how to apply mean and stddev\n-    return random_normal_variable(shape=shape, mean=mean, scale=1.0)\n+    return random_normal_variable(shape=shape, mean=mean, scale=1.0, seed=seed)\n \n \n def truncated_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):"
    },
    {
        "commit_id": "5822ee2b95ab2fff640abcc7233c0ee67620cdf6",
        "commit_message": "Regularization bug. Tests and fix. (#9098)\n\n* Added tests showing regularization bug.\r\n\r\n* Fixed bug using the 'is' operator in losses(self).\r\n\r\n* The check is only performed for tensors that are associated with weight regularization.\r\n\r\n* Improved tests. Created id for weights.\r\n\r\n* Used set() only for tensors.\r\n\r\n* Changed seed for random_normal.",
        "commit_url": "https://github.com/keras-team/keras/commit/5822ee2b95ab2fff640abcc7233c0ee67620cdf6",
        "buggy_code": "rand = k.eval(k.random_normal((300, 200), mean=mean, stddev=std))",
        "fixed_code": "rand = k.eval(k.random_normal((300, 200), mean=mean, stddev=std, seed=1337))",
        "patch": "@@ -885,7 +885,7 @@ def test_random_normal(self):\n         mean = 0.\n         std = 1.\n         for k in BACKENDS:\n-            rand = k.eval(k.random_normal((300, 200), mean=mean, stddev=std))\n+            rand = k.eval(k.random_normal((300, 200), mean=mean, stddev=std, seed=1337))\n             assert rand.shape == (300, 200)\n             assert np.abs(np.mean(rand) - mean) < 0.015\n             assert np.abs(np.std(rand) - std) < 0.015"
    },
    {
        "commit_id": "9ab8070c77b047f8c519bd97cb38c33533639224",
        "commit_message": "Fix documentation for size of the average pooling window. (#9148)",
        "commit_url": "https://github.com/keras-team/keras/commit/9ab8070c77b047f8c519bd97cb38c33533639224",
        "buggy_code": "pool_size: Integer, size of the max pooling windows.",
        "fixed_code": "pool_size: Integer, size of the average pooling windows.",
        "patch": "@@ -88,7 +88,7 @@ class AveragePooling1D(_Pooling1D):\n     \"\"\"Average pooling for temporal data.\n \n     # Arguments\n-        pool_size: Integer, size of the max pooling windows.\n+        pool_size: Integer, size of the average pooling windows.\n         strides: Integer, or None. Factor by which to downscale.\n             E.g. 2 will halve the input.\n             If None, it will default to `pool_size`."
    },
    {
        "commit_id": "abe06d593391d25e463970e8618fc0a0f9279c45",
        "commit_message": "Fix typos (#9138)",
        "commit_url": "https://github.com/keras-team/keras/commit/abe06d593391d25e463970e8618fc0a0f9279c45",
        "buggy_code": "'''Trains a denoising autoenconder on MNIST dataset.",
        "fixed_code": "'''Trains a denoising autoencoder on MNIST dataset.",
        "patch": "@@ -1,4 +1,4 @@\n-'''Trains a denoising autoenconder on MNIST dataset.\n+'''Trains a denoising autoencoder on MNIST dataset.\n \n Denoising is one of the classic applications of autoencoders.\n The denoising process removes unwanted noise that corrupted the"
    },
    {
        "commit_id": "abe06d593391d25e463970e8618fc0a0f9279c45",
        "commit_message": "Fix typos (#9138)",
        "commit_url": "https://github.com/keras-team/keras/commit/abe06d593391d25e463970e8618fc0a0f9279c45",
        "buggy_code": "Tensorflow does not support NCHW on CPU. Therefore we check if we are not explicitly put on",
        "fixed_code": "TensorFlow does not support NCHW on CPU. Therefore we check if we are not explicitly put on",
        "patch": "@@ -272,7 +272,7 @@ def _get_available_gpus():\n def _has_nchw_support():\n     \"\"\"Check whether the current scope supports NCHW ops.\n \n-    Tensorflow does not support NCHW on CPU. Therefore we check if we are not explicitly put on\n+    TensorFlow does not support NCHW on CPU. Therefore we check if we are not explicitly put on\n     CPU, and have GPUs available. In this case there will be soft-placing on the GPU device.\n \n     # Returns"
    },
    {
        "commit_id": "b300bfb198cb1c4967b912009e18ada1affa8c38",
        "commit_message": "Fix application tests (#9135)",
        "commit_url": "https://github.com/keras-team/keras/commit/b300bfb198cb1c4967b912009e18ada1affa8c38",
        "buggy_code": "os.environ('APP_CHANGED', 'True') == 'False',",
        "fixed_code": "os.environ.get('APP_CHANGED', 'True') == 'False',",
        "patch": "@@ -12,7 +12,7 @@\n \n pytestmark = pytest.mark.skipif(\n     os.environ.get('CORE_CHANGED', 'True') == 'False' and\n-    os.environ('APP_CHANGED', 'True') == 'False',\n+    os.environ.get('APP_CHANGED', 'True') == 'False',\n     reason='Runs only when the relevant files have been modified.')\n \n "
    },
    {
        "commit_id": "58cf55038e4011bc80632f9b5fe271de22ca71f9",
        "commit_message": "Fix renamed inbound_nodes in CuDNN recurrent test. (#9127)\n\n- forgotten in commit 958239c (Make private topological properties Python-private)\r\n- rename inbound_nodes to _inbound_nodes\r\n- BTW: tests from cudnn_recurrent_test.py are not ran on Travis CI (without GPU)",
        "commit_url": "https://github.com/keras-team/keras/commit/58cf55038e4011bc80632f9b5fe271de22ca71f9",
        "buggy_code": "assert initial_state[0] in layer.inbound_nodes[0].input_tensors",
        "fixed_code": "assert initial_state[0] in layer._inbound_nodes[0].input_tensors",
        "patch": "@@ -295,7 +295,7 @@ def test_specify_initial_state_keras_tensor():\n             output = layer(inputs, initial_state=initial_state[0])\n         else:\n             output = layer(inputs, initial_state=initial_state)\n-        assert initial_state[0] in layer.inbound_nodes[0].input_tensors\n+        assert initial_state[0] in layer._inbound_nodes[0].input_tensors\n \n         model = keras.models.Model([inputs] + initial_state, output)\n         model.compile(loss='categorical_crossentropy', optimizer='adam')"
    },
    {
        "commit_id": "64f80d6077edd5f277a1181df94bf4510ea0517a",
        "commit_message": "Fix StackedRNNCells step input shape (#9090)\n\n* Fix StackedRNNCells step input shape\r\n\r\n* Add test for input shape in MinimalRNNCell.build",
        "commit_url": "https://github.com/keras-team/keras/commit/64f80d6077edd5f277a1181df94bf4510ea0517a",
        "buggy_code": "input_shape = (input_shape[0], input_shape[1], output_dim)",
        "fixed_code": "input_shape = (input_shape[0], output_dim)",
        "patch": "@@ -106,7 +106,7 @@ def build(self, input_shape):\n                 output_dim = cell.state_size[0]\n             else:\n                 output_dim = cell.state_size\n-            input_shape = (input_shape[0], input_shape[1], output_dim)\n+            input_shape = (input_shape[0], output_dim)\n         self.built = True\n \n     def get_config(self):"
    },
    {
        "commit_id": "ab25382a2fe7c0684089918ae0fdbfcecd4065d4",
        "commit_message": "Fix SyntaxError: invalid syntax in lstm_stateful.py (#9078)",
        "commit_url": "https://github.com/keras-team/keras/commit/ab25382a2fe7c0684089918ae0fdbfcecd4065d4",
        "buggy_code": "def create_model(stateful: bool):",
        "fixed_code": "def create_model(stateful):",
        "patch": "@@ -139,7 +139,7 @@ def gen_uniform_amp(amp=1, xn=10000):\n plt.show()\n \n \n-def create_model(stateful: bool):\n+def create_model(stateful):\n     model = Sequential()\n     model.add(LSTM(20,\n               input_shape=(lahead, 1),"
    },
    {
        "commit_id": "311f4542636fb070842c67da52dcea6c482bf6e9",
        "commit_message": "Update optimizers.py (#9067)\n\ntypo fix.",
        "commit_url": "https://github.com/keras-team/keras/commit/311f4542636fb070842c67da52dcea6c482bf6e9",
        "buggy_code": "amsgrad: boolean. Weather to apply the AMSGrad variant of this",
        "fixed_code": "amsgrad: boolean. Whether to apply the AMSGrad variant of this",
        "patch": "@@ -405,7 +405,7 @@ class Adam(Optimizer):\n         beta_2: float, 0 < beta < 1. Generally close to 1.\n         epsilon: float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.\n         decay: float >= 0. Learning rate decay over each update.\n-        amsgrad: boolean. Weather to apply the AMSGrad variant of this\n+        amsgrad: boolean. Whether to apply the AMSGrad variant of this\n             algorithm from the paper \"On the Convergence of Adam and\n             Beyond\".\n "
    },
    {
        "commit_id": "c3e844e7063efc14f6a8364cc04df4526b57352e",
        "commit_message": "Rewrite test_progbar(), and fix the triggered Python3 bug. (#8172)\n\n* Rewrite test_progbar\r\n\r\n* pep8\r\n\r\n* Check if target is not None before comparison.\r\n\r\nIn Python2 (None < 3)==False, but Python3 raises.",
        "commit_url": "https://github.com/keras-team/keras/commit/c3e844e7063efc14f6a8364cc04df4526b57352e",
        "buggy_code": "(self.target is not None and current < self.target)):",
        "fixed_code": "self.target is not None and current < self.target):",
        "patch": "@@ -327,7 +327,7 @@ def update(self, current, values=None, force=False):\n         info = ' - %.0fs' % (now - self.start)\n         if self.verbose == 1:\n             if (not force and (now - self.last_update) < self.interval and\n-                    (self.target is not None and current < self.target)):\n+                    self.target is not None and current < self.target):\n                 return\n \n             prev_total_width = self.total_width"
    },
    {
        "commit_id": "a5ecde595c47f35fd7293d52eba48efd687ca94e",
        "commit_message": "Fix progress bar when total number of steps is unknown (#9052)\n\n* Fix get_file when total size is unknown\r\n\r\n* Update test case",
        "commit_url": "https://github.com/keras-team/keras/commit/a5ecde595c47f35fd7293d52eba48efd687ca94e",
        "buggy_code": "current < self.target):",
        "fixed_code": "(self.target is not None and current < self.target)):",
        "patch": "@@ -327,7 +327,7 @@ def update(self, current, values=None, force=False):\n         info = ' - %.0fs' % (now - self.start)\n         if self.verbose == 1:\n             if (not force and (now - self.last_update) < self.interval and\n-                    current < self.target):\n+                    (self.target is not None and current < self.target)):\n                 return\n \n             prev_total_width = self.total_width"
    },
    {
        "commit_id": "e32c5b4b9e3068ec213f90489e0dd7487c9d191b",
        "commit_message": "Minor fix to an error message from RNN (#8969)\n\nIt appears to be a copy-paste error.",
        "commit_url": "https://github.com/keras-team/keras/commit/e32c5b4b9e3068ec213f90489e0dd7487c9d191b",
        "buggy_code": "'the time dimension by passing a '",
        "fixed_code": "'the batch size by passing a '",
        "patch": "@@ -668,7 +668,7 @@ def reset_states(self, states=None):\n                              'a `batch_input_shape` '\n                              'argument to your first layer.\\n'\n                              '- If using the functional API, specify '\n-                             'the time dimension by passing a '\n+                             'the batch size by passing a '\n                              '`batch_shape` argument to your Input layer.')\n         # initialize state if None\n         if self.states[0] is None:"
    },
    {
        "commit_id": "41d967f573868a7828c8b89bac0df9e9cfcc6785",
        "commit_message": "Fix type annotation (#8904)\n\n* Fix type annotation\r\n\r\n* remove type annotation",
        "commit_url": "https://github.com/keras-team/keras/commit/41d967f573868a7828c8b89bac0df9e9cfcc6785",
        "buggy_code": "def split_data(x, y, ratio: int = 0.8):",
        "fixed_code": "def split_data(x, y, ratio=0.8):",
        "patch": "@@ -154,7 +154,7 @@ def create_model(stateful: bool):\n \n \n # split train/test data\n-def split_data(x, y, ratio: int = 0.8):\n+def split_data(x, y, ratio=0.8):\n     to_train = int(input_len * ratio)\n     # tweak to match with batch_size\n     to_train -= to_train % batch_size"
    },
    {
        "commit_id": "3bdc086bbd6109f773d0f539d03fd0db253393d0",
        "commit_message": "Fix doc string for elu (#8898)",
        "commit_url": "https://github.com/keras-team/keras/commit/3bdc086bbd6109f773d0f539d03fd0db253393d0",
        "buggy_code": "alpha: A scalar, slope of positive section.",
        "fixed_code": "alpha: A scalar, slope of negative section.",
        "patch": "@@ -2925,7 +2925,7 @@ def elu(x, alpha=1.):\n \n     # Arguments\n         x: A tensor or variable to compute the activation function for.\n-        alpha: A scalar, slope of positive section.\n+        alpha: A scalar, slope of negative section.\n \n     # Returns\n         A tensor."
    },
    {
        "commit_id": "0d66dc4252f56bec1214874dbf766bdbb2c9ac10",
        "commit_message": "Fix predict_generator output shape for multi-output models when batch size is larger than the dataset. (#8795)\n\n* Fix incorrect predict_generator output shape when using multi-output model and steps_done=1.\r\n\r\n* Allow for RandomSequence instances with custom lengths during testing.\r\n\r\n* Adding unit tests to check for expected predict_generator output shapes.\r\n\r\n* Making variable names more explicit.",
        "commit_url": "https://github.com/keras-team/keras/commit/0d66dc4252f56bec1214874dbf766bdbb2c9ac10",
        "buggy_code": "return [out for out in all_outs]",
        "fixed_code": "return [out[0] for out in all_outs]",
        "patch": "@@ -2445,6 +2445,6 @@ def predict_generator(self, generator, steps=None,\n             else:\n                 return np.concatenate(all_outs[0])\n         if steps_done == 1:\n-            return [out for out in all_outs]\n+            return [out[0] for out in all_outs]\n         else:\n             return [np.concatenate(out) for out in all_outs]"
    },
    {
        "commit_id": "e39f6ed3ebf4fc5495ddcab4832d9ede6067aba2",
        "commit_message": "Fix Adam saving (#8804)",
        "commit_url": "https://github.com/keras-team/keras/commit/e39f6ed3ebf4fc5495ddcab4832d9ede6067aba2",
        "buggy_code": "vhats = [None for p in params]",
        "fixed_code": "vhats = [K.zeros(1) for _ in params]",
        "patch": "@@ -443,7 +443,7 @@ def get_updates(self, loss, params):\n         if self.amsgrad:\n             vhats = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n         else:\n-            vhats = [None for p in params]\n+            vhats = [K.zeros(1) for _ in params]\n         self.weights = [self.iterations] + ms + vs + vhats\n \n         for p, g, m, v, vhat in zip(params, grads, ms, vs, vhats):"
    },
    {
        "commit_id": "e39f6ed3ebf4fc5495ddcab4832d9ede6067aba2",
        "commit_message": "Fix Adam saving (#8804)",
        "commit_url": "https://github.com/keras-team/keras/commit/e39f6ed3ebf4fc5495ddcab4832d9ede6067aba2",
        "buggy_code": "optimizer=optimizers.RMSprop(lr=0.0001),",
        "fixed_code": "optimizer=optimizers.Adam(),",
        "patch": "@@ -84,7 +84,7 @@ def test_functional_model_saving():\n \n     model = Model(inputs, outputs)\n     model.compile(loss=losses.MSE,\n-                  optimizer=optimizers.RMSprop(lr=0.0001),\n+                  optimizer=optimizers.Adam(),\n                   metrics=[metrics.categorical_accuracy])\n     x = np.random.random((1, 3))\n     y = np.random.random((1, 3))"
    },
    {
        "commit_id": "a18aed4f8fcb8e4d6b4433fb56754a4a73f9224a",
        "commit_message": "Fix typos (#8774)",
        "commit_url": "https://github.com/keras-team/keras/commit/a18aed4f8fcb8e4d6b4433fb56754a4a73f9224a",
        "buggy_code": "Adjusts the input `previou path` to match the shape of the `input`",
        "fixed_code": "Adjusts the input `previous path` to match the shape of the `input`",
        "patch": "@@ -472,7 +472,7 @@ def _separable_conv_block(ip, filters, kernel_size=(3, 3), strides=(1, 1),\n \n def _adjust_block(p, ip, filters, block_id=None):\n     '''\n-    Adjusts the input `previou path` to match the shape of the `input`\n+    Adjusts the input `previous path` to match the shape of the `input`\n     or situations where the output number of filters needs to be changed\n \n     # Arguments:"
    },
    {
        "commit_id": "a18aed4f8fcb8e4d6b4433fb56754a4a73f9224a",
        "commit_message": "Fix typos (#8774)",
        "commit_url": "https://github.com/keras-team/keras/commit/a18aed4f8fcb8e4d6b4433fb56754a4a73f9224a",
        "buggy_code": "In particular additonal operations via `fetches` argument and additional",
        "fixed_code": "In particular additional operations via `fetches` argument and additional",
        "patch": "@@ -2300,7 +2300,7 @@ class Function(object):\n     \"\"\"Runs a computation graph.\n \n     It's possible to pass arguments to `tf.Session.run()` via `session_kwargs`.\n-    In particular additonal operations via `fetches` argument and additional\n+    In particular additional operations via `fetches` argument and additional\n     tensor substitutions via `feed_dict` arguments. Note that given\n     substitutions are merged with substitutions from `inputs`. Even though\n     `feed_dict` is passed once in the constructor (called in `model.compile()`)"
    },
    {
        "commit_id": "fefa846e573fa160da033d1c90060bc0dcff4a56",
        "commit_message": "Fix typos",
        "commit_url": "https://github.com/keras-team/keras/commit/fefa846e573fa160da033d1c90060bc0dcff4a56",
        "buggy_code": "_LEARNING_PHASE = C.constant(shape=(), dtype=np.float32, value=1.0, name=\"_keras_learning_phase\")",
        "fixed_code": "_LEARNING_PHASE = C.constant(shape=(), dtype=np.float32, value=1.0, name='_keras_learning_phase')",
        "patch": "@@ -21,7 +21,7 @@\n \n # A learning phase is a bool tensor used to run Keras models in\n # either train mode (learning_phase == 1) or test mode (learning_phase == 0).\n-_LEARNING_PHASE = C.constant(shape=(), dtype=np.float32, value=1.0, name=\"_keras_learning_phase\")\n+_LEARNING_PHASE = C.constant(shape=(), dtype=np.float32, value=1.0, name='_keras_learning_phase')\n _UID_PREFIXES = defaultdict(int)\n \n # cntk doesn't support gradient as symbolic op, to hook up with keras model,"
    },
    {
        "commit_id": "c31a2dfd014c2c48b8c3c54015f00275915662fc",
        "commit_message": "Integrate with cntk 2.3.1 (#8713)\n\n* enable recurrent layer's dropout on cntk\r\n\r\n* update cntk to 2.3.1\r\n\r\nupdate cntk 2.3.1 with py 36 wheel\r\n\r\nuse correct cpu-only build\r\n\r\n* fix a bug when calculate cntk version\r\n\r\n* fix pep8 style issue\r\n\r\n* refactor rnn generate dropout mask method, to enable cntk and theano\r\n\r\n* disable theano for dropout\r\n\r\n* keep existing behavior for tensorflow",
        "commit_url": "https://github.com/keras-team/keras/commit/c31a2dfd014c2c48b8c3c54015f00275915662fc",
        "buggy_code": "@pytest.mark.skipif((K.backend() in ['cntk', 'theano']),",
        "fixed_code": "@pytest.mark.skipif((K.backend() in ['theano']),",
        "patch": "@@ -70,7 +70,7 @@ def test_stateful_invalid_use(layer_class):\n \n \n @rnn_test\n-@pytest.mark.skipif((K.backend() in ['cntk', 'theano']),\n+@pytest.mark.skipif((K.backend() in ['theano']),\n                     reason='Not supported.')\n def test_dropout(layer_class):\n     for unroll in [True, False]:"
    },
    {
        "commit_id": "d956d19fccf6de6344c282218f1b027453785fa9",
        "commit_message": "Fix inconsistency with to_categorical applied to length 1 list",
        "commit_url": "https://github.com/keras-team/keras/commit/d956d19fccf6de6344c282218f1b027453785fa9",
        "buggy_code": "if input_shape and input_shape[-1] == 1:",
        "fixed_code": "if input_shape and input_shape[-1] == 1 and len(input_shape) > 1:",
        "patch": "@@ -19,7 +19,7 @@ def to_categorical(y, num_classes=None):\n     \"\"\"\n     y = np.array(y, dtype='int')\n     input_shape = y.shape\n-    if input_shape and input_shape[-1] == 1:\n+    if input_shape and input_shape[-1] == 1 and len(input_shape) > 1:\n         input_shape = tuple(input_shape[:-1])\n     y = y.ravel()\n     if not num_classes:"
    },
    {
        "commit_id": "722f710a5307dfeca8945975f9550a962e60aa4b",
        "commit_message": "Documentation fix for imdb.load_data (#8646)\n\nmaxlen is passed to _remove_long_seq which filters out sequences; the\r\ndocumentation stated sequences would be truncated.",
        "commit_url": "https://github.com/keras-team/keras/commit/722f710a5307dfeca8945975f9550a962e60aa4b",
        "buggy_code": "maxlen: truncate sequences after this length.",
        "fixed_code": "maxlen: sequences longer than this will be filtered out.",
        "patch": "@@ -18,7 +18,7 @@ def load_data(path='imdb.npz', num_words=None, skip_top=0,\n             the most frequent words are kept\n         skip_top: skip the top N most frequently occurring words\n             (which may not be informative).\n-        maxlen: truncate sequences after this length.\n+        maxlen: sequences longer than this will be filtered out.\n         seed: random seed for sample shuffling.\n         start_char: The start of a sequence will be marked with this character.\n             Set to 1 because 0 is usually the padding character."
    },
    {
        "commit_id": "cac44b56baec55b73f655f41f878380962140337",
        "commit_message": "fix incorrect example code of the def variable (#8603)",
        "commit_url": "https://github.com/keras-team/keras/commit/cac44b56baec55b73f655f41f878380962140337",
        "buggy_code": ">>> kvar.eval()",
        "fixed_code": ">>> K.eval(kvar)",
        "patch": "@@ -365,7 +365,7 @@ def variable(value, dtype=None, name=None, constraint=None):\n         'float64'\n         >>> print(kvar)\n         example_var\n-        >>> kvar.eval()\n+        >>> K.eval(kvar)\n         array([[ 1.,  2.],\n                [ 3.,  4.]])\n     ```"
    },
    {
        "commit_id": "58c219164a0050a38cdafea7a6ff3d7181855326",
        "commit_message": "Docstring fix",
        "commit_url": "https://github.com/keras-team/keras/commit/58c219164a0050a38cdafea7a6ff3d7181855326",
        "buggy_code": "with the template model (the argument you passed to `multi_gpu_model),",
        "fixed_code": "with the template model (the argument you passed to `multi_gpu_model`),",
        "patch": "@@ -89,7 +89,7 @@ def multi_gpu_model(model, gpus):\n     # On model saving\n \n     To save the multi-gpu model, use `.save(fname)` or `.save_weights(fname)`\n-    with the template model (the argument you passed to `multi_gpu_model),\n+    with the template model (the argument you passed to `multi_gpu_model`),\n     rather than the model returned by `multi_gpu_model`.\n     \"\"\"\n     if K.backend() != 'tensorflow':"
    },
    {
        "commit_id": "8c1af0ab8d617f0d28548bc77e5540142f338068",
        "commit_message": "fix typo in keras/layers/merge-> concatenate description (#8453)",
        "commit_url": "https://github.com/keras-team/keras/commit/8c1af0ab8d617f0d28548bc77e5540142f338068",
        "buggy_code": "all of the same shape expect for the concatenation axis,",
        "fixed_code": "all of the same shape except for the concatenation axis,",
        "patch": "@@ -309,7 +309,7 @@ class Concatenate(_Merge):\n     \"\"\"Layer that concatenates a list of inputs.\n \n     It takes as input a list of tensors,\n-    all of the same shape expect for the concatenation axis,\n+    all of the same shape except for the concatenation axis,\n     and returns a single tensor, the concatenation of all inputs.\n \n     # Arguments"
    },
    {
        "commit_id": "bbb5bd0e30fe3e75e1b2b7d670f5cbbb8ccd7c2f",
        "commit_message": "Improve error msg",
        "commit_url": "https://github.com/keras-team/keras/commit/bbb5bd0e30fe3e75e1b2b7d670f5cbbb8ccd7c2f",
        "buggy_code": "'from keras.utils.np_utils import to_categorical\\n'",
        "fixed_code": "'from keras.utils import to_categorical\\n'",
        "patch": "@@ -290,7 +290,7 @@ def _check_loss_and_target_compatibility(targets, loss_fns, output_shapes):\n                     'If your targets are integer classes, '\n                     'you can convert them to the expected format via:\\n'\n                     '```\\n'\n-                    'from keras.utils.np_utils import to_categorical\\n'\n+                    'from keras.utils import to_categorical\\n'\n                     'y_binary = to_categorical(y_int)\\n'\n                     '```\\n'\n                     '\\n'"
    },
    {
        "commit_id": "e4e01c5aae883f8131ebef455939f313e7125520",
        "commit_message": "Fix docstring in private model method. (#8422)",
        "commit_url": "https://github.com/keras-team/keras/commit/e4e01c5aae883f8131ebef455939f313e7125520",
        "buggy_code": "`_collected_trainable_weights` are consistent (i.e. have the same",
        "fixed_code": "`_collected_trainable_weights` are inconsistent (i.e. have different",
        "patch": "@@ -958,7 +958,7 @@ def _check_trainable_weights_consistency(self):\n         \"\"\"Check trainable weights count consistency.\n \n         This will raise a warning if `trainable_weights` and\n-        `_collected_trainable_weights` are consistent (i.e. have the same\n+        `_collected_trainable_weights` are inconsistent (i.e. have different\n         number of parameters).\n         Inconsistency will typically arise when one modifies `model.trainable`\n         without calling `model.compile` again."
    },
    {
        "commit_id": "211ec41c1c4f62cb58a55e111010e0492d7463d0",
        "commit_message": "Fix imdb random seed",
        "commit_url": "https://github.com/keras-team/keras/commit/211ec41c1c4f62cb58a55e111010e0492d7463d0",
        "buggy_code": "from six.moves import zip",
        "fixed_code": "np.random.seed(seed)",
        "patch": "@@ -1,7 +1,6 @@\n from __future__ import absolute_import\n from ..utils.data_utils import get_file\n from ..preprocessing.sequence import _remove_long_seq\n-from six.moves import zip\n import numpy as np\n import json\n import warnings\n@@ -55,6 +54,7 @@ def load_data(path='imdb.npz', num_words=None, skip_top=0,\n         x_train, labels_train = f['x_train'], f['y_train']\n         x_test, labels_test = f['x_test'], f['y_test']\n \n+    np.random.seed(seed)\n     indices = np.arange(len(x_train))\n     np.random.shuffle(indices)\n     x_train = x_train[indices]"
    },
    {
        "commit_id": "b1d298a1260d620e3fff873d19d7ca22d832e88e",
        "commit_message": "Fix docs autogen script.",
        "commit_url": "https://github.com/keras-team/keras/commit/b1d298a1260d620e3fff873d19d7ca22d832e88e",
        "buggy_code": "Consider a custom object `MyObject`",
        "fixed_code": "Consider a custom object `MyObject` (e.g. a class):",
        "patch": "@@ -24,7 +24,7 @@ class CustomObjectScope(object):\n \n     # Example\n \n-    Consider a custom object `MyObject`\n+    Consider a custom object `MyObject` (e.g. a class):\n \n     ```python\n         with CustomObjectScope({'MyObject':MyObject}):"
    },
    {
        "commit_id": "13876a1548e1183c4cc534226151891f9644642a",
        "commit_message": "Increase file save hash size (#8277)\n\n* Increase file save hash size\r\n\r\nIssue #8249 runs into a problem where the max hash size is low, resulting in files being potentially overwritten.\r\n\r\nThe behavior of this functionality is as such:\r\nAs batch size increases, the probability that any given file will have a conflict in the hash reduces. However, when the author wants to save images with a batch size of one, the probability of a conflict increases since {index} is always 1. This seems to just be an unforeseen bug because a batch size of one is uncommon.\r\n\r\n* Change hash size to 1e7",
        "commit_url": "https://github.com/keras-team/keras/commit/13876a1548e1183c4cc534226151891f9644642a",
        "buggy_code": "hash=np.random.randint(1e4),",
        "fixed_code": "hash=np.random.randint(1e7),",
        "patch": "@@ -1104,7 +1104,7 @@ def _get_batches_of_transformed_samples(self, index_array):\n                 img = array_to_img(batch_x[i], self.data_format, scale=True)\n                 fname = '{prefix}_{index}_{hash}.{format}'.format(prefix=self.save_prefix,\n                                                                   index=j,\n-                                                                  hash=np.random.randint(1e4),\n+                                                                  hash=np.random.randint(1e7),\n                                                                   format=self.save_format)\n                 img.save(os.path.join(self.save_to_dir, fname))\n         # build batch of labels"
    },
    {
        "commit_id": "b5612acd748b90dc5853cd11f357536a20dba1ec",
        "commit_message": "Fix post_process_signature for floating point (#8247)",
        "commit_url": "https://github.com/keras-team/keras/commit/b5612acd748b90dc5853cd11f357536a20dba1ec",
        "buggy_code": "parts = signature.split('.')",
        "fixed_code": "parts = re.split('\\.(?!\\d)', signature)",
        "patch": "@@ -369,7 +369,7 @@ def get_class_signature(cls):\n \n \n def post_process_signature(signature):\n-    parts = signature.split('.')\n+    parts = re.split('\\.(?!\\d)', signature)\n     if len(parts) >= 4:\n         if parts[1] == 'layers':\n             signature = 'keras.layers.' + '.'.join(parts[3:])"
    },
    {
        "commit_id": "ce406b773b9f36be5718a4369ad07fea4f9ebdba",
        "commit_message": "Fix word embeddings example.",
        "commit_url": "https://github.com/keras-team/keras/commit/ce406b773b9f36be5718a4369ad07fea4f9ebdba",
        "buggy_code": "data_path = '/Users/fchollet/Downloads/fra-eng/fra.txt'",
        "fixed_code": "data_path = 'fra-eng/fra.txt'",
        "patch": "@@ -59,7 +59,7 @@\n latent_dim = 256  # Latent dimensionality of the encoding space.\n num_samples = 10000  # Number of samples to train on.\n # Path to the data txt file on disk.\n-data_path = '/Users/fchollet/Downloads/fra-eng/fra.txt'\n+data_path = 'fra-eng/fra.txt'\n \n # Vectorize the data.\n input_texts = []"
    },
    {
        "commit_id": "8167253fa22a5a3fc2604193f2e2e1395c6010bf",
        "commit_message": "Fix MobileNet link for TensorFlow checkpoints (#8122)",
        "commit_url": "https://github.com/keras-team/keras/commit/8167253fa22a5a3fc2604193f2e2e1395c6010bf",
        "buggy_code": "https://github.com/tensorflow/models/blob/master/slim/nets/mobilenet_v1.md",
        "fixed_code": "https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.md",
        "patch": "@@ -43,7 +43,7 @@\n \n The weights for all 16 models are obtained and translated\n from TensorFlow checkpoints found at\n-https://github.com/tensorflow/models/blob/master/slim/nets/mobilenet_v1.md\n+https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.md\n \n # Reference\n - [MobileNets: Efficient Convolutional Neural Networks for"
    },
    {
        "commit_id": "40fd9ca3c877d2e29a2cf077902d61f38aa161f2",
        "commit_message": " Replace literal constant 10 with variable num_classes in example/ (#8041)\n\n* Replace literal constant 10 with variable num_classes\r\n\r\n* Fix PEP8 errors",
        "commit_url": "https://github.com/keras-team/keras/commit/40fd9ca3c877d2e29a2cf077902d61f38aa161f2",
        "buggy_code": "model.add(layers.Dense(10))",
        "fixed_code": "model.add(layers.Dense(num_classes))",
        "patch": "@@ -88,7 +88,7 @@ def call(self, inputs):\n model.add(layers.Dense(256))\n model.add(Antirectifier())\n model.add(layers.Dropout(0.1))\n-model.add(layers.Dense(10))\n+model.add(layers.Dense(num_classes))\n model.add(layers.Activation('softmax'))\n \n # compile the model"
    },
    {
        "commit_id": "cc7ec458053b7a2cf93b5b1d2b5adefb90e051ea",
        "commit_message": "Fix typos (#7916)",
        "commit_url": "https://github.com/keras-team/keras/commit/cc7ec458053b7a2cf93b5b1d2b5adefb90e051ea",
        "buggy_code": "x: A tenor or variable to compute the activation function for.",
        "fixed_code": "x: A tensor or variable to compute the activation function for.",
        "patch": "@@ -2667,7 +2667,7 @@ def elu(x, alpha=1.):\n     \"\"\"Exponential linear unit.\n \n     # Arguments\n-        x: A tenor or variable to compute the activation function for.\n+        x: A tensor or variable to compute the activation function for.\n         alpha: A scalar, slope of positive section.\n \n     # Returns"
    },
    {
        "commit_id": "2df5650ab64a173973a3a4b434d2f801b4694ce3",
        "commit_message": "IndexError fix (#7865)\n\n* IndexError fix\r\n\r\nWhen a corpus has less than MAX_NB_WORDS, num_words will be set to len(word_index) . However, since the index is zero based it causes an IndexError. eg. When there are 57 total words in the corpus you get the error 'IndexError: index 57 is out of bounds for axis 0 with size 57' since the index should stop at 56 (zero based).\r\n\r\n* missed one more spot\r\n\r\n* Correction to previous commit\r\n\r\n* Reverted to previous commit",
        "commit_url": "https://github.com/keras-team/keras/commit/2df5650ab64a173973a3a4b434d2f801b4694ce3",
        "buggy_code": "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))",
        "fixed_code": "embedding_matrix = np.zeros((num_words + 1, EMBEDDING_DIM))",
        "patch": "@@ -106,7 +106,7 @@\n \n # prepare embedding matrix\n num_words = min(MAX_NB_WORDS, len(word_index))\n-embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n+embedding_matrix = np.zeros((num_words + 1, EMBEDDING_DIM))\n for word, i in word_index.items():\n     if i >= MAX_NB_WORDS:\n         continue"
    },
    {
        "commit_id": "66c4fdb8937abe725018de7156c5f66f2ec335ed",
        "commit_message": "Fix HDF5Matrix.__getitem__ for validation_split (#7863)\n\n* Changed HDF5Matrix.__getitem__ to set stop to self.shape[0] instead of\r\nself.data.shape[0]\r\n\r\n* Added unit test for HDF5Matrix slicing with indefiinite stop index",
        "commit_url": "https://github.com/keras-team/keras/commit/66c4fdb8937abe725018de7156c5f66f2ec335ed",
        "buggy_code": "stop = self.data.shape[0]",
        "fixed_code": "stop = self.shape[0]",
        "patch": "@@ -67,7 +67,7 @@ def __getitem__(self, key):\n             if start is None:\n                 start = 0\n             if stop is None:\n-                stop = self.data.shape[0]\n+                stop = self.shape[0]\n             if stop + self.start <= self.end:\n                 idx = slice(start + self.start, stop + self.start)\n             else:"
    },
    {
        "commit_id": "b76571f636ba37a04d4f104d701a62a536dfa0b4",
        "commit_message": "Fix typo (#7849)",
        "commit_url": "https://github.com/keras-team/keras/commit/b76571f636ba37a04d4f104d701a62a536dfa0b4",
        "buggy_code": "channel_shift_range: shift range for each channels.",
        "fixed_code": "channel_shift_range: shift range for each channel.",
        "patch": "@@ -356,7 +356,7 @@ class ImageDataGenerator(object):\n         zoom_range: amount of zoom. if scalar z, zoom will be randomly picked\n             in the range [1-z, 1+z]. A sequence of two can be passed instead\n             to select this range.\n-        channel_shift_range: shift range for each channels.\n+        channel_shift_range: shift range for each channel.\n         fill_mode: points outside the boundaries are filled according to the\n             given mode ('constant', 'nearest', 'reflect' or 'wrap'). Default\n             is 'nearest'."
    },
    {
        "commit_id": "073c9ff3e3baebffa9d33057c951eeb02c4c36a4",
        "commit_message": "Fixes set_learning_phase in CNTK (#7826)\n\nWas getting an error when calling\r\n\r\n```\r\nK.set_learning_phase(0)\r\n```",
        "commit_url": "https://github.com/keras-team/keras/commit/073c9ff3e3baebffa9d33057c951eeb02c4c36a4",
        "buggy_code": "v = np.float32([value])",
        "fixed_code": "v = np.asarray(value)",
        "patch": "@@ -57,7 +57,7 @@ def set_learning_phase(value):\n         raise ValueError('CNTK Backend: Set learning phase '\n                          'with value %s is not supported, '\n                          'expected 0 or 1.' % value)\n-    v = np.float32([value])\n+    v = np.asarray(value)\n     _LEARNING_PHASE.value = v\n \n "
    },
    {
        "commit_id": "5625d70ed9fbb0692ddde085009c8f2ef1111838",
        "commit_message": "Various spelling and grammar fixes (#7793)\n\n* Various spelling and grammar fixes\r\n\r\n* changed Nvidia to NVIDIA as per review\r\n\r\n* spelling fix",
        "commit_url": "https://github.com/keras-team/keras/commit/5625d70ed9fbb0692ddde085009c8f2ef1111838",
        "buggy_code": "ax.text(1, 3, 'Inital trajectory', fontsize=20)",
        "fixed_code": "ax.text(1, 3, 'Initial trajectory', fontsize=20)",
        "patch": "@@ -125,7 +125,7 @@ def generate_movies(n_samples=1200, n_frames=15):\n     if i >= 7:\n         ax.text(1, 3, 'Predictions !', fontsize=20, color='w')\n     else:\n-        ax.text(1, 3, 'Inital trajectory', fontsize=20)\n+        ax.text(1, 3, 'Initial trajectory', fontsize=20)\n \n     toplot = track[i, ::, ::, 0]\n "
    },
    {
        "commit_id": "5625d70ed9fbb0692ddde085009c8f2ef1111838",
        "commit_message": "Various spelling and grammar fixes (#7793)\n\n* Various spelling and grammar fixes\r\n\r\n* changed Nvidia to NVIDIA as per review\r\n\r\n* spelling fix",
        "commit_url": "https://github.com/keras-team/keras/commit/5625d70ed9fbb0692ddde085009c8f2ef1111838",
        "buggy_code": "'''Trains a LSTM on the IMDB sentiment classification task.",
        "fixed_code": "'''Trains an LSTM model on the IMDB sentiment classification task.",
        "patch": "@@ -1,4 +1,4 @@\n-'''Trains a LSTM on the IMDB sentiment classification task.\n+'''Trains an LSTM model on the IMDB sentiment classification task.\n The dataset is actually too small for LSTM to be of any advantage\n compared to simpler, much faster methods such as TF-IDF + LogReg.\n Notes:"
    },
    {
        "commit_id": "5625d70ed9fbb0692ddde085009c8f2ef1111838",
        "commit_message": "Various spelling and grammar fixes (#7793)\n\n* Various spelling and grammar fixes\r\n\r\n* changed Nvidia to NVIDIA as per review\r\n\r\n* spelling fix",
        "commit_url": "https://github.com/keras-team/keras/commit/5625d70ed9fbb0692ddde085009c8f2ef1111838",
        "buggy_code": "HRNNs can learn across multiple levels of temporal hiearchy over a complex sequence.",
        "fixed_code": "HRNNs can learn across multiple levels of temporal hierarchy over a complex sequence.",
        "patch": "@@ -1,6 +1,6 @@\n \"\"\"This is an example of using Hierarchical RNN (HRNN) to classify MNIST digits.\n \n-HRNNs can learn across multiple levels of temporal hiearchy over a complex sequence.\n+HRNNs can learn across multiple levels of temporal hierarchy over a complex sequence.\n Usually, the first recurrent layer of an HRNN encodes a sentence (e.g. of word vectors)\n into a  sentence vector. The second recurrent layer then encodes a sequence of\n such vectors (encoded by the first layer) into a document vector. This"
    },
    {
        "commit_id": "5625d70ed9fbb0692ddde085009c8f2ef1111838",
        "commit_message": "Various spelling and grammar fixes (#7793)\n\n* Various spelling and grammar fixes\r\n\r\n* changed Nvidia to NVIDIA as per review\r\n\r\n* spelling fix",
        "commit_url": "https://github.com/keras-team/keras/commit/5625d70ed9fbb0692ddde085009c8f2ef1111838",
        "buggy_code": "'supported for all TF ops.')",
        "fixed_code": "'supported for all TensorFlow ops.')",
        "patch": "@@ -105,7 +105,7 @@ def getwhere(x):\n                        'Theano backend for the time being, '\r\n                        'because it requires taking the gradient '\r\n                        'of a gradient, which isn\\'t '\r\n-                       'supported for all TF ops.')\r\n+                       'supported for all TensorFlow ops.')\r\n \r\n # This example assume 'channels_first' data format.\r\n K.set_image_data_format('channels_first')\r"
    },
    {
        "commit_id": "5625d70ed9fbb0692ddde085009c8f2ef1111838",
        "commit_message": "Various spelling and grammar fixes (#7793)\n\n* Various spelling and grammar fixes\r\n\r\n* changed Nvidia to NVIDIA as per review\r\n\r\n* spelling fix",
        "commit_url": "https://github.com/keras-team/keras/commit/5625d70ed9fbb0692ddde085009c8f2ef1111838",
        "buggy_code": "(classication of newsgroup messages into 20 different categories).",
        "fixed_code": "(classification of newsgroup messages into 20 different categories).",
        "patch": "@@ -1,7 +1,7 @@\n '''This script loads pre-trained word embeddings (GloVe embeddings)\n into a frozen Keras Embedding layer, and uses it to\n train a text classification model on the 20 Newsgroup dataset\n-(classication of newsgroup messages into 20 different categories).\n+(classification of newsgroup messages into 20 different categories).\n \n GloVe embedding data can be found at:\n http://nlp.stanford.edu/data/glove.6B.zip"
    },
    {
        "commit_id": "5625d70ed9fbb0692ddde085009c8f2ef1111838",
        "commit_message": "Various spelling and grammar fixes (#7793)\n\n* Various spelling and grammar fixes\r\n\r\n* changed Nvidia to NVIDIA as per review\r\n\r\n* spelling fix",
        "commit_url": "https://github.com/keras-team/keras/commit/5625d70ed9fbb0692ddde085009c8f2ef1111838",
        "buggy_code": "count samples seens or steps (batches) seen.",
        "fixed_code": "count samples seen or steps (batches) seen.",
        "patch": "@@ -248,7 +248,7 @@ class ProgbarLogger(Callback):\n     # Arguments\n         count_mode: One of \"steps\" or \"samples\".\n             Whether the progress bar should\n-            count samples seens or steps (batches) seen.\n+            count samples seen or steps (batches) seen.\n \n     # Raises\n         ValueError: In case of invalid `count_mode`."
    },
    {
        "commit_id": "5625d70ed9fbb0692ddde085009c8f2ef1111838",
        "commit_message": "Various spelling and grammar fixes (#7793)\n\n* Various spelling and grammar fixes\r\n\r\n* changed Nvidia to NVIDIA as per review\r\n\r\n* spelling fix",
        "commit_url": "https://github.com/keras-team/keras/commit/5625d70ed9fbb0692ddde085009c8f2ef1111838",
        "buggy_code": "to be fed to a LSTM layer.",
        "fixed_code": "to be fed to an LSTM layer.",
        "patch": "@@ -36,7 +36,7 @@ class Masking(Layer):\n     # Example\n \n     Consider a Numpy data array `x` of shape `(samples, timesteps, features)`,\n-    to be fed to a LSTM layer.\n+    to be fed to an LSTM layer.\n     You want to mask timestep #3 and #5 because you lack data for\n     these timesteps. You can:\n "
    },
    {
        "commit_id": "5625d70ed9fbb0692ddde085009c8f2ef1111838",
        "commit_message": "Various spelling and grammar fixes (#7793)\n\n* Various spelling and grammar fixes\r\n\r\n* changed Nvidia to NVIDIA as per review\r\n\r\n* spelling fix",
        "commit_url": "https://github.com/keras-team/keras/commit/5625d70ed9fbb0692ddde085009c8f2ef1111838",
        "buggy_code": "classes: Optional list of strings, names of sudirectories",
        "fixed_code": "classes: Optional list of strings, names of subdirectories",
        "patch": "@@ -908,7 +908,7 @@ class DirectoryIterator(Iterator):\n             to use for random transformations and normalization.\n         target_size: tuple of integers, dimensions to resize input images to.\n         color_mode: One of `\"rgb\"`, `\"grayscale\"`. Color mode to read images.\n-        classes: Optional list of strings, names of sudirectories\n+        classes: Optional list of strings, names of subdirectories\n             containing images from each class (e.g. `[\"dogs\", \"cats\"]`).\n             It will be computed automatically if not set.\n         class_mode: Mode for yielding the targets:"
    },
    {
        "commit_id": "5625d70ed9fbb0692ddde085009c8f2ef1111838",
        "commit_message": "Various spelling and grammar fixes (#7793)\n\n* Various spelling and grammar fixes\r\n\r\n* changed Nvidia to NVIDIA as per review\r\n\r\n* spelling fix",
        "commit_url": "https://github.com/keras-team/keras/commit/5625d70ed9fbb0692ddde085009c8f2ef1111838",
        "buggy_code": "encodes the probabibily to sample a word of rank i.",
        "fixed_code": "encodes the probability to sample a word of rank i.",
        "patch": "@@ -139,7 +139,7 @@ def skipgrams(sequence, vocabulary_size,\n             integers (eg. [0, 1, 1 .. ]),\n             if True labels will be categorical eg. [[1,0],[0,1],[0,1] .. ]\n         sampling_table: 1D array of size `vocabulary_size` where the entry i\n-            encodes the probabibily to sample a word of rank i.\n+            encodes the probability to sample a word of rank i.\n         seed: random seed.\n \n     # Returns"
    },
    {
        "commit_id": "5625d70ed9fbb0692ddde085009c8f2ef1111838",
        "commit_message": "Various spelling and grammar fixes (#7793)\n\n* Various spelling and grammar fixes\r\n\r\n* changed Nvidia to NVIDIA as per review\r\n\r\n* spelling fix",
        "commit_url": "https://github.com/keras-team/keras/commit/5625d70ed9fbb0692ddde085009c8f2ef1111838",
        "buggy_code": "@pytest.mark.skipif(K.backend() != 'tensorflow', reason='Requires TF backend')",
        "fixed_code": "@pytest.mark.skipif(K.backend() != 'tensorflow', reason='Requires TensorFlow backend')",
        "patch": "@@ -206,7 +206,7 @@ def test_masked_temporal():\n     assert(np.abs(history.history['loss'][-1] - ground_truth) < 0.06)\n \n \n-@pytest.mark.skipif(K.backend() != 'tensorflow', reason='Requires TF backend')\n+@pytest.mark.skipif(K.backend() != 'tensorflow', reason='Requires TensorFlow backend')\n @keras_test\n def test_embedding_with_clipnorm():\n     model = Sequential()"
    },
    {
        "commit_id": "5625d70ed9fbb0692ddde085009c8f2ef1111838",
        "commit_message": "Various spelling and grammar fixes (#7793)\n\n* Various spelling and grammar fixes\r\n\r\n* changed Nvidia to NVIDIA as per review\r\n\r\n* spelling fix",
        "commit_url": "https://github.com/keras-team/keras/commit/5625d70ed9fbb0692ddde085009c8f2ef1111838",
        "buggy_code": "reason='Requires tensorflow backend')",
        "fixed_code": "reason='Requires TensorFlow backend')",
        "patch": "@@ -117,7 +117,7 @@ def test_clipvalue():\n \n @keras_test\n @pytest.mark.skipif((K.backend() != 'tensorflow'),\n-                    reason='Requires tensorflow backend')\n+                    reason='Requires TensorFlow backend')\n def test_tfoptimizer():\n     from keras import constraints\n     from tensorflow import train"
    },
    {
        "commit_id": "fb7361ec2277598a6d8d25eb822c86d34194fdf2",
        "commit_message": "Change in variational autoencoder example to resolve issue #6373  (#7764)\n\n* Update variational_autoencoder.py\r\n\r\nChange in y value in Validation part to remove error \"ValueError: The model expects 0 input arrays, but only received one array.\"\r\n\r\n* Update variational_autoencoder_deconv.py\r\n\r\nChange in y value of validation_data to remove error \"ValueError: The model expects 0 input arrays, but only received one array.\".",
        "commit_url": "https://github.com/keras-team/keras/commit/fb7361ec2277598a6d8d25eb822c86d34194fdf2",
        "buggy_code": "validation_data=(x_test, x_test))",
        "fixed_code": "validation_data=(x_test, None))",
        "patch": "@@ -78,7 +78,7 @@ def call(self, inputs):\n         shuffle=True,\n         epochs=epochs,\n         batch_size=batch_size,\n-        validation_data=(x_test, x_test))\n+        validation_data=(x_test, None))\n \n # build a model to project inputs on the latent space\n encoder = Model(x, z_mean)"
    },
    {
        "commit_id": "fb7361ec2277598a6d8d25eb822c86d34194fdf2",
        "commit_message": "Change in variational autoencoder example to resolve issue #6373  (#7764)\n\n* Update variational_autoencoder.py\r\n\r\nChange in y value in Validation part to remove error \"ValueError: The model expects 0 input arrays, but only received one array.\"\r\n\r\n* Update variational_autoencoder_deconv.py\r\n\r\nChange in y value of validation_data to remove error \"ValueError: The model expects 0 input arrays, but only received one array.\".",
        "commit_url": "https://github.com/keras-team/keras/commit/fb7361ec2277598a6d8d25eb822c86d34194fdf2",
        "buggy_code": "validation_data=(x_test, x_test))",
        "fixed_code": "validation_data=(x_test, None))",
        "patch": "@@ -148,7 +148,7 @@ def call(self, inputs):\n         shuffle=True,\n         epochs=epochs,\n         batch_size=batch_size,\n-        validation_data=(x_test, x_test))\n+        validation_data=(x_test, None))\n \n # build a model to project inputs on the latent space\n encoder = Model(x, z_mean)"
    },
    {
        "commit_id": "5672db9b4104021faa8476985f36975d8d31be1d",
        "commit_message": "Fix typo in docstring.",
        "commit_url": "https://github.com/keras-team/keras/commit/5672db9b4104021faa8476985f36975d8d31be1d",
        "buggy_code": "dropout: wether to apply dropout (same dropout mask",
        "fixed_code": "dropout: whether to apply dropout (same dropout mask",
        "patch": "@@ -21,7 +21,7 @@ def _time_distributed_dense(x, w, b=None, dropout=None,\n         x: input tensor.\n         w: weight matrix.\n         b: optional bias vector.\n-        dropout: wether to apply dropout (same dropout mask\n+        dropout: whether to apply dropout (same dropout mask\n             for every temporal slice of the input).\n         input_dim: integer; optional dimensionality of the input.\n         output_dim: integer; optional dimensionality of the output."
    },
    {
        "commit_id": "9e1dd0ac58ba5f1343af76a69a762cb75ca3315d",
        "commit_message": "Style fix",
        "commit_url": "https://github.com/keras-team/keras/commit/9e1dd0ac58ba5f1343af76a69a762cb75ca3315d",
        "buggy_code": "x_train_input = layers.Input(tensor=x_train_batch, batch_shape=x_batch_shape)",
        "fixed_code": "x_train_input = layers.Input(tensor=x_train_batch)",
        "patch": "@@ -111,7 +111,7 @@ def cnn_layers(x_train_input):\n x_batch_shape = x_train_batch.get_shape().as_list()\n y_batch_shape = y_train_batch.get_shape().as_list()\n \n-x_train_input = layers.Input(tensor=x_train_batch, batch_shape=x_batch_shape)\n+x_train_input = layers.Input(tensor=x_train_batch)\n x_train_out = cnn_layers(x_train_input)\n train_model = keras.models.Model(inputs=x_train_input, outputs=x_train_out)\n "
    },
    {
        "commit_id": "22e6bea8c2e23c6bbd6d98b4d3fe8b2e74c33c3d",
        "commit_message": "add .ppm support to ImageDataGenerator (#7712)\n\n* add .ppm support to DirectoryIterator\r\n\r\n* fix dot",
        "commit_url": "https://github.com/keras-team/keras/commit/22e6bea8c2e23c6bbd6d98b4d3fe8b2e74c33c3d",
        "buggy_code": "white_list_formats = {'png', 'jpg', 'jpeg', 'bmp'}",
        "fixed_code": "white_list_formats = {'png', 'jpg', 'jpeg', 'bmp', 'ppm'}",
        "patch": "@@ -971,7 +971,7 @@ def __init__(self, directory, image_data_generator,\n         self.save_prefix = save_prefix\n         self.save_format = save_format\n \n-        white_list_formats = {'png', 'jpg', 'jpeg', 'bmp'}\n+        white_list_formats = {'png', 'jpg', 'jpeg', 'bmp', 'ppm'}\n \n         # first, count the number of samples and classes\n         self.samples = 0"
    },
    {
        "commit_id": "1386dbae617641d6c60025bc9f68391766323ffe",
        "commit_message": "Minor typo fix (#7721)",
        "commit_url": "https://github.com/keras-team/keras/commit/1386dbae617641d6c60025bc9f68391766323ffe",
        "buggy_code": "A sparse tensor representation of the lablels.",
        "fixed_code": "A sparse tensor representation of the labels.",
        "patch": "@@ -3605,7 +3605,7 @@ def ctc_label_dense_to_sparse(labels, label_lengths):\n         label_lengths: length of the labels.\n \n     # Returns\n-        A sparse tensor representation of the lablels.\n+        A sparse tensor representation of the labels.\n     \"\"\"\n     label_shape = tf.shape(labels)\n     num_batches_tns = tf.stack([label_shape[0]])"
    },
    {
        "commit_id": "9772b1179c39433cf6babf96b53b7987e5cb5027",
        "commit_message": "HDF5Matrix can handle np.int64 indexing (#7686)\n\nRight now HDF5Matrix's raise an index error when a np.int64 number is used to index them (such as from np.arange). In contrast normal numpy array can handle this situation. This PR fixes that by also checking for numpy integer types.",
        "commit_url": "https://github.com/keras-team/keras/commit/9772b1179c39433cf6babf96b53b7987e5cb5027",
        "buggy_code": "elif isinstance(key, int):",
        "fixed_code": "elif isinstance(key, (int, np.integer)):",
        "patch": "@@ -72,7 +72,7 @@ def __getitem__(self, key):\n                 idx = slice(start + self.start, stop + self.start)\n             else:\n                 raise IndexError\n-        elif isinstance(key, int):\n+        elif isinstance(key, (int, np.integer)):\n             if key + self.start < self.end:\n                 idx = key + self.start\n             else:"
    },
    {
        "commit_id": "a095c1b16f8368a996ec345c4f3fd0a77cdf54f3",
        "commit_message": "Fix typo in Layer.add_loss. (#7657)",
        "commit_url": "https://github.com/keras-team/keras/commit/a095c1b16f8368a996ec345c4f3fd0a77cdf54f3",
        "buggy_code": "if isinstance(input, list) and inputs == []:",
        "fixed_code": "if isinstance(inputs, list) and inputs == []:",
        "patch": "@@ -1098,7 +1098,7 @@ def add_loss(self, losses, inputs=None):\n         if hasattr(self, '_losses'):\n             self._losses += losses\n         # Update self._per_input_updates\n-        if isinstance(input, list) and inputs == []:\n+        if isinstance(inputs, list) and inputs == []:\n             inputs = None\n         if inputs is not None:\n             inputs_hash = _object_list_uid(inputs)"
    },
    {
        "commit_id": "57bc4da51329a48937f809aed0b80d23575bc209",
        "commit_message": "grammar fix (#7635)",
        "commit_url": "https://github.com/keras-team/keras/commit/57bc4da51329a48937f809aed0b80d23575bc209",
        "buggy_code": "' arrays but instead got '",
        "fixed_code": "' array(s), but instead got '",
        "patch": "@@ -72,7 +72,7 @@ def _standardize_input_data(data, names, shapes=None,\n                                  'that you are passing to your model '\n                                  'is not the size the model expected. '\n                                  'Expected to see ' + str(len(names)) +\n-                                 ' arrays but instead got '\n+                                 ' array(s), but instead got '\n                                  'the following list of ' + str(len(data)) +\n                                  ' arrays: ' + str(data)[:200] +\n                                  '...')"
    },
    {
        "commit_id": "1d176e261469651067221448ee27c9b83abd1cc7",
        "commit_message": "Fix #7550. (#7552)",
        "commit_url": "https://github.com/keras-team/keras/commit/1d176e261469651067221448ee27c9b83abd1cc7",
        "buggy_code": "return inputs * K.cast(boolean_mask, K.floatx())",
        "fixed_code": "return inputs * K.cast(boolean_mask, inputs.dtype)",
        "patch": "@@ -61,7 +61,7 @@ def compute_mask(self, inputs, mask=None):\n     def call(self, inputs):\n         boolean_mask = K.any(K.not_equal(inputs, self.mask_value),\n                              axis=-1, keepdims=True)\n-        return inputs * K.cast(boolean_mask, K.floatx())\n+        return inputs * K.cast(boolean_mask, inputs.dtype)\n \n     def get_config(self):\n         config = {'mask_value': self.mask_value}"
    },
    {
        "commit_id": "281bc587b38b91abd3a2af41fb43848dd38b042c",
        "commit_message": "Fix sparse_categorical_crossentropy argument and add value test for it  (#7513) (#7524)\n\n* Add value test for sparse_categorical_crossentropy (#7513)\r\n\r\n* Swap sparse_categorical_crossentropy's target for output",
        "commit_url": "https://github.com/keras-team/keras/commit/281bc587b38b91abd3a2af41fb43848dd38b042c",
        "buggy_code": "return categorical_crossentropy(output, target, from_logits)",
        "fixed_code": "return categorical_crossentropy(target, output, from_logits)",
        "patch": "@@ -1629,7 +1629,7 @@ def categorical_crossentropy(target, output, from_logits=False):\n def sparse_categorical_crossentropy(target, output, from_logits=False):\n     target = C.one_hot(target, output.shape[-1])\n     target = C.reshape(target, output.shape)\n-    return categorical_crossentropy(output, target, from_logits)\n+    return categorical_crossentropy(target, output, from_logits)\n \n \n class Function(object):"
    },
    {
        "commit_id": "1cb81f2f9fe20074a3df13716ee3c8eb7bdec109",
        "commit_message": "fix issue #7512 (#7513)",
        "commit_url": "https://github.com/keras-team/keras/commit/1cb81f2f9fe20074a3df13716ee3c8eb7bdec109",
        "buggy_code": "return categorical_crossentropy(output, target, from_logits)",
        "fixed_code": "return categorical_crossentropy(target, output, from_logits)",
        "patch": "@@ -1536,7 +1536,7 @@ def sparse_categorical_crossentropy(target, output, from_logits=False):\n     target = T.cast(T.flatten(target), 'int32')\n     target = T.extra_ops.to_one_hot(target, nb_class=output.shape[-1])\n     target = reshape(target, shape(output))\n-    return categorical_crossentropy(output, target, from_logits)\n+    return categorical_crossentropy(target, output, from_logits)\n \n \n def binary_crossentropy(target, output, from_logits=False):"
    },
    {
        "commit_id": "788c56b9c60120e42f5d6cbd269499b878ba4859",
        "commit_message": "Crossentropy backend API consistency cleanup (#7199)\n\n* Style cleanup, in particular crossentropy backend API\r\n\r\n* Fix backend tests\r\n\r\n* Update backend docs.\r\n\r\n* Fix backend test",
        "commit_url": "https://github.com/keras-team/keras/commit/788c56b9c60120e42f5d6cbd269499b878ba4859",
        "buggy_code": "check_two_tensor_operation('categorical_crossentropy', xval, yval,",
        "fixed_code": "check_two_tensor_operation('categorical_crossentropy', yval, xval,",
        "patch": "@@ -756,7 +756,7 @@ def test_nn_operations(self):\n                            [0.20225059, -0.38956559], [-0.13805378, 0.08506755]], dtype=np.float32)\n         yval = np.asarray([[0.46221867, 0.53778133], [0.51228984, 0.48771016],\n                            [0.64916514, 0.35083486], [0.47028078, 0.52971922]], dtype=np.float32)\n-        check_two_tensor_operation('categorical_crossentropy', xval, yval,\n+        check_two_tensor_operation('categorical_crossentropy', yval, xval,\n                                    BACKENDS, cntk_two_dynamicity=True, from_logits=True)\n         check_two_tensor_operation('binary_crossentropy', (4, 2), (4, 2), BACKENDS, from_logits=False)\n         check_two_tensor_operation('categorical_crossentropy', (4, 2), (4, 2), BACKENDS, from_logits=False)"
    },
    {
        "commit_id": "cbecc6a2fba8729b34c3e852ed4f17aa7bc2ecdd",
        "commit_message": "Fix l2_normalize",
        "commit_url": "https://github.com/keras-team/keras/commit/cbecc6a2fba8729b34c3e852ed4f17aa7bc2ecdd",
        "buggy_code": "norm = T.sqrt(T.maximum(square_sum, epsilon=_EPSILON))",
        "fixed_code": "norm = T.sqrt(T.maximum(square_sum, _EPSILON))",
        "patch": "@@ -1585,7 +1585,7 @@ def dropout(x, level, noise_shape=None, seed=None):\n \n def l2_normalize(x, axis=None):\n     square_sum = T.sum(T.square(x), axis=axis, keepdims=True)\n-    norm = T.sqrt(T.maximum(square_sum, epsilon=_EPSILON))\n+    norm = T.sqrt(T.maximum(square_sum, _EPSILON))\n     return x / norm\n \n "
    },
    {
        "commit_id": "64321deb7e8b7eabc12da0a5ca48da78e132dd57",
        "commit_message": "Docs fix: `pointwise` instead of `depthwise` for SeparableConv2D (#7444)",
        "commit_url": "https://github.com/keras-team/keras/commit/64321deb7e8b7eabc12da0a5ca48da78e132dd57",
        "buggy_code": "the depthwise kernel matrix",
        "fixed_code": "the pointwise kernel matrix",
        "patch": "@@ -1094,7 +1094,7 @@ class SeparableConv2D(Conv2D):\n             the depthwise kernel matrix\n             (see [regularizer](../regularizers.md)).\n         pointwise_regularizer: Regularizer function applied to\n-            the depthwise kernel matrix\n+            the pointwise kernel matrix\n             (see [regularizer](../regularizers.md)).\n         bias_regularizer: Regularizer function applied to the bias vector\n             (see [regularizer](../regularizers.md))."
    },
    {
        "commit_id": "e3dbd93cb92a1abb7cf802a8f9422d3b9dd8cf34",
        "commit_message": "Style fix\n\nRemove extra space.",
        "commit_url": "https://github.com/keras-team/keras/commit/e3dbd93cb92a1abb7cf802a8f9422d3b9dd8cf34",
        "buggy_code": "self.updates .append(K.update_add(self.iterations, 1))",
        "fixed_code": "self.updates.append(K.update_add(self.iterations, 1))",
        "patch": "@@ -155,7 +155,7 @@ def get_updates(self, params, constraints, loss):\n         lr = self.lr\n         if self.initial_decay > 0:\n             lr *= (1. / (1. + self.decay * self.iterations))\n-            self.updates .append(K.update_add(self.iterations, 1))\n+            self.updates.append(K.update_add(self.iterations, 1))\n \n         # momentum\n         shapes = [K.get_variable_shape(p) for p in params]"
    },
    {
        "commit_id": "b1f90950fa077acb1c8f98f01a99848b153f1c91",
        "commit_message": "Fix typos. (#7374)",
        "commit_url": "https://github.com/keras-team/keras/commit/b1f90950fa077acb1c8f98f01a99848b153f1c91",
        "buggy_code": "It should have exactly 3 inputs channels,",
        "fixed_code": "It should have exactly 3 input channels,",
        "patch": "@@ -60,7 +60,7 @@ def VGG16(include_top=True, weights='imagenet',\n             if `include_top` is False (otherwise the input shape\n             has to be `(224, 224, 3)` (with `channels_last` data format)\n             or `(3, 224, 224)` (with `channels_first` data format).\n-            It should have exactly 3 inputs channels,\n+            It should have exactly 3 input channels,\n             and width and height should be no smaller than 48.\n             E.g. `(200, 200, 3)` would be one valid value.\n         pooling: Optional pooling mode for feature extraction"
    },
    {
        "commit_id": "4de120f051cd21ea7b7f11ec72b4606a1577fd4d",
        "commit_message": "Fix computation of receptive field size for 'channels_last' (#7200)",
        "commit_url": "https://github.com/keras-team/keras/commit/4de120f051cd21ea7b7f11ec72b4606a1577fd4d",
        "buggy_code": "receptive_field_size = np.prod(shape[:2])",
        "fixed_code": "receptive_field_size = np.prod(shape[:-2])",
        "patch": "@@ -458,7 +458,7 @@ def _compute_fans(shape, data_format='channels_last'):\n             fan_in = shape[1] * receptive_field_size\n             fan_out = shape[0] * receptive_field_size\n         elif data_format == 'channels_last':\n-            receptive_field_size = np.prod(shape[:2])\n+            receptive_field_size = np.prod(shape[:-2])\n             fan_in = shape[-2] * receptive_field_size\n             fan_out = shape[-1] * receptive_field_size\n         else:"
    },
    {
        "commit_id": "ec048edffc1f6292b7d9ca54b31af3659b902353",
        "commit_message": "Fix typo (#7191)",
        "commit_url": "https://github.com/keras-team/keras/commit/ec048edffc1f6292b7d9ca54b31af3659b902353",
        "buggy_code": "use_multiprocessing: Ff True, use process based threading.",
        "fixed_code": "use_multiprocessing: if True, use process based threading.",
        "patch": "@@ -1067,7 +1067,7 @@ def fit_generator(self, generator,\n                 for the class.\n             max_queue_size: Maximum size for the generator queue\n             workers: Maximum number of processes to spin up\n-            use_multiprocessing: Ff True, use process based threading.\n+            use_multiprocessing: if True, use process based threading.\n                 Note that because\n                 this implementation relies on multiprocessing,\n                 you should not pass"
    },
    {
        "commit_id": "49a7c7376d0057ab85e00f1ee3387ce36797e994",
        "commit_message": "Addition of MobileNet to application (#7009)\n\n* Add MobileNet to application\r\n\r\n* Add support for 1001 classes in imagenet utils\r\n\r\n* Revert a mistake in the tests\r\n\r\n* Setup application test for mobilenet to run only when on tensorflow\r\n\r\n* Correct pytest.mark.skipif explanation for skipping tests if not on tensorflow\r\n\r\n* Corrected mobilenet to support 1000 classes and reverted imagenet_utils to prior state\r\n\r\n* Fix tensorflow test\r\n\r\n* Restrict mobilenets to data format \"channels_last\"\r\n\r\n* Add review fixes\r\n\r\n* PEP8 fix\r\n\r\n* Add relu6 to activations.py\r\n\r\n* Corrected imports in mobilenet.py\r\n\r\n* Rolled back activation relu6 and inlined it to mobilenet.py\r\n\r\n* Refactored DepthwiseConv2D and other corrections\r\n\r\n* Fixed tests\r\n\r\n* PEP8 correction\r\n\r\n* Add docs to private functions and other fixes\r\n\r\n* Fix failed test where input shape is None\r\n\r\n* Fix value of size for model name",
        "commit_url": "https://github.com/keras-team/keras/commit/49a7c7376d0057ab85e00f1ee3387ce36797e994",
        "buggy_code": "'(i.e. a 2D array of shape (samples, 1000)). '",
        "fixed_code": "'(i.e. a 2D array of shape (samples, 1000)).'",
        "patch": "@@ -58,7 +58,7 @@ def decode_predictions(preds, top=5):\n     if len(preds.shape) != 2 or preds.shape[1] != 1000:\n         raise ValueError('`decode_predictions` expects '\n                          'a batch of predictions '\n-                         '(i.e. a 2D array of shape (samples, 1000)). '\n+                         '(i.e. a 2D array of shape (samples, 1000)).'\n                          'Found array with shape: ' + str(preds.shape))\n     if CLASS_INDEX is None:\n         fpath = get_file('imagenet_class_index.json',"
    },
    {
        "commit_id": "5a7f6b0e74673eae86c07fc642018745443bb335",
        "commit_message": "fix dtype handling in 2 optimizers and 1 layer (#7088)\n\n* fix dtype handling in 2 optimizers and 1 layer\r\n\r\n* fix zeros\r\n\r\n* Add base_dtype argument\r\n\r\n* Fix base_dtype\r\n\r\n* remove base_dtype",
        "commit_url": "https://github.com/keras-team/keras/commit/5a7f6b0e74673eae86c07fc642018745443bb335",
        "buggy_code": "return x.dtype.name",
        "fixed_code": "return x.dtype.base_dtype.name",
        "patch": "@@ -550,7 +550,7 @@ def dtype(x):\n         'float32_ref'\n     ```\n     \"\"\"\n-    return x.dtype.name\n+    return x.dtype.base_dtype.name\n \n \n def eval(x):"
    },
    {
        "commit_id": "60cf7ca6b28967b9ab9b41a959520532028eeaa5",
        "commit_message": "Fix typos (#7087)",
        "commit_url": "https://github.com/keras-team/keras/commit/60cf7ca6b28967b9ab9b41a959520532028eeaa5",
        "buggy_code": "skip_top: skip the top N most frequently occuring words",
        "fixed_code": "skip_top: skip the top N most frequently occurring words",
        "patch": "@@ -17,7 +17,7 @@ def load_data(path='imdb.npz', num_words=None, skip_top=0,\n         num_words: max number of words to include. Words are ranked\n             by how often they occur (in the training set) and only\n             the most frequent words are kept\n-        skip_top: skip the top N most frequently occuring words\n+        skip_top: skip the top N most frequently occurring words\n             (which may not be informative).\n         maxlen: truncate sequences after this length.\n         seed: random seed for sample shuffling."
    },
    {
        "commit_id": "60cf7ca6b28967b9ab9b41a959520532028eeaa5",
        "commit_message": "Fix typos (#7087)",
        "commit_url": "https://github.com/keras-team/keras/commit/60cf7ca6b28967b9ab9b41a959520532028eeaa5",
        "buggy_code": "skip_top: skip the top N most frequently occuring words",
        "fixed_code": "skip_top: skip the top N most frequently occurring words",
        "patch": "@@ -18,7 +18,7 @@ def load_data(path='reuters.npz', num_words=None, skip_top=0,\n         num_words: max number of words to include. Words are ranked\n             by how often they occur (in the training set) and only\n             the most frequent words are kept\n-        skip_top: skip the top N most frequently occuring words\n+        skip_top: skip the top N most frequently occurring words\n             (which may not be informative).\n         maxlen: truncate sequences after this length.\n         test_split: Fraction of the dataset to be used as test data."
    },
    {
        "commit_id": "60cf7ca6b28967b9ab9b41a959520532028eeaa5",
        "commit_message": "Fix typos (#7087)",
        "commit_url": "https://github.com/keras-team/keras/commit/60cf7ca6b28967b9ab9b41a959520532028eeaa5",
        "buggy_code": "The same structure, where occurences",
        "fixed_code": "The same structure, where occurrences",
        "patch": "@@ -207,7 +207,7 @@ def convert_custom_objects(obj):\n             obj: object, dict, or list.\n \n         # Returns\n-            The same structure, where occurences\n+            The same structure, where occurrences\n                 of a custom object name have been replaced\n                 with the custom object.\n         \"\"\""
    },
    {
        "commit_id": "60cf7ca6b28967b9ab9b41a959520532028eeaa5",
        "commit_message": "Fix typos (#7087)",
        "commit_url": "https://github.com/keras-team/keras/commit/60cf7ca6b28967b9ab9b41a959520532028eeaa5",
        "buggy_code": "the 10-th most frequently occuring token).",
        "fixed_code": "the 10-th most frequently occurring token).",
        "patch": "@@ -127,7 +127,7 @@ def skipgrams(sequence, vocabulary_size,\n             of word indices (integers). If using a `sampling_table`,\n             word indices are expected to match the rank\n             of the words in a reference dataset (e.g. 10 would encode\n-            the 10-th most frequently occuring token).\n+            the 10-th most frequently occurring token).\n             Note that index 0 is expected to be a non-word and will be skipped.\n         vocabulary_size: int. maximum possible word index + 1\n         window_size: int. actually half-window."
    },
    {
        "commit_id": "a2f6ae2c66f22a2415d069913479990ce73e98b7",
        "commit_message": "Style fix (#7079)",
        "commit_url": "https://github.com/keras-team/keras/commit/a2f6ae2c66f22a2415d069913479990ce73e98b7",
        "buggy_code": "rank = np.array(list(range(size)))",
        "fixed_code": "rank = np.arange(size)",
        "patch": "@@ -104,7 +104,7 @@ def make_sampling_table(size, sampling_factor=1e-5):\n         is the probability that a word of rank i should be sampled.\n     \"\"\"\n     gamma = 0.577\n-    rank = np.array(list(range(size)))\n+    rank = np.arange(size)\n     rank[0] = 1\n     inv_fq = rank * (np.log(rank) + gamma) + 0.5 - 1. / (12. * rank)\n     f = sampling_factor * inv_fq"
    },
    {
        "commit_id": "767846e642dc73e421ac426380485fc3348c4f69",
        "commit_message": "fix url to LSTM paper (#7025)",
        "commit_url": "https://github.com/keras-team/keras/commit/767846e642dc73e421ac426380485fc3348c4f69",
        "buggy_code": "- [Long short-term memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf) (original 1997 paper)",
        "fixed_code": "- [Long short-term memory](http://www.bioinf.jku.at/publications/older/2604.pdf) (original 1997 paper)",
        "patch": "@@ -953,7 +953,7 @@ class LSTM(Recurrent):\n             the linear transformation of the recurrent state.\n \n     # References\n-        - [Long short-term memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf) (original 1997 paper)\n+        - [Long short-term memory](http://www.bioinf.jku.at/publications/older/2604.pdf) (original 1997 paper)\n         - [Learning to forget: Continual prediction with LSTM](http://www.mitpressjournals.org/doi/pdf/10.1162/089976600300015015)\n         - [Supervised sequence labeling with recurrent neural networks](http://www.cs.toronto.edu/~graves/preprint.pdf)\n         - [A Theoretically Grounded Application of Dropout in Recurrent Neural Networks](http://arxiv.org/abs/1512.05287)"
    },
    {
        "commit_id": "5ca5699b00881f6995dda787efdb1df461014b67",
        "commit_message": "Fixed some descriptions in backend (#6778)\n\n* Fix to use floatx as argument in set_floatx\r\n\r\n* Add line break\r\n\r\n* Change to lower case\r\n\r\n* Use 'x' as in moving_average_update description\r\n\r\n* Fix to drop duplicate in one_hot Returns\r\n\r\n* The foldr Returns convert to foldl itself\r\n\r\n* Add back quote\r\n\r\n* Add back quote\r\n\r\n* Rebase and integrate comment on one-hot",
        "commit_url": "https://github.com/keras-team/keras/commit/5ca5699b00881f6995dda787efdb1df461014b67",
        "buggy_code": "String: 'float16', 'float32', or 'float64'.",
        "fixed_code": "floatx: String, 'float16', 'float32', or 'float64'.",
        "patch": "@@ -63,7 +63,7 @@ def set_floatx(floatx):\n     \"\"\"Sets the default float type.\n \n     # Arguments\n-        String: 'float16', 'float32', or 'float64'.\n+        floatx: String, 'float16', 'float32', or 'float64'.\n \n     # Example\n     ```python"
    },
    {
        "commit_id": "be6503a8a81873109cf830bef225bf06a13edda2",
        "commit_message": "Add space in error message",
        "commit_url": "https://github.com/keras-team/keras/commit/be6503a8a81873109cf830bef225bf06a13edda2",
        "buggy_code": "raise ValueError('The model expects ' + str(len(names)) +",
        "fixed_code": "raise ValueError('The model expects ' + str(len(names)) + ' ' +",
        "patch": "@@ -100,7 +100,7 @@ def _standardize_input_data(data, names, shapes=None,\n         if len(names) > 1:\n             # Case: model expects multiple inputs but only received\n             # a single Numpy array.\n-            raise ValueError('The model expects ' + str(len(names)) +\n+            raise ValueError('The model expects ' + str(len(names)) + ' ' +\n                              exception_prefix +\n                              ' arrays, but only received one array. '\n                              'Found: array with shape ' + str(data.shape))"
    },
    {
        "commit_id": "c73ba916f6295586324a298316b5774a53505d8a",
        "commit_message": "Fix model loading for LeakyReLU layer (#7010)",
        "commit_url": "https://github.com/keras-team/keras/commit/c73ba916f6295586324a298316b5774a53505d8a",
        "buggy_code": "config = {'alpha': self.alpha}",
        "fixed_code": "config = {'alpha': float(self.alpha)}",
        "patch": "@@ -41,7 +41,7 @@ def call(self, inputs):\n         return K.relu(inputs, alpha=self.alpha)\n \n     def get_config(self):\n-        config = {'alpha': self.alpha}\n+        config = {'alpha': float(self.alpha)}\n         base_config = super(LeakyReLU, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n "
    },
    {
        "commit_id": "4a6f06f06d6a90eabfbdc48ec549d351dc012185",
        "commit_message": "Increase test coverage (#6765)\n\n* Increase test coverage\r\n\r\n* Move sequence util and fix merge conflict",
        "commit_url": "https://github.com/keras-team/keras/commit/4a6f06f06d6a90eabfbdc48ec549d351dc012185",
        "buggy_code": "with pytest.raises(Exception):",
        "fixed_code": "with pytest.raises(ValueError):",
        "patch": "@@ -99,7 +99,7 @@ def test_orthogonal(tensor_shape):\n @pytest.mark.parametrize('tensor_shape', [(100, 100), (1, 2, 3, 4)], ids=['FC', 'CONV'])\n def test_identity(tensor_shape):\n     if len(tensor_shape) > 2:\n-        with pytest.raises(Exception):\n+        with pytest.raises(ValueError):\n             _runner(initializers.identity(), tensor_shape,\n                     target_mean=1. / tensor_shape[0], target_max=1.)\n     else:"
    },
    {
        "commit_id": "fd427b8cdb35b80c72782f03ae03d4d58830faef",
        "commit_message": "Fix typos (#6879)",
        "commit_url": "https://github.com/keras-team/keras/commit/fd427b8cdb35b80c72782f03ae03d4d58830faef",
        "buggy_code": "\"\"\"Does validation on the compatiblity of targets and loss functions.",
        "fixed_code": "\"\"\"Does validation on the compatibility of targets and loss functions.",
        "patch": "@@ -241,7 +241,7 @@ def _check_array_lengths(inputs, targets, weights):\n \n \n def _check_loss_and_target_compatibility(targets, loss_fns, output_shapes):\n-    \"\"\"Does validation on the compatiblity of targets and loss functions.\n+    \"\"\"Does validation on the compatibility of targets and loss functions.\n \n     This helps prevent users from using loss functions incorrectly.\n "
    },
    {
        "commit_id": "1b67c59de8c1f61fa785c5192dff4b6a9a409153",
        "commit_message": "Style fix.",
        "commit_url": "https://github.com/keras-team/keras/commit/1b67c59de8c1f61fa785c5192dff4b6a9a409153",
        "buggy_code": "print(\"Pad sequences (samples x time)\")",
        "fixed_code": "print('Pad sequences (samples x time)')",
        "patch": "@@ -24,7 +24,7 @@\n print(len(x_train), 'train sequences')\n print(len(x_test), 'test sequences')\n \n-print(\"Pad sequences (samples x time)\")\n+print('Pad sequences (samples x time)')\n x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n print('x_train shape:', x_train.shape)"
    },
    {
        "commit_id": "1e09e0a9d4180638b9afcfbb8071cb0e5efc7919",
        "commit_message": "Style fix.",
        "commit_url": "https://github.com/keras-team/keras/commit/1e09e0a9d4180638b9afcfbb8071cb0e5efc7919",
        "buggy_code": "if type(input_shape) is list:",
        "fixed_code": "if isinstance(input_shape, list):",
        "patch": "@@ -109,7 +109,7 @@ def __init__(self, filters,\n         self.state_spec = None\n \n     def compute_output_shape(self, input_shape):\n-        if type(input_shape) is list:\n+        if isinstance(input_shape, list):\n             input_shape = input_shape[0]\n         if self.data_format == 'channels_first':\n             rows = input_shape[3]"
    },
    {
        "commit_id": "7ef13165b7e985b89516023b9608780b0fcbe261",
        "commit_message": "Improve documents (#6727)\n\n* Improve documents\r\n\r\n* Fix style",
        "commit_url": "https://github.com/keras-team/keras/commit/7ef13165b7e985b89516023b9608780b0fcbe261",
        "buggy_code": "to_file: File name of the",
        "fixed_code": "to_file: File name of the plot image.",
        "patch": "@@ -113,7 +113,7 @@ def plot_model(model,\n \n     # Arguments\n         model: A Keras model instance\n-        to_file: File name of the\n+        to_file: File name of the plot image.\n         show_shapes: whether to display shape information.\n         show_layer_names: whether to display layer names.\n         rankdir: `rankdir` argument passed to PyDot,"
    },
    {
        "commit_id": "7f09d45efb7d0d0e8f43b9c2975caa6be0fda00d",
        "commit_message": "Fix typo in docstring\n\nCorrected a small annotation in Input()",
        "commit_url": "https://github.com/keras-team/keras/commit/7f09d45efb7d0d0e8f43b9c2975caa6be0fda00d",
        "buggy_code": "For instance, if a, b and c and Keras tensors,",
        "fixed_code": "For instance, if a, b and c are Keras tensors,",
        "patch": "@@ -1370,7 +1370,7 @@ def Input(shape=None, batch_shape=None,\n     attributes that allow us to build a Keras model\n     just by knowing the inputs and outputs of the model.\n \n-    For instance, if a, b and c and Keras tensors,\n+    For instance, if a, b and c are Keras tensors,\n     it becomes possible to do:\n     `model = Model(input=[a, b], output=c)`\n "
    },
    {
        "commit_id": "bac16379a2452f975946a5007304083a1cd3c224",
        "commit_message": "Fix typos (#6702)",
        "commit_url": "https://github.com/keras-team/keras/commit/bac16379a2452f975946a5007304083a1cd3c224",
        "buggy_code": "or `(3, 224, 244)` (with `channels_first` data format).",
        "fixed_code": "or `(3, 224, 224)` (with `channels_first` data format).",
        "patch": "@@ -59,7 +59,7 @@ def VGG16(include_top=True, weights='imagenet',\n         input_shape: optional shape tuple, only to be specified\n             if `include_top` is False (otherwise the input shape\n             has to be `(224, 224, 3)` (with `channels_last` data format)\n-            or `(3, 224, 244)` (with `channels_first` data format).\n+            or `(3, 224, 224)` (with `channels_first` data format).\n             It should have exactly 3 inputs channels,\n             and width and height should be no smaller than 48.\n             E.g. `(200, 200, 3)` would be one valid value."
    },
    {
        "commit_id": "bac16379a2452f975946a5007304083a1cd3c224",
        "commit_message": "Fix typos (#6702)",
        "commit_url": "https://github.com/keras-team/keras/commit/bac16379a2452f975946a5007304083a1cd3c224",
        "buggy_code": "or `(3, 224, 244)` (with `channels_first` data format).",
        "fixed_code": "or `(3, 224, 224)` (with `channels_first` data format).",
        "patch": "@@ -59,7 +59,7 @@ def VGG19(include_top=True, weights='imagenet',\n         input_shape: optional shape tuple, only to be specified\n             if `include_top` is False (otherwise the input shape\n             has to be `(224, 224, 3)` (with `channels_last` data format)\n-            or `(3, 224, 244)` (with `channels_first` data format).\n+            or `(3, 224, 224)` (with `channels_first` data format).\n             It should have exactly 3 inputs channels,\n             and width and height should be no smaller than 48.\n             E.g. `(200, 200, 3)` would be one valid value."
    },
    {
        "commit_id": "3061fcce608677578d2db72203171f9a42badb2a",
        "commit_message": "Fix a typo in expand_dims() (#6671)\n\nIn comment: expended -> expanded",
        "commit_url": "https://github.com/keras-team/keras/commit/3061fcce608677578d2db72203171f9a42badb2a",
        "buggy_code": "A tensor with expended dimensions.",
        "fixed_code": "A tensor with expanded dimensions.",
        "patch": "@@ -1944,7 +1944,7 @@ def expand_dims(x, axis=-1):\n         axis: Position where to add a new axis.\n \n     # Returns\n-        A tensor with expended dimensions.\n+        A tensor with expanded dimensions.\n     \"\"\"\n     return tf.expand_dims(x, axis)\n "
    },
    {
        "commit_id": "6642d496e509e780f70c33d8cd1a802b94f6b587",
        "commit_message": "Recurrent : InputSpec fixes (#6568)\n\n* Recurrent : InputSpec fixes\r\n\r\n* Update convolutional_recurrent.py\r\n\r\n* pep8 fix\r\n\r\n* Update convolutional_recurrent.py",
        "commit_url": "https://github.com/keras-team/keras/commit/6642d496e509e780f70c33d8cd1a802b94f6b587",
        "buggy_code": "self.input_spec[0] = InputSpec(shape=(batch_size,) + input_shape[1:])",
        "fixed_code": "self.input_spec[0] = InputSpec(shape=(batch_size, None) + input_shape[2:])",
        "patch": "@@ -334,7 +334,7 @@ def build(self, input_shape):\n         if isinstance(input_shape, list):\n             input_shape = input_shape[0]\n         batch_size = input_shape[0] if self.stateful else None\n-        self.input_spec[0] = InputSpec(shape=(batch_size,) + input_shape[1:])\n+        self.input_spec[0] = InputSpec(shape=(batch_size, None) + input_shape[2:])\n         if self.stateful:\n             self.reset_states()\n         else:"
    },
    {
        "commit_id": "ea8e2edf17fed647037109f712672a44f5a66ac9",
        "commit_message": "fix tuple error message (#6530)",
        "commit_url": "https://github.com/keras-team/keras/commit/ea8e2edf17fed647037109f712672a44f5a66ac9",
        "buggy_code": "raise ValueError('Unknown ' + printable_module_name,",
        "fixed_code": "raise ValueError('Unknown ' + printable_module_name +",
        "patch": "@@ -153,7 +153,7 @@ def deserialize_keras_object(identifier, module_objects=None,\n         else:\n             fn = module_objects.get(function_name)\n             if fn is None:\n-                raise ValueError('Unknown ' + printable_module_name,\n+                raise ValueError('Unknown ' + printable_module_name +\n                                  ':' + function_name)\n         return fn\n     else:"
    },
    {
        "commit_id": "dc3d164c6b1079f647ac7ed416cb917a1cc72c18",
        "commit_message": "Tokenizer docs patch (#6506)\n\n* Tokenizer docs patch\r\n\r\n* Minor change",
        "commit_url": "https://github.com/keras-team/keras/commit/dc3d164c6b1079f647ac7ed416cb917a1cc72c18",
        "buggy_code": "char_level: if True, every character will be treated as a word.",
        "fixed_code": "char_level: if True, every character will be treated as a token.",
        "patch": "@@ -68,7 +68,7 @@ class Tokenizer(object):\n             tabs and line breaks, minus the `'` character.\n         lower: boolean. Whether to convert the texts to lowercase.\n         split: character or string to use for token splitting.\n-        char_level: if True, every character will be treated as a word.\n+        char_level: if True, every character will be treated as a token.\n \n     By default, all punctuation is removed, turning the texts into\n     space-separated sequences of words"
    },
    {
        "commit_id": "0c237ebea2633afbb92809da07734b9bac82a9c5",
        "commit_message": "Fix missing quote mark in Cropping2D docstring (#6428)",
        "commit_url": "https://github.com/keras-team/keras/commit/0c237ebea2633afbb92809da07734b9bac82a9c5",
        "buggy_code": "model.add(Conv2D(64, (3, 3), padding='same))",
        "fixed_code": "model.add(Conv2D(64, (3, 3), padding='same'))",
        "patch": "@@ -1571,7 +1571,7 @@ class Cropping2D(Layer):\n         model.add(Cropping2D(cropping=((2, 2), (4, 4)),\n                              input_shape=(28, 28, 3)))\n         # now model.output_shape == (None, 24, 20, 3)\n-        model.add(Conv2D(64, (3, 3), padding='same))\n+        model.add(Conv2D(64, (3, 3), padding='same'))\n         model.add(Cropping2D(cropping=((2, 2), (2, 2))))\n         # now model.output_shape == (None, 20, 16. 64)\n     ```"
    },
    {
        "commit_id": "bcbfcc000ce07078786bae5f66f8b30dbe82fb64",
        "commit_message": "Fix oov_char=None case in IMDB/Reuters datasets (#6397)\n\nCloses: #3688",
        "commit_url": "https://github.com/keras-team/keras/commit/bcbfcc000ce07078786bae5f66f8b30dbe82fb64",
        "buggy_code": "if w >= num_words or w < skip_top:",
        "fixed_code": "if skip_top <= w < num_words:",
        "patch": "@@ -100,7 +100,7 @@ def load_data(path='imdb.npz', num_words=None, skip_top=0,\n         for x in xs:\n             nx = []\n             for w in x:\n-                if w >= num_words or w < skip_top:\n+                if skip_top <= w < num_words:\n                     nx.append(w)\n             new_xs.append(nx)\n         xs = new_xs"
    },
    {
        "commit_id": "bcbfcc000ce07078786bae5f66f8b30dbe82fb64",
        "commit_message": "Fix oov_char=None case in IMDB/Reuters datasets (#6397)\n\nCloses: #3688",
        "commit_url": "https://github.com/keras-team/keras/commit/bcbfcc000ce07078786bae5f66f8b30dbe82fb64",
        "buggy_code": "if w >= num_words or w < skip_top:",
        "fixed_code": "if skip_top <= w < num_words:",
        "patch": "@@ -84,7 +84,7 @@ def load_data(path='reuters.npz', num_words=None, skip_top=0,\n         for x in xs:\n             nx = []\n             for w in x:\n-                if w >= num_words or w < skip_top:\n+                if skip_top <= w < num_words:\n                     nx.append(w)\n             new_xs.append(nx)\n         xs = new_xs"
    },
    {
        "commit_id": "365f621b24631a03f995e3b30e1800d327e42fc1",
        "commit_message": "Fix Specifying Initial States of RNN Layers (#5795)\n\n* fix specify state\r\n\r\n* Added documentation for `reset_states`\r\n\r\n* Remove unneeded check\r\n\r\n* Update Documentation\r\n\r\n* pep8\r\n\r\n* Fix when initial_states is a tensor\r\n\r\n* modify tests for non-list initial states.\r\n\r\n* use initial_state instead of initial_states\r\n\r\n* pep8\r\n\r\n* change get_initial_states to get_initial_state in ConvLSTM2D\r\n\r\n* Check for Keras Tensors in Recurrent\r\n\r\n* check if initial_state is passed to call\r\n\r\n* pep8\r\n\r\n* Move state_spec definition to __init__\r\n\r\n* Fix reset states\r\n\r\n* fix masking when specifying state\r\n\r\n* added masking test for RNNs with specified state\r\n\r\n* pep8\r\n\r\n* remove unnecessary blank line",
        "commit_url": "https://github.com/keras-team/keras/commit/365f621b24631a03f995e3b30e1800d327e42fc1",
        "buggy_code": "def get_initial_states(self, inputs):",
        "fixed_code": "def get_initial_state(self, inputs):",
        "patch": "@@ -396,7 +396,7 @@ def build(self, input_shape):\n             self.bias_o = None\n         self.built = True\n \n-    def get_initial_states(self, inputs):\n+    def get_initial_state(self, inputs):\n         # (samples, timesteps, rows, cols, filters)\n         initial_state = K.zeros_like(inputs)\n         # (samples, rows, cols, filters)"
    },
    {
        "commit_id": "73bf06fb023a8b37ddf2e2a168bbf920c7a6c766",
        "commit_message": "Style fixes (#6271)\n\n* Fix link in FAQ\r\n\r\n* Fix link in FAQ\r\n\r\n* Style fix\r\n\r\n* Rename objectives to losses",
        "commit_url": "https://github.com/keras-team/keras/commit/73bf06fb023a8b37ddf2e2a168bbf920c7a6c766",
        "buggy_code": "See [objectives](/objectives).",
        "fixed_code": "See [losses](/losses).",
        "patch": "@@ -744,7 +744,7 @@ def compile(self, optimizer, loss,\n             optimizer: str (name of optimizer) or optimizer object.\n                 See [optimizers](/optimizers).\n             loss: str (name of objective function) or objective function.\n-                See [objectives](/objectives).\n+                See [losses](/losses).\n             metrics: list of metrics to be evaluated by the model\n                 during training and testing.\n                 Typically you will use `metrics=['accuracy']`."
    },
    {
        "commit_id": "2a675067287428bd0d6c2c968bac4d0e17e2356d",
        "commit_message": "Fix GRU bias initializer selection",
        "commit_url": "https://github.com/keras-team/keras/commit/2a675067287428bd0d6c2c968bac4d0e17e2356d",
        "buggy_code": "initializer='zero',",
        "fixed_code": "initializer=self.bias_initializer,",
        "patch": "@@ -705,7 +705,7 @@ def build(self, input_shape):\n         if self.use_bias:\n             self.bias = self.add_weight((self.units * 3,),\n                                         name='bias',\n-                                        initializer='zero',\n+                                        initializer=self.bias_initializer,\n                                         regularizer=self.bias_regularizer,\n                                         constraint=self.bias_constraint)\n         else:"
    },
    {
        "commit_id": "90758c3f4ed2208b053ef8b7ecc3e0721d9d83ec",
        "commit_message": "typo in model_from_config error flag (#6238)",
        "commit_url": "https://github.com/keras-team/keras/commit/90758c3f4ed2208b053ef8b7ecc3e0721d9d83ec",
        "buggy_code": "raise TypeError('`model_fom_config` expects a dictionary, not a list. '",
        "fixed_code": "raise TypeError('`model_from_config` expects a dictionary, not a list. '",
        "patch": "@@ -295,7 +295,7 @@ def model_from_config(config, custom_objects=None):\n         A Keras model instance (uncompiled).\n     \"\"\"\n     if isinstance(config, list):\n-        raise TypeError('`model_fom_config` expects a dictionary, not a list. '\n+        raise TypeError('`model_from_config` expects a dictionary, not a list. '\n                         'Maybe you meant to use '\n                         '`Sequential.from_config(config)`?')\n     return layer_module.deserialize(config, custom_objects=custom_objects)"
    },
    {
        "commit_id": "28b731a3d11f75b3c2a24c580c49b3625e3e6998",
        "commit_message": "Fix doc typo in ResNet50. (#6202)",
        "commit_url": "https://github.com/keras-team/keras/commit/28b731a3d11f75b3c2a24c580c49b3625e3e6998",
        "buggy_code": "or `(3, 224, 244)` (with `channels_first` data format).",
        "fixed_code": "or `(3, 224, 224)` (with `channels_first` data format).",
        "patch": "@@ -149,7 +149,7 @@ def ResNet50(include_top=True, weights='imagenet',\n         input_shape: optional shape tuple, only to be specified\n             if `include_top` is False (otherwise the input shape\n             has to be `(224, 224, 3)` (with `channels_last` data format)\n-            or `(3, 224, 244)` (with `channels_first` data format).\n+            or `(3, 224, 224)` (with `channels_first` data format).\n             It should have exactly 3 inputs channels,\n             and width and height should be no smaller than 197.\n             E.g. `(200, 200, 3)` would be one valid value."
    },
    {
        "commit_id": "4785d51705949e72316770413ba187f07f05a5bc",
        "commit_message": "Typo fix (#6141)",
        "commit_url": "https://github.com/keras-team/keras/commit/4785d51705949e72316770413ba187f07f05a5bc",
        "buggy_code": "str(input))",
        "fixed_code": "str(inputs))",
        "patch": "@@ -398,7 +398,7 @@ def assert_input_compatibility(self, inputs):\n                              str(len(input_spec)) + ' inputs, '\n                              'but it received ' + str(len(inputs)) +\n                              ' input tensors. Input received: ' +\n-                             str(input))\n+                             str(inputs))\n         for input_index, (x, spec) in enumerate(zip(inputs, input_spec)):\n             if spec is None:\n                 continue"
    },
    {
        "commit_id": "3a666b497db59491d71ce671e3b01af90332e8b9",
        "commit_message": "review the docs (#6103)\n\n* review the docs\r\n\r\n* fix pep8 issues",
        "commit_url": "https://github.com/keras-team/keras/commit/3a666b497db59491d71ce671e3b01af90332e8b9",
        "buggy_code": "a fraction `p` of input units to 0 at each update during training time,",
        "fixed_code": "a fraction `rate` of input units to 0 at each update during training time,",
        "patch": "@@ -73,7 +73,7 @@ class Dropout(Layer):\n     \"\"\"Applies Dropout to the input.\n \n     Dropout consists in randomly setting\n-    a fraction `p` of input units to 0 at each update during training time,\n+    a fraction `rate` of input units to 0 at each update during training time,\n     which helps prevent overfitting.\n \n     # Arguments"
    },
    {
        "commit_id": "86b12f6fd2c4e2d1f362cc526351e0bbae348240",
        "commit_message": "bug fix, cast batch_sizes as a list to support indexing (#6057)",
        "commit_url": "https://github.com/keras-team/keras/commit/86b12f6fd2c4e2d1f362cc526351e0bbae348240",
        "buggy_code": "output_shape = (batch_sizes[0],) + output_shape",
        "fixed_code": "output_shape = (list(batch_sizes)[0],) + output_shape",
        "patch": "@@ -160,7 +160,7 @@ def compute_output_shape(self, input_shape):\n         batch_sizes = set(batch_sizes)\n         batch_sizes -= set([None])\n         if len(batch_sizes) == 1:\n-            output_shape = (batch_sizes[0],) + output_shape\n+            output_shape = (list(batch_sizes)[0],) + output_shape\n         else:\n             output_shape = (None,) + output_shape\n         return output_shape"
    },
    {
        "commit_id": "fa4c747b7e9ef8deca9f806dd8e77315f805f2ca",
        "commit_message": "Typo Fix (#6017)",
        "commit_url": "https://github.com/keras-team/keras/commit/fa4c747b7e9ef8deca9f806dd8e77315f805f2ca",
        "buggy_code": "- Net2WiderNet exepriment:",
        "fixed_code": "- Net2WiderNet experiment:",
        "patch": "@@ -26,7 +26,7 @@\n \n Experiments\n - Teacher model: a basic CNN model trained on MNIST for 3 epochs.\n-- Net2WiderNet exepriment:\n+- Net2WiderNet experiment:\n   + Student model has a wider Conv2D layer and a wider FC layer.\n   + Comparison of 'random-padding' vs 'net2wider' weight initialization.\n   + With both methods, student model should immediately perform as well as"
    },
    {
        "commit_id": "9f6fb452a231dc83468b9c3be29cd160af53ea9b",
        "commit_message": "Fix typo\n\nLooks like eec61d9 changed the stride from 1 to 2.",
        "commit_url": "https://github.com/keras-team/keras/commit/9f6fb452a231dc83468b9c3be29cd160af53ea9b",
        "buggy_code": "cnn.add(Conv2D(64, 3, padding='same', strides=2))",
        "fixed_code": "cnn.add(Conv2D(64, 3, padding='same', strides=1))",
        "patch": "@@ -101,7 +101,7 @@ def build_discriminator():\n     cnn.add(LeakyReLU())\n     cnn.add(Dropout(0.3))\n \n-    cnn.add(Conv2D(64, 3, padding='same', strides=2))\n+    cnn.add(Conv2D(64, 3, padding='same', strides=1))\n     cnn.add(LeakyReLU())\n     cnn.add(Dropout(0.3))\n "
    },
    {
        "commit_id": "f1732555403aeff4f8756637508e2aa43a1be6e3",
        "commit_message": "Fix docstring for SpatialDropout1D. (#5994)",
        "commit_url": "https://github.com/keras-team/keras/commit/f1732555403aeff4f8756637508e2aa43a1be6e3",
        "buggy_code": "p: float between 0 and 1. Fraction of the input units to drop.",
        "fixed_code": "rate: float between 0 and 1. Fraction of the input units to drop.",
        "patch": "@@ -129,7 +129,7 @@ class SpatialDropout1D(Dropout):\n     between feature maps and should be used instead.\n \n     # Arguments\n-        p: float between 0 and 1. Fraction of the input units to drop.\n+        rate: float between 0 and 1. Fraction of the input units to drop.\n \n     # Input shape\n         3D tensor with shape:"
    },
    {
        "commit_id": "e21c1fa7d39df780c44ff53247c68cc3892a4d2b",
        "commit_message": "Fix wrong error message in `load_model` (#5936)",
        "commit_url": "https://github.com/keras-team/keras/commit/e21c1fa7d39df780c44ff53247c68cc3892a4d2b",
        "buggy_code": "raise ImportError('`save_model` requires h5py.')",
        "fixed_code": "raise ImportError('`load_model` requires h5py.')",
        "patch": "@@ -186,7 +186,7 @@ def load_model(filepath, custom_objects=None):\n         ValueError: In case of an invalid savefile.\n     \"\"\"\n     if h5py is None:\n-        raise ImportError('`save_model` requires h5py.')\n+        raise ImportError('`load_model` requires h5py.')\n \n     if not custom_objects:\n         custom_objects = {}"
    },
    {
        "commit_id": "330ffa41dd949fdf48cc11f76fb410bf3551657c",
        "commit_message": "fix causal padding dostrings (#5943)",
        "commit_url": "https://github.com/keras-team/keras/commit/330ffa41dd949fdf48cc11f76fb410bf3551657c",
        "buggy_code": "depends solely on input[:t-1]. Useful when modeling temporal data",
        "fixed_code": "does not depend on input[t+1:]. Useful when modeling temporal data",
        "patch": "@@ -257,7 +257,7 @@ class Conv1D(_Conv):\n             any `dilation_rate` value != 1.\n         padding: One of `\"valid\"`, `\"causal\"` or `\"same\"` (case-insensitive).\n             `\"causal\"` results in causal (dilated) convolutions, e.g. output[t]\n-            depends solely on input[:t-1]. Useful when modeling temporal data\n+            does not depend on input[t+1:]. Useful when modeling temporal data\n             where the model should not violate the temporal order.\n             See [WaveNet: A Generative Model for Raw Audio, section 2.1](https://arxiv.org/abs/1609.03499).\n         dilation_rate: an integer or tuple/list of a single integer, specifying"
    },
    {
        "commit_id": "b4f7340cc9be4ce23c768c26a612df287c5bb883",
        "commit_message": "Fix the issue that when n can be mod by batch_size, the shuffle never happened (#5883)",
        "commit_url": "https://github.com/keras-team/keras/commit/b4f7340cc9be4ce23c768c26a612df287c5bb883",
        "buggy_code": "if n >= current_index + batch_size:",
        "fixed_code": "if n > current_index + batch_size:",
        "patch": "@@ -708,7 +708,7 @@ def _flow_index(self, n, batch_size=32, shuffle=False, seed=None):\n                     index_array = np.random.permutation(n)\n \n             current_index = (self.batch_index * batch_size) % n\n-            if n >= current_index + batch_size:\n+            if n > current_index + batch_size:\n                 current_batch_size = batch_size\n                 self.batch_index += 1\n             else:"
    },
    {
        "commit_id": "ec9c95fdbd60c2d86288858563c57b0007b24430",
        "commit_message": "fix a typo in the step func. of GRU (implementation=1) (#5888)",
        "commit_url": "https://github.com/keras-team/keras/commit/ec9c95fdbd60c2d86288858563c57b0007b24430",
        "buggy_code": "x_h = K.bias_add(x_r, self.bias_h)",
        "fixed_code": "x_h = K.bias_add(x_h, self.bias_h)",
        "patch": "@@ -812,7 +812,7 @@ def step(self, inputs, states):\n                 if self.use_bias:\n                     x_z = K.bias_add(x_z, self.bias_z)\n                     x_r = K.bias_add(x_r, self.bias_r)\n-                    x_h = K.bias_add(x_r, self.bias_h)\n+                    x_h = K.bias_add(x_h, self.bias_h)\n             else:\n                 raise ValueError('Unknown `implementation` mode.')\n             z = self.recurrent_activation(x_z + K.dot(h_tm1 * rec_dp_mask[0],"
    },
    {
        "commit_id": "2b3579ecfce5706e356673b573ccbee9496803d7",
        "commit_message": "Add verbose argument to predict_generator (Resolve #3793) (#5850)\n\n* Add verbose argument to predict_generator\r\n\r\n* Add verbose option to predict_generator test case",
        "commit_url": "https://github.com/keras-team/keras/commit/2b3579ecfce5706e356673b573ccbee9496803d7",
        "buggy_code": "prediction = model.predict_generator(data_generator(x_test, y_test), 1, max_q_size=2)",
        "fixed_code": "prediction = model.predict_generator(data_generator(x_test, y_test), 1, max_q_size=2, verbose=1)",
        "patch": "@@ -122,7 +122,7 @@ def data_generator(x, y, batch_size=50):\n \n     loss = model.evaluate(x_test, y_test)\n \n-    prediction = model.predict_generator(data_generator(x_test, y_test), 1, max_q_size=2)\n+    prediction = model.predict_generator(data_generator(x_test, y_test), 1, max_q_size=2, verbose=1)\n     gen_loss = model.evaluate_generator(data_generator(x_test, y_test, 50), 1, max_q_size=2)\n     pred_loss = K.eval(K.mean(losses.get(model.loss)(K.variable(y_test), K.variable(prediction))))\n "
    },
    {
        "commit_id": "f4f3567e156c6b964d17e24fa4a4073f00851463",
        "commit_message": "Fixes error in generic_utils error. (#5844)",
        "commit_url": "https://github.com/keras-team/keras/commit/f4f3567e156c6b964d17e24fa4a4073f00851463",
        "buggy_code": "':' + class_name)",
        "fixed_code": "':' + function_name)",
        "patch": "@@ -154,7 +154,7 @@ def deserialize_keras_object(identifier, module_objects=None,\n             fn = module_objects.get(function_name)\n             if fn is None:\n                 raise ValueError('Unknown ' + printable_module_name,\n-                                 ':' + class_name)\n+                                 ':' + function_name)\n         return fn\n     else:\n         raise ValueError('Could not interpret serialized ' +"
    },
    {
        "commit_id": "10399242459eb222afece5edc5645ad458ea43c7",
        "commit_message": "fix typo in some layers' `get_config()` (#5810)\n\n* fix typo\r\n\r\n* fix typo\r\n\r\n* fix typo",
        "commit_url": "https://github.com/keras-team/keras/commit/10399242459eb222afece5edc5645ad458ea43c7",
        "buggy_code": "'bias_initializer': initializers.serialize(self.kernel_initializer),",
        "fixed_code": "'bias_initializer': initializers.serialize(self.bias_initializer),",
        "patch": "@@ -219,7 +219,7 @@ def get_config(self):\n             'activation': activations.serialize(self.activation),\n             'use_bias': self.use_bias,\n             'kernel_initializer': initializers.serialize(self.kernel_initializer),\n-            'bias_initializer': initializers.serialize(self.kernel_initializer),\n+            'bias_initializer': initializers.serialize(self.bias_initializer),\n             'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n             'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n             'activity_regularizer': regularizers.serialize(self.activity_regularizer),"
    },
    {
        "commit_id": "10399242459eb222afece5edc5645ad458ea43c7",
        "commit_message": "fix typo in some layers' `get_config()` (#5810)\n\n* fix typo\r\n\r\n* fix typo\r\n\r\n* fix typo",
        "commit_url": "https://github.com/keras-team/keras/commit/10399242459eb222afece5edc5645ad458ea43c7",
        "buggy_code": "'bias_initializer': initializers.serialize(self.kernel_initializer),",
        "fixed_code": "'bias_initializer': initializers.serialize(self.bias_initializer),",
        "patch": "@@ -857,7 +857,7 @@ def get_config(self):\n             'activation': activations.serialize(self.activation),\n             'use_bias': self.use_bias,\n             'kernel_initializer': initializers.serialize(self.kernel_initializer),\n-            'bias_initializer': initializers.serialize(self.kernel_initializer),\n+            'bias_initializer': initializers.serialize(self.bias_initializer),\n             'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n             'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n             'activity_regularizer': regularizers.serialize(self.activity_regularizer),"
    },
    {
        "commit_id": "0cc52cf2511fb024ebb6045544b58fe6334fb105",
        "commit_message": "Fix typos (#5753)",
        "commit_url": "https://github.com/keras-team/keras/commit/0cc52cf2511fb024ebb6045544b58fe6334fb105",
        "buggy_code": "\"\"\"Reverse a tensor along the the specified axes",
        "fixed_code": "\"\"\"Reverse a tensor along the specified axes",
        "patch": "@@ -1002,7 +1002,7 @@ def one_hot(indices, num_classes):\n \n \n def reverse(x, axes):\n-    \"\"\"Reverse a tensor along the the specified axes\n+    \"\"\"Reverse a tensor along the specified axes\n     \"\"\"\n     if isinstance(axes, int):\n         axes = [axes]"
    },
    {
        "commit_id": "0cc52cf2511fb024ebb6045544b58fe6334fb105",
        "commit_message": "Fix typos (#5753)",
        "commit_url": "https://github.com/keras-team/keras/commit/0cc52cf2511fb024ebb6045544b58fe6334fb105",
        "buggy_code": "lass indices (integers) to",
        "fixed_code": "class indices (integers) to",
        "patch": "@@ -1594,7 +1594,7 @@ def train_on_batch(self, x, y,\n                 In this case you should make sure to specify\n                 sample_weight_mode=\"temporal\" in compile().\n             class_weight: optional dictionary mapping\n-                lass indices (integers) to\n+                class indices (integers) to\n                 a weight (float) to apply to the model's loss for the samples\n                 from this class during training.\n                 This can be useful to tell the model to \"pay more attention\" to"
    },
    {
        "commit_id": "0cc52cf2511fb024ebb6045544b58fe6334fb105",
        "commit_message": "Fix typos (#5753)",
        "commit_url": "https://github.com/keras-team/keras/commit/0cc52cf2511fb024ebb6045544b58fe6334fb105",
        "buggy_code": "are equal to `mask_value`, then the timestep will masked (skipped)",
        "fixed_code": "are equal to `mask_value`, then the timestep will be masked (skipped)",
        "patch": "@@ -27,7 +27,7 @@ class Masking(Layer):\n \n     For each timestep in the input tensor (dimension #1 in the tensor),\n     if all values in the input tensor at that timestep\n-    are equal to `mask_value`, then the timestep will masked (skipped)\n+    are equal to `mask_value`, then the timestep will be masked (skipped)\n     in all downstream layers (as long as they support masking).\n \n     If any downstream layer does not support masking yet receives such"
    },
    {
        "commit_id": "c469f80f81e0c2e366fb549a418e28f183ea8bba",
        "commit_message": "Merge pull request #1 from israelg99/patch-1\n\nFix multiple spaces after operator",
        "commit_url": "https://github.com/keras-team/keras/commit/c469f80f81e0c2e366fb549a418e28f183ea8bba",
        "buggy_code": "states =  list(states)",
        "fixed_code": "states = list(states)",
        "patch": "@@ -334,7 +334,7 @@ def call(self, inputs, mask=None, initial_state=None, training=None):\n             if not isinstance(states, (list, tuple)):\n                 states = [states]\n             else:\n-                states =  list(states)\n+                states = list(states)\n             return [output] + states\n         else:\n             return output"
    },
    {
        "commit_id": "44b25b80b2fe0928378efd115c9a290ae1623445",
        "commit_message": "Fix multiple spaces after operator",
        "commit_url": "https://github.com/keras-team/keras/commit/44b25b80b2fe0928378efd115c9a290ae1623445",
        "buggy_code": "states =  list(states)",
        "fixed_code": "states = list(states)",
        "patch": "@@ -334,7 +334,7 @@ def call(self, inputs, mask=None, initial_state=None, training=None):\n             if not isinstance(states, (list, tuple)):\n                 states = [states]\n             else:\n-                states =  list(states)\n+                states = list(states)\n             return [output] + states\n         else:\n             return output"
    },
    {
        "commit_id": "28c208deab339a12c4133f9859145afb5b37f151",
        "commit_message": "typo fix (#5727)",
        "commit_url": "https://github.com/keras-team/keras/commit/28c208deab339a12c4133f9859145afb5b37f151",
        "buggy_code": "You can specify the initial state of RNN layers by calling theme with",
        "fixed_code": "You can specify the initial state of RNN layers by calling them with",
        "patch": "@@ -166,7 +166,7 @@ class Recurrent(Layer):\n         a specific layer, or on your entire model.\n \n     # Note on specifying initial states in RNNs\n-        You can specify the initial state of RNN layers by calling theme with\n+        You can specify the initial state of RNN layers by calling them with\n         the keyword argument `initial_state`. The value of `initial_state`\n         should be a tensor or list of tensors representing the initial state\n         of the RNN layer."
    },
    {
        "commit_id": "21bf90cbf561250b256d7b30c7545da3bf092552",
        "commit_message": "Fix bug in convlstm.",
        "commit_url": "https://github.com/keras-team/keras/commit/21bf90cbf561250b256d7b30c7545da3bf092552",
        "buggy_code": "self.states = [None, None, None, None]",
        "fixed_code": "self.states = [None, None]",
        "patch": "@@ -335,7 +335,7 @@ def build(self, input_shape):\n             self.reset_states()\n         else:\n             # initial states: 2 all-zero tensor of shape (filters)\n-            self.states = [None, None, None, None]\n+            self.states = [None, None]\n \n         if self.data_format == 'channels_first':\n             channel_axis = 1"
    },
    {
        "commit_id": "d72514d6cca9b09842ab31536c16a01e5cd51f6f",
        "commit_message": "Fix activity_regularizer in convlstm.",
        "commit_url": "https://github.com/keras-team/keras/commit/d72514d6cca9b09842ab31536c16a01e5cd51f6f",
        "buggy_code": "'Received input shape:', str(input_shape))",
        "fixed_code": "'; Received input shape:', str(input_shape))",
        "patch": "@@ -702,7 +702,7 @@ def build(self, input_shape):\n         if len(input_shape) != 4:\n             raise ValueError('Inputs should have rank ' +\n                              str(4) +\n-                             'Received input shape:', str(input_shape))\n+                             '; Received input shape:', str(input_shape))\n         if self.data_format == 'channels_first':\n             channel_axis = 1\n         else:"
    },
    {
        "commit_id": "77ea18e8f795102da6cee35a716b29c6929574a2",
        "commit_message": "Fix typo\n\n* spelling mistake trining -> training\r\n\r\n* Update reuters.py\r\n\r\n* Update imdb.py",
        "commit_url": "https://github.com/keras-team/keras/commit/77ea18e8f795102da6cee35a716b29c6929574a2",
        "buggy_code": "Words that were not seen in the trining set but are in the test set",
        "fixed_code": "Words that were not seen in the training set but are in the test set",
        "patch": "@@ -35,7 +35,7 @@ def load_data(path='imdb.npz', num_words=None, skip_top=0,\n     Note that the 'out of vocabulary' character is only used for\n     words that were present in the training set but are not included\n     because they're not making the `num_words` cut here.\n-    Words that were not seen in the trining set but are in the test set\n+    Words that were not seen in the training set but are in the test set\n     have simply been skipped.\n     \"\"\"\n     path = get_file(path,"
    },
    {
        "commit_id": "77ea18e8f795102da6cee35a716b29c6929574a2",
        "commit_message": "Fix typo\n\n* spelling mistake trining -> training\r\n\r\n* Update reuters.py\r\n\r\n* Update imdb.py",
        "commit_url": "https://github.com/keras-team/keras/commit/77ea18e8f795102da6cee35a716b29c6929574a2",
        "buggy_code": "Words that were not seen in the trining set but are in the test set",
        "fixed_code": "Words that were not seen in the training set but are in the test set",
        "patch": "@@ -33,7 +33,7 @@ def load_data(path='reuters.npz', num_words=None, skip_top=0,\n     Note that the 'out of vocabulary' character is only used for\n     words that were present in the training set but are not included\n     because they're not making the `num_words` cut here.\n-    Words that were not seen in the trining set but are in the test set\n+    Words that were not seen in the training set but are in the test set\n     have simply been skipped.\n     \"\"\"\n     path = get_file(path, origin='https://s3.amazonaws.com/text-datasets/reuters.npz')"
    },
    {
        "commit_id": "8d34c7ed3c632a31f1d491d733eb9a7bfa11043f",
        "commit_message": "Fix typo.",
        "commit_url": "https://github.com/keras-team/keras/commit/8d34c7ed3c632a31f1d491d733eb9a7bfa11043f",
        "buggy_code": "return Sum(**kwargs)(inputs)",
        "fixed_code": "return Add(**kwargs)(inputs)",
        "patch": "@@ -323,7 +323,7 @@ def add(inputs, **kwargs):\n     # Returns\n         A tensor, the sum of the inputs.\n     \"\"\"\n-    return Sum(**kwargs)(inputs)\n+    return Add(**kwargs)(inputs)\n \n \n def multiply(inputs, **kwargs):"
    },
    {
        "commit_id": "1193427fd39355431bc0b1f36bfbd9e3c2360385",
        "commit_message": "Bug fix.",
        "commit_url": "https://github.com/keras-team/keras/commit/1193427fd39355431bc0b1f36bfbd9e3c2360385",
        "buggy_code": "from . import __version__ as keras_version",
        "fixed_code": "from .. import __version__ as keras_version",
        "patch": "@@ -2682,7 +2682,7 @@ def _collect_input_shape(input_tensors):\n \n \n def save_weights_to_hdf5_group(f, layers):\n-    from . import __version__ as keras_version\n+    from .. import __version__ as keras_version\n \n     f.attrs['layer_names'] = [layer.name.encode('utf8') for layer in layers]\n     f.attrs['backend'] = K.backend().encode('utf8')"
    },
    {
        "commit_id": "7e7d2ed1f9d87e5ab46a5c1e7254a000c7d0b9a3",
        "commit_message": "Fix deprecated scoring function (#5452)\n\n`'log_loss'` is deprecated; replaced by `'neg_log_loss'`",
        "commit_url": "https://github.com/keras-team/keras/commit/7e7d2ed1f9d87e5ab46a5c1e7254a000c7d0b9a3",
        "buggy_code": "scoring='log_loss',",
        "fixed_code": "scoring='neg_log_loss',",
        "patch": "@@ -88,7 +88,7 @@ def make_model(dense_layer_sizes, filterss, num_conv, num_pool):\n                                      'filterss': [8],\n                                      'num_conv': [3],\n                                      'num_pool': [2]},\n-                         scoring='log_loss',\n+                         scoring='neg_log_loss',\n                          n_jobs=1)\n validator.fit(X_train, y_train)\n "
    },
    {
        "commit_id": "0564b940ec8f5008018c12c24a1431e91407d8c0",
        "commit_message": "Fix up initializers, constraints.",
        "commit_url": "https://github.com/keras-team/keras/commit/0564b940ec8f5008018c12c24a1431e91407d8c0",
        "buggy_code": "custom_objects=None,",
        "fixed_code": "custom_objects=custom_objects,",
        "patch": "@@ -446,7 +446,7 @@ def serialize(initializer):\n def deserialize(config, custom_objects=None):\n     return deserialize_keras_object(config,\n                                     module_objects=globals(),\n-                                    custom_objects=None,\n+                                    custom_objects=custom_objects,\n                                     printable_module_name='initializer')\n \n "
    },
    {
        "commit_id": "10c76237abf9913dfcba9a0ac73e8db50ea21a44",
        "commit_message": "Bug fixes",
        "commit_url": "https://github.com/keras-team/keras/commit/10c76237abf9913dfcba9a0ac73e8db50ea21a44",
        "buggy_code": "':', class_name)",
        "fixed_code": "':' + class_name)",
        "patch": "@@ -147,7 +147,7 @@ def deserialize_keras_object(identifier, module_objects=None,\n             fn = module_objects.get(function_name)\n             if fn is None:\n                 raise ValueError('Unknown ' + printable_module_name,\n-                                 ':', class_name)\n+                                 ':' + class_name)\n         return fn\n     else:\n         raise ValueError('Could not interpret serialized ' +"
    },
    {
        "commit_id": "d663fda862df1c831e7f93f1e3feb2e189a1b9ef",
        "commit_message": "Fix up layers unit tests with TF.",
        "commit_url": "https://github.com/keras-team/keras/commit/d663fda862df1c831e7f93f1e3feb2e189a1b9ef",
        "buggy_code": "printable_module_name='regularizer')",
        "fixed_code": "printable_module_name='constraint')",
        "patch": "@@ -154,7 +154,7 @@ def serialize(constraint):\n def deserialize(config):\n     return deserialize_keras_object(config,\n                                     module_objects=globals(),\n-                                    printable_module_name='regularizer')\n+                                    printable_module_name='constraint')\n \n \n def get(identifier):"
    },
    {
        "commit_id": "2562172adcd15e60763dfd601d8f0a5697a2bbdd",
        "commit_message": "Fix shuffling of output_shape in Theano conv2d_transpose. (#5382)",
        "commit_url": "https://github.com/keras-team/keras/commit/2562172adcd15e60763dfd601d8f0a5697a2bbdd",
        "buggy_code": "if data_format == 'channels_first':",
        "fixed_code": "if data_format == 'channels_last':",
        "patch": "@@ -1640,7 +1640,7 @@ def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n     if data_format not in {'channels_first', 'channels_last'}:\n         raise ValueError('Unknown data_format ' + data_format)\n \n-    if data_format == 'channels_first':\n+    if data_format == 'channels_last':\n         output_shape = (output_shape[0],\n                         output_shape[3],\n                         output_shape[1],"
    },
    {
        "commit_id": "97f327317f5f0a3b85e00c7b461233f5101526ee",
        "commit_message": "fix merge conflicts",
        "commit_url": "https://github.com/keras-team/keras/commit/97f327317f5f0a3b85e00c7b461233f5101526ee",
        "buggy_code": "def __init__(self, target, width=30, verbose=1, interval=0.01):",
        "fixed_code": "def __init__(self, target, width=30, verbose=1, interval=0.05):",
        "patch": "@@ -197,7 +197,7 @@ class Progbar(object):\n         interval: Minimum visual progress update interval (in seconds).\n     \"\"\"\n \n-    def __init__(self, target, width=30, verbose=1, interval=0.01):\n+    def __init__(self, target, width=30, verbose=1, interval=0.05):\n         self.width = width\n         self.target = target\n         self.sum_values = {}"
    },
    {
        "commit_id": "97f327317f5f0a3b85e00c7b461233f5101526ee",
        "commit_message": "fix merge conflicts",
        "commit_url": "https://github.com/keras-team/keras/commit/97f327317f5f0a3b85e00c7b461233f5101526ee",
        "buggy_code": "raise ImportError('The use of `save_array` requires '",
        "fixed_code": "raise ImportError('The use of `load_array` requires '",
        "patch": "@@ -110,7 +110,7 @@ def save_array(array, name):\n \n def load_array(name):\n     if tables is None:\n-        raise ImportError('The use of `save_array` requires '\n+        raise ImportError('The use of `load_array` requires '\n                           'the tables module.')\n     f = tables.open_file(name)\n     array = f.root.data"
    },
    {
        "commit_id": "9777b51ee2f898c176b6e7d2c9412eb7556bb60b",
        "commit_message": "fix typo for load array (#5315)",
        "commit_url": "https://github.com/keras-team/keras/commit/9777b51ee2f898c176b6e7d2c9412eb7556bb60b",
        "buggy_code": "raise ImportError('The use of `save_array` requires '",
        "fixed_code": "raise ImportError('The use of `load_array` requires '",
        "patch": "@@ -110,7 +110,7 @@ def save_array(array, name):\n \n def load_array(name):\n     if tables is None:\n-        raise ImportError('The use of `save_array` requires '\n+        raise ImportError('The use of `load_array` requires '\n                           'the tables module.')\n     f = tables.open_file(name)\n     array = f.root.data"
    },
    {
        "commit_id": "3ad7463b60e269986697ae692fae93cf6056e56f",
        "commit_message": "Correction of an error phrase for a better feedback. (#5215)",
        "commit_url": "https://github.com/keras-team/keras/commit/3ad7463b60e269986697ae692fae93cf6056e56f",
        "buggy_code": "str(data.keys()))",
        "fixed_code": "str(names))",
        "patch": "@@ -49,7 +49,7 @@ def standardize_input_data(data, names, shapes=None,\n             if name not in data:\n                 raise ValueError('No data provided for \"' +\n                                  name + '\". Need data for each key in: ' +\n-                                 str(data.keys()))\n+                                 str(names))\n             arrays.append(data[name])\n     elif isinstance(data, list):\n         if len(data) != len(names):"
    },
    {
        "commit_id": "1585b8dd4e877e022e3c5f5dbecec51666b2218c",
        "commit_message": "Fix documentation of K.rnn unroll parameter (#5192)",
        "commit_url": "https://github.com/keras-team/keras/commit/1585b8dd4e877e022e3c5f5dbecec51666b2218c",
        "buggy_code": "unroll: whether to unroll the RNN or to use a symbolic loop (`scan`).",
        "fixed_code": "unroll: whether to unroll the RNN or to use a symbolic loop (`while_loop` or `scan` depending on backend).",
        "patch": "@@ -1008,7 +1008,7 @@ def rnn(step_function, inputs, initial_states,\n         mask: binary tensor with shape (samples, time),\n             with a zero for every element that is masked.\n         constants: a list of constant values passed at each step.\n-        unroll: whether to unroll the RNN or to use a symbolic loop (`scan`).\n+        unroll: whether to unroll the RNN or to use a symbolic loop (`while_loop` or `scan` depending on backend).\n         input_length: must be specified if using `unroll`.\n \n     # Returns"
    },
    {
        "commit_id": "200b19328275f992f21ae101d74a5e4798a712c9",
        "commit_message": "fix merge conflicts",
        "commit_url": "https://github.com/keras-team/keras/commit/200b19328275f992f21ae101d74a5e4798a712c9",
        "buggy_code": "return np.mean(labels == (predictions.ravel() > 0.5))",
        "fixed_code": "return labels[predictions.ravel() < 0.5].mean()",
        "patch": "@@ -75,7 +75,7 @@ def create_base_network(input_dim):\n def compute_accuracy(predictions, labels):\n     '''Compute classification accuracy with a fixed threshold on distances.\n     '''\n-    return np.mean(labels == (predictions.ravel() > 0.5))\n+    return labels[predictions.ravel() < 0.5].mean()\n \n \n # the data, shuffled and split between train and test sets"
    },
    {
        "commit_id": "9736056a60f08988d398f6592b28c97ffbe4e26f",
        "commit_message": "Fix issue in mnist siamese graph example.",
        "commit_url": "https://github.com/keras-team/keras/commit/9736056a60f08988d398f6592b28c97ffbe4e26f",
        "buggy_code": "return np.mean(labels == (predictions.ravel() > 0.5))",
        "fixed_code": "return labels[predictions.ravel() < 0.5].mean()",
        "patch": "@@ -75,7 +75,7 @@ def create_base_network(input_dim):\n def compute_accuracy(predictions, labels):\n     '''Compute classification accuracy with a fixed threshold on distances.\n     '''\n-    return np.mean(labels == (predictions.ravel() > 0.5))\n+    return labels[predictions.ravel() < 0.5].mean()\n \n \n # the data, shuffled and split between train and test sets"
    },
    {
        "commit_id": "72f1ce4ed4396a308f831c717d8c2856a7a4e86b",
        "commit_message": "Fix Sckit-learn API get_parameters bug (#5121)\n\nAdd **params to BaseWrapper.get_params(self,_) to fix TypeError",
        "commit_url": "https://github.com/keras-team/keras/commit/72f1ce4ed4396a308f831c717d8c2856a7a4e86b",
        "buggy_code": "def get_params(self, _):",
        "fixed_code": "def get_params(self, **params):",
        "patch": "@@ -84,7 +84,7 @@ def check_params(self, params):\n             if params_name not in legal_params:\n                 raise ValueError('{} is not a legal parameter'.format(params_name))\n \n-    def get_params(self, _):\n+    def get_params(self, **params):\n         \"\"\"Gets parameters for this estimator.\n \n         # Returns"
    },
    {
        "commit_id": "c57d1a32194983f28cb944722e6f7bc6de82cb10",
        "commit_message": "Update audio_conv_utils.py (#5111)\n\nCorrected a typo in line 65. This was giving `TypeError: mel() got an unexpected keyword argument 'hop_lengthgth'` error. Please verify and merge.\r\nThanks.",
        "commit_url": "https://github.com/keras-team/keras/commit/c57d1a32194983f28cb944722e6f7bc6de82cb10",
        "buggy_code": "x = logam(melgram(y=src, sr=sr, hop_lengthgth=hop_length,",
        "fixed_code": "x = logam(melgram(y=src, sr=sr, hop_length=hop_length,",
        "patch": "@@ -62,7 +62,7 @@ def preprocess_input(audio_path, dim_ordering='default'):\n \n     logam = librosa.logamplitude\n     melgram = librosa.feature.melspectrogram\n-    x = logam(melgram(y=src, sr=sr, hop_lengthgth=hop_length,\n+    x = logam(melgram(y=src, sr=sr, hop_length=hop_length,\n                       n_fft=n_fft, n_mels=n_mels) ** 2,\n               ref_power=1.0)\n "
    },
    {
        "commit_id": "445aecdeb77876909fc1e6c3b34e0361c5db9e72",
        "commit_message": "change rounding mode in theano backend to match tensorflow backend (#5089)\n\n* changed rounding mode in theano to match tensorflow and updated docs\r\n\r\n* pep8 fix\r\n\r\n* Style fix in docstring.",
        "commit_url": "https://github.com/keras-team/keras/commit/445aecdeb77876909fc1e6c3b34e0361c5db9e72",
        "buggy_code": "return T.round(x)",
        "fixed_code": "return T.round(x, mode='half_to_even')",
        "patch": "@@ -389,7 +389,7 @@ def log(x):\n \n \n def round(x):\n-    return T.round(x)\n+    return T.round(x, mode='half_to_even')\n \n \n def sign(x):"
    },
    {
        "commit_id": "fff781cf155091c7d168ef061013876ae8034af0",
        "commit_message": "fix merge conflict",
        "commit_url": "https://github.com/keras-team/keras/commit/fff781cf155091c7d168ef061013876ae8034af0",
        "buggy_code": "split_at = len(X) - len(X) / 10",
        "fixed_code": "split_at = len(X) - len(X) // 10",
        "patch": "@@ -120,7 +120,7 @@ class colors:\n y = y[indices]\n \n # Explicitly set apart 10% for validation data that we never train over\n-split_at = len(X) - len(X) / 10\n+split_at = len(X) - len(X) // 10\n (X_train, X_val) = (slice_X(X, 0, split_at), slice_X(X, split_at))\n (y_train, y_val) = (y[:split_at], y[split_at:])\n "
    },
    {
        "commit_id": "8f8d97e6150cf318a505fb7343ecff4ede76ba4f",
        "commit_message": "Small fix to array_to_img function (#5070)\n\nSmall fix to array_to_img function, it won't change the value of x when set scale=True now.",
        "commit_url": "https://github.com/keras-team/keras/commit/8f8d97e6150cf318a505fb7343ecff4ede76ba4f",
        "buggy_code": "x += max(-np.min(x), 0)",
        "fixed_code": "x = x + max(-np.min(x), 0)",
        "patch": "@@ -226,7 +226,7 @@ def array_to_img(x, dim_ordering='default', scale=True):\n     if dim_ordering == 'th':\n         x = x.transpose(1, 2, 0)\n     if scale:\n-        x += max(-np.min(x), 0)\n+        x = x + max(-np.min(x), 0)\n         x_max = np.max(x)\n         if x_max != 0:\n             x /= x_max"
    },
    {
        "commit_id": "82ca6d418588ccd61d663ec8029937290b62d583",
        "commit_message": "Fix a warning on Python3 (#5042)\n\n* Fix a warning on python3\r\n\r\nIn Python3, 50000 / 10 = 5000.0. This will result in a warning from numpy:\r\nVisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future.\r\n\r\n* Use // instead",
        "commit_url": "https://github.com/keras-team/keras/commit/82ca6d418588ccd61d663ec8029937290b62d583",
        "buggy_code": "split_at = len(X) - len(X) / 10",
        "fixed_code": "split_at = len(X) - len(X) // 10",
        "patch": "@@ -120,7 +120,7 @@ class colors:\n y = y[indices]\n \n # Explicitly set apart 10% for validation data that we never train over\n-split_at = len(X) - len(X) / 10\n+split_at = len(X) - len(X) // 10\n (X_train, X_val) = (slice_X(X, 0, split_at), slice_X(X, split_at))\n (y_train, y_val) = (y[:split_at], y[split_at:])\n "
    },
    {
        "commit_id": "c6bf7558b2121c3f2f280a0d15ee4354994e0c86",
        "commit_message": "Potential deconv model saving fix? (#4999)\n\nAdding this cast to a tuple seems to fix this issue.",
        "commit_url": "https://github.com/keras-team/keras/commit/c6bf7558b2121c3f2f280a0d15ee4354994e0c86",
        "buggy_code": "shape = (tf.shape(x)[0], ) + shape[1:]",
        "fixed_code": "shape = (tf.shape(x)[0], ) + tuple(shape[1:])",
        "patch": "@@ -2468,7 +2468,7 @@ def _preprocess_deconv_output_shape(x, shape, dim_ordering):\n         shape = (shape[0], shape[2], shape[3], shape[1])\n \n     if shape[0] is None:\n-        shape = (tf.shape(x)[0], ) + shape[1:]\n+        shape = (tf.shape(x)[0], ) + tuple(shape[1:])\n     return shape\n \n "
    },
    {
        "commit_id": "6fb7ba721cf215e88176c665d2d7f90027f4e26f",
        "commit_message": "Fix issue with clip max_value.",
        "commit_url": "https://github.com/keras-team/keras/commit/6fb7ba721cf215e88176c665d2d7f90027f4e26f",
        "buggy_code": "if max_value < min_value:",
        "fixed_code": "if max_value is not None and max_value < min_value:",
        "patch": "@@ -1248,7 +1248,7 @@ def clip(x, min_value, max_value):\n     # Returns\n         A tensor.\n     \"\"\"\n-    if max_value < min_value:\n+    if max_value is not None and max_value < min_value:\n         max_value = min_value\n     min_value = _to_tensor(min_value, x.dtype.base_dtype)\n     max_value = _to_tensor(max_value, x.dtype.base_dtype)"
    },
    {
        "commit_id": "6fb7ba721cf215e88176c665d2d7f90027f4e26f",
        "commit_message": "Fix issue with clip max_value.",
        "commit_url": "https://github.com/keras-team/keras/commit/6fb7ba721cf215e88176c665d2d7f90027f4e26f",
        "buggy_code": "if max_value < min_value:",
        "fixed_code": "if max_value is not None and max_value < min_value:",
        "patch": "@@ -401,7 +401,7 @@ def pow(x, a):\n \n \n def clip(x, min_value, max_value):\n-    if max_value < min_value:\n+    if max_value is not None and max_value < min_value:\n         max_value = min_value\n     return T.clip(x, min_value, max_value)\n "
    },
    {
        "commit_id": "1f5455e29efa4579eebbf894e97ee53cd1257529",
        "commit_message": "Fix a number of PEP8 errors.",
        "commit_url": "https://github.com/keras-team/keras/commit/1f5455e29efa4579eebbf894e97ee53cd1257529",
        "buggy_code": "output_shape[i+1] = target_dim",
        "fixed_code": "output_shape[i + 1] = target_dim",
        "patch": "@@ -428,7 +428,7 @@ def get_output_shape_for(self, input_shape):\n         output_shape = copy.copy(input_shape)\n         for i, dim in enumerate(self.dims):\n             target_dim = input_shape[dim]\n-            output_shape[i+1] = target_dim\n+            output_shape[i + 1] = target_dim\n         return tuple(output_shape)\n \n     def call(self, x, mask=None):"
    },
    {
        "commit_id": "1f5455e29efa4579eebbf894e97ee53cd1257529",
        "commit_message": "Fix a number of PEP8 errors.",
        "commit_url": "https://github.com/keras-team/keras/commit/1f5455e29efa4579eebbf894e97ee53cd1257529",
        "buggy_code": "bar += ('=' * (prog_width-1))",
        "fixed_code": "bar += ('=' * (prog_width - 1))",
        "patch": "@@ -114,7 +114,7 @@ def update(self, current, values=[], force=False):\n             prog = float(current) / self.target\n             prog_width = int(self.width * prog)\n             if prog_width > 0:\n-                bar += ('=' * (prog_width-1))\n+                bar += ('=' * (prog_width - 1))\n                 if current < self.target:\n                     bar += '>'\n                 else:"
    },
    {
        "commit_id": "1f5455e29efa4579eebbf894e97ee53cd1257529",
        "commit_message": "Fix a number of PEP8 errors.",
        "commit_url": "https://github.com/keras-team/keras/commit/1f5455e29efa4579eebbf894e97ee53cd1257529",
        "buggy_code": "idx = slice(key.start+self.start, key.stop + self.start)",
        "fixed_code": "idx = slice(key.start + self.start, key.stop + self.start)",
        "patch": "@@ -54,7 +54,7 @@ def __len__(self):\n     def __getitem__(self, key):\n         if isinstance(key, slice):\n             if key.stop + self.start <= self.end:\n-                idx = slice(key.start+self.start, key.stop + self.start)\n+                idx = slice(key.start + self.start, key.stop + self.start)\n             else:\n                 raise IndexError\n         elif isinstance(key, int):"
    },
    {
        "commit_id": "6b05aebc0ce0717297d65305801e27f62a38cff5",
        "commit_message": "Reference Style Fix (#4972)",
        "commit_url": "https://github.com/keras-team/keras/commit/6b05aebc0ce0717297d65305801e27f62a38cff5",
        "buggy_code": "- [A Hierarchical Neural Autoencoder for Paragraphs and Documents](https://web.stanford.edu/~jurafsky/pubs/P15-1107.pdf)",
        "fixed_code": "- [A Hierarchical Neural Autoencoder for Paragraphs and Documents](https://arxiv.org/abs/1506.01057)",
        "patch": "@@ -8,7 +8,7 @@\n sentence-level structure of the context.\n \n # References\n-    - [A Hierarchical Neural Autoencoder for Paragraphs and Documents](https://web.stanford.edu/~jurafsky/pubs/P15-1107.pdf)\n+    - [A Hierarchical Neural Autoencoder for Paragraphs and Documents](https://arxiv.org/abs/1506.01057)\n         Encodes paragraphs and documents with HRNN.\n         Results have shown that HRNN outperforms standard\n         RNNs and may play some role in more sophisticated generation tasks like"
    },
    {
        "commit_id": "6b05aebc0ce0717297d65305801e27f62a38cff5",
        "commit_message": "Reference Style Fix (#4972)",
        "commit_url": "https://github.com/keras-team/keras/commit/6b05aebc0ce0717297d65305801e27f62a38cff5",
        "buggy_code": "[1] [A guide to convolution arithmetic for deep learning](https://arxiv.org/abs/1603.07285 \"arXiv:1603.07285v1 [stat.ML]\")",
        "fixed_code": "[1] [A guide to convolution arithmetic for deep learning](https://arxiv.org/abs/1603.07285v1)",
        "patch": "@@ -583,7 +583,7 @@ class Deconvolution2D(Convolution2D):\n         `rows` and `cols` values might have changed due to padding.\n \n     # References\n-        [1] [A guide to convolution arithmetic for deep learning](https://arxiv.org/abs/1603.07285 \"arXiv:1603.07285v1 [stat.ML]\")\n+        [1] [A guide to convolution arithmetic for deep learning](https://arxiv.org/abs/1603.07285v1)\n         [2] [Transposed convolution arithmetic](http://deeplearning.net/software/theano_versions/dev/tutorial/conv_arithmetic.html#transposed-convolution-arithmetic)\n         [3] [Deconvolutional Networks](http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf)\n     '''"
    },
    {
        "commit_id": "6b05aebc0ce0717297d65305801e27f62a38cff5",
        "commit_message": "Reference Style Fix (#4972)",
        "commit_url": "https://github.com/keras-team/keras/commit/6b05aebc0ce0717297d65305801e27f62a38cff5",
        "buggy_code": "Precipitation Nowcasting](http://arxiv.org/pdf/1506.04214v1.pdf)",
        "fixed_code": "Precipitation Nowcasting](http://arxiv.org/abs/1506.04214v1)",
        "patch": "@@ -243,7 +243,7 @@ class ConvLSTM2D(ConvRecurrent2D):\n \n     # References\n         - [Convolutional LSTM Network: A Machine Learning Approach for\n-        Precipitation Nowcasting](http://arxiv.org/pdf/1506.04214v1.pdf)\n+        Precipitation Nowcasting](http://arxiv.org/abs/1506.04214v1)\n         The current implementation does not include the feedback loop on the\n         cells output\n     '''"
    },
    {
        "commit_id": "6b05aebc0ce0717297d65305801e27f62a38cff5",
        "commit_message": "Reference Style Fix (#4972)",
        "commit_url": "https://github.com/keras-team/keras/commit/6b05aebc0ce0717297d65305801e27f62a38cff5",
        "buggy_code": "- [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](http://jmlr.org/proceedings/papers/v37/ioffe15.pdf)",
        "fixed_code": "- [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167)",
        "patch": "@@ -59,7 +59,7 @@ class BatchNormalization(Layer):\n         Same shape as input.\n \n     # References\n-        - [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](http://jmlr.org/proceedings/papers/v37/ioffe15.pdf)\n+        - [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167)\n     '''\n     def __init__(self, epsilon=1e-3, mode=0, axis=-1, momentum=0.99,\n                  weights=None, beta_init='zero', gamma_init='one',"
    },
    {
        "commit_id": "f0369909d0c5cc5c9cccbcf98b09c16fadea5457",
        "commit_message": "Style Fix (#4923)\n\n* Style Fix\r\n\r\n* Style Fix",
        "commit_url": "https://github.com/keras-team/keras/commit/f0369909d0c5cc5c9cccbcf98b09c16fadea5457",
        "buggy_code": "if type(v) == str:",
        "fixed_code": "if isinstance(v, str):",
        "patch": "@@ -312,7 +312,7 @@ def get_function_signature(function, method=True):\n     for a in args:\n         st += str(a) + ', '\n     for a, v in kwargs:\n-        if type(v) == str:\n+        if isinstance(v, str):\n             v = '\\'' + v + '\\''\n         st += str(a) + '=' + str(v) + ', '\n     if kwargs or args:"
    },
    {
        "commit_id": "f0369909d0c5cc5c9cccbcf98b09c16fadea5457",
        "commit_message": "Style Fix (#4923)\n\n* Style Fix\r\n\r\n* Style Fix",
        "commit_url": "https://github.com/keras-team/keras/commit/f0369909d0c5cc5c9cccbcf98b09c16fadea5457",
        "buggy_code": "if type(grads) in {list, tuple}:",
        "fixed_code": "if isinstance(grads, (list, tuple)):",
        "patch": "@@ -140,7 +140,7 @@ def continuity_loss(x):\n grads = K.gradients(loss, dream)\n \n outputs = [loss]\n-if type(grads) in {list, tuple}:\n+if isinstance(grads, (list, tuple)):\n     outputs += grads\n else:\n     outputs.append(grads)"
    },
    {
        "commit_id": "f0369909d0c5cc5c9cccbcf98b09c16fadea5457",
        "commit_message": "Style Fix (#4923)\n\n* Style Fix\r\n\r\n* Style Fix",
        "commit_url": "https://github.com/keras-team/keras/commit/f0369909d0c5cc5c9cccbcf98b09c16fadea5457",
        "buggy_code": "if type(loss_grads) in {list, tuple}:",
        "fixed_code": "if isinstance(loss_grads, (list, tuple)):",
        "patch": "@@ -301,7 +301,7 @@ def total_variation_loss(x):\n \r\n # Evaluator class for computing efficiency\r\n outputs = [loss]\r\n-if type(loss_grads) in {list, tuple}:\r\n+if isinstance(loss_grads, (list, tuple)):\r\n     outputs += loss_grads\r\n else:\r\n     outputs.append(loss_grads)\r"
    },
    {
        "commit_id": "f0369909d0c5cc5c9cccbcf98b09c16fadea5457",
        "commit_message": "Style Fix (#4923)\n\n* Style Fix\r\n\r\n* Style Fix",
        "commit_url": "https://github.com/keras-team/keras/commit/f0369909d0c5cc5c9cccbcf98b09c16fadea5457",
        "buggy_code": "if type(grads) in {list, tuple}:",
        "fixed_code": "if isinstance(grads, (list, tuple)):",
        "patch": "@@ -208,7 +208,7 @@ def total_variation_loss(x):\n grads = K.gradients(loss, combination_image)\n \n outputs = [loss]\n-if type(grads) in {list, tuple}:\n+if isinstance(grads, (list, tuple)):\n     outputs += grads\n else:\n     outputs.append(grads)"
    },
    {
        "commit_id": "f0369909d0c5cc5c9cccbcf98b09c16fadea5457",
        "commit_message": "Style Fix (#4923)\n\n* Style Fix\r\n\r\n* Style Fix",
        "commit_url": "https://github.com/keras-team/keras/commit/f0369909d0c5cc5c9cccbcf98b09c16fadea5457",
        "buggy_code": "if type(layer) in (Model, Sequential):",
        "fixed_code": "if isinstance(layer, (Model, Sequential)):",
        "patch": "@@ -126,7 +126,7 @@ def count_total_params(layers, layer_set=None):\n         if layer in layer_set:\n             continue\n         layer_set.add(layer)\n-        if type(layer) in (Model, Sequential):\n+        if isinstance(layer, (Model, Sequential)):\n             t, nt = count_total_params(layer.layers, layer_set)\n             trainable_count += t\n             non_trainable_count += nt"
    },
    {
        "commit_id": "44bf298ec3236f4a7281be04716a58163469b4de",
        "commit_message": "docs: fix typo inputs_shape -> input_shape (#4901)",
        "commit_url": "https://github.com/keras-team/keras/commit/44bf298ec3236f4a7281be04716a58163469b4de",
        "buggy_code": "inputs_shape: optional shape tuple, only to be specified",
        "fixed_code": "input_shape: optional shape tuple, only to be specified",
        "patch": "@@ -83,7 +83,7 @@ def InceptionV3(include_top=True, weights='imagenet',\n             or \"imagenet\" (pre-training on ImageNet).\n         input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n             to use as image input for the model.\n-        inputs_shape: optional shape tuple, only to be specified\n+        input_shape: optional shape tuple, only to be specified\n             if `include_top` is False (otherwise the input shape\n             has to be `(299, 299, 3)` (with `tf` dim ordering)\n             or `(3, 299, 299)` (with `th` dim ordering)."
    },
    {
        "commit_id": "44bf298ec3236f4a7281be04716a58163469b4de",
        "commit_message": "docs: fix typo inputs_shape -> input_shape (#4901)",
        "commit_url": "https://github.com/keras-team/keras/commit/44bf298ec3236f4a7281be04716a58163469b4de",
        "buggy_code": "inputs_shape: optional shape tuple, only to be specified",
        "fixed_code": "input_shape: optional shape tuple, only to be specified",
        "patch": "@@ -129,7 +129,7 @@ def ResNet50(include_top=True, weights='imagenet',\n             or \"imagenet\" (pre-training on ImageNet).\n         input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n             to use as image input for the model.\n-        inputs_shape: optional shape tuple, only to be specified\n+        input_shape: optional shape tuple, only to be specified\n             if `include_top` is False (otherwise the input shape\n             has to be `(224, 224, 3)` (with `tf` dim ordering)\n             or `(3, 224, 244)` (with `th` dim ordering)."
    },
    {
        "commit_id": "44bf298ec3236f4a7281be04716a58163469b4de",
        "commit_message": "docs: fix typo inputs_shape -> input_shape (#4901)",
        "commit_url": "https://github.com/keras-team/keras/commit/44bf298ec3236f4a7281be04716a58163469b4de",
        "buggy_code": "inputs_shape: optional shape tuple, only to be specified",
        "fixed_code": "input_shape: optional shape tuple, only to be specified",
        "patch": "@@ -48,7 +48,7 @@ def VGG16(include_top=True, weights='imagenet',\n             or \"imagenet\" (pre-training on ImageNet).\n         input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n             to use as image input for the model.\n-        inputs_shape: optional shape tuple, only to be specified\n+        input_shape: optional shape tuple, only to be specified\n             if `include_top` is False (otherwise the input shape\n             has to be `(224, 224, 3)` (with `tf` dim ordering)\n             or `(3, 224, 244)` (with `th` dim ordering)."
    },
    {
        "commit_id": "44bf298ec3236f4a7281be04716a58163469b4de",
        "commit_message": "docs: fix typo inputs_shape -> input_shape (#4901)",
        "commit_url": "https://github.com/keras-team/keras/commit/44bf298ec3236f4a7281be04716a58163469b4de",
        "buggy_code": "inputs_shape: optional shape tuple, only to be specified",
        "fixed_code": "input_shape: optional shape tuple, only to be specified",
        "patch": "@@ -48,7 +48,7 @@ def VGG19(include_top=True, weights='imagenet',\n             or \"imagenet\" (pre-training on ImageNet).\n         input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n             to use as image input for the model.\n-        inputs_shape: optional shape tuple, only to be specified\n+        input_shape: optional shape tuple, only to be specified\n             if `include_top` is False (otherwise the input shape\n             has to be `(224, 224, 3)` (with `tf` dim ordering)\n             or `(3, 224, 244)` (with `th` dim ordering)."
    },
    {
        "commit_id": "44bf298ec3236f4a7281be04716a58163469b4de",
        "commit_message": "docs: fix typo inputs_shape -> input_shape (#4901)",
        "commit_url": "https://github.com/keras-team/keras/commit/44bf298ec3236f4a7281be04716a58163469b4de",
        "buggy_code": "inputs_shape: optional shape tuple, only to be specified",
        "fixed_code": "input_shape: optional shape tuple, only to be specified",
        "patch": "@@ -54,7 +54,7 @@ def Xception(include_top=True, weights='imagenet',\n             or \"imagenet\" (pre-training on ImageNet).\n         input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n             to use as image input for the model.\n-        inputs_shape: optional shape tuple, only to be specified\n+        input_shape: optional shape tuple, only to be specified\n             if `include_top` is False (otherwise the input shape\n             has to be `(299, 299, 3)`.\n             It should have exactly 3 inputs channels,"
    },
    {
        "commit_id": "c2e36f369b411ad1d0a40ac096fe35f73b9dffd3",
        "commit_message": "Fix kullback_leibler_divergence (#4800)\n\nThe kullback_leibler_divergence metric in metrics.py returned an output\r\nwith dimensionality N-1 (where N is the dimensionality of the target).\r\nAdd mean after sum to fix this, such that always a scalar is returned.",
        "commit_url": "https://github.com/keras-team/keras/commit/c2e36f369b411ad1d0a40ac096fe35f73b9dffd3",
        "buggy_code": "return K.sum(y_true * K.log(y_true / y_pred), axis=-1)",
        "fixed_code": "return K.mean(K.sum(y_true * K.log(y_true / y_pred), axis=-1))",
        "patch": "@@ -108,7 +108,7 @@ def kullback_leibler_divergence(y_true, y_pred):\n     '''\n     y_true = K.clip(y_true, K.epsilon(), 1)\n     y_pred = K.clip(y_pred, K.epsilon(), 1)\n-    return K.sum(y_true * K.log(y_true / y_pred), axis=-1)\n+    return K.mean(K.sum(y_true * K.log(y_true / y_pred), axis=-1))\n \n \n def poisson(y_true, y_pred):"
    },
    {
        "commit_id": "fefb70b217af9d9a5de780873db218fffaaf9544",
        "commit_message": "fix a bug in evaluating accuracy (#2736)\n\n* fix accuracy computation in MNIST siamese graph example\r\n\r\nprevious code:\r\n```\r\ndef compute_accuracy(predictions, labels):\r\n    '''Compute classification accuracy with a fixed threshold on distances.\r\n    '''\r\n    return labels[predictions.ravel() < 0.5].mean()\r\n```\r\nis not accuracy over all the samples, but over samples with negative prediction.\r\n\r\n* add space around  \"==\"\r\n\r\nfollow Fran\u00e7ois's suggestion",
        "commit_url": "https://github.com/keras-team/keras/commit/fefb70b217af9d9a5de780873db218fffaaf9544",
        "buggy_code": "return labels[predictions.ravel() < 0.5].mean()",
        "fixed_code": "return np.mean(labels == (predictions.ravel() > 0.5))",
        "patch": "@@ -75,7 +75,7 @@ def create_base_network(input_dim):\n def compute_accuracy(predictions, labels):\n     '''Compute classification accuracy with a fixed threshold on distances.\n     '''\n-    return labels[predictions.ravel() < 0.5].mean()\n+    return np.mean(labels == (predictions.ravel() > 0.5))\n \n \n # the data, shuffled and split between train and test sets"
    },
    {
        "commit_id": "4b1b706aa4effbf7c2886755ab99f5b75377762b",
        "commit_message": "Fix a typo in Cropping3D docs. (#4742)\n\nsaptio -> spatio",
        "commit_url": "https://github.com/keras-team/keras/commit/4b1b706aa4effbf7c2886755ab99f5b75377762b",
        "buggy_code": "'''Cropping layer for 3D data (e.g. spatial or saptio-temporal).",
        "fixed_code": "'''Cropping layer for 3D data (e.g. spatial or spatio-temporal).",
        "patch": "@@ -1750,7 +1750,7 @@ def get_config(self):\n \n \n class Cropping3D(Layer):\n-    '''Cropping layer for 3D data (e.g. spatial or saptio-temporal).\n+    '''Cropping layer for 3D data (e.g. spatial or spatio-temporal).\n \n     # Arguments\n         cropping: tuple of tuple of int (length 3)"
    },
    {
        "commit_id": "ff62eb251b04b8301e71aee970bdb157f2649fa9",
        "commit_message": "Refactor regularizers and add add_weight method. (#4703)\n\n* Refactor regularizers, introduce layer.add_weight\r\n\r\n* Fix BN add_update syntax\r\n\r\n* Fix eigenvalue regularizer\r\n\r\n* Style fixes.",
        "commit_url": "https://github.com/keras-team/keras/commit/ff62eb251b04b8301e71aee970bdb157f2649fa9",
        "buggy_code": "'''Instantiate a tensor variable.",
        "fixed_code": "'''Instantiates a variable.",
        "patch": "@@ -57,7 +57,7 @@ def to_dense(tensor):\n \n \n def variable(value, dtype=_FLOATX, name=None):\n-    '''Instantiate a tensor variable.\n+    '''Instantiates a variable.\n     '''\n     if hasattr(value, 'tocoo'):\n         _assert_sparse_module()"
    },
    {
        "commit_id": "e8939f43a6df0df76dc6e0e0e97aaeca664a2d19",
        "commit_message": "Fix BN reuse issue in TF backend",
        "commit_url": "https://github.com/keras-team/keras/commit/e8939f43a6df0df76dc6e0e0e97aaeca664a2d19",
        "buggy_code": "variable, value, momentum)",
        "fixed_code": "variable, value, momentum, zero_debias=False)",
        "patch": "@@ -361,7 +361,7 @@ def update_sub(x, decrement):\n \n def moving_average_update(variable, value, momentum):\n     return moving_averages.assign_moving_average(\n-        variable, value, momentum)\n+        variable, value, momentum, zero_debias=False)\n \n \n # LINEAR ALGEBRA"
    },
    {
        "commit_id": "1fd2108bcfa906ed61accaeca5b9238b96afad07",
        "commit_message": "fix load_model so that it can load customized optimizer (#4625)",
        "commit_url": "https://github.com/keras-team/keras/commit/1fd2108bcfa906ed61accaeca5b9238b96afad07",
        "buggy_code": "optimizer = optimizer_from_config(optimizer_config)",
        "fixed_code": "optimizer = optimizer_from_config(optimizer_config, custom_objects=custom_objects)",
        "patch": "@@ -151,7 +151,7 @@ def deserialize(obj):\n         return model\n     training_config = json.loads(training_config.decode('utf-8'))\n     optimizer_config = training_config['optimizer_config']\n-    optimizer = optimizer_from_config(optimizer_config)\n+    optimizer = optimizer_from_config(optimizer_config, custom_objects=custom_objects)\n \n     # recover loss functions and metrics\n     loss = deserialize(training_config['loss'])"
    },
    {
        "commit_id": "90c4895a7a5b8246b8f3927a6a8304d660bfa5fd",
        "commit_message": "Fix document in convolutional_recurrent.py (#4586)\n\n* Fix mismatch of interface and document in convolutional_recurrent.py\r\n\r\n* Update document of convolutional_recurrent.py to match the interface",
        "commit_url": "https://github.com/keras-team/keras/commit/90c4895a7a5b8246b8f3927a6a8304d660bfa5fd",
        "buggy_code": "sub_sample: tuple of length 2. Factor by which to subsample output.",
        "fixed_code": "subsample: tuple of length 2. Factor by which to subsample output.",
        "patch": "@@ -225,7 +225,7 @@ class ConvLSTM2D(ConvRecurrent2D):\n             nb_row: Number of rows in the convolution kernel.\n             nb_col: Number of columns in the convolution kernel.\n             border_mode: 'valid' or 'same'.\n-            sub_sample: tuple of length 2. Factor by which to subsample output.\n+            subsample: tuple of length 2. Factor by which to subsample output.\n                 Also called strides elsewhere.\n             dim_ordering: 'tf' if the feature are at the last dimension or 'th'\n             stateful : Boolean (default False). If True, the last state"
    },
    {
        "commit_id": "cb4f93913eb871a5e234db0c31f885daff87ecdf",
        "commit_message": "Fix shape validation issue with imagenet_utils",
        "commit_url": "https://github.com/keras-team/keras/commit/cb4f93913eb871a5e234db0c31f885daff87ecdf",
        "buggy_code": "if input_shape[1] != 3:",
        "fixed_code": "if input_shape[0] != 3:",
        "patch": "@@ -67,7 +67,7 @@ def _obtain_input_shape(input_shape, default_size, min_size, dim_ordering, inclu\n             if input_shape is not None:\n                 if len(input_shape) != 3:\n                     raise ValueError('`input_shape` must be a tuple of three integers.')\n-                if input_shape[1] != 3:\n+                if input_shape[0] != 3:\n                     raise ValueError('The input must have 3 channels; got '\n                                      '`input_shape=' + str(input_shape) + '`')\n                 if ((input_shape[1] is not None and input_shape[1] < min_size) or"
    },
    {
        "commit_id": "149946c706042e0db96664aa8c7bb0d61c224d9d",
        "commit_message": "Fix typos (#4591)",
        "commit_url": "https://github.com/keras-team/keras/commit/149946c706042e0db96664aa8c7bb0d61c224d9d",
        "buggy_code": "Currentl only symmetric padding is supported.",
        "fixed_code": "Currently only symmetric padding is supported.",
        "patch": "@@ -1587,7 +1587,7 @@ class ZeroPadding3D(Layer):\n         padding: tuple of int (length 3)\n             How many zeros to add at the beginning and end of\n             the 3 padding dimensions (axis 3, 4 and 5).\n-            Currentl only symmetric padding is supported.\n+            Currently only symmetric padding is supported.\n         dim_ordering: 'th' or 'tf'.\n             In 'th' mode, the channels dimension (the depth)\n             is at index 1, in 'tf' mode is it at index 4."
    },
    {
        "commit_id": "149946c706042e0db96664aa8c7bb0d61c224d9d",
        "commit_message": "Fix typos (#4591)",
        "commit_url": "https://github.com/keras-team/keras/commit/149946c706042e0db96664aa8c7bb0d61c224d9d",
        "buggy_code": "- [Supervised sequence labelling with recurrent neural networks](http://www.cs.toronto.edu/~graves/preprint.pdf)",
        "fixed_code": "- [Supervised sequence labeling with recurrent neural networks](http://www.cs.toronto.edu/~graves/preprint.pdf)",
        "patch": "@@ -653,7 +653,7 @@ class LSTM(Recurrent):\n     # References\n         - [Long short-term memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf) (original 1997 paper)\n         - [Learning to forget: Continual prediction with LSTM](http://www.mitpressjournals.org/doi/pdf/10.1162/089976600300015015)\n-        - [Supervised sequence labelling with recurrent neural networks](http://www.cs.toronto.edu/~graves/preprint.pdf)\n+        - [Supervised sequence labeling with recurrent neural networks](http://www.cs.toronto.edu/~graves/preprint.pdf)\n         - [A Theoretically Grounded Application of Dropout in Recurrent Neural Networks](http://arxiv.org/abs/1512.05287)\n     '''\n     def __init__(self, output_dim,"
    },
    {
        "commit_id": "68af216772980a7c8811bc1ad5421970fb6a978c",
        "commit_message": "Fix issue with custom Application input_tensor",
        "commit_url": "https://github.com/keras-team/keras/commit/68af216772980a7c8811bc1ad5421970fb6a978c",
        "buggy_code": "raise Exception('Tensor must be a Keras tensor. Found: ' + str(tensor))",
        "fixed_code": "return tensor",
        "patch": "@@ -2725,7 +2725,7 @@ def get_source_inputs(tensor, layer=None, node_index=None):\n         node_index: Origin node index of the tensor.\n     '''\n     if not hasattr(tensor, '_keras_history'):\n-        raise Exception('Tensor must be a Keras tensor. Found: ' + str(tensor))\n+        return tensor\n \n     if layer is None or node_index:\n         layer, node_index, _ = tensor._keras_history"
    },
    {
        "commit_id": "04ea01f3857f83e01590991f8df8475af03aa4a0",
        "commit_message": "Bug fix of Bidirectional(LSTM(..., stateful=True)) (#4424)\n\n* Bug fix of Bidirectional(LSTM(..., stateful=True)) https://github.com/fchollet/keras/issues/4421\r\n\r\n* Add Recurrent.from_config() test",
        "commit_url": "https://github.com/keras-team/keras/commit/04ea01f3857f83e01590991f8df8475af03aa4a0",
        "buggy_code": "if self.stateful:",
        "fixed_code": "if self.stateful and self.input_spec[0].shape:",
        "patch": "@@ -242,7 +242,7 @@ def get_config(self):\n                   'stateful': self.stateful,\n                   'unroll': self.unroll,\n                   'consume_less': self.consume_less}\n-        if self.stateful:\n+        if self.stateful and self.input_spec[0].shape:\n             config['batch_input_shape'] = self.input_spec[0].shape\n         else:\n             config['input_dim'] = self.input_dim"
    },
    {
        "commit_id": "71494ffdbc8193ece7a82496ec7835f195fb8309",
        "commit_message": "changed VAE sampling variance to 1 (#4211)\n\n* Update variational_autoencoder.py\r\n\r\nfixed sampling bug\r\n\r\n* Update variational_autoencoder_deconv.py\r\n\r\nfixed variance bug",
        "commit_url": "https://github.com/keras-team/keras/commit/71494ffdbc8193ece7a82496ec7835f195fb8309",
        "buggy_code": "epsilon_std = 0.01",
        "fixed_code": "epsilon_std = 1.0",
        "patch": "@@ -16,7 +16,7 @@\n latent_dim = 2\n intermediate_dim = 256\n nb_epoch = 50\n-epsilon_std = 0.01\n+epsilon_std = 1.0\n \n x = Input(batch_shape=(batch_size, original_dim))\n h = Dense(intermediate_dim, activation='relu')(x)"
    },
    {
        "commit_id": "71494ffdbc8193ece7a82496ec7835f195fb8309",
        "commit_message": "changed VAE sampling variance to 1 (#4211)\n\n* Update variational_autoencoder.py\r\n\r\nfixed sampling bug\r\n\r\n* Update variational_autoencoder_deconv.py\r\n\r\nfixed variance bug",
        "commit_url": "https://github.com/keras-team/keras/commit/71494ffdbc8193ece7a82496ec7835f195fb8309",
        "buggy_code": "epsilon_std = 0.01",
        "fixed_code": "epsilon_std = 1.0",
        "patch": "@@ -27,7 +27,7 @@\n     original_img_size = (img_rows, img_cols, img_chns)\n latent_dim = 2\n intermediate_dim = 128\n-epsilon_std = 0.01\n+epsilon_std = 1.0\n nb_epoch = 5\n \n x = Input(batch_shape=(batch_size,) + original_img_size)"
    },
    {
        "commit_id": "531147c8774af745d823d13227da4c2a3fa51118",
        "commit_message": "Fix review",
        "commit_url": "https://github.com/keras-team/keras/commit/531147c8774af745d823d13227da4c2a3fa51118",
        "buggy_code": "from .recurrent_convolutional import *",
        "fixed_code": "from .convolutional_recurrent import *",
        "patch": "@@ -10,4 +10,4 @@\n from .noise import *\n from .advanced_activations import *\n from .wrappers import *\n-from .recurrent_convolutional import *\n+from .convolutional_recurrent import *"
    },
    {
        "commit_id": "61c21ef9eef30cd18a1f6f2a0253cb05eb46fca0",
        "commit_message": "Imagenet predictions sorting fix",
        "commit_url": "https://github.com/keras-team/keras/commit/61c21ef9eef30cd18a1f6f2a0253cb05eb46fca0",
        "buggy_code": "top_indices = np.argpartition(pred, -top)[-top:][::-1]",
        "fixed_code": "top_indices = pred.argsort()[-top:][::-1]",
        "patch": "@@ -44,7 +44,7 @@ def decode_predictions(preds, top=5):\n         CLASS_INDEX = json.load(open(fpath))\n     results = []\n     for pred in preds:\n-        top_indices = np.argpartition(pred, -top)[-top:][::-1]\n+        top_indices = pred.argsort()[-top:][::-1]\n         result = [tuple(CLASS_INDEX[str(i)]) + (pred[i],) for i in top_indices]\n         results.append(result)\n     return results"
    },
    {
        "commit_id": "7d143370d8ee6ceb4b72790c6b859ce9ce6880d5",
        "commit_message": "BUG: Deconvolution2D output shape not correctly referenced (#4251)",
        "commit_url": "https://github.com/keras-team/keras/commit/7d143370d8ee6ceb4b72790c6b859ce9ce6880d5",
        "buggy_code": "config = {'output_shape': self.output_shape}",
        "fixed_code": "config = {'output_shape': self.output_shape_}",
        "patch": "@@ -663,7 +663,7 @@ def call(self, x, mask=None):\n         return output\n \n     def get_config(self):\n-        config = {'output_shape': self.output_shape}\n+        config = {'output_shape': self.output_shape_}\n         base_config = super(Deconvolution2D, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n "
    },
    {
        "commit_id": "80fbbc3a6a2a30f391bad2aa85e7558c50ca0709",
        "commit_message": "Bug fix in zca_whitening (#4181)\n\nWhen calculating 'sigma' denominator is # of instances (axis=0), not dimensionality (axis=1)\r\n\r\nProof:\r\nhttp://ufldl.stanford.edu/wiki/index.php/Implementing_PCA/Whitening\r\nhttp://ufldl.stanford.edu/wiki/index.php/Exercise:PCA_and_Whitening\r\nNg uses 2nd dim in denominator because his matrix is features x instances",
        "commit_url": "https://github.com/keras-team/keras/commit/80fbbc3a6a2a30f391bad2aa85e7558c50ca0709",
        "buggy_code": "sigma = np.dot(flatX.T, flatX) / flatX.shape[1]",
        "fixed_code": "sigma = np.dot(flatX.T, flatX) / flatX.shape[0]",
        "patch": "@@ -411,7 +411,7 @@ def fit(self, X,\n \n         if self.zca_whitening:\n             flatX = np.reshape(X, (X.shape[0], X.shape[1] * X.shape[2] * X.shape[3]))\n-            sigma = np.dot(flatX.T, flatX) / flatX.shape[1]\n+            sigma = np.dot(flatX.T, flatX) / flatX.shape[0]\n             U, S, V = linalg.svd(sigma)\n             self.principal_components = np.dot(np.dot(U, np.diag(1. / np.sqrt(S + 10e-7))), U.T)\n "
    },
    {
        "commit_id": "66e59447995bcdf0c2adad98766efa666fb2684f",
        "commit_message": "Fix Merge layer docstring (#4132)",
        "commit_url": "https://github.com/keras-team/keras/commit/66e59447995bcdf0c2adad98766efa666fb2684f",
        "buggy_code": "model2.add(Dense(32))",
        "fixed_code": "model2.add(Dense(32, input_dim=32))",
        "patch": "@@ -1109,7 +1109,7 @@ class Merge(Layer):\n     model1.add(Dense(32, input_dim=32))\n \n     model2 = Sequential()\n-    model2.add(Dense(32))\n+    model2.add(Dense(32, input_dim=32))\n \n     merged_model = Sequential()\n     merged_model.add(Merge([model1, model2], mode='concat', concat_axis=1)"
    },
    {
        "commit_id": "6ffa6f39e6222c5417f70eea84ebd92e2d6113f5",
        "commit_message": "Fix typo in Merge layer docstring.",
        "commit_url": "https://github.com/keras-team/keras/commit/6ffa6f39e6222c5417f70eea84ebd92e2d6113f5",
        "buggy_code": "model1.add(Dense(32))",
        "fixed_code": "model1.add(Dense(32, input_dim=32))",
        "patch": "@@ -1106,7 +1106,7 @@ class Merge(Layer):\n \n     ```python\n     model1 = Sequential()\n-    model1.add(Dense(32))\n+    model1.add(Dense(32, input_dim=32))\n \n     model2 = Sequential()\n     model2.add(Dense(32))"
    },
    {
        "commit_id": "570fdf31c5cb9a580496d1d93320bc7ab1b9ad46",
        "commit_message": "Python3 fix for deserialization of closures (#3961)",
        "commit_url": "https://github.com/keras-team/keras/commit/570fdf31c5cb9a580496d1d93320bc7ab1b9ad46",
        "buggy_code": "exec(src)",
        "fixed_code": "exec(src, globals())",
        "patch": "@@ -66,7 +66,7 @@ def func_reconstruct_closure(values):\n     src += [\"  return lambda:(%s)\" % ','.join([\"_%d\" % n for n in nums]), \"\"]\n     src = '\\n'.join(src)\n     try:\n-        exec(src)\n+        exec(src, globals())\n     except:\n         raise SyntaxError(src)\n     return func(values).__closure__"
    },
    {
        "commit_id": "56f3c85b87c2fbe75d9d791b7eb924bd455776d3",
        "commit_message": "Fix ValueError(ndim of gamma and beta) of batch normalization when using Theano (#3740)\n\n* Fix ndim mismatch error when using theano\r\n\r\n* Change keras backend call",
        "commit_url": "https://github.com/keras-team/keras/commit/56f3c85b87c2fbe75d9d791b7eb924bd455776d3",
        "buggy_code": "if sorted(reduction_axes) == range(K.ndim(x))[:-1]:",
        "fixed_code": "if K.backend() == 'tensorflow' and sorted(reduction_axes) == range(K.ndim(x))[:-1]:",
        "patch": "@@ -140,7 +140,7 @@ def call(self, x, mask=None):\n                 self.updates = [K.moving_average_update(self.running_mean, mean, self.momentum),\n                                 K.moving_average_update(self.running_std, std, self.momentum)]\n \n-                if sorted(reduction_axes) == range(K.ndim(x))[:-1]:\n+                if K.backend() == 'tensorflow' and sorted(reduction_axes) == range(K.ndim(x))[:-1]:\n                     x_normed_running = K.batch_normalization(\n                         x, self.running_mean, self.running_std,\n                         self.beta, self.gamma,"
    },
    {
        "commit_id": "f05cd95fadfd9a2084f27eb88ff62d1bdfe5d5e5",
        "commit_message": "Dot/cos merge : bug fix (#3708)",
        "commit_url": "https://github.com/keras-team/keras/commit/f05cd95fadfd9a2084f27eb88ff62d1bdfe5d5e5",
        "buggy_code": "'%s != %s. ' % (shape1[dot_axes[0]], shape2[dot_axes[1]]) +",
        "fixed_code": "'%s != %s. ' % (shape1[self.dot_axes[0]], shape2[self.dot_axes[1]]) +",
        "patch": "@@ -1233,7 +1233,7 @@ def _arguments_validation(self, layers, mode, concat_axis, dot_axes,\n                 raise Exception('Invalid format for dot_axes - list elements should be \"int\".')\n             if shape1[self.dot_axes[0]] != shape2[self.dot_axes[1]]:\n                 raise Exception('Dimension incompatibility using dot mode: ' +\n-                                '%s != %s. ' % (shape1[dot_axes[0]], shape2[dot_axes[1]]) +\n+                                '%s != %s. ' % (shape1[self.dot_axes[0]], shape2[self.dot_axes[1]]) +\n                                 'Layer shapes: %s, %s' % (shape1, shape2))\n         elif mode == 'concat':\n             reduced_inputs_shapes = [list(shape) for shape in input_shapes]"
    },
    {
        "commit_id": "48ae7217e482a1a3624d6e5380c972a653cacfaf",
        "commit_message": "Fix TensorFlow RNN backwards support. (#3662)",
        "commit_url": "https://github.com/keras-team/keras/commit/48ae7217e482a1a3624d6e5380c972a653cacfaf",
        "buggy_code": "mask = tf.reverse(mask, [True] + [False] * (ndim - 1))",
        "fixed_code": "mask = tf.reverse(mask, [True] + [False] * (ndim - 2))",
        "patch": "@@ -1136,7 +1136,7 @@ def rnn(step_function, inputs, initial_states,\n \n         if mask is not None:\n             if go_backwards:\n-                mask = tf.reverse(mask, [True] + [False] * (ndim - 1))\n+                mask = tf.reverse(mask, [True] + [False] * (ndim - 2))\n \n             # Transpose not supported by bool tensor types, hence round-trip to uint8.\n             mask = tf.cast(mask, tf.uint8)"
    },
    {
        "commit_id": "6f54b233f101323c55fc1d34696938713c2679b2",
        "commit_message": "Fix Theano input shape inference in InputLayer",
        "commit_url": "https://github.com/keras-team/keras/commit/6f54b233f101323c55fc1d34696938713c2679b2",
        "buggy_code": "img_input = Input(tensor=input_tensor)",
        "fixed_code": "img_input = Input(tensor=input_tensor, shape=input_shape)",
        "patch": "@@ -106,7 +106,7 @@ def InceptionV3(include_top=True, weights='imagenet',\n         img_input = Input(shape=input_shape)\n     else:\n         if not K.is_keras_tensor(input_tensor):\n-            img_input = Input(tensor=input_tensor)\n+            img_input = Input(tensor=input_tensor, shape=input_shape)\n         else:\n             img_input = input_tensor\n "
    },
    {
        "commit_id": "6f54b233f101323c55fc1d34696938713c2679b2",
        "commit_message": "Fix Theano input shape inference in InputLayer",
        "commit_url": "https://github.com/keras-team/keras/commit/6f54b233f101323c55fc1d34696938713c2679b2",
        "buggy_code": "img_input = Input(tensor=input_tensor)",
        "fixed_code": "img_input = Input(tensor=input_tensor, shape=input_shape)",
        "patch": "@@ -152,7 +152,7 @@ def ResNet50(include_top=True, weights='imagenet',\n         img_input = Input(shape=input_shape)\n     else:\n         if not K.is_keras_tensor(input_tensor):\n-            img_input = Input(tensor=input_tensor)\n+            img_input = Input(tensor=input_tensor, shape=input_shape)\n         else:\n             img_input = input_tensor\n     if K.image_dim_ordering() == 'tf':"
    },
    {
        "commit_id": "6f54b233f101323c55fc1d34696938713c2679b2",
        "commit_message": "Fix Theano input shape inference in InputLayer",
        "commit_url": "https://github.com/keras-team/keras/commit/6f54b233f101323c55fc1d34696938713c2679b2",
        "buggy_code": "img_input = Input(tensor=input_tensor)",
        "fixed_code": "img_input = Input(tensor=input_tensor, shape=input_shape)",
        "patch": "@@ -71,7 +71,7 @@ def VGG16(include_top=True, weights='imagenet',\n         img_input = Input(shape=input_shape)\n     else:\n         if not K.is_keras_tensor(input_tensor):\n-            img_input = Input(tensor=input_tensor)\n+            img_input = Input(tensor=input_tensor, shape=input_shape)\n         else:\n             img_input = input_tensor\n     # Block 1"
    },
    {
        "commit_id": "6f54b233f101323c55fc1d34696938713c2679b2",
        "commit_message": "Fix Theano input shape inference in InputLayer",
        "commit_url": "https://github.com/keras-team/keras/commit/6f54b233f101323c55fc1d34696938713c2679b2",
        "buggy_code": "img_input = Input(tensor=input_tensor)",
        "fixed_code": "img_input = Input(tensor=input_tensor, shape=input_shape)",
        "patch": "@@ -71,7 +71,7 @@ def VGG19(include_top=True, weights='imagenet',\n         img_input = Input(shape=input_shape)\n     else:\n         if not K.is_keras_tensor(input_tensor):\n-            img_input = Input(tensor=input_tensor)\n+            img_input = Input(tensor=input_tensor, shape=input_shape)\n         else:\n             img_input = input_tensor\n     # Block 1"
    },
    {
        "commit_id": "c478409dadb4a9c33fd5481efbdcaa06a5f8c4f0",
        "commit_message": "Fix weight constraint sharing issue",
        "commit_url": "https://github.com/keras-team/keras/commit/c478409dadb4a9c33fd5481efbdcaa06a5f8c4f0",
        "buggy_code": "if key in cons:",
        "fixed_code": "if key in cons and cons[key] != value:",
        "patch": "@@ -1950,7 +1950,7 @@ def constraints(self):\n         cons = {}\n         for layer in self.layers:\n             for key, value in layer.constraints.items():\n-                if key in cons:\n+                if key in cons and cons[key] != value:\n                     raise Exception('Received multiple constraints '\n                                     'for one weight tensor: ' + str(key))\n                 cons[key] = value"
    },
    {
        "commit_id": "9c28d21b4f89260cde311099195fd0d8e21f6f56",
        "commit_message": "Fix lambda layer docstring (#3604)",
        "commit_url": "https://github.com/keras-team/keras/commit/9c28d21b4f89260cde311099195fd0d8e21f6f56",
        "buggy_code": "Takes one argument: the output of previous layer",
        "fixed_code": "Takes input tensor as first argument.",
        "patch": "@@ -484,7 +484,7 @@ def antirectifier_output_shape(input_shape):\n \n     # Arguments\n         function: The function to be evaluated.\n-            Takes one argument: the output of previous layer\n+            Takes input tensor as first argument.\n         output_shape: Expected output shape from function.\n             Can be a tuple or function.\n             If a tuple, it only specifies the first dimension onward; "
    },
    {
        "commit_id": "9e58b8237bce22e7c2bc625c6820b288c3887890",
        "commit_message": "Enable colocate_gradients_with_ops=True (#3620)\n\nBy default TensorFlow allocates all gradient matricies on gpu:0, which makes it pretty much impossible to do parallelize a large model.\r\n\r\ncolocate_gradients_with_ops puts these matricies next to the operations, allowing you to split your model across multiple GPUs. I ran into this issue myself and this fixed it for me.\r\n\r\nI think it's also meant to set gradient computations to be done on the device where the operations are stored, but my belief about that comes from https://github.com/tensorflow/tensorflow/issues/2441\r\n\r\nI'm not sure why this isn't the default in TF, so I'm not sure if this should be behind a flag or something, but having to make my own patches to keras to do multi-GPU training seems like the wrong answer.",
        "commit_url": "https://github.com/keras-team/keras/commit/9e58b8237bce22e7c2bc625c6820b288c3887890",
        "buggy_code": "return tf.gradients(loss, variables)",
        "fixed_code": "return tf.gradients(loss, variables, colocate_gradients_with_ops=True)",
        "patch": "@@ -993,7 +993,7 @@ def gradients(loss, variables):\n     '''Returns the gradients of `variables` (list of tensor variables)\n     with regard to `loss`.\n     '''\n-    return tf.gradients(loss, variables)\n+    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)\n \n \n def stop_gradient(variables):"
    },
    {
        "commit_id": "88b301f182d904e71478e8985155500e3ce38d1a",
        "commit_message": "Update io_utils.py (#3577)\n\n* Update io_utils.py\r\n\r\nFix for wrong input dimension when using HDF5matrix for loading data\r\n\r\n* Update io_utils.py",
        "commit_url": "https://github.com/keras-team/keras/commit/88b301f182d904e71478e8985155500e3ce38d1a",
        "buggy_code": "return tuple([self.end - self.start, self.data.shape[1]])",
        "fixed_code": "return (self.end - self.start,) + self.data.shape[1:]",
        "patch": "@@ -52,7 +52,7 @@ def __getitem__(self, key):\n \n     @property\n     def shape(self):\n-        return tuple([self.end - self.start, self.data.shape[1]])\n+        return (self.end - self.start,) + self.data.shape[1:]\n \n \n def save_array(array, name):"
    },
    {
        "commit_id": "045d442fcdd52e923fc3ef68f552eac83d6216a1",
        "commit_message": "Update scikit_learn.py (#3567)\n\nSklearn (e.g. the Bagging estimator) expects a value error if a parameter isn't recognized.",
        "commit_url": "https://github.com/keras-team/keras/commit/045d442fcdd52e923fc3ef68f552eac83d6216a1",
        "buggy_code": "assert False, '{} is not a legal parameter'.format(params_name)",
        "fixed_code": "raise ValueError('{} is not a legal parameter'.format(params_name))",
        "patch": "@@ -78,7 +78,7 @@ def check_params(self, params):\n \n         for params_name in params:\n             if params_name not in legal_params:\n-                assert False, '{} is not a legal parameter'.format(params_name)\n+                raise ValueError('{} is not a legal parameter'.format(params_name))\n \n     def get_params(self, deep=True):\n         '''Get parameters for this estimator."
    },
    {
        "commit_id": "519d1e742011258742af664bb2a6db7a805add38",
        "commit_message": "bug fix : cnn tensorflow backend error (#3558)",
        "commit_url": "https://github.com/keras-team/keras/commit/519d1e742011258742af664bb2a6db7a805add38",
        "buggy_code": "x = tf.reshape(x, [-1, prod(shape(x)[1:])])",
        "fixed_code": "x = tf.reshape(x, tf.pack([-1, prod(shape(x)[1:])]))",
        "patch": "@@ -783,7 +783,7 @@ def batch_flatten(x):\n     '''Turn a n-D tensor into a 2D tensor where\n     the first dimension is conserved.\n     '''\n-    x = tf.reshape(x, [-1, prod(shape(x)[1:])])\n+    x = tf.reshape(x, tf.pack([-1, prod(shape(x)[1:])]))\n     return x\n \n "
    },
    {
        "commit_id": "6a6d939dea195ab94dfad2050cd2a0b3555a2568",
        "commit_message": "Style fix",
        "commit_url": "https://github.com/keras-team/keras/commit/6a6d939dea195ab94dfad2050cd2a0b3555a2568",
        "buggy_code": "activation=act, input_shape=(1, img_h, img_w), name='conv1')(input_data)",
        "fixed_code": "activation=act, name='conv1')(input_data)",
        "patch": "@@ -389,7 +389,7 @@ def on_epoch_end(self, epoch, logs={}):\n act = 'relu'\n input_data = Input(name='the_input', shape=(1, img_h, img_w), dtype='float32')\n inner = Convolution2D(conv_num_filters, filter_size, filter_size, border_mode='same',\n-                      activation=act, input_shape=(1, img_h, img_w), name='conv1')(input_data)\n+                      activation=act, name='conv1')(input_data)\n inner = MaxPooling2D(pool_size=(pool_size_1, pool_size_1), name='max1')(inner)\n inner = Convolution2D(conv_num_filters, filter_size, filter_size, border_mode='same',\n                       activation=act, name='conv2')(inner)"
    },
    {
        "commit_id": "f2786d9d800325cd4032af4041614f7a0d900efb",
        "commit_message": "Update theano_backend.py (#3532)\n\nfix batch norm causing NaN for many datasets",
        "commit_url": "https://github.com/keras-team/keras/commit/f2786d9d800325cd4032af4041614f7a0d900efb",
        "buggy_code": "return T.nnet.bn.batch_normalization(x, gamma, beta, mean, sqrt(var) + epsilon,",
        "fixed_code": "return T.nnet.bn.batch_normalization(x, gamma, beta, mean, sqrt(var + epsilon),",
        "patch": "@@ -392,7 +392,7 @@ def batch_normalization(x, mean, var, beta, gamma, epsilon=0.0001):\n                                                                         'spatial', epsilon)\n         except AttributeError:\n             pass\n-    return T.nnet.bn.batch_normalization(x, gamma, beta, mean, sqrt(var) + epsilon,\n+    return T.nnet.bn.batch_normalization(x, gamma, beta, mean, sqrt(var + epsilon),\n                                          mode='high_mem')\n \n "
    },
    {
        "commit_id": "3d5bf9753f6a770bf02b3eecd8b85fb2195cbc85",
        "commit_message": "Fix typo (#3505)",
        "commit_url": "https://github.com/keras-team/keras/commit/3d5bf9753f6a770bf02b3eecd8b85fb2195cbc85",
        "buggy_code": "this implementation relies on multiprocessing, you should not pass non",
        "fixed_code": "this implementation relies on multiprocessing, you should not pass",
        "patch": "@@ -811,7 +811,7 @@ def fit_generator(self, generator, samples_per_epoch, nb_epoch,\n             max_q_size: maximum size for the generator queue\n             nb_worker: maximum number of processes to spin up\n             pickle_safe: if True, use process based threading. Note that because\n-                this implementation relies on multiprocessing, you should not pass non\n+                this implementation relies on multiprocessing, you should not pass\n                 non picklable arguments to the generator as they can't be passed\n                 easily to children processes.\n "
    },
    {
        "commit_id": "e3c260e7d38e65eadd348337d206a66f82ae8029",
        "commit_message": "Fix test flakes",
        "commit_url": "https://github.com/keras-team/keras/commit/e3c260e7d38e65eadd348337d206a66f82ae8029",
        "buggy_code": "assert(history.history['val_loss'][-1] < 0.8)",
        "fixed_code": "assert(history.history['val_loss'][-1] < 1.)",
        "patch": "@@ -61,7 +61,7 @@ def test_temporal_regression():\n     model.compile(loss='hinge', optimizer='adam')\n     history = model.fit(X_train, y_train, nb_epoch=5, batch_size=16,\n                         validation_data=(X_test, y_test), verbose=0)\n-    assert(history.history['val_loss'][-1] < 0.8)\n+    assert(history.history['val_loss'][-1] < 1.)\n \n \n @keras_test"
    },
    {
        "commit_id": "3c8f91ee3d32222633c125dd97b669dbf740a1eb",
        "commit_message": "Style fix",
        "commit_url": "https://github.com/keras-team/keras/commit/3c8f91ee3d32222633c125dd97b669dbf740a1eb",
        "buggy_code": "x = tf.python.framework.ops.convert_to_tensor(x)",
        "fixed_code": "x = tf.convert_to_tensor(x)",
        "patch": "@@ -99,7 +99,7 @@ def _convert_string_dtype(dtype):\n \n \n def _to_tensor(x, dtype):\n-    x = tf.python.framework.ops.convert_to_tensor(x)\n+    x = tf.convert_to_tensor(x)\n     if x.dtype != dtype:\n         x = tf.cast(x, dtype)\n     return x"
    },
    {
        "commit_id": "74c51f213c7a187b76098331ca10fee10c9e5e59",
        "commit_message": "Fix flaky test",
        "commit_url": "https://github.com/keras-team/keras/commit/74c51f213c7a187b76098331ca10fee10c9e5e59",
        "buggy_code": "kwargs={'output_dim': 4., 'input_dim': 10, 'input_length': 2},",
        "fixed_code": "kwargs={'output_dim': 4, 'input_dim': 10, 'input_length': 2},",
        "patch": "@@ -7,7 +7,7 @@\n @keras_test\n def test_embedding():\n     layer_test(Embedding,\n-               kwargs={'output_dim': 4., 'input_dim': 10, 'input_length': 2},\n+               kwargs={'output_dim': 4, 'input_dim': 10, 'input_length': 2},\n                input_shape=(3, 2),\n                input_dtype='int32',\n                expected_output_dtype=K.floatx())"
    },
    {
        "commit_id": "4302d8060d06b8a19f2d16b5565ffdabf82277dd",
        "commit_message": "Fix image resizing in preprocessing/image",
        "commit_url": "https://github.com/keras-team/keras/commit/4302d8060d06b8a19f2d16b5565ffdabf82277dd",
        "buggy_code": "img = img.resize(target_size)",
        "fixed_code": "img = img.resize((target_size[1], target_size[0]))",
        "patch": "@@ -162,7 +162,7 @@ def load_img(path, grayscale=False, target_size=None):\n     else:  # Ensure 3 channel even when loaded image is grayscale\n         img = img.convert('RGB')\n     if target_size:\n-        img = img.resize(target_size)\n+        img = img.resize((target_size[1], target_size[0]))\n     return img\n \n "
    },
    {
        "commit_id": "aa2ec42da619f8f044e57686ea52b2df6da5a924",
        "commit_message": "stop gradients (#3221)\n\n* stop gradients\r\n\r\n* fix stop grad test\r\n\r\n* stop gradients",
        "commit_url": "https://github.com/keras-team/keras/commit/aa2ec42da619f8f044e57686ea52b2df6da5a924",
        "buggy_code": "dilated_filter_size = filter_size + (filter_size -1) * (dilation - 1)",
        "fixed_code": "dilated_filter_size = filter_size + (filter_size - 1) * (dilation - 1)",
        "patch": "@@ -114,7 +114,7 @@ def conv_output_length(input_length, filter_size, border_mode, stride, dilation=\n     if input_length is None:\n         return None\n     assert border_mode in {'same', 'valid'}\n-    dilated_filter_size = filter_size + (filter_size -1) * (dilation - 1)\n+    dilated_filter_size = filter_size + (filter_size - 1) * (dilation - 1)\n     if border_mode == 'same':\n         output_length = input_length\n     elif border_mode == 'valid':"
    },
    {
        "commit_id": "98974efa5f51d6f55afbf2bc125d6fd090bcf782",
        "commit_message": "Fix to error message in exception (#3213)\n\nWas incorrectly reporting the `loss` argument instead of the `loss_weights` argument when an exception related to loss_weights was thrown.",
        "commit_url": "https://github.com/keras-team/keras/commit/98974efa5f51d6f55afbf2bc125d6fd090bcf782",
        "buggy_code": "str(loss))",
        "fixed_code": "str(loss_weights))",
        "patch": "@@ -510,7 +510,7 @@ def compile(self, optimizer, loss, metrics=[], loss_weights=None,\n                                 'it should have one entry per model outputs. '\n                                 'The model has ' + str(len(self.outputs)) +\n                                 ' outputs, but you passed loss_weights=' +\n-                                str(loss))\n+                                str(loss_weights))\n             loss_weights_list = loss_weights\n         else:\n             raise Exception('Could not interpret loss_weights argument: ' +"
    },
    {
        "commit_id": "3ffff6d5793c5b6c1c2fab5416ca8ed9c4556044",
        "commit_message": "fix get_output_shape_for in Merge, when mode is callable (#3144)",
        "commit_url": "https://github.com/keras-team/keras/commit/3ffff6d5793c5b6c1c2fab5416ca8ed9c4556044",
        "buggy_code": "return (input_shape[0],) + tuple(self._output_shape)",
        "fixed_code": "return (input_shape[0][0],) + tuple(self._output_shape)",
        "patch": "@@ -1286,7 +1286,7 @@ def get_output_shape_for(self, input_shape):\n                 output_shape = self._output_shape(input_shape)\n                 return output_shape\n             elif self._output_shape is not None:\n-                return (input_shape[0],) + tuple(self._output_shape)\n+                return (input_shape[0][0],) + tuple(self._output_shape)\n             else:\n                 # TODO: consider shape auto-inference with TF\n                 raise Exception('The Merge layer ' + self.name +"
    },
    {
        "commit_id": "6b90eff03c4fdb66f7532145ac68f03e3bec2d2a",
        "commit_message": "Fix flaky test",
        "commit_url": "https://github.com/keras-team/keras/commit/6b90eff03c4fdb66f7532145ac68f03e3bec2d2a",
        "buggy_code": "assert(loss < 4.0)",
        "fixed_code": "assert(loss < 5.0)",
        "patch": "@@ -209,7 +209,7 @@ def test_siamese_1():\n     loss = graph.test_on_batch({'input1': X_test_graph, 'input2': X2_test_graph, 'output1': y_test_graph})\n     loss = graph.train_on_batch({'input1': X_test_graph, 'input2': X2_test_graph, 'output1': y_test_graph})\n     loss = graph.evaluate({'input1': X_test_graph, 'input2': X2_test_graph, 'output1': y_test_graph})\n-    assert(loss < 4.0)\n+    assert(loss < 5.0)\n \n     # test serialization\n     config = graph.get_config()"
    },
    {
        "commit_id": "89f6d374e98545c99742102e2d791cacb5d32c35",
        "commit_message": "Fix typo (#3070)",
        "commit_url": "https://github.com/keras-team/keras/commit/89f6d374e98545c99742102e2d791cacb5d32c35",
        "buggy_code": "print('Ploting Results')",
        "fixed_code": "print('Plotting Results')",
        "patch": "@@ -74,7 +74,7 @@ def gen_cosine_amp(amp=100, period=25, x0=0, xn=50000, step=1, k=0.0001):\n print('Predicting')\n predicted_output = model.predict(cos, batch_size=batch_size)\n \n-print('Ploting Results')\n+print('Plotting Results')\n plt.subplot(2, 1, 1)\n plt.plot(expected_output)\n plt.title('Expected')"
    },
    {
        "commit_id": "cdb5b09cd7f1f02d9eced2ad75b55cd56c679d34",
        "commit_message": "fix: Sort subdirs before mapping them to classes. (#3052)\n\nThe documentation says that [1]: \r\n\r\n> If [classes are] not provided, the list of classes will be automatically inferred (and the order of the classes, which will map to the label indices, will be alphanumeric).\r\n\r\nHowever, the code was adding classes in the order `os.listdir` returned them. This commit alphanumerically sorts the sub-directories before mapping them to label indices.\r\n\r\n[1] http://keras.io/preprocessing/image/",
        "commit_url": "https://github.com/keras-team/keras/commit/cdb5b09cd7f1f02d9eced2ad75b55cd56c679d34",
        "buggy_code": "for subdir in os.listdir(directory):",
        "fixed_code": "for subdir in sorted(os.listdir(directory)):",
        "patch": "@@ -532,7 +532,7 @@ def __init__(self, directory, image_data_generator,\n \n         if not classes:\n             classes = []\n-            for subdir in os.listdir(directory):\n+            for subdir in sorted(os.listdir(directory)):\n                 if os.path.isdir(os.path.join(directory, subdir)):\n                     classes.append(subdir)\n         self.nb_class = len(classes)"
    },
    {
        "commit_id": "60e0c96f6c4ac60f174b733b94342939e086d214",
        "commit_message": "Fix typo in training (#3014)",
        "commit_url": "https://github.com/keras-team/keras/commit/60e0c96f6c4ac60f174b733b94342939e086d214",
        "buggy_code": "'but the model expects a '",
        "fixed_code": "'but the model expects '",
        "patch": "@@ -55,7 +55,7 @@ def standardize_input_data(data, names, shapes=None,\n                     raise Exception('Error when checking ' + exception_prefix +\n                                     ': you are passing a list as '\n                                     'input to your model, '\n-                                    'but the model expects a '\n+                                    'but the model expects '\n                                     'a list of ' + str(len(names)) +\n                                     ' Numpy arrays instead. '\n                                     'The list you passed was: ' +"
    },
    {
        "commit_id": "7397f4b0d0d4ffd0685a2a9c84d407b348199f5d",
        "commit_message": "Resolve #2960 (#2961)\n\n* Resolve #2960\r\n\r\nIntroduce `K.var` so that the standard deviation computation can\r\nbe made numerically stable. Instead of\r\n\r\n\tK.std(x)\r\n\r\nthe user is able to write\r\n\r\n\tK.sqrt(K.var(x) + self.epsilon)\r\n\r\navoiding a division by zero in the gradient computation of `sqrt`.\r\n\r\n* Fix typos",
        "commit_url": "https://github.com/keras-team/keras/commit/7397f4b0d0d4ffd0685a2a9c84d407b348199f5d",
        "buggy_code": "std = K.std(x, axis=-1, keepdims=True)",
        "fixed_code": "std = K.sqrt(K.var(x, axis=-1, keepdims=True) + self.epsilon)",
        "patch": "@@ -139,7 +139,7 @@ def call(self, x, mask=None):\n         elif self.mode == 1:\n             # sample-wise normalization\n             m = K.mean(x, axis=-1, keepdims=True)\n-            std = K.std(x, axis=-1, keepdims=True)\n+            std = K.sqrt(K.var(x, axis=-1, keepdims=True) + self.epsilon)\n             x_normed = (x - m) / (std + self.epsilon)\n             out = self.gamma * x_normed + self.beta\n         return out"
    },
    {
        "commit_id": "3b83a1b1ac69d3bb3c2ac55e61878df1fd392768",
        "commit_message": "Fix initial variable in Evaluator. (#2955)",
        "commit_url": "https://github.com/keras-team/keras/commit/3b83a1b1ac69d3bb3c2ac55e61878df1fd392768",
        "buggy_code": "self.grads_values = None",
        "fixed_code": "self.grad_values = None",
        "patch": "@@ -189,7 +189,7 @@ def eval_loss_and_grads(x):\n class Evaluator(object):\n     def __init__(self):\n         self.loss_value = None\n-        self.grads_values = None\n+        self.grad_values = None\n \n     def loss(self, x):\n         assert self.loss_value is None"
    },
    {
        "commit_id": "d7e39347b99dd5489b089ffac8a525db0ff5cc03",
        "commit_message": "Add mode=2 option to the docstring in BatchNormalization (#2919)\n\nFix a tiny typo.",
        "commit_url": "https://github.com/keras-team/keras/commit/d7e39347b99dd5489b089ffac8a525db0ff5cc03",
        "buggy_code": "mode: integer, 0 or 1.",
        "fixed_code": "mode: integer, 0, 1 or 2.",
        "patch": "@@ -10,7 +10,7 @@ class BatchNormalization(Layer):\n \n     # Arguments\n         epsilon: small float > 0. Fuzz parameter.\n-        mode: integer, 0 or 1.\n+        mode: integer, 0, 1 or 2.\n             - 0: feature-wise normalization.\n                 Each feature map in the input will\n                 be normalized separately. The axis on which"
    },
    {
        "commit_id": "5a71090476da28a7258ed8653bf89d831d03cf22",
        "commit_message": "limit progress bar update rate (#2860)\n\n* limit progress bar update rate\r\n\r\nLimit progress bar update rate in verbose=1 mode. This patch allows to\r\nreduce terminal I/O throughput while keeping reasonable high visual\r\nupdate rate (defaults to 100 refreshes per second). It helps greatly\r\nwhen working with large but simple data sets with small batches, which\r\nleads to millions of relatively useless screen updates per second. Also\r\nit helps to keep network traffic at reasonable rates, which\r\nexceptionally useful within laggy networking conditions when using\r\nkeras over telnet/ssh, and improve web browser responsibility when\r\nusing keras within Jupyter Notebook.\r\n\r\n* add docstrings for 'interval' and 'force' arguments",
        "commit_url": "https://github.com/keras-team/keras/commit/5a71090476da28a7258ed8653bf89d831d03cf22",
        "buggy_code": "self.progbar.update(self.seen, self.log_values)",
        "fixed_code": "self.progbar.update(self.seen, self.log_values, force=True)",
        "patch": "@@ -192,7 +192,7 @@ def on_epoch_end(self, epoch, logs={}):\n             if k in logs:\n                 self.log_values.append((k, logs[k]))\n         if self.verbose:\n-            self.progbar.update(self.seen, self.log_values)\n+            self.progbar.update(self.seen, self.log_values, force=True)\n \n \n class History(Callback):"
    },
    {
        "commit_id": "80bfec725315e68762155cd47e8e9abf45c644f8",
        "commit_message": "Fix JSON deserialization issue",
        "commit_url": "https://github.com/keras-team/keras/commit/80bfec725315e68762155cd47e8e9abf45c644f8",
        "buggy_code": "return (input_shape[0],) + self._output_shape",
        "fixed_code": "return (input_shape[0],) + tuple(self._output_shape)",
        "patch": "@@ -1279,7 +1279,7 @@ def get_output_shape_for(self, input_shape):\n                 output_shape = self._output_shape(input_shape)\n                 return output_shape\n             elif self._output_shape is not None:\n-                return (input_shape[0],) + self._output_shape\n+                return (input_shape[0],) + tuple(self._output_shape)\n             else:\n                 # TODO: consider shape auto-inference with TF\n                 raise Exception('The Merge layer ' + self.name +"
    },
    {
        "commit_id": "e2abb5ef2c12a57f973331eb7e0fb0b4e19419bf",
        "commit_message": "Fix merge conflicts",
        "commit_url": "https://github.com/keras-team/keras/commit/e2abb5ef2c12a57f973331eb7e0fb0b4e19419bf",
        "buggy_code": "return shape1",
        "fixed_code": "return (shape1[0], 1)",
        "patch": "@@ -30,7 +30,7 @@ def euclidean_distance(vects):\n \n def eucl_dist_output_shape(shapes):\n     shape1, shape2 = shapes\n-    return shape1\n+    return (shape1[0], 1)\n \n \n def contrastive_loss(y_true, y_pred):"
    },
    {
        "commit_id": "e2abb5ef2c12a57f973331eb7e0fb0b4e19419bf",
        "commit_message": "Fix merge conflicts",
        "commit_url": "https://github.com/keras-team/keras/commit/e2abb5ef2c12a57f973331eb7e0fb0b4e19419bf",
        "buggy_code": "weight_values = layer.get_weights()",
        "fixed_code": "weight_values = K.batch_get_value(symbolic_weights)",
        "patch": "@@ -2273,7 +2273,7 @@ def save_weights(self, filepath, overwrite=False):\n         for layer in flattened_layers:\n             g = f.create_group(layer.name)\n             symbolic_weights = layer.trainable_weights + layer.non_trainable_weights\n-            weight_values = layer.get_weights()\n+            weight_values = K.batch_get_value(symbolic_weights)\n             weight_names = []\n             for i, (w, val) in enumerate(zip(symbolic_weights, weight_values)):\n                 if hasattr(w, 'name') and w.name:"
    },
    {
        "commit_id": "7cb41fc5cc5cef878cb8bfce40285f6cecdf1f24",
        "commit_message": "Fix weight saving issue",
        "commit_url": "https://github.com/keras-team/keras/commit/7cb41fc5cc5cef878cb8bfce40285f6cecdf1f24",
        "buggy_code": "weight_values = layer.get_weights()",
        "fixed_code": "weight_values = K.batch_get_value(symbolic_weights)",
        "patch": "@@ -2273,7 +2273,7 @@ def save_weights(self, filepath, overwrite=False):\n         for layer in flattened_layers:\n             g = f.create_group(layer.name)\n             symbolic_weights = layer.trainable_weights + layer.non_trainable_weights\n-            weight_values = layer.get_weights()\n+            weight_values = K.batch_get_value(symbolic_weights)\n             weight_names = []\n             for i, (w, val) in enumerate(zip(symbolic_weights, weight_values)):\n                 if hasattr(w, 'name') and w.name:"
    },
    {
        "commit_id": "18841fa58de4f45eb64311ee513d16247ae96077",
        "commit_message": "Fix build",
        "commit_url": "https://github.com/keras-team/keras/commit/18841fa58de4f45eb64311ee513d16247ae96077",
        "buggy_code": "def cos(x)",
        "fixed_code": "def cos(x):",
        "patch": "@@ -430,7 +430,7 @@ def sin(x):\n     return tf.sin(x)\n \n \n-def cos(x)\n+def cos(x):\n     '''Computes cos of x element-wise.\n     '''\n     return tf.cos(x)"
    },
    {
        "commit_id": "18841fa58de4f45eb64311ee513d16247ae96077",
        "commit_message": "Fix build",
        "commit_url": "https://github.com/keras-team/keras/commit/18841fa58de4f45eb64311ee513d16247ae96077",
        "buggy_code": "def cos(x)",
        "fixed_code": "def cos(x):",
        "patch": "@@ -269,7 +269,7 @@ def sin(x):\n     return T.sin(x)\n \n \n-def cos(x)\n+def cos(x):\n     return T.cos(x)\n \n "
    },
    {
        "commit_id": "c525e634dc1ad6ea4815035b059c13d901209a6a",
        "commit_message": "Fix loss compatibility validation",
        "commit_url": "https://github.com/keras-team/keras/commit/c525e634dc1ad6ea4815035b059c13d901209a6a",
        "buggy_code": "if loss.__name__ in key_losses and y.shape[1] != shape[1]:",
        "fixed_code": "if loss.__name__ in key_losses and shape[1] is not None and y.shape[1] != shape[1]:",
        "patch": "@@ -195,7 +195,7 @@ def check_loss_and_target_compatibility(targets, losses, output_shapes):\n                                 'Alternatively, you can use the loss function '\n                                 '`sparse_categorical_crossentropy` instead, '\n                                 'which does expect integer targets.')\n-        if loss.__name__ in key_losses and y.shape[1] != shape[1]:\n+        if loss.__name__ in key_losses and shape[1] is not None and y.shape[1] != shape[1]:\n                 raise Exception('A target array with shape ' + str(y.shape) +\n                                 ' was passed for an output of shape ' + str(shape) +\n                                 ' while using as loss `' + loss.__name__ + '`. '"
    },
    {
        "commit_id": "7ce144881a1dad0bde8f5ff481155f4408de70c4",
        "commit_message": "Fix stateful unrolled RNNs in Theano",
        "commit_url": "https://github.com/keras-team/keras/commit/7ce144881a1dad0bde8f5ff481155f4408de70c4",
        "buggy_code": "output, new_states = step_function(inputs[i], states)",
        "fixed_code": "output, new_states = step_function(inputs[i], states + constants)",
        "patch": "@@ -576,7 +576,7 @@ def rnn(step_function, inputs, initial_states,\n             successive_states = []\n             states = initial_states\n             for i in indices:\n-                output, new_states = step_function(inputs[i], states)\n+                output, new_states = step_function(inputs[i], states + constants)\n \n                 if len(successive_outputs) == 0:\n                     prev_output = zeros_like(output)"
    },
    {
        "commit_id": "6ea3188971a29405710563be48956da94ae26fa8",
        "commit_message": "Fix typo",
        "commit_url": "https://github.com/keras-team/keras/commit/6ea3188971a29405710563be48956da94ae26fa8",
        "buggy_code": "metrics=['acccuracy'])",
        "fixed_code": "metrics=['accuracy'])",
        "patch": "@@ -312,7 +312,7 @@ def compile(self, optimizer, loss,\n                 model.add(Dense(10, activation='softmax'))\n                 model.compile(optimizer='rmsprop',\n                               loss='categorical_crossentropy',\n-                              metrics=['acccuracy'])\n+                              metrics=['accuracy'])\n             ```\n         '''\n         # create the underlying model"
    },
    {
        "commit_id": "3b196feda5cce3b362353b0647363d85ef4d3e43",
        "commit_message": "Typo fix (#2234)",
        "commit_url": "https://github.com/keras-team/keras/commit/3b196feda5cce3b362353b0647363d85ef4d3e43",
        "buggy_code": "A None entry in a shaple is compatible with any dimension,",
        "fixed_code": "A None entry in a shape is compatible with any dimension,",
        "patch": "@@ -31,7 +31,7 @@ class InputSpec(object):\n     Every layer should expose (if appropriate) an `input_spec` attribute:\n     a list of instances of InputSpec (one per input tensor).\n \n-    A None entry in a shaple is compatible with any dimension,\n+    A None entry in a shape is compatible with any dimension,\n     a None shape is compatible with any shape.\n     '''\n     def __init__(self, dtype=None, shape=None, ndim=None):"
    },
    {
        "commit_id": "dd766c68d929c394cb17dd92b9cca20cbd7d32c4",
        "commit_message": "Fix LeakyReLU return dtype (#2214)\n\nLeakyReLU returns a tensor with float64 dtype.\r\nIt is stupid, but this line actually produces a float64 array:\r\n\r\n```\r\n    0.5*np.array(0.2, dtype=np.float32)\r\n```\r\n\r\nThe theano nnet.relu function does something similar like this with the\r\nLeakyReLU alpha parameter, which lead to a float64 tensor.\r\nThe solution is to not cast the alpha to float32.\r\n\r\nFurthermore I tighten the `test_utils.layer_test`. It is now\r\nrequired that the layer's output dtype is equal to the input dtype.",
        "commit_url": "https://github.com/keras-team/keras/commit/dd766c68d929c394cb17dd92b9cca20cbd7d32c4",
        "buggy_code": "self.alpha = K.cast_to_floatx(alpha)",
        "fixed_code": "self.alpha = alpha",
        "patch": "@@ -23,7 +23,7 @@ class LeakyReLU(Layer):\n     '''\n     def __init__(self, alpha=0.3, **kwargs):\n         self.supports_masking = True\n-        self.alpha = K.cast_to_floatx(alpha)\n+        self.alpha = alpha\n         super(LeakyReLU, self).__init__(**kwargs)\n \n     def call(self, x, mask=None):"
    },
    {
        "commit_id": "43187187692bdfed0bb5c27c730aa8506e83dcab",
        "commit_message": "Fix PEP8",
        "commit_url": "https://github.com/keras-team/keras/commit/43187187692bdfed0bb5c27c730aa8506e83dcab",
        "buggy_code": "from keras.models import Graph, Sequential #, model_from_json, model_from_yaml",
        "fixed_code": "from keras.models import Graph, Sequential",
        "patch": "@@ -6,7 +6,7 @@\n np.random.seed(1337)\n \n from keras import backend as K\n-from keras.models import Graph, Sequential #, model_from_json, model_from_yaml\n+from keras.models import Graph, Sequential\n from keras.layers.core import Dense, Activation, Merge, Lambda\n from keras.utils import np_utils\n from keras.utils.test_utils import get_test_data"
    },
    {
        "commit_id": "d09e2a67bb9ce53f9318930296a9825dd82f7197",
        "commit_message": "fix batch_dot tests on backend\n\n* Fix merge_dot tests\r\n\r\n* Make batch_dot unique\r\n\r\nbatch_dot is not tensordot! It only accepts one reduce dimension at a\r\ntime. Other reduce dimensions should be dome afterwards with K.sum\r\nThis means that K.batch_dot will have the same behavior in both\r\ntensorflow and theano. This also means that we have less parenthesis and\r\nless nested lists.\r\n\r\nNew usage:\r\n\r\nmerge_mode = 'dot', dot_axes=[axis1, axis2]\r\n\r\nBefore:\r\n\r\nmerge_mode = 'dot', dot_axes=[[axis1], [axis2]]\r\n\r\n* Backport sign by @the-moliver\r\n\r\n* Fix docstrings\r\n\r\n* Fix backend batch_dot tests",
        "commit_url": "https://github.com/keras-team/keras/commit/d09e2a67bb9ce53f9318930296a9825dd82f7197",
        "buggy_code": "axes=((2,), (2,)))",
        "fixed_code": "axes=(2, 2))",
        "patch": "@@ -43,7 +43,7 @@ def test_linear_operations(self):\n         check_two_tensor_operation('dot', (4, 2), (5, 2, 3))\n \n         check_two_tensor_operation('batch_dot', (4, 2, 3), (4, 5, 3),\n-                                   axes=((2,), (2,)))\n+                                   axes=(2, 2))\n         check_single_tensor_operation('transpose', (4, 2))\n \n     def test_shape_operations(self):"
    },
    {
        "commit_id": "8b3543fca9d811c638bb72d78601c8564f5465fd",
        "commit_message": "Fix merge_dot tests\n\n* Fix merge_dot tests\r\n\r\n* Make batch_dot unique\r\n\r\nbatch_dot is not tensordot! It only accepts one reduce dimension at a\r\ntime. Other reduce dimensions should be dome afterwards with K.sum\r\nThis means that K.batch_dot will have the same behavior in both\r\ntensorflow and theano. This also means that we have less parenthesis and\r\nless nested lists.\r\n\r\nNew usage:\r\n\r\nmerge_mode = 'dot', dot_axes=[axis1, axis2]\r\n\r\nBefore:\r\n\r\nmerge_mode = 'dot', dot_axes=[[axis1], [axis2]]\r\n\r\n* Backport sign by @the-moliver\r\n\r\n* Fix docstrings",
        "commit_url": "https://github.com/keras-team/keras/commit/8b3543fca9d811c638bb72d78601c8564f5465fd",
        "buggy_code": "dot_axes=[(2,), (2,)]))",
        "fixed_code": "dot_axes=[2, 2]))",
        "patch": "@@ -167,7 +167,7 @@ def vectorize_stories(data, word_idx, story_maxlen, query_maxlen):\n match = Sequential()\n match.add(Merge([input_encoder_m, question_encoder],\n                 mode='dot',\n-                dot_axes=[(2,), (2,)]))\n+                dot_axes=[2, 2]))\n # output: (samples, story_maxlen, query_maxlen)\n # embed the input into a single vector with size = story_maxlen:\n input_encoder_c = Sequential()"
    },
    {
        "commit_id": "8b3543fca9d811c638bb72d78601c8564f5465fd",
        "commit_message": "Fix merge_dot tests\n\n* Fix merge_dot tests\r\n\r\n* Make batch_dot unique\r\n\r\nbatch_dot is not tensordot! It only accepts one reduce dimension at a\r\ntime. Other reduce dimensions should be dome afterwards with K.sum\r\nThis means that K.batch_dot will have the same behavior in both\r\ntensorflow and theano. This also means that we have less parenthesis and\r\nless nested lists.\r\n\r\nNew usage:\r\n\r\nmerge_mode = 'dot', dot_axes=[axis1, axis2]\r\n\r\nBefore:\r\n\r\nmerge_mode = 'dot', dot_axes=[[axis1], [axis2]]\r\n\r\n* Backport sign by @the-moliver\r\n\r\n* Fix docstrings",
        "commit_url": "https://github.com/keras-team/keras/commit/8b3543fca9d811c638bb72d78601c8564f5465fd",
        "buggy_code": "model.add(Merge([left, right], mode='dot', dot_axes=([1], [1])))",
        "fixed_code": "model.add(Merge([left, right], mode='dot', dot_axes=[1, 1]))",
        "patch": "@@ -281,7 +281,7 @@ def test_merge_dot():\n     right.add(Activation('relu'))\n \n     model = Sequential()\n-    model.add(Merge([left, right], mode='dot', dot_axes=([1], [1])))\n+    model.add(Merge([left, right], mode='dot', dot_axes=[1, 1]))\n     model.add(Dense(nb_class))\n     model.add(Activation('softmax'))\n "
    },
    {
        "commit_id": "dc3c1488bb5a75af798cee7a81a46e454e17d85d",
        "commit_message": "Fix unit tests for Merge",
        "commit_url": "https://github.com/keras-team/keras/commit/dc3c1488bb5a75af798cee7a81a46e454e17d85d",
        "buggy_code": "axes = [(x.ndim-1,), (y.ndim-2,)]",
        "fixed_code": "axes = [(x.ndim - 1,), (y.ndim - 2,)]",
        "patch": "@@ -129,7 +129,7 @@ def dot(x, y):\n def batch_dot(x, y, axes=None):\n     if axes is None:\n         # behaves like tf.batch_matmul as default\n-        axes = [(x.ndim-1,), (y.ndim-2,)]\n+        axes = [(x.ndim - 1,), (y.ndim - 2,)]\n     return T.batched_tensordot(x, y, axes=axes)\n \n "
    },
    {
        "commit_id": "8ad686595202c6aabc44af3d16c0440e016e3fae",
        "commit_message": "Fix conv3d tests",
        "commit_url": "https://github.com/keras-team/keras/commit/8ad686595202c6aabc44af3d16c0440e016e3fae",
        "buggy_code": "return self.input_shape",
        "fixed_code": "return input_shape",
        "patch": "@@ -372,7 +372,7 @@ def get_output_shape_for(self, input_shape):\n                 else:\n                     return K.int_shape(x)\n             # otherwise, we default to the input shape\n-            return self.input_shape\n+            return input_shape\n         elif type(self._output_shape) in {tuple, list}:\n             nb_samples = input_shape[0] if input_shape else None\n             return (nb_samples,) + tuple(self._output_shape)"
    },
    {
        "commit_id": "8ad686595202c6aabc44af3d16c0440e016e3fae",
        "commit_message": "Fix conv3d tests",
        "commit_url": "https://github.com/keras-team/keras/commit/8ad686595202c6aabc44af3d16c0440e016e3fae",
        "buggy_code": "model.compile('rmsprop', 'mse', mode='FAST_COMPILE')",
        "fixed_code": "model.compile('rmsprop', 'mse')",
        "patch": "@@ -63,7 +63,7 @@ def layer_test(layer_cls, kwargs={}, input_shape=None, input_dtype=None,\n     x = Input(shape=input_shape[1:], dtype=input_dtype)\n     y = layer(x)\n     model = Model(input=x, output=y)\n-    model.compile('rmsprop', 'mse', mode='FAST_COMPILE')\n+    model.compile('rmsprop', 'mse')\n \n     expected_output_shape = layer.get_output_shape_for(input_shape)\n     actual_output = model.predict(input_data)"
    },
    {
        "commit_id": "fcb6ae8eed5058d7759d2db8bdfbf59e1033b1d9",
        "commit_message": "Fix activity regularization",
        "commit_url": "https://github.com/keras-team/keras/commit/fcb6ae8eed5058d7759d2db8bdfbf59e1033b1d9",
        "buggy_code": "regularized_loss = self.l1 * K.sum(K.mean(K.abs(output), axis=0))",
        "fixed_code": "regularized_loss = loss + self.l1 * K.sum(K.mean(K.abs(output), axis=0))",
        "patch": "@@ -46,7 +46,7 @@ def set_layer(self, layer):\n \n     def __call__(self, loss):\n         output = self.layer.output\n-        regularized_loss = self.l1 * K.sum(K.mean(K.abs(output), axis=0))\n+        regularized_loss = loss + self.l1 * K.sum(K.mean(K.abs(output), axis=0))\n         regularized_loss += self.l2 * K.sum(K.mean(K.square(output), axis=0))\n         return K.in_train_phase(regularized_loss, loss)\n "
    },
    {
        "commit_id": "80a831de1a954d23b5b9f7b9526398e10a1512e1",
        "commit_message": "Fix failing Lambda test",
        "commit_url": "https://github.com/keras-team/keras/commit/80a831de1a954d23b5b9f7b9526398e10a1512e1",
        "buggy_code": "g.add_node(Lambda(difference),",
        "fixed_code": "g.add_node(Lambda(difference, output_shape=(2,)),",
        "patch": "@@ -511,7 +511,7 @@ def difference(input_dict):\n     g = Graph()\n     g.add_input(name='input_a', input_shape=(2,))\n     g.add_input(name='input_b', input_shape=(2,))\n-    g.add_node(Lambda(difference),\n+    g.add_node(Lambda(difference, output_shape=(2,)),\n                inputs=['input_a', 'input_b'],\n                merge_mode='join',\n                name='d')"
    },
    {
        "commit_id": "e5ccf535312626a2727cbfd15455c592357f7568",
        "commit_message": "Fix typo",
        "commit_url": "https://github.com/keras-team/keras/commit/e5ccf535312626a2727cbfd15455c592357f7568",
        "buggy_code": "self.non_trainable_weights = self.layer.non_traible_weights",
        "fixed_code": "self.non_trainable_weights = self.layer.non_trainable_weights",
        "patch": "@@ -49,7 +49,7 @@ def build(self):\n \n         trainable_weights, regularizers, constraints, updates = self.layer.get_params()\n         self.trainable_weights = trainable_weights\n-        self.non_trainable_weights = self.layer.non_traible_weights\n+        self.non_trainable_weights = self.layer.non_trainable_weights\n         self.regularizers = regularizers\n         self.constraints = constraints\n         self.updates = updates"
    },
    {
        "commit_id": "7552f2c26dbae67de27d02db793e5e805de8339b",
        "commit_message": "Merge pull request #1834 from farizrahman4u/patch-5\n\nFix imports : bAbI Example",
        "commit_url": "https://github.com/keras-team/keras/commit/7552f2c26dbae67de27d02db793e5e805de8339b",
        "buggy_code": "from keras.layers.core import Dense, Merge",
        "fixed_code": "from keras.layers.core import Dense, Merge, Dropout, RepeatVector",
        "patch": "@@ -66,7 +66,7 @@\n \n from keras.datasets.data_utils import get_file\n from keras.layers.embeddings import Embedding\n-from keras.layers.core import Dense, Merge\n+from keras.layers.core import Dense, Merge, Dropout, RepeatVector\n from keras.layers import recurrent\n from keras.models import Sequential\n from keras.preprocessing.sequence import pad_sequences"
    },
    {
        "commit_id": "0eea5f8867bb2ef68c116e7c827436f59ef11a2e",
        "commit_message": "Fix imports : bAbI Example",
        "commit_url": "https://github.com/keras-team/keras/commit/0eea5f8867bb2ef68c116e7c827436f59ef11a2e",
        "buggy_code": "from keras.layers.core import Dense, Merge",
        "fixed_code": "from keras.layers.core import Dense, Merge, Dropout, RepeatVector",
        "patch": "@@ -66,7 +66,7 @@\n \n from keras.datasets.data_utils import get_file\n from keras.layers.embeddings import Embedding\n-from keras.layers.core import Dense, Merge\n+from keras.layers.core import Dense, Merge, Dropout, RepeatVector\n from keras.layers import recurrent\n from keras.models import Sequential\n from keras.preprocessing.sequence import pad_sequences"
    },
    {
        "commit_id": "d20fe64a69a4c7374091b25311f0941f0e20ecc3",
        "commit_message": "Merge pull request #1823 from EderSantana/patch-6\n\nUpdate SiameseHead",
        "commit_url": "https://github.com/keras-team/keras/commit/d20fe64a69a4c7374091b25311f0941f0e20ecc3",
        "buggy_code": "Y = self.layer(X, mask)",
        "fixed_code": "Y = self.layer(X, mask=mask, train=train)",
        "patch": "@@ -1744,7 +1744,7 @@ def set_layer_input(self, head):\n     def get_output_at(self, head, train=False):\n         X = self.inputs[head].get_output(train)\n         mask = self.inputs[head].get_output_mask(train)\n-        Y = self.layer(X, mask)\n+        Y = self.layer(X, mask=mask, train=train)\n         return Y\n \n     def get_output_shape(self, head, train=False):"
    },
    {
        "commit_id": "c6c150b0427c19f17e45471e450ddf87ac046419",
        "commit_message": "Update SiameseHead\n\nWe forgot to pass the train parameter to the layer.__call__ inside get_output_at. This is a bug.",
        "commit_url": "https://github.com/keras-team/keras/commit/c6c150b0427c19f17e45471e450ddf87ac046419",
        "buggy_code": "Y = self.layer(X, mask)",
        "fixed_code": "Y = self.layer(X, mask=mask, train=train)",
        "patch": "@@ -1743,7 +1743,7 @@ def set_layer_input(self, head):\n     def get_output_at(self, head, train=False):\n         X = self.inputs[head].get_output(train)\n         mask = self.inputs[head].get_output_mask(train)\n-        Y = self.layer(X, mask)\n+        Y = self.layer(X, mask=mask, train=train)\n         return Y\n \n     def get_output_shape(self, head, train=False):"
    },
    {
        "commit_id": "73e563ecaf915d073d8b8fabc4a568ecddb0ea11",
        "commit_message": "Speed up RNNs\n\nUpdate core.py\n\nFix TF indexing issue\n\nUpdate recurrent.py\n\nTF slicing issue workaround\n\nUpdate recurrent.py\n\nUpdate core.py\n\nUpdate core.py\n\nRemove all backend specific code\n\nshape[-1] instead of input_dim\n\nUpdate core.py\n\nspace fix\n\nUpdate core.py\n\nFix TF reshape issue\n\nUpdate recurrent.py\n\nUpdate core.py\n\nFix overflow issue in 3D softmax\n\nImprove readability",
        "commit_url": "https://github.com/keras-team/keras/commit/73e563ecaf915d073d8b8fabc4a568ecddb0ea11",
        "buggy_code": "e = K.exp(x)",
        "fixed_code": "e = K.exp(x - K.max(x, axis=-1, keepdims=True))",
        "patch": "@@ -7,7 +7,7 @@ def softmax(x):\n     if ndim == 2:\n         return K.softmax(x)\n     elif ndim == 3:\n-        e = K.exp(x)\n+        e = K.exp(x - K.max(x, axis=-1, keepdims=True))\n         s = K.sum(e, axis=-1, keepdims=True)\n         return e / s\n     else:"
    },
    {
        "commit_id": "3f905e4a357c05b216c29e34d26c12a4cd866f8e",
        "commit_message": "Merge pull request #1817 from AIshb/patch-1\n\nFix a little bug in pad_sequences",
        "commit_url": "https://github.com/keras-team/keras/commit/3f905e4a357c05b216c29e34d26c12a4cd866f8e",
        "buggy_code": "raise ValueError(\"Truncating type '%s' not understood\" % padding)",
        "fixed_code": "raise ValueError(\"Truncating type '%s' not understood\" % truncating)",
        "patch": "@@ -52,7 +52,7 @@ def pad_sequences(sequences, maxlen=None, dtype='int32', padding='pre', truncati\n         elif truncating == 'post':\n             trunc = s[:maxlen]\n         else:\n-            raise ValueError(\"Truncating type '%s' not understood\" % padding)\n+            raise ValueError(\"Truncating type '%s' not understood\" % truncating)\n \n         # check `trunc` has expected shape\n         trunc = np.asarray(trunc, dtype=dtype)"
    },
    {
        "commit_id": "f4af11c7300816ca28b6b707fdf7d64b00430074",
        "commit_message": "Update sequence.py\n\nfix a little mistake in pad_sequences",
        "commit_url": "https://github.com/keras-team/keras/commit/f4af11c7300816ca28b6b707fdf7d64b00430074",
        "buggy_code": "raise ValueError(\"Truncating type '%s' not understood\" % padding)",
        "fixed_code": "raise ValueError(\"Truncating type '%s' not understood\" % truncating)",
        "patch": "@@ -52,7 +52,7 @@ def pad_sequences(sequences, maxlen=None, dtype='int32', padding='pre', truncati\n         elif truncating == 'post':\n             trunc = s[:maxlen]\n         else:\n-            raise ValueError(\"Truncating type '%s' not understood\" % padding)\n+            raise ValueError(\"Truncating type '%s' not understood\" % truncating)\n \n         # check `trunc` has expected shape\n         trunc = np.asarray(trunc, dtype=dtype)"
    },
    {
        "commit_id": "abca83373d6d7df2747c5cdcc2bb7234395604e6",
        "commit_message": "Possibly faster RNNs\n\nForgot dropout.\n\nVarious fixes\n\nFix SimpleRNN dropout typo",
        "commit_url": "https://github.com/keras-team/keras/commit/abca83373d6d7df2747c5cdcc2bb7234395604e6",
        "buggy_code": "model.add(LSTM(128, dropout_W=0.5, dropout_U=0.5))  # try using a GRU instead, for fun",
        "fixed_code": "model.add(LSTM(128, dropout_W=0.5, dropout_U=0.1))  # try using a GRU instead, for fun",
        "patch": "@@ -47,7 +47,7 @@\n print('Build model...')\n model = Sequential()\n model.add(Embedding(max_features, 128, input_length=maxlen, dropout=0.5))\n-model.add(LSTM(128, dropout_W=0.5, dropout_U=0.5))  # try using a GRU instead, for fun\n+model.add(LSTM(128, dropout_W=0.5, dropout_U=0.1))  # try using a GRU instead, for fun\n model.add(Dropout(0.5))\n model.add(Dense(1))\n model.add(Activation('sigmoid'))"
    },
    {
        "commit_id": "f10c430731904a11558632a0a4936eb3f154647e",
        "commit_message": "Style fixes, fix flaky test",
        "commit_url": "https://github.com/keras-team/keras/commit/f10c430731904a11558632a0a4936eb3f154647e",
        "buggy_code": "val = np.random.random((20, 20))",
        "fixed_code": "val = np.random.random((100, 100))",
        "patch": "@@ -273,7 +273,7 @@ def test_nn_operations(self):\n         check_single_tensor_operation('tanh', (4, 2))\n \n         # dropout\n-        val = np.random.random((20, 20))\n+        val = np.random.random((100, 100))\n         xth = KTH.variable(val)\n         xtf = KTF.variable(val)\n         zth = KTH.eval(KTH.dropout(xth, level=0.2))"
    },
    {
        "commit_id": "96483326d8e1bd7ba7d9368d8e7552ec19b27a74",
        "commit_message": "fixed tensorflow bug",
        "commit_url": "https://github.com/keras-team/keras/commit/96483326d8e1bd7ba7d9368d8e7552ec19b27a74",
        "buggy_code": "B = K.random_binomial((self.input_dim), p=retain_p)",
        "fixed_code": "B = K.random_binomial((self.input_dim,), p=retain_p)",
        "patch": "@@ -105,7 +105,7 @@ def get_output(self, train=False):\n         X = self.get_input(train)\n         retain_p = 1. - self.p\n         if train and self.p > 0:\n-            B = K.random_binomial((self.input_dim), p=retain_p)\n+            B = K.random_binomial((self.input_dim,), p=retain_p)\n         else:\n             B = K.ones((self.input_dim)) * retain_p\n         out = K.gather(self.W * K.expand_dims(B), X) # we zero-out rows of W at random"
    },
    {
        "commit_id": "c23579e059c9cd88a956b7eac9a69f7d7e276fc8",
        "commit_message": "Fixed load_weights to not create empty/corrupt .h5 files\n\nFixes issue #1734 non-existant .h5 files will not be created, IOError will be raised.",
        "commit_url": "https://github.com/keras-team/keras/commit/c23579e059c9cd88a956b7eac9a69f7d7e276fc8",
        "buggy_code": "f = h5py.File(filepath)",
        "fixed_code": "f = h5py.File(filepath,mode=\"r\")",
        "patch": "@@ -845,7 +845,7 @@ def load_weights(self, filepath):\n         '''Load all layer weights from a HDF5 save file.\n         '''\n         import h5py\n-        f = h5py.File(filepath)\n+        f = h5py.File(filepath,mode=\"r\")\n         for k in range(f.attrs['nb_layers']):\n             # This method does not make use of Sequential.set_weights()\n             # for backwards compatibility."
    },
    {
        "commit_id": "1e46a5d3ec173b3f5f264a080bd29901c3839bd7",
        "commit_message": "Improve error message",
        "commit_url": "https://github.com/keras-team/keras/commit/1e46a5d3ec173b3f5f264a080bd29901c3839bd7",
        "buggy_code": "raise Exception('Layer shape %s not compatible with weight shape %s.' % (K.get_value(p).shape, w.shape))",
        "fixed_code": "raise Exception('Layer weight shape %s not compatible with provided weight shape %s.' % (K.get_value(p).shape, w.shape))",
        "patch": "@@ -230,7 +230,7 @@ def set_weights(self, weights):\n                                              str(len(weights)) + ' provided weights)')\n         for p, w in zip(params, weights):\n             if K.get_value(p).shape != w.shape:\n-                raise Exception('Layer shape %s not compatible with weight shape %s.' % (K.get_value(p).shape, w.shape))\n+                raise Exception('Layer weight shape %s not compatible with provided weight shape %s.' % (K.get_value(p).shape, w.shape))\n             K.set_value(p, w)\n \n     def get_weights(self):"
    },
    {
        "commit_id": "359f91ff6c189f625a875e37592cd84f3f554d28",
        "commit_message": "Fix py3 test",
        "commit_url": "https://github.com/keras-team/keras/commit/359f91ff6c189f625a875e37592cd84f3f554d28",
        "buggy_code": "keys = input_dict.keys()",
        "fixed_code": "keys = list(input_dict.keys())",
        "patch": "@@ -424,7 +424,7 @@ def output_shape(input_shapes):\n     # test \"join\" mode in Lambda\n     def difference(input_dict):\n         assert(len(input_dict) == 2)\n-        keys = input_dict.keys()\n+        keys = list(input_dict.keys())\n         return input_dict[keys[0]] - input_dict[keys[1]]\n \n     g = Graph()"
    },
    {
        "commit_id": "ff4a9b7b24011e5eec09bbf03c7b3afe8f1a958c",
        "commit_message": "fix BN serialization",
        "commit_url": "https://github.com/keras-team/keras/commit/ff4a9b7b24011e5eec09bbf03c7b3afe8f1a958c",
        "buggy_code": "nb_param = len(self.layers[i].params)",
        "fixed_code": "nb_param = len(self.layers[i].params) + len(self.layers[i].non_trainable_weights)",
        "patch": "@@ -155,7 +155,7 @@ def get_weights(self):\n \n     def set_weights(self, weights):\n         for i in range(len(self.layers)):\n-            nb_param = len(self.layers[i].params)\n+            nb_param = len(self.layers[i].params) + len(self.layers[i].non_trainable_weights)\n             self.layers[i].set_weights(weights[:nb_param])\n             weights = weights[nb_param:]\n "
    },
    {
        "commit_id": "ef22fcf548814b37e794073068b422581f4a1881",
        "commit_message": "Fix TF dim check",
        "commit_url": "https://github.com/keras-team/keras/commit/ef22fcf548814b37e794073068b422581f4a1881",
        "buggy_code": "assert x.ndim == 2",
        "fixed_code": "assert ndim(x) == 2",
        "patch": "@@ -289,7 +289,7 @@ def repeat(x, n):\n     if x has shape (samples, dim) and n=2,\n     the output will have shape (samples, 2, dim)\n     '''\n-    assert x.ndim == 2\n+    assert ndim(x) == 2\n     tensors = [x] * n\n     stacked = tf.pack(tensors)\n     return tf.transpose(stacked, (1, 0, 2))"
    },
    {
        "commit_id": "095b6c118cb0b0c3bfda9c012e2dbcd5546f4afb",
        "commit_message": "Fix merge conflicts",
        "commit_url": "https://github.com/keras-team/keras/commit/095b6c118cb0b0c3bfda9c012e2dbcd5546f4afb",
        "buggy_code": "return K.expand_dims(K.not_equal(X, 0))",
        "fixed_code": "return K.not_equal(X, 0)",
        "patch": "@@ -89,7 +89,7 @@ def get_output_mask(self, train=None):\n         if not self.mask_zero:\n             return None\n         else:\n-            return K.expand_dims(K.not_equal(X, 0))\n+            return K.not_equal(X, 0)\n \n     @property\n     def output_shape(self):"
    },
    {
        "commit_id": "c94cf4b32a22504a01953c917402ab27b926875f",
        "commit_message": "Auto-expand mask dims. Fix categorical_crossentropy.\n\n     - Categorical_crossentropy was taking an extra mean, the function\n      already removes the final dimension of your input, so you don't need\n      to take a mean as you would with, say, L2 loss.\n\n     - The RNN backend call can now take a mask with or without the same\n      number of dimensions as the input data\n\n     - Fix Masking layer for Tensorflow\n\n     - Add some tests to confirm objective function shapes",
        "commit_url": "https://github.com/keras-team/keras/commit/c94cf4b32a22504a01953c917402ab27b926875f",
        "buggy_code": "return K.expand_dims(K.not_equal(X, 0))",
        "fixed_code": "return K.not_equal(X, 0)",
        "patch": "@@ -89,7 +89,7 @@ def get_output_mask(self, train=None):\n         if not self.mask_zero:\n             return None\n         else:\n-            return K.expand_dims(K.not_equal(X, 0))\n+            return K.not_equal(X, 0)\n \n     @property\n     def output_shape(self):"
    },
    {
        "commit_id": "9720db95669abdca9f57438be708b3edf37c5485",
        "commit_message": "Fix typo",
        "commit_url": "https://github.com/keras-team/keras/commit/9720db95669abdca9f57438be708b3edf37c5485",
        "buggy_code": "autoencoder.output_reconstruction = False",
        "fixed_code": "autoencoder.output_reconstruction = True",
        "patch": "@@ -1183,7 +1183,7 @@ class AutoEncoder(Layer):\n     autoencoder.fit(X_test, representations, nb_epoch=1)  # in this case the loss will be 0, so it's useless\n \n     # to keep training against the original inputs, just switch back output_reconstruction to True:\n-    autoencoder.output_reconstruction = False\n+    autoencoder.output_reconstruction = True\n     autoencoder.compile(optimizer='sgd', loss='mse')\n     autoencoder.fit(X_train, X_train, nb_epoch=10)\n     ```"
    },
    {
        "commit_id": "9720db95669abdca9f57438be708b3edf37c5485",
        "commit_message": "Fix typo",
        "commit_url": "https://github.com/keras-team/keras/commit/9720db95669abdca9f57438be708b3edf37c5485",
        "buggy_code": "autoencoder.output_reconstruction = False",
        "fixed_code": "autoencoder.output_reconstruction = True",
        "patch": "@@ -139,7 +139,7 @@ def test_autoencoder_advanced():\n     autoencoder.fit(X_test, representations, nb_epoch=1, batch_size=32)\n \n     # to keep training against the original inputs, just switch back output_reconstruction to True:\n-    autoencoder.output_reconstruction = False\n+    autoencoder.output_reconstruction = True\n     autoencoder.compile(optimizer='sgd', loss='mse')\n     autoencoder.fit(X_train, X_train, nb_epoch=1)\n "
    },
    {
        "commit_id": "efe4fc72e53cd123996514848786ecba48b8a360",
        "commit_message": "Fix loss weighting tests",
        "commit_url": "https://github.com/keras-team/keras/commit/efe4fc72e53cd123996514848786ecba48b8a360",
        "buggy_code": "y = np.random.randint(0, nb_class, size=(nb_sample, 1))",
        "fixed_code": "y = np.random.randint(0, nb_class, size=(nb_sample,))",
        "patch": "@@ -12,7 +12,7 @@ def get_test_data(nb_train=1000, nb_test=500, input_shape=(10,), output_shape=(2\n     '''\n     nb_sample = nb_train + nb_test\n     if classification:\n-        y = np.random.randint(0, nb_class, size=(nb_sample, 1))\n+        y = np.random.randint(0, nb_class, size=(nb_sample,))\n         X = np.zeros((nb_sample,) + input_shape)\n         for i in range(nb_sample):\n             X[i] = np.random.normal(loc=y[i], scale=0.7, size=input_shape)"
    },
    {
        "commit_id": "3f599b9204832a0f42bf1d3b20685daf8d780499",
        "commit_message": "Merge pull request #1525 from wxs/fix-masking-3d+\n\nSupport >3d mask matrices.",
        "commit_url": "https://github.com/keras-team/keras/commit/3f599b9204832a0f42bf1d3b20685daf8d780499",
        "buggy_code": "mask = tf.cast(tf.transpose(tf.cast(mask, tf.uint8), (1, 0, 2)), tf.bool)",
        "fixed_code": "mask = tf.cast(tf.transpose(tf.cast(mask, tf.uint8), axes), tf.bool)",
        "patch": "@@ -440,7 +440,7 @@ def rnn(step_function, inputs, initial_states,\n         mask = tf.cast(mask, tf.bool)\n     else:\n         # Transpose not supported by bool tensor types, hence round-trip to uint8.\n-        mask = tf.cast(tf.transpose(tf.cast(mask, tf.uint8), (1, 0, 2)), tf.bool)\n+        mask = tf.cast(tf.transpose(tf.cast(mask, tf.uint8), axes), tf.bool)\n \n     mask_list = tf.unpack(mask)\n "
    },
    {
        "commit_id": "3f599b9204832a0f42bf1d3b20685daf8d780499",
        "commit_message": "Merge pull request #1525 from wxs/fix-masking-3d+\n\nSupport >3d mask matrices.",
        "commit_url": "https://github.com/keras-team/keras/commit/3f599b9204832a0f42bf1d3b20685daf8d780499",
        "buggy_code": "mask = mask.dimshuffle((1, 0, 2))",
        "fixed_code": "mask = mask.dimshuffle(axes)",
        "patch": "@@ -447,7 +447,7 @@ def rnn(step_function, inputs, initial_states,\n     if mask is None:\n         mask = expand_dims(ones_like(T.sum(inputs, axis=-1)))\n     else:\n-        mask = mask.dimshuffle((1, 0, 2))\n+        mask = mask.dimshuffle(axes)\n \n     def _step(input, mask, output_tm1, *states):\n         output, new_states = step_function(input, states)"
    },
    {
        "commit_id": "3ed897332f1c61c1c608e0eeccb8244769d9f1f2",
        "commit_message": "Merge pull request #1501 from farizrahman4u/patch-25\n\nRemove output_dim argument from RNN API",
        "commit_url": "https://github.com/keras-team/keras/commit/3ed897332f1c61c1c608e0eeccb8244769d9f1f2",
        "buggy_code": "last_output, outputs, states = K.rnn(self.step, X, self.output_dim,",
        "fixed_code": "last_output, outputs, states = K.rnn(self.step, X,",
        "patch": "@@ -140,7 +140,7 @@ def get_output(self, train=False):\n         else:\n             initial_states = self.get_initial_states(X)\n \n-        last_output, outputs, states = K.rnn(self.step, X, self.output_dim,\n+        last_output, outputs, states = K.rnn(self.step, X,\n                                              initial_states,\n                                              go_backwards=self.go_backwards,\n                                              mask=mask)"
    },
    {
        "commit_id": "52cb803debe7a21ed06d8b17b36d6326434bb04c",
        "commit_message": "Merge pull request #1511 from farizrahman4u/patch-24\n\nWhite space fix",
        "commit_url": "https://github.com/keras-team/keras/commit/52cb803debe7a21ed06d8b17b36d6326434bb04c",
        "buggy_code": "'and is not an input layer.')",
        "fixed_code": "' and is not an input layer.')",
        "patch": "@@ -179,7 +179,7 @@ def get_input(self, train=False):\n             return self.input\n         else:\n             raise Exception('Layer is not connected' +\n-                            'and is not an input layer.')\n+                            ' and is not an input layer.')\n \n     def supports_masked_input(self):\n         '''Whether or not this layer respects the output mask of its previous"
    },
    {
        "commit_id": "d08b0efc80e08f74507990f0ae02ba63ee2f968c",
        "commit_message": "White space fix",
        "commit_url": "https://github.com/keras-team/keras/commit/d08b0efc80e08f74507990f0ae02ba63ee2f968c",
        "buggy_code": "'and is not an input layer.')",
        "fixed_code": "' and is not an input layer.')",
        "patch": "@@ -179,7 +179,7 @@ def get_input(self, train=False):\n             return self.input\n         else:\n             raise Exception('Layer is not connected' +\n-                            'and is not an input layer.')\n+                            ' and is not an input layer.')\n \n     def supports_masked_input(self):\n         '''Whether or not this layer respects the output mask of its previous"
    },
    {
        "commit_id": "9d120bf9e02520e91cb7a3cc7453f27d9c404412",
        "commit_message": "Fix py3 compatibility",
        "commit_url": "https://github.com/keras-team/keras/commit/9d120bf9e02520e91cb7a3cc7453f27d9c404412",
        "buggy_code": "reduction_axes = range(len(input_shape))",
        "fixed_code": "reduction_axes = list(range(len(input_shape)))",
        "patch": "@@ -80,7 +80,7 @@ def get_output(self, train):\n         X = self.get_input(train)\n         if self.mode == 0:\n             input_shape = self.input_shape\n-            reduction_axes = range(len(input_shape))\n+            reduction_axes = list(range(len(input_shape)))\n             broadcast_shape = [1] * len(input_shape)\n             broadcast_shape[self.axis] = input_shape[self.axis]\n             del reduction_axes[self.axis]"
    },
    {
        "commit_id": "a563a8446e8b7c568cefa18225d2156f75ae7c5b",
        "commit_message": "Add an automatic PEP8 check on the pull request submission:\\n - ignore most of the errors to avoid disrupting others\\n - add a separate job to avoid confusion that all jobs fail because of a single pep error\\n - fix few small pep errors",
        "commit_url": "https://github.com/keras-team/keras/commit/a563a8446e8b7c568cefa18225d2156f75ae7c5b",
        "buggy_code": "if  type(v) == str:",
        "fixed_code": "if type(v) == str:",
        "patch": "@@ -80,7 +80,7 @@ def get_method_signature(method):\n     for a in args:\n         st += str(a) + ', '\n     for a, v in kwargs:\n-        if  type(v) == str:\n+        if type(v) == str:\n             v = '\\'' + v + '\\''\n         elif type(v) == unicode:\n             v = 'u\\'' + v + '\\''"
    },
    {
        "commit_id": "a563a8446e8b7c568cefa18225d2156f75ae7c5b",
        "commit_message": "Add an automatic PEP8 check on the pull request submission:\\n - ignore most of the errors to avoid disrupting others\\n - add a separate job to avoid confusion that all jobs fail because of a single pep error\\n - fix few small pep errors",
        "commit_url": "https://github.com/keras-team/keras/commit/a563a8446e8b7c568cefa18225d2156f75ae7c5b",
        "buggy_code": "return obj.item();",
        "fixed_code": "return obj.item()",
        "patch": "@@ -385,7 +385,7 @@ def get_json_type(obj):\n \n             # if obj is any numpy type\n             if type(obj).__module__ == np.__name__:\n-                return obj.item();\n+                return obj.item()\n \n             # if obj is a python 'type'\n             if type(obj).__name__ == type.__name__:"
    },
    {
        "commit_id": "a563a8446e8b7c568cefa18225d2156f75ae7c5b",
        "commit_message": "Add an automatic PEP8 check on the pull request submission:\\n - ignore most of the errors to avoid disrupting others\\n - add a separate job to avoid confusion that all jobs fail because of a single pep error\\n - fix few small pep errors",
        "commit_url": "https://github.com/keras-team/keras/commit/a563a8446e8b7c568cefa18225d2156f75ae7c5b",
        "buggy_code": "couples += [[words[i%len(words)], random.randint(1, vocabulary_size-1)] for i in range(nb_negative_samples)]",
        "fixed_code": "couples += [[words[i %len(words)], random.randint(1, vocabulary_size-1)] for i in range(nb_negative_samples)]",
        "patch": "@@ -135,7 +135,7 @@ def skipgrams(sequence, vocabulary_size,\n         words = [c[0] for c in couples]\n         random.shuffle(words)\n \n-        couples += [[words[i%len(words)], random.randint(1, vocabulary_size-1)] for i in range(nb_negative_samples)]\n+        couples += [[words[i %len(words)], random.randint(1, vocabulary_size-1)] for i in range(nb_negative_samples)]\n         if categorical:\n             labels += [[1,0]]*nb_negative_samples\n         else:"
    },
    {
        "commit_id": "e21a6a9ebff8659594ecd70e8123252715d6b101",
        "commit_message": "Fix output_shape too.",
        "commit_url": "https://github.com/keras-team/keras/commit/e21a6a9ebff8659594ecd70e8123252715d6b101",
        "buggy_code": "shape = output_shape_func(self.previous.output_shape)",
        "fixed_code": "shape = output_shape_func(self.input_shape)",
        "patch": "@@ -1376,7 +1376,7 @@ def output_shape(self):\n         else:\n             output_shape_func = marshal.loads(self._output_shape)\n             output_shape_func = types.FunctionType(output_shape_func, globals())\n-            shape = output_shape_func(self.previous.output_shape)\n+            shape = output_shape_func(self.input_shape)\n             if type(shape) not in {list, tuple}:\n                 raise Exception('output_shape function must return a tuple')\n             return tuple(shape)"
    },
    {
        "commit_id": "0ed465acfa4e92b80e034d059c5e369809c4b854",
        "commit_message": "Merge pull request #1397 from stevenxxiu/batch_input_shape_fix\n\nbatch_input_shape fix",
        "commit_url": "https://github.com/keras-team/keras/commit/0ed465acfa4e92b80e034d059c5e369809c4b854",
        "buggy_code": "if len(input_shape) == 1:",
        "fixed_code": "if (input_shape and len(input_shape) == 1) or (batch_input_shape and len(batch_input_shape) == 2):",
        "patch": "@@ -313,7 +313,7 @@ def add_input(self, name, input_shape=None,\n         if dtype == 'float':\n             layer.input = K.placeholder(shape=layer.input_shape, name=name)\n         else:\n-            if len(input_shape) == 1:\n+            if (input_shape and len(input_shape) == 1) or (batch_input_shape and len(batch_input_shape) == 2):\n                 layer.input = K.placeholder(shape=layer.input_shape,\n                                             dtype='int32',\n                                             name=name)"
    },
    {
        "commit_id": "b17e4c5edfa8a82c82054d0ba3c92d568b1f4d20",
        "commit_message": "input_shape fix",
        "commit_url": "https://github.com/keras-team/keras/commit/b17e4c5edfa8a82c82054d0ba3c92d568b1f4d20",
        "buggy_code": "if len(input_shape) == 1:",
        "fixed_code": "if (input_shape and len(input_shape) == 1) or (batch_input_shape and len(batch_input_shape) == 2):",
        "patch": "@@ -313,7 +313,7 @@ def add_input(self, name, input_shape=None,\n         if dtype == 'float':\n             layer.input = K.placeholder(shape=layer.input_shape, name=name)\n         else:\n-            if len(input_shape) == 1:\n+            if (input_shape and len(input_shape) == 1) or (batch_input_shape and len(batch_input_shape) == 2):\n                 layer.input = K.placeholder(shape=layer.input_shape,\n                                             dtype='int32',\n                                             name=name)"
    },
    {
        "commit_id": "bb45991899a86df0490029661735ad9213f1e3bd",
        "commit_message": "Merge pull request #1388 from kylemcdonald/patch-1\n\ntypo in doc: batch_input_size => batch_input_shape",
        "commit_url": "https://github.com/keras-team/keras/commit/bb45991899a86df0490029661735ad9213f1e3bd",
        "buggy_code": "a `batch_input_size=(...)` to the first layer in your model.",
        "fixed_code": "a `batch_input_shape=(...)` to the first layer in your model.",
        "patch": "@@ -73,7 +73,7 @@ class Recurrent(MaskedLayer):\n         To enable statefulness:\n             - specify `stateful=True` in the layer constructor.\n             - specify a fixed batch size for your model, by passing\n-                a `batch_input_size=(...)` to the first layer in your model.\n+                a `batch_input_shape=(...)` to the first layer in your model.\n                 This is the expected shape of your inputs *including the batch size*.\n                 It should be a tuple of integers, e.g. `(32, 10, 100)`.\n "
    },
    {
        "commit_id": "7a61cc20b94714d964d4eca557da2aa35859e4bb",
        "commit_message": "Merge pull request #1338 from rpinsler/master\n\nFix typos and minor inconsistencies.",
        "commit_url": "https://github.com/keras-team/keras/commit/7a61cc20b94714d964d4eca557da2aa35859e4bb",
        "buggy_code": "The function returns the variable that is passed in, so all types work",
        "fixed_code": "The function returns the variable that is passed in, so all types work.",
        "patch": "@@ -39,7 +39,7 @@ def hard_sigmoid(x):\n \n def linear(x):\n     '''\n-    The function returns the variable that is passed in, so all types work\n+    The function returns the variable that is passed in, so all types work.\n     '''\n     return x\n "
    },
    {
        "commit_id": "7a61cc20b94714d964d4eca557da2aa35859e4bb",
        "commit_message": "Merge pull request #1338 from rpinsler/master\n\nFix typos and minor inconsistencies.",
        "commit_url": "https://github.com/keras-team/keras/commit/7a61cc20b94714d964d4eca557da2aa35859e4bb",
        "buggy_code": "'for 2D square matrices')",
        "fixed_code": "'for 2D square matrices.')",
        "patch": "@@ -69,7 +69,7 @@ def orthogonal(shape, scale=1.1):\n def identity(shape, scale=1):\n     if len(shape) != 2 or shape[0] != shape[1]:\n         raise Exception('Identity matrix initialization can only be used '\n-                        'for 2D square matrices')\n+                        'for 2D square matrices.')\n     else:\n         return K.variable(scale * np.identity(shape[0]))\n "
    },
    {
        "commit_id": "7a61cc20b94714d964d4eca557da2aa35859e4bb",
        "commit_message": "Merge pull request #1338 from rpinsler/master\n\nFix typos and minor inconsistencies.",
        "commit_url": "https://github.com/keras-team/keras/commit/7a61cc20b94714d964d4eca557da2aa35859e4bb",
        "buggy_code": "close to 0. and the activation standard deviation close to 1.",
        "fixed_code": "close to 0 and the activation standard deviation close to 1.",
        "patch": "@@ -6,7 +6,7 @@\n class BatchNormalization(Layer):\n     '''Normalize the activations of the previous layer at each batch,\n     i.e. applies a transformation that maintains the mean activation\n-    close to 0. and the activation standard deviation close to 1.\n+    close to 0 and the activation standard deviation close to 1.\n \n     # Input shape\n         Arbitrary. Use the keyword argument `input_shape`"
    },
    {
        "commit_id": "7a61cc20b94714d964d4eca557da2aa35859e4bb",
        "commit_message": "Merge pull request #1338 from rpinsler/master\n\nFix typos and minor inconsistencies.",
        "commit_url": "https://github.com/keras-team/keras/commit/7a61cc20b94714d964d4eca557da2aa35859e4bb",
        "buggy_code": "'''Expects a binary class matrix instead of a vector of scalar classes",
        "fixed_code": "'''Expects a binary class matrix instead of a vector of scalar classes.",
        "patch": "@@ -35,7 +35,7 @@ def hinge(y_true, y_pred):\n \n \n def categorical_crossentropy(y_true, y_pred):\n-    '''Expects a binary class matrix instead of a vector of scalar classes\n+    '''Expects a binary class matrix instead of a vector of scalar classes.\n     '''\n     return K.mean(K.categorical_crossentropy(y_pred, y_true), axis=-1)\n "
    },
    {
        "commit_id": "7a61cc20b94714d964d4eca557da2aa35859e4bb",
        "commit_message": "Merge pull request #1338 from rpinsler/master\n\nFix typos and minor inconsistencies.",
        "commit_url": "https://github.com/keras-team/keras/commit/7a61cc20b94714d964d4eca557da2aa35859e4bb",
        "buggy_code": "to binary class matrix, for use with categorical_crossentropy",
        "fixed_code": "to binary class matrix, for use with categorical_crossentropy.",
        "patch": "@@ -7,7 +7,7 @@\n \n def to_categorical(y, nb_classes=None):\n     '''Convert class vector (integers from 0 to nb_classes)\n-    to binary class matrix, for use with categorical_crossentropy\n+    to binary class matrix, for use with categorical_crossentropy.\n     '''\n     y = np.asarray(y, dtype='int32')\n     if not nb_classes:"
    },
    {
        "commit_id": "534f68ec7752c615ac0092af2af64796a6d001fb",
        "commit_message": "Merge pull request #1336 from wb14123/loop\n\nfix iteration shadowed in loop",
        "commit_url": "https://github.com/keras-team/keras/commit/534f68ec7752c615ac0092af2af64796a6d001fb",
        "buggy_code": "for iteration in range(400):",
        "fixed_code": "for i in range(400):",
        "patch": "@@ -85,7 +85,7 @@ def sample(a, temperature=1.0):\n         print('----- Generating with seed: \"' + sentence + '\"')\n         sys.stdout.write(generated)\n \n-        for iteration in range(400):\n+        for i in range(400):\n             x = np.zeros((1, maxlen, len(chars)))\n             for t, char in enumerate(sentence):\n                 x[0, t, char_indices[char]] = 1."
    },
    {
        "commit_id": "85e51a0f8f6bfbb2ca8c0b5e07f87e843313c3e9",
        "commit_message": "Fix typos and minor inconsistencies.",
        "commit_url": "https://github.com/keras-team/keras/commit/85e51a0f8f6bfbb2ca8c0b5e07f87e843313c3e9",
        "buggy_code": "The function returns the variable that is passed in, so all types work",
        "fixed_code": "The function returns the variable that is passed in, so all types work.",
        "patch": "@@ -39,7 +39,7 @@ def hard_sigmoid(x):\n \n def linear(x):\n     '''\n-    The function returns the variable that is passed in, so all types work\n+    The function returns the variable that is passed in, so all types work.\n     '''\n     return x\n "
    },
    {
        "commit_id": "85e51a0f8f6bfbb2ca8c0b5e07f87e843313c3e9",
        "commit_message": "Fix typos and minor inconsistencies.",
        "commit_url": "https://github.com/keras-team/keras/commit/85e51a0f8f6bfbb2ca8c0b5e07f87e843313c3e9",
        "buggy_code": "'for 2D square matrices')",
        "fixed_code": "'for 2D square matrices.')",
        "patch": "@@ -69,7 +69,7 @@ def orthogonal(shape, scale=1.1):\n def identity(shape, scale=1):\n     if len(shape) != 2 or shape[0] != shape[1]:\n         raise Exception('Identity matrix initialization can only be used '\n-                        'for 2D square matrices')\n+                        'for 2D square matrices.')\n     else:\n         return K.variable(scale * np.identity(shape[0]))\n "
    },
    {
        "commit_id": "85e51a0f8f6bfbb2ca8c0b5e07f87e843313c3e9",
        "commit_message": "Fix typos and minor inconsistencies.",
        "commit_url": "https://github.com/keras-team/keras/commit/85e51a0f8f6bfbb2ca8c0b5e07f87e843313c3e9",
        "buggy_code": "close to 0. and the activation standard deviation close to 1.",
        "fixed_code": "close to 0 and the activation standard deviation close to 1.",
        "patch": "@@ -6,7 +6,7 @@\n class BatchNormalization(Layer):\n     '''Normalize the activations of the previous layer at each batch,\n     i.e. applies a transformation that maintains the mean activation\n-    close to 0. and the activation standard deviation close to 1.\n+    close to 0 and the activation standard deviation close to 1.\n \n     # Input shape\n         Arbitrary. Use the keyword argument `input_shape`"
    },
    {
        "commit_id": "85e51a0f8f6bfbb2ca8c0b5e07f87e843313c3e9",
        "commit_message": "Fix typos and minor inconsistencies.",
        "commit_url": "https://github.com/keras-team/keras/commit/85e51a0f8f6bfbb2ca8c0b5e07f87e843313c3e9",
        "buggy_code": "'''Expects a binary class matrix instead of a vector of scalar classes",
        "fixed_code": "'''Expects a binary class matrix instead of a vector of scalar classes.",
        "patch": "@@ -35,7 +35,7 @@ def hinge(y_true, y_pred):\n \n \n def categorical_crossentropy(y_true, y_pred):\n-    '''Expects a binary class matrix instead of a vector of scalar classes\n+    '''Expects a binary class matrix instead of a vector of scalar classes.\n     '''\n     return K.mean(K.categorical_crossentropy(y_pred, y_true), axis=-1)\n "
    },
    {
        "commit_id": "85e51a0f8f6bfbb2ca8c0b5e07f87e843313c3e9",
        "commit_message": "Fix typos and minor inconsistencies.",
        "commit_url": "https://github.com/keras-team/keras/commit/85e51a0f8f6bfbb2ca8c0b5e07f87e843313c3e9",
        "buggy_code": "to binary class matrix, for use with categorical_crossentropy",
        "fixed_code": "to binary class matrix, for use with categorical_crossentropy.",
        "patch": "@@ -7,7 +7,7 @@\n \n def to_categorical(y, nb_classes=None):\n     '''Convert class vector (integers from 0 to nb_classes)\n-    to binary class matrix, for use with categorical_crossentropy\n+    to binary class matrix, for use with categorical_crossentropy.\n     '''\n     y = np.asarray(y, dtype='int32')\n     if not nb_classes:"
    },
    {
        "commit_id": "0695b82f7476329bd1dcba1baf482986b357c0c0",
        "commit_message": "fix iteration shadowed in loop",
        "commit_url": "https://github.com/keras-team/keras/commit/0695b82f7476329bd1dcba1baf482986b357c0c0",
        "buggy_code": "for iteration in range(400):",
        "fixed_code": "for i in range(400):",
        "patch": "@@ -85,7 +85,7 @@ def sample(a, temperature=1.0):\n         print('----- Generating with seed: \"' + sentence + '\"')\n         sys.stdout.write(generated)\n \n-        for iteration in range(400):\n+        for i in range(400):\n             x = np.zeros((1, maxlen, len(chars)))\n             for t, char in enumerate(sentence):\n                 x[0, t, char_indices[char]] = 1."
    },
    {
        "commit_id": "7f3cd093c096c03d9710940dc5cd700c2b7142a6",
        "commit_message": "Fix flaky test",
        "commit_url": "https://github.com/keras-team/keras/commit/7f3cd093c096c03d9710940dc5cd700c2b7142a6",
        "buggy_code": "assert(history.history['val_acc'][-1] > 0.9)",
        "fixed_code": "assert(history.history['val_acc'][-1] > 0.85)",
        "patch": "@@ -39,7 +39,7 @@ def test_image_classification():\n     history = model.fit(X_train, y_train, nb_epoch=10, batch_size=16,\n                         validation_data=(X_test, y_test),\n                         show_accuracy=True, verbose=0)\n-    assert(history.history['val_acc'][-1] > 0.9)\n+    assert(history.history['val_acc'][-1] > 0.85)\n \n \n if __name__ == '__main__':"
    },
    {
        "commit_id": "d870e45eb0e4b3d6a8c8441d797becde2d17ab4d",
        "commit_message": "Fix flaky test",
        "commit_url": "https://github.com/keras-team/keras/commit/d870e45eb0e4b3d6a8c8441d797becde2d17ab4d",
        "buggy_code": "assert_allclose(norm, np.ones_like(norm).astype('float32'))",
        "fixed_code": "assert_allclose(norm, np.ones_like(norm).astype('float32'), rtol=1e-05)",
        "patch": "@@ -24,7 +24,7 @@ def test_unitnorm_constraint():\n                    class_mode='binary')\n     lookup.train_on_batch(X1, np.array([[1], [0]], dtype='int32'))\n     norm = np.linalg.norm(K.get_value(lookup.params[0]), axis=1)\n-    assert_allclose(norm, np.ones_like(norm).astype('float32'))\n+    assert_allclose(norm, np.ones_like(norm).astype('float32'), rtol=1e-05)\n \n \n if __name__ == '__main__':"
    },
    {
        "commit_id": "7a6a47888c8c54da54d746a0c3e1e1d08d46f6b6",
        "commit_message": "Merge pull request #1324 from Chasego/patch-1\n\nFix the wrong link",
        "commit_url": "https://github.com/keras-team/keras/commit/7a6a47888c8c54da54d746a0c3e1e1d08d46f6b6",
        "buggy_code": "http://arxiv.org/abs/1503.08895",
        "fixed_code": "http://arxiv.org/abs/1502.05698",
        "patch": "@@ -3,7 +3,7 @@\n References:\n - Jason Weston, Antoine Bordes, Sumit Chopra, Tomas Mikolov, Alexander M. Rush,\n   \"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\",\n-  http://arxiv.org/abs/1503.08895\n+  http://arxiv.org/abs/1502.05698\n \n - Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus,\n   \"End-To-End Memory Networks\","
    },
    {
        "commit_id": "d8e83cc773a0f7bd7ed550c784bacda4fa4da53b",
        "commit_message": "Fix the wrong link\n\nFix the wrong link for \"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\"",
        "commit_url": "https://github.com/keras-team/keras/commit/d8e83cc773a0f7bd7ed550c784bacda4fa4da53b",
        "buggy_code": "http://arxiv.org/abs/1503.08895",
        "fixed_code": "http://arxiv.org/abs/1502.05698",
        "patch": "@@ -3,7 +3,7 @@\n References:\n - Jason Weston, Antoine Bordes, Sumit Chopra, Tomas Mikolov, Alexander M. Rush,\n   \"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\",\n-  http://arxiv.org/abs/1503.08895\n+  http://arxiv.org/abs/1502.05698\n \n - Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus,\n   \"End-To-End Memory Networks\","
    },
    {
        "commit_id": "332f5c661f3eeb370be7fd599c5e62bea4dfb576",
        "commit_message": "Merge pull request #1307 from gw0/fix-shape-tuples\n\nFix shapes should be tuples.",
        "commit_url": "https://github.com/keras-team/keras/commit/332f5c661f3eeb370be7fd599c5e62bea4dfb576",
        "buggy_code": "self.b = K.zeros((self.output_dim))",
        "fixed_code": "self.b = K.zeros((self.output_dim,))",
        "patch": "@@ -1018,7 +1018,7 @@ def build(self):\n         input_dim = self.input_shape[2]\n \n         self.W = self.init((input_dim, self.output_dim))\n-        self.b = K.zeros((self.output_dim))\n+        self.b = K.zeros((self.output_dim,))\n \n         self.params = [self.W, self.b]\n         self.regularizers = []"
    },
    {
        "commit_id": "bdf084e35ef015eae45d3eed79758f652c717056",
        "commit_message": "Fix shapes should be tuples.",
        "commit_url": "https://github.com/keras-team/keras/commit/bdf084e35ef015eae45d3eed79758f652c717056",
        "buggy_code": "self.b = K.zeros((self.output_dim))",
        "fixed_code": "self.b = K.zeros((self.output_dim,))",
        "patch": "@@ -1018,7 +1018,7 @@ def build(self):\n         input_dim = self.input_shape[2]\n \n         self.W = self.init((input_dim, self.output_dim))\n-        self.b = K.zeros((self.output_dim))\n+        self.b = K.zeros((self.output_dim,))\n \n         self.params = [self.W, self.b]\n         self.regularizers = []"
    },
    {
        "commit_id": "3f67168c44f8c7d34e5266a99bbdd90669a8eaa6",
        "commit_message": "Fix flaky test",
        "commit_url": "https://github.com/keras-team/keras/commit/3f67168c44f8c7d34e5266a99bbdd90669a8eaa6",
        "buggy_code": "assert(loss < 0.8)",
        "fixed_code": "assert(loss < 0.9)",
        "patch": "@@ -64,7 +64,7 @@ def data_generator(train):\n     model.fit_generator(data_generator(True), len(X_train), nb_epoch, show_accuracy=True, validation_data=(X_test, y_test))\n \n     loss = model.evaluate(X_train, y_train, verbose=0)\n-    assert(loss < 0.8)\n+    assert(loss < 0.9)\n \n \n def test_sequential():"
    },
    {
        "commit_id": "d04cac6526171af608baf38f68f9767af62b0555",
        "commit_message": "Fix GRU activation",
        "commit_url": "https://github.com/keras-team/keras/commit/d04cac6526171af608baf38f68f9767af62b0555",
        "buggy_code": "hh = self.inner_activation(x_h + K.dot(r * h_tm1, self.U_h))",
        "fixed_code": "hh = self.activation(x_h + K.dot(r * h_tm1, self.U_h))",
        "patch": "@@ -326,7 +326,7 @@ def step(self, x, states):\n         z = self.inner_activation(x_z + K.dot(h_tm1, self.U_z))\n         r = self.inner_activation(x_r + K.dot(h_tm1, self.U_r))\n \n-        hh = self.inner_activation(x_h + K.dot(r * h_tm1, self.U_h))\n+        hh = self.activation(x_h + K.dot(r * h_tm1, self.U_h))\n         h = z * h_tm1 + (1 - z) * hh\n         return h, [h]\n "
    },
    {
        "commit_id": "42b3d37a54545882699283b5764cf3c997f8d9cd",
        "commit_message": "Fix flaky test in preprocessing",
        "commit_url": "https://github.com/keras-team/keras/commit/42b3d37a54545882699283b5764cf3c997f8d9cd",
        "buggy_code": "assert couple[0] - couple[1] < 3",
        "fixed_code": "assert couple[0] - couple[1] <= 3",
        "patch": "@@ -43,7 +43,7 @@ def test_skipgrams():\n     couples, labels = skipgrams(np.arange(5), vocabulary_size=5, window_size=1,\n                                 categorical=True)\n     for couple in couples:\n-        assert couple[0] - couple[1] < 3\n+        assert couple[0] - couple[1] <= 3\n     for l in labels:\n         assert len(l) == 2\n "
    },
    {
        "commit_id": "3d51a26749937cb1a1aec40c20bc505e82809dce",
        "commit_message": "Fix json serializing",
        "commit_url": "https://github.com/keras-team/keras/commit/3d51a26749937cb1a1aec40c20bc505e82809dce",
        "buggy_code": "'inputs': [s],",
        "fixed_code": "'inputs': [name],",
        "patch": "@@ -449,7 +449,7 @@ def add_shared_node(self, layer, name, inputs=[], merge_mode=None,\n                 self.namespace.add(sh_name)\n                 self.nodes[sh_name] = sh\n                 self.node_config.append({'name': sh_name,\n-                                         'inputs': [s],\n+                                         'inputs': [name],\n                                          'create_output': create_output})\n                 if create_output:\n                     self.add_output(sh_name, input=sh_name)"
    },
    {
        "commit_id": "08470363ad652eb72bec82ee486859d1d3f0629b",
        "commit_message": "Merge pull request #1243 from jeffzhengye/rnn_float32_issue\n\nfix float32 issue: int32 times float32 will generate float64",
        "commit_url": "https://github.com/keras-team/keras/commit/08470363ad652eb72bec82ee486859d1d3f0629b",
        "buggy_code": "X *= K.expand_dims(mask)",
        "fixed_code": "X *= K.cast(K.expand_dims(mask), X.dtype)",
        "patch": "@@ -65,7 +65,7 @@ def get_output(self, train=False):\n         mask = self.get_output_mask(train)\n         if mask:\n             # apply mask\n-            X *= K.expand_dims(mask)\n+            X *= K.cast(K.expand_dims(mask), X.dtype)\n             masking = True\n         else:\n             masking = False"
    },
    {
        "commit_id": "f04272e6978662d954fc25c4d8cf9329004061f9",
        "commit_message": "fix float32 issue: int32 times float32 will generate float64",
        "commit_url": "https://github.com/keras-team/keras/commit/f04272e6978662d954fc25c4d8cf9329004061f9",
        "buggy_code": "X *= K.expand_dims(mask)",
        "fixed_code": "X *= K.expand_dims(mask).astype(X.dtype)",
        "patch": "@@ -65,7 +65,7 @@ def get_output(self, train=False):\n         mask = self.get_output_mask(train)\n         if mask:\n             # apply mask\n-            X *= K.expand_dims(mask)\n+            X *= K.expand_dims(mask).astype(X.dtype)\n             masking = True\n         else:\n             masking = False"
    },
    {
        "commit_id": "a4fff5aba3679a7d98297c9cc74764080a268c18",
        "commit_message": "Fix set_input in Sequential container.",
        "commit_url": "https://github.com/keras-team/keras/commit/a4fff5aba3679a7d98297c9cc74764080a268c18",
        "buggy_code": "ndim = len(K.get_shape(l.input))",
        "fixed_code": "ndim = K.ndim(l.input)",
        "patch": "@@ -84,7 +84,7 @@ def get_output(self, train=False):\n     def set_input(self):\n         for l in self.layers:\n             if hasattr(l, 'input'):\n-                ndim = len(K.get_shape(l.input))\n+                ndim = K.ndim(l.input)\n                 self.layers[0].input = K.placeholder(ndim=ndim)\n                 break\n "
    },
    {
        "commit_id": "c2534964b76015eb3d76261b025c7556b354764c",
        "commit_message": "Fix SimpleRNN step function.",
        "commit_url": "https://github.com/keras-team/keras/commit/c2534964b76015eb3d76261b025c7556b354764c",
        "buggy_code": "output = self.activation(h * K.dot(prev_output, self.U))",
        "fixed_code": "output = self.activation(h + K.dot(prev_output, self.U))",
        "patch": "@@ -158,7 +158,7 @@ def step(self, x, states):\n         assert len(states) == 1\n         prev_output = states[0]\n         h = K.dot(x, self.W) + self.b\n-        output = self.activation(h * K.dot(prev_output, self.U))\n+        output = self.activation(h + K.dot(prev_output, self.U))\n         return output, [output]\n \n     def get_config(self):"
    },
    {
        "commit_id": "258688408042b9ba757e75e6fb1da3097afb4e47",
        "commit_message": "Merge pull request #1216 from farizrahman4u/patch-20\n\nBug fix - Siamese",
        "commit_url": "https://github.com/keras-team/keras/commit/258688408042b9ba757e75e6fb1da3097afb4e47",
        "buggy_code": "\"layer\": self.layer.get_config,",
        "fixed_code": "\"layer\": self.layer.get_config(),",
        "patch": "@@ -1381,7 +1381,7 @@ def set_weights(self, weights):\n     def get_config(self):\n \n         config = {\"name\": self.__class__.__name__,\n-                  \"layer\": self.layer.get_config,\n+                  \"layer\": self.layer.get_config(),\n                   \"inputs\": [m.get_config() for m in self.inputs],\n                   \"merge_mode\": self.merge_mode,\n                   \"concat_axis\": self.concat_axis,"
    },
    {
        "commit_id": "cee4f72a8ee98468146a4c97f53592b77127654d",
        "commit_message": "Bug fix - Siamese",
        "commit_url": "https://github.com/keras-team/keras/commit/cee4f72a8ee98468146a4c97f53592b77127654d",
        "buggy_code": "\"layer\": self.layer.get_config,",
        "fixed_code": "\"layer\": self.layer.get_config(),",
        "patch": "@@ -1381,7 +1381,7 @@ def set_weights(self, weights):\n     def get_config(self):\n \n         config = {\"name\": self.__class__.__name__,\n-                  \"layer\": self.layer.get_config,\n+                  \"layer\": self.layer.get_config(),\n                   \"inputs\": [m.get_config() for m in self.inputs],\n                   \"merge_mode\": self.merge_mode,\n                   \"concat_axis\": self.concat_axis,"
    },
    {
        "commit_id": "31cf6b16f48d1da338c7af26d64f5104534fe0ab",
        "commit_message": "Fix Adadelta serialization",
        "commit_url": "https://github.com/keras-team/keras/commit/31cf6b16f48d1da338c7af26d64f5104534fe0ab",
        "buggy_code": "\"rho\": float(K.get_value(self.rho)),",
        "fixed_code": "\"rho\": self.rho,",
        "patch": "@@ -168,7 +168,7 @@ def get_updates(self, params, constraints, loss):\n     def get_config(self):\n         return {\"name\": self.__class__.__name__,\n                 \"lr\": float(K.get_value(self.lr)),\n-                \"rho\": float(K.get_value(self.rho)),\n+                \"rho\": self.rho,\n                 \"epsilon\": self.epsilon}\n \n "
    },
    {
        "commit_id": "f295ecb302ea3298ab61dda892f323c7c7807d02",
        "commit_message": "Actually fix floatx encoding",
        "commit_url": "https://github.com/keras-team/keras/commit/f295ecb302ea3298ab61dda892f323c7c7807d02",
        "buggy_code": "floatx = floatx.encode('ascii')",
        "fixed_code": "floatx = str(floatx)",
        "patch": "@@ -22,7 +22,7 @@ def set_floatx(floatx):\n     global _FLOATX\n     if floatx not in {'float32', 'float64'}:\n         raise Exception('Unknown floatx type: ' + str(floatx))\n-    floatx = floatx.encode('ascii')\n+    floatx = str(floatx)\n     _FLOATX = floatx\n \n "
    },
    {
        "commit_id": "1c6ab36c63044199c2219e9c9cb1f03e1b54361f",
        "commit_message": "Fix typo in recurrent.",
        "commit_url": "https://github.com/keras-team/keras/commit/1c6ab36c63044199c2219e9c9cb1f03e1b54361f",
        "buggy_code": "self.states = [K.zeros(input_shape[0], self.output_dim)]",
        "fixed_code": "self.states = [K.zeros((input_shape[0], self.output_dim))]",
        "patch": "@@ -216,7 +216,7 @@ def build(self):\n                 raise Exception('If a RNN is stateful, a complete ' +\n                                 'input_shape must be provided ' +\n                                 '(including batch size).')\n-            self.states = [K.zeros(input_shape[0], self.output_dim)]\n+            self.states = [K.zeros((input_shape[0], self.output_dim))]\n         else:\n             # initial states: all-zero tensor of shape (output_dim)\n             self.states = [None]"
    },
    {
        "commit_id": "535af0b17d15baf660ea25aeaad6af413e0e8dda",
        "commit_message": "Merge pull request #1137 from stonebig/patch-1\n\nversion adjustement",
        "commit_url": "https://github.com/keras-team/keras/commit/535af0b17d15baf660ea25aeaad6af413e0e8dda",
        "buggy_code": "__version__ = '0.2.0'",
        "fixed_code": "__version__ = '0.3.0'",
        "patch": "@@ -12,4 +12,4 @@\n See http://keras.io/\r\n \"\"\"\r\n \r\n-__version__ = '0.2.0'\r\n+__version__ = '0.3.0'\r"
    },
    {
        "commit_id": "cbee000b66b747e09ea6521ff08fcdfdaecead6c",
        "commit_message": "Fix TF RNN issues",
        "commit_url": "https://github.com/keras-team/keras/commit/cbee000b66b747e09ea6521ff08fcdfdaecead6c",
        "buggy_code": "model.add_input(name='input', input_shape=(1,), dtype=int)",
        "fixed_code": "model.add_input(name='input', input_shape=(maxlen,), dtype=int)",
        "patch": "@@ -41,7 +41,7 @@\n \n print('Build model...')\n model = Graph()\n-model.add_input(name='input', input_shape=(1,), dtype=int)\n+model.add_input(name='input', input_shape=(maxlen,), dtype=int)\n model.add_node(Embedding(max_features, 128, input_length=maxlen),\n                name='embedding', input='input')\n model.add_node(LSTM(64), name='forward', input='embedding')"
    },
    {
        "commit_id": "cbee000b66b747e09ea6521ff08fcdfdaecead6c",
        "commit_message": "Fix TF RNN issues",
        "commit_url": "https://github.com/keras-team/keras/commit/cbee000b66b747e09ea6521ff08fcdfdaecead6c",
        "buggy_code": "input_list = input_list.reverse()",
        "fixed_code": "input_list.reverse()",
        "patch": "@@ -381,7 +381,7 @@ def rnn(step_function, inputs, initial_states,\n     successive_states = []\n     successive_outputs = []\n     if go_backwards:\n-        input_list = input_list.reverse()\n+        input_list.reverse()\n     for input in input_list:\n         output, new_states = step_function(input, states)\n         if masking:"
    },
    {
        "commit_id": "7ecd6c3c5f4d3008b197a40e89681455bf3d796c",
        "commit_message": "Fix backend tests",
        "commit_url": "https://github.com/keras-team/keras/commit/7ecd6c3c5f4d3008b197a40e89681455bf3d796c",
        "buggy_code": "@pytest.mark.skipif(sys.version_info < (2, 7), reason=\"Requires Python 2.7\")",
        "fixed_code": "@pytest.mark.skipif(sys.version_info.major != 2, reason=\"Requires Python 2.7\")",
        "patch": "@@ -38,7 +38,7 @@ def check_two_tensor_operation(function_name, x_input_shape,\n     assert_allclose(zth, ztf, atol=1e-06)\n \n \n-@pytest.mark.skipif(sys.version_info < (2, 7), reason=\"Requires Python 2.7\")\n+@pytest.mark.skipif(sys.version_info.major != 2, reason=\"Requires Python 2.7\")\n class TestBackend(unittest.TestCase):\n \n     def test_linear_operations(self):"
    },
    {
        "commit_id": "b82223b2f2b3f4f5bef63758c149b50612fbe837",
        "commit_message": "Merge pull request #1037 from farizrahman4u/patch-9\n\nFix load_from_json for models with Lambda layer",
        "commit_url": "https://github.com/keras-team/keras/commit/b82223b2f2b3f4f5bef63758c149b50612fbe837",
        "buggy_code": "from ..layers.core import Dense, Merge, Dropout, Activation, Reshape, Flatten, RepeatVector, Layer, AutoEncoder, Masking, Permute",
        "fixed_code": "from ..layers.core import Dense, Merge, Dropout, Activation, Reshape, Flatten, RepeatVector, Layer, AutoEncoder, Masking, Permute, Lambda, MaskedLambda, LambdaMerge",
        "patch": "@@ -5,7 +5,7 @@\n import copy\n \n from ..layers.advanced_activations import LeakyReLU, PReLU\n-from ..layers.core import Dense, Merge, Dropout, Activation, Reshape, Flatten, RepeatVector, Layer, AutoEncoder, Masking, Permute\n+from ..layers.core import Dense, Merge, Dropout, Activation, Reshape, Flatten, RepeatVector, Layer, AutoEncoder, Masking, Permute, Lambda, MaskedLambda, LambdaMerge\n from ..layers.core import ActivityRegularization, TimeDistributedDense, TimeDistributedMerge, AutoEncoder, MaxoutDense\n from ..layers.convolutional import Convolution1D, Convolution2D, MaxPooling1D, MaxPooling2D, ZeroPadding2D\n from ..layers.embeddings import Embedding, WordContextProduct"
    },
    {
        "commit_id": "16590ccce51c44e72b0826f50641bcbb2a09a3d5",
        "commit_message": "Fix typo in Lambda layer",
        "commit_url": "https://github.com/keras-team/keras/commit/16590ccce51c44e72b0826f50641bcbb2a09a3d5",
        "buggy_code": "if self._ouput_shape is None:",
        "fixed_code": "if self._output_shape is None:",
        "patch": "@@ -1005,7 +1005,7 @@ def __init__(self, function, output_shape=None):\n \n     @property\n     def output_shape(self):\n-        if self._ouput_shape is None:\n+        if self._output_shape is None:\n             return self.input_shape\n         elif type(self._output_shape) == tuple:\n             return (self.input_shape[0], ) + self._output_shape"
    },
    {
        "commit_id": "24b5e80667c8998d7e5e9689085fecc92a9506d3",
        "commit_message": "Fix axis specification in TF.",
        "commit_url": "https://github.com/keras-team/keras/commit/24b5e80667c8998d7e5e9689085fecc92a9506d3",
        "buggy_code": "x = T.clip(x, _EPSILON, np.inf)",
        "fixed_code": "x = T.clip(x, 0., np.inf)",
        "patch": "@@ -138,7 +138,7 @@ def abs(x):\n \n \n def sqrt(x):\n-    x = T.clip(x, _EPSILON, np.inf)\n+    x = T.clip(x, 0., np.inf)\n     return T.sqrt(x)\n \n "
    },
    {
        "commit_id": "e037e17557ddeb989de970bb2dc875a1fbea230c",
        "commit_message": "Merge pull request #950 from rushter/autoencoder-fix\n\nFix AutoEncoder's input_shape",
        "commit_url": "https://github.com/keras-team/keras/commit/e037e17557ddeb989de970bb2dc875a1fbea230c",
        "buggy_code": "self.encoder.previous.output_shape",
        "fixed_code": "return self.encoder.input_shape",
        "patch": "@@ -863,7 +863,7 @@ def _get_hidden(self, train=False):\n \n     @property\n     def input_shape(self):\n-        self.encoder.previous.output_shape\n+        return self.encoder.input_shape\n \n     @property\n     def output_shape(self):"
    },
    {
        "commit_id": "28882a868dc8a3da12004a9303756cc6980293cd",
        "commit_message": "fix https://github.com/fchollet/keras/pull/970#issuecomment-154886091",
        "commit_url": "https://github.com/keras-team/keras/commit/28882a868dc8a3da12004a9303756cc6980293cd",
        "buggy_code": "model.compile('adam',{'output':'binary_crossentropy'})",
        "fixed_code": "model.compile('adam', {'output':'binary_crossentropy'})",
        "patch": "@@ -55,7 +55,7 @@\n model.add_output(name='output', input='sigmoid')\n \n # try using different optimizers and different optimizer configs\n-model.compile('adam',{'output':'binary_crossentropy'})\n+model.compile('adam', {'output':'binary_crossentropy'})\n \n print(\"Train...\")\n model.fit({'input':X_train, 'output':y_train}, batch_size=batch_size, nb_epoch=4)"
    },
    {
        "commit_id": "cc0108097c7dcd52977066bd9aa754885945088b",
        "commit_message": "Fix AutoEncoder's input_shape",
        "commit_url": "https://github.com/keras-team/keras/commit/cc0108097c7dcd52977066bd9aa754885945088b",
        "buggy_code": "self.encoder.previous.output_shape",
        "fixed_code": "return self.encoder.input_shape",
        "patch": "@@ -859,7 +859,7 @@ def _get_hidden(self, train=False):\n \n     @property\n     def input_shape(self):\n-        self.encoder.previous.output_shape\n+        return self.encoder.input_shape\n \n     @property\n     def output_shape(self):"
    },
    {
        "commit_id": "5964848bdfb6dd6848148e7c86fda5d2d458e52d",
        "commit_message": "Fix Python3 compatibility",
        "commit_url": "https://github.com/keras-team/keras/commit/5964848bdfb6dd6848148e7c86fda5d2d458e52d",
        "buggy_code": "if type(dot_axes[0]) not in [list, tuple] or type(dot_axes[1]) not in [list, tuple]:",
        "fixed_code": "if type(dot_axes[0]) not in [list, tuple, range] or type(dot_axes[1]) not in [list, tuple, range]:",
        "patch": "@@ -308,7 +308,7 @@ def __init__(self, layers, mode='sum', concat_axis=-1, dot_axes=-1):\n                     raise Exception(\"Invalid type for dot_axes - should be a list.\")\n                 if len(dot_axes) != 2:\n                     raise Exception(\"Invalid format for dot_axes - should contain two elements.\")\n-                if type(dot_axes[0]) not in [list, tuple] or type(dot_axes[1]) not in [list, tuple]:\n+                if type(dot_axes[0]) not in [list, tuple, range] or type(dot_axes[1]) not in [list, tuple, range]:\n                     raise Exception(\"Invalid format for dot_axes - list elements should have type 'list' or 'tuple'.\")\n                 for i in range(len(dot_axes[0])):\n                     if shape1[dot_axes[0][i]] != shape2[dot_axes[1][i]]:"
    },
    {
        "commit_id": "99331b83f92fce6d18463c43f8f11621399246e1",
        "commit_message": "Merge pull request #938 from farizrahman4u/patch-12\n\nAvoid recalculation of output in join merge.",
        "commit_url": "https://github.com/keras-team/keras/commit/99331b83f92fce6d18463c43f8f11621399246e1",
        "buggy_code": "inputs[X.name] = self.layers[i].get_output(train)",
        "fixed_code": "inputs[X.name] = X",
        "patch": "@@ -381,7 +381,7 @@ def get_output(self, train=False):\n                 if X.name is None:\n                     raise ValueError(\"merge_mode='join' only works with named inputs\")\n                 else:\n-                    inputs[X.name] = self.layers[i].get_output(train)\n+                    inputs[X.name] = X\n             return inputs\n         elif self.mode == 'mul':\n             s = self.layers[0].get_output(train)"
    },
    {
        "commit_id": "5590dc7b0dcec920403fcda0e09620d56c925bf5",
        "commit_message": "FIx read-only property can't be changed",
        "commit_url": "https://github.com/keras-team/keras/commit/5590dc7b0dcec920403fcda0e09620d56c925bf5",
        "buggy_code": "self.input_shape = input_shape",
        "fixed_code": "self._input_shape = input_shape",
        "patch": "@@ -74,7 +74,7 @@ def build(self):\n         self.alphas = sharedX(self.alpha_init * np.ones(input_shape))\n         self.betas = sharedX(self.beta_init * np.ones(input_shape))\n         self.params = [self.alphas, self.betas]\n-        self.input_shape = input_shape\n+        self._input_shape = input_shape\n \n         if self.initial_weights is not None:\n             self.set_weights(self.initial_weights)"
    },
    {
        "commit_id": "a2d01238af24c38a84b5eca1a719bc1b69029174",
        "commit_message": "Fix flaky Travis test",
        "commit_url": "https://github.com/keras-team/keras/commit/a2d01238af24c38a84b5eca1a719bc1b69029174",
        "buggy_code": "self.assertTrue(history.history['val_acc'][-1] > 0.9)",
        "fixed_code": "self.assertTrue(history.history['val_acc'][-1] > 0.8)",
        "patch": "@@ -34,7 +34,7 @@ def test_vector_clf(self):\n         model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n         history = model.fit(X_train, y_train, nb_epoch=15, batch_size=16, validation_data=(X_test, y_test), show_accuracy=True, verbose=2)\n         print(history.history)\n-        self.assertTrue(history.history['val_acc'][-1] > 0.9)\n+        self.assertTrue(history.history['val_acc'][-1] > 0.8)\n \n     def test_vector_reg(self):\n         nb_hidden = 10"
    },
    {
        "commit_id": "ba982e7ee030afb946b246d85132533dde0ffe2f",
        "commit_message": "Whitespace fix",
        "commit_url": "https://github.com/keras-team/keras/commit/ba982e7ee030afb946b246d85132533dde0ffe2f",
        "buggy_code": "dot_axes = [range(dot_axes % n1,n1), range(dot_axes % n2,n2)]",
        "fixed_code": "dot_axes = [range(dot_axes % n1, n1), range(dot_axes % n2, n2)]",
        "patch": "@@ -300,7 +300,7 @@ def __init__(self, layers, mode='sum', concat_axis=-1, dot_axes=-1):\n             if mode == 'dot':\n                 if type(dot_axes) == int:\n                     if dot_axes < 0:\n-                        dot_axes = [range(dot_axes % n1,n1), range(dot_axes % n2,n2)]\n+                        dot_axes = [range(dot_axes % n1, n1), range(dot_axes % n2, n2)]\n                     else:\n                         dot_axes = [range(n1 - dot_axes, n2), range(1, dot_axes + 1)]\n                 for i in range(len(dot_axes[0])):"
    },
    {
        "commit_id": "1c7585a5639970837a3e37b5c87ac8fe0f2ae212",
        "commit_message": "Fix failing test",
        "commit_url": "https://github.com/keras-team/keras/commit/1c7585a5639970837a3e37b5c87ac8fe0f2ae212",
        "buggy_code": "history = model.fit(X_train, y_train, nb_epoch=12, batch_size=16, validation_data=(X_test, y_test), show_accuracy=True, verbose=2)",
        "fixed_code": "history = model.fit(X_train, y_train, nb_epoch=15, batch_size=16, validation_data=(X_test, y_test), show_accuracy=True, verbose=2)",
        "patch": "@@ -32,7 +32,7 @@ def test_vector_clf(self):\n         model.add(Dense(y_train.shape[-1]))\n         model.add(Activation('softmax'))\n         model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n-        history = model.fit(X_train, y_train, nb_epoch=12, batch_size=16, validation_data=(X_test, y_test), show_accuracy=True, verbose=2)\n+        history = model.fit(X_train, y_train, nb_epoch=15, batch_size=16, validation_data=(X_test, y_test), show_accuracy=True, verbose=2)\n         print(history.history)\n         self.assertTrue(history.history['val_acc'][-1] > 0.9)\n "
    },
    {
        "commit_id": "22566c37ce75ec6ddecf62be27b8ba98456695e2",
        "commit_message": "Fix dot_axes API in Merge",
        "commit_url": "https://github.com/keras-team/keras/commit/22566c37ce75ec6ddecf62be27b8ba98456695e2",
        "buggy_code": "dot_axes = len(shape1) - 1",
        "fixed_code": "dot_axes = dot_axes % len(shape1)",
        "patch": "@@ -298,7 +298,7 @@ def __init__(self, layers, mode='sum', concat_axis=-1, dot_axes=-1):\n             if mode == 'dot':\n                 if type(dot_axes) == int:\n                     if dot_axes < 0:\n-                        dot_axes = len(shape1) - 1\n+                        dot_axes = dot_axes % len(shape1)\n                     dot_axes = [range(len(shape1) - dot_axes, len(shape2)), range(1, dot_axes + 1)]\n                 for i in range(len(dot_axes[0])):\n                     if shape1[dot_axes[0][i]] != shape2[dot_axes[1][i]]:"
    },
    {
        "commit_id": "ad254f99ebf3ba32607fd0395edff48d19b98121",
        "commit_message": "Bug fix",
        "commit_url": "https://github.com/keras-team/keras/commit/ad254f99ebf3ba32607fd0395edff48d19b98121",
        "buggy_code": "output_shape_func = marshal.loads.dumps(self._output_shape)",
        "fixed_code": "output_shape_func = marshal.loads(self._output_shape)",
        "patch": "@@ -917,7 +917,7 @@ def output_shape(self):\n \t\tif type(self._output_shape) == tuple:\n \t\t\treturn self._output_shape\n \t\telse:\n-\t\t\toutput_shape_func = marshal.loads.dumps(self._output_shape)\n+\t\t\toutput_shape_func = marshal.loads(self._output_shape)\n \t\t\toutput_shape_func = types.FunctionType(output_shape_func, globals())\n \t\t\treturn output_shape_func(self.previous)\n "
    },
    {
        "commit_id": "6e2e6eff89bdb293faf2c4d39be7db07a5f87ddb",
        "commit_message": "Merge pull request #892 from amitbeka/fix-requirements\n\nfix setup.py: add six as a requirement",
        "commit_url": "https://github.com/keras-team/keras/commit/6e2e6eff89bdb293faf2c4d39be7db07a5f87ddb",
        "buggy_code": "install_requires=['theano', 'pyyaml'],",
        "fixed_code": "install_requires=['theano', 'pyyaml', 'six'],",
        "patch": "@@ -10,7 +10,7 @@\n       url='https://github.com/fchollet/keras',\n       download_url='https://github.com/fchollet/keras/tarball/0.2.0',\n       license='MIT',\n-      install_requires=['theano', 'pyyaml'],\n+      install_requires=['theano', 'pyyaml', 'six'],\n       extras_require={\n           'h5py': ['h5py'],\n       },"
    },
    {
        "commit_id": "e60680b12c30ad053f37488a398292b9cb2774aa",
        "commit_message": "fix setup.py: add six as a requirement\n\nSigned-off-by: Amit Beka <amit.beka@gmail.com>",
        "commit_url": "https://github.com/keras-team/keras/commit/e60680b12c30ad053f37488a398292b9cb2774aa",
        "buggy_code": "install_requires=['theano', 'pyyaml'],",
        "fixed_code": "install_requires=['theano', 'pyyaml', 'six'],",
        "patch": "@@ -10,7 +10,7 @@\n       url='https://github.com/fchollet/keras',\n       download_url='https://github.com/fchollet/keras/tarball/0.2.0',\n       license='MIT',\n-      install_requires=['theano', 'pyyaml'],\n+      install_requires=['theano', 'pyyaml', 'six'],\n       extras_require={\n           'h5py': ['h5py'],\n       },"
    },
    {
        "commit_id": "6cc827ca5521bf830e9be619fb0a03c2841138ea",
        "commit_message": "Bug fix",
        "commit_url": "https://github.com/keras-team/keras/commit/6cc827ca5521bf830e9be619fb0a03c2841138ea",
        "buggy_code": "input_shapes = set([l.output_shape.pop(concat_axis) for l in layers])",
        "fixed_code": "input_shapes = set([list(l.output_shape).pop(concat_axis) for l in layers])",
        "patch": "@@ -276,7 +276,7 @@ def __init__(self, layers, mode='sum', concat_axis=-1):\n             if len(input_shapes) > 1:\n                 raise Exception(\"Only layers of same output shape can be merged using \" + mode + \" mode\")\n         elif mode == 'concat':\n-            input_shapes = set([l.output_shape.pop(concat_axis) for l in layers])\n+            input_shapes = set([list(l.output_shape).pop(concat_axis) for l in layers])\n             if len(input_shapes) > 1:\n                 raise Exception(\"Only layers with same dimensions across all axes except concat axis can me merged using concat mode\")\n         self.mode = mode"
    },
    {
        "commit_id": "80e85836c18df54ef0b7c3f29a6d9821226eca48",
        "commit_message": "Merge pull request #876 from farizrahman4u/patch-2\n\nUpdate comment to include new join merge mode",
        "commit_url": "https://github.com/keras-team/keras/commit/80e85836c18df54ef0b7c3f29a6d9821226eca48",
        "buggy_code": "mode: {'sum', 'mul', 'concat', 'ave'}",
        "fixed_code": "mode: {'sum', 'mul', 'concat', 'ave', 'join'}",
        "patch": "@@ -263,7 +263,7 @@ def get_config(self):\n class Merge(Layer):\n     def __init__(self, layers, mode='sum', concat_axis=-1):\n         ''' Merge the output of a list of layers or containers into a single tensor.\n-            mode: {'sum', 'mul', 'concat', 'ave'}\n+            mode: {'sum', 'mul', 'concat', 'ave', 'join'}\n         '''\n         if len(layers) < 2:\n             raise Exception(\"Please specify two or more input layers (or containers) to merge\")"
    },
    {
        "commit_id": "a19c9ecfbd99a0fc60c476fb8a0fbd3284a9d620",
        "commit_message": "Merge pull request #865 from suixudongi8/patch-1\n\nUpdate optimizers.py",
        "commit_url": "https://github.com/keras-team/keras/commit/a19c9ecfbd99a0fc60c476fb8a0fbd3284a9d620",
        "buggy_code": "\"decay\": float(self.decay),",
        "fixed_code": "\"decay\": float(self.decay.get_value()),",
        "patch": "@@ -82,7 +82,7 @@ def get_config(self):\n         return {\"name\": self.__class__.__name__,\n                 \"lr\": float(self.lr.get_value()),\n                 \"momentum\": float(self.momentum.get_value()),\n-                \"decay\": float(self.decay),\n+                \"decay\": float(self.decay.get_value()),\n                 \"nesterov\": self.nesterov}\n \n "
    },
    {
        "commit_id": "11e4c4b90f3ce07b10aa06a0f117e122b0c7b368",
        "commit_message": "Update optimizers.py\n\nBug:\r\nfloat() argument must be a string or a number, not 'TensorSharedVariable'\r\nfixed!",
        "commit_url": "https://github.com/keras-team/keras/commit/11e4c4b90f3ce07b10aa06a0f117e122b0c7b368",
        "buggy_code": "\"decay\": float(self.decay),",
        "fixed_code": "\"decay\": float(self.decay.get_value()),",
        "patch": "@@ -82,7 +82,7 @@ def get_config(self):\n         return {\"name\": self.__class__.__name__,\n                 \"lr\": float(self.lr.get_value()),\n                 \"momentum\": float(self.momentum.get_value()),\n-                \"decay\": float(self.decay),\n+                \"decay\": float(self.decay.get_value()),\n                 \"nesterov\": self.nesterov}\n \n "
    },
    {
        "commit_id": "025cd16854c6068769c6b65196390a8c8eef67af",
        "commit_message": "Merge pull request #859 from r9y9/patch-1\n\nFIx `Exception: Invalid layer: LRN2D`",
        "commit_url": "https://github.com/keras-team/keras/commit/025cd16854c6068769c6b65196390a8c8eef67af",
        "buggy_code": "from ..layers.normalization import BatchNormalization",
        "fixed_code": "from ..layers.normalization import BatchNormalization, LRN2D",
        "patch": "@@ -10,7 +10,7 @@\n from ..layers.convolutional import Convolution1D, Convolution2D, MaxPooling1D, MaxPooling2D, ZeroPadding2D\n from ..layers.embeddings import Embedding, WordContextProduct\n from ..layers.noise import GaussianNoise, GaussianDropout\n-from ..layers.normalization import BatchNormalization\n+from ..layers.normalization import BatchNormalization, LRN2D\n from ..layers.recurrent import SimpleRNN, SimpleDeepRNN, GRU, LSTM, JZS1, JZS2, JZS3\n from ..layers import containers\n from .. import regularizers"
    },
    {
        "commit_id": "68f619b9f9e42a2baae5fdbbc904ec324d580928",
        "commit_message": "import LRN2D\n\nThis should fix the problem`Exception: Invalid layer: LRN2D` while loading a model that includes LRN2D.\r\n\r\n```py\r\nmodel = Sequential()\r\nmodel.add(Convolution2D(30, 3, 3, input_shape=(1, 28, 28)))\r\nmodel.add(LRN2D())\r\n\r\nmodel_def = model.to_yaml()\r\n\r\n# this line raises Exception: Invalid layer: LRN2D\r\nmodel_from_yaml(model_def)\r\n```\r\n\r\nThe code above could reproduce the problem.",
        "commit_url": "https://github.com/keras-team/keras/commit/68f619b9f9e42a2baae5fdbbc904ec324d580928",
        "buggy_code": "from ..layers.normalization import BatchNormalization",
        "fixed_code": "from ..layers.normalization import BatchNormalization, LRN2D",
        "patch": "@@ -10,7 +10,7 @@\n from ..layers.convolutional import Convolution1D, Convolution2D, MaxPooling1D, MaxPooling2D, ZeroPadding2D\n from ..layers.embeddings import Embedding, WordContextProduct\n from ..layers.noise import GaussianNoise, GaussianDropout\n-from ..layers.normalization import BatchNormalization\n+from ..layers.normalization import BatchNormalization, LRN2D\n from ..layers.recurrent import SimpleRNN, SimpleDeepRNN, GRU, LSTM, JZS1, JZS2, JZS3\n from ..layers import containers\n from .. import regularizers"
    },
    {
        "commit_id": "cc26bc24a98d666828393192fbe93cda8a5b8b2f",
        "commit_message": "Merge pull request #826 from jfsantos/patch-5\n\nFix #821",
        "commit_url": "https://github.com/keras-team/keras/commit/cc26bc24a98d666828393192fbe93cda8a5b8b2f",
        "buggy_code": "\"decay\": float(self.decay.get_value()),",
        "fixed_code": "\"decay\": float(self.decay),",
        "patch": "@@ -82,7 +82,7 @@ def get_config(self):\n         return {\"name\": self.__class__.__name__,\n                 \"lr\": float(self.lr.get_value()),\n                 \"momentum\": float(self.momentum.get_value()),\n-                \"decay\": float(self.decay.get_value()),\n+                \"decay\": float(self.decay),\n                 \"nesterov\": self.nesterov}\n \n "
    },
    {
        "commit_id": "f62c03bdea7ff95a1360cbc38c2523bee4c59204",
        "commit_message": "Fix #821\n\n`decay` in `SGD` is not a shared value, so it does not have a `get_value` method.",
        "commit_url": "https://github.com/keras-team/keras/commit/f62c03bdea7ff95a1360cbc38c2523bee4c59204",
        "buggy_code": "\"decay\": float(self.decay.get_value()),",
        "fixed_code": "\"decay\": float(self.decay),",
        "patch": "@@ -82,7 +82,7 @@ def get_config(self):\n         return {\"name\": self.__class__.__name__,\n                 \"lr\": float(self.lr.get_value()),\n                 \"momentum\": float(self.momentum.get_value()),\n-                \"decay\": float(self.decay.get_value()),\n+                \"decay\": float(self.decay),\n                 \"nesterov\": self.nesterov}\n \n "
    },
    {
        "commit_id": "73aac1c7c9a934d065c429cb33d5960b7c34eed5",
        "commit_message": "Merge pull request #813 from hedeon/keras_hq\n\nFix: added \"Permute\" into imports of line 8: keras/keras/utils/layer_utils.py",
        "commit_url": "https://github.com/keras-team/keras/commit/73aac1c7c9a934d065c429cb33d5960b7c34eed5",
        "buggy_code": "from ..layers.core import Dense, Merge, Dropout, Activation, Reshape, Flatten, RepeatVector, Layer, AutoEncoder, Masking",
        "fixed_code": "from ..layers.core import Dense, Merge, Dropout, Activation, Reshape, Flatten, RepeatVector, Layer, AutoEncoder, Masking, Permute",
        "patch": "@@ -5,7 +5,7 @@\n import copy\n \n from ..layers.advanced_activations import LeakyReLU, PReLU\n-from ..layers.core import Dense, Merge, Dropout, Activation, Reshape, Flatten, RepeatVector, Layer, AutoEncoder, Masking\n+from ..layers.core import Dense, Merge, Dropout, Activation, Reshape, Flatten, RepeatVector, Layer, AutoEncoder, Masking, Permute\n from ..layers.core import ActivityRegularization, TimeDistributedDense, AutoEncoder, MaxoutDense\n from ..layers.convolutional import Convolution1D, Convolution2D, MaxPooling1D, MaxPooling2D, ZeroPadding2D\n from ..layers.embeddings import Embedding, WordContextProduct"
    },
    {
        "commit_id": "815f7064a2a77cbaed4cff6e2b00b08ac14c04f3",
        "commit_message": "Fix: added \"Permute\" into imports",
        "commit_url": "https://github.com/keras-team/keras/commit/815f7064a2a77cbaed4cff6e2b00b08ac14c04f3",
        "buggy_code": "from ..layers.core import Dense, Merge, Dropout, Activation, Reshape, Flatten, RepeatVector, Layer, AutoEncoder, Masking",
        "fixed_code": "from ..layers.core import Dense, Merge, Dropout, Activation, Reshape, Flatten, RepeatVector, Layer, AutoEncoder, Masking, Permute",
        "patch": "@@ -5,7 +5,7 @@\n import copy\n \n from ..layers.advanced_activations import LeakyReLU, PReLU\n-from ..layers.core import Dense, Merge, Dropout, Activation, Reshape, Flatten, RepeatVector, Layer, AutoEncoder, Masking\n+from ..layers.core import Dense, Merge, Dropout, Activation, Reshape, Flatten, RepeatVector, Layer, AutoEncoder, Masking, Permute\n from ..layers.core import ActivityRegularization, TimeDistributedDense, AutoEncoder, MaxoutDense\n from ..layers.convolutional import Convolution1D, Convolution2D, MaxPooling1D, MaxPooling2D, ZeroPadding2D\n from ..layers.embeddings import Embedding, WordContextProduct"
    },
    {
        "commit_id": "4c1a6fc27ebbcdda62febfd54f1e21426596d17d",
        "commit_message": "fix Embedding config property to include new input_length property, add input_length to all examples with Embedding layer",
        "commit_url": "https://github.com/keras-team/keras/commit/4c1a6fc27ebbcdda62febfd54f1e21426596d17d",
        "buggy_code": "model.add(Embedding(max_features, 128))",
        "fixed_code": "model.add(Embedding(max_features, 128, input_length=maxlen))",
        "patch": "@@ -48,7 +48,7 @@\n \n print('Build model...')\n model = Sequential()\n-model.add(Embedding(max_features, 128))\n+model.add(Embedding(max_features, 128, input_length=maxlen))\n model.add(LSTM(128))  # try using a GRU instead, for fun\n model.add(Dropout(0.5))\n model.add(Dense(1))"
    },
    {
        "commit_id": "4c1a6fc27ebbcdda62febfd54f1e21426596d17d",
        "commit_message": "fix Embedding config property to include new input_length property, add input_length to all examples with Embedding layer",
        "commit_url": "https://github.com/keras-team/keras/commit/4c1a6fc27ebbcdda62febfd54f1e21426596d17d",
        "buggy_code": "\"max_lenght\": self.max_lenght,",
        "fixed_code": "\"input_length\": self.input_length,",
        "patch": "@@ -75,7 +75,7 @@ def get_config(self):\n                   \"input_dim\": self.input_dim,\n                   \"output_dim\": self.output_dim,\n                   \"init\": self.init.__name__,\n-                  \"max_lenght\": self.max_lenght,\n+                  \"input_length\": self.input_length,\n                   \"mask_zero\": self.mask_zero,\n                   \"activity_regularizer\": self.activity_regularizer.get_config() if self.activity_regularizer else None,\n                   \"W_regularizer\": self.W_regularizer.get_config() if self.W_regularizer else None,"
    },
    {
        "commit_id": "0e62ae4eaa8807b7e0e27e73ca1ff6be05e8b715",
        "commit_message": "fix merge conflict",
        "commit_url": "https://github.com/keras-team/keras/commit/0e62ae4eaa8807b7e0e27e73ca1ff6be05e8b715",
        "buggy_code": "model.add(MaxPooling2D(poolsize=(nb_pool, nb_pool)))",
        "fixed_code": "model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))",
        "patch": "@@ -54,7 +54,7 @@\n model.add(Activation('relu'))\n model.add(Convolution2D(nb_filters, nb_filters, nb_conv, nb_conv))\n model.add(Activation('relu'))\n-model.add(MaxPooling2D(poolsize=(nb_pool, nb_pool)))\n+model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n model.add(Dropout(0.25))\n \n model.add(Flatten())"
    },
    {
        "commit_id": "37978fcda6c2f4223f9cea886eb9c5ec002fa821",
        "commit_message": "fix merge conflict",
        "commit_url": "https://github.com/keras-team/keras/commit/37978fcda6c2f4223f9cea886eb9c5ec002fa821",
        "buggy_code": "return (x + abs(x)) / 2.0",
        "fixed_code": "return T.nnet.relu(x)",
        "patch": "@@ -17,7 +17,7 @@ def softplus(x):\n \n \n def relu(x):\n-    return (x + abs(x)) / 2.0\n+    return T.nnet.relu(x)\n \n \n def tanh(x):"
    },
    {
        "commit_id": "61d76d4a0794aedb7ae387318689cad34a59e8bc",
        "commit_message": "fix merge conflict",
        "commit_url": "https://github.com/keras-team/keras/commit/61d76d4a0794aedb7ae387318689cad34a59e8bc",
        "buggy_code": "return (x + abs(x)) / 2.0",
        "fixed_code": "return T.nnet.relu(x)",
        "patch": "@@ -17,7 +17,7 @@ def softplus(x):\n \n \n def relu(x):\n-    return (x + abs(x)) / 2.0\n+    return T.nnet.relu(x)\n \n \n def tanh(x):"
    },
    {
        "commit_id": "af932d34808fa5e6cf8b7d03fbd70b2d1fc52798",
        "commit_message": "Merge pull request #752 from jfsantos/patch-4\n\nFix typo in docstring",
        "commit_url": "https://github.com/keras-team/keras/commit/af932d34808fa5e6cf8b7d03fbd70b2d1fc52798",
        "buggy_code": "the length of the longuest sequence.",
        "fixed_code": "the length of the longest sequence.",
        "patch": "@@ -7,7 +7,7 @@\n def pad_sequences(sequences, maxlen=None, dtype='int32', padding='pre', truncating='pre', value=0.):\n     \"\"\"\n         Pad each sequence to the same length: \n-        the length of the longuest sequence.\n+        the length of the longest sequence.\n \n         If maxlen is provided, any sequence longer\n         than maxlen is truncated to maxlen. Truncation happens off either the beginning (default) or"
    },
    {
        "commit_id": "4ed53ae5a488b08cd9d65bc12f03859b56e79a88",
        "commit_message": "Fix typo in docstring\n\nlonguest -> longest",
        "commit_url": "https://github.com/keras-team/keras/commit/4ed53ae5a488b08cd9d65bc12f03859b56e79a88",
        "buggy_code": "the length of the longuest sequence.",
        "fixed_code": "the length of the longest sequence.",
        "patch": "@@ -7,7 +7,7 @@\n def pad_sequences(sequences, maxlen=None, dtype='int32', padding='pre', truncating='pre', value=0.):\n     \"\"\"\n         Pad each sequence to the same length: \n-        the length of the longuest sequence.\n+        the length of the longest sequence.\n \n         If maxlen is provided, any sequence longer\n         than maxlen is truncated to maxlen. Truncation happens off either the beginning (default) or"
    },
    {
        "commit_id": "0b1a1e9761e3283fd5f2f01023dce1d930d75dbc",
        "commit_message": "Merge pull request #734 from EderSantana/master\n\nFix order of sings of clipvalue",
        "commit_url": "https://github.com/keras-team/keras/commit/0b1a1e9761e3283fd5f2f01023dce1d930d75dbc",
        "buggy_code": "grads = [T.clip(g, self.clipvalue, -self.clipvalue) for g in grads]",
        "fixed_code": "grads = [T.clip(g, -self.clipvalue, self.clipvalue) for g in grads]",
        "patch": "@@ -42,7 +42,7 @@ def get_gradients(self, loss, params):\n             grads = [clip_norm(g, self.clipnorm, norm) for g in grads]\n \n         if hasattr(self, 'clipvalue') and self.clipvalue > 0:\n-            grads = [T.clip(g, self.clipvalue, -self.clipvalue) for g in grads]\n+            grads = [T.clip(g, -self.clipvalue, self.clipvalue) for g in grads]\n \n         return grads\n "
    },
    {
        "commit_id": "46a2fb6fd8e52b02df78f1416cc9fbd4b3156604",
        "commit_message": "Fix sign order for clipvalue",
        "commit_url": "https://github.com/keras-team/keras/commit/46a2fb6fd8e52b02df78f1416cc9fbd4b3156604",
        "buggy_code": "grads = [T.clip(g, self.clipvalue, -self.clipvalue) for g in grads]",
        "fixed_code": "grads = [T.clip(g, -self.clipvalue, self.clipvalue) for g in grads]",
        "patch": "@@ -42,7 +42,7 @@ def get_gradients(self, loss, params):\n             grads = [clip_norm(g, self.clipnorm, norm) for g in grads]\n \n         if hasattr(self, 'clipvalue') and self.clipvalue > 0:\n-            grads = [T.clip(g, self.clipvalue, -self.clipvalue) for g in grads]\n+            grads = [T.clip(g, -self.clipvalue, self.clipvalue) for g in grads]\n \n         return grads\n "
    },
    {
        "commit_id": "b0f2446370dae108ac49566e5d3e7951255663fe",
        "commit_message": "Fix relu",
        "commit_url": "https://github.com/keras-team/keras/commit/b0f2446370dae108ac49566e5d3e7951255663fe",
        "buggy_code": "return T.nnet.relu(X)",
        "fixed_code": "return T.nnet.relu(x)",
        "patch": "@@ -17,7 +17,7 @@ def softplus(x):\n \n \n def relu(x):\n-    return T.nnet.relu(X)\n+    return T.nnet.relu(x)\n \n \n def tanh(x):"
    },
    {
        "commit_id": "c5b3959b4214cfe324573b0b1ed0c3d79a1ed1a2",
        "commit_message": "Fix test_tasks",
        "commit_url": "https://github.com/keras-team/keras/commit/c5b3959b4214cfe324573b0b1ed0c3d79a1ed1a2",
        "buggy_code": "self.assertTrue(history.history['val_loss'][-1] < 0.75)",
        "fixed_code": "self.assertTrue(history.history['val_loss'][-1] < 0.8)",
        "patch": "@@ -101,7 +101,7 @@ def test_seq_to_seq(self):\n         model.add(TimeDistributedDense(X_train.shape[-1], y_train.shape[-1]))\n         model.compile(loss='hinge', optimizer='rmsprop')\n         history = model.fit(X_train, y_train, nb_epoch=12, batch_size=16, validation_data=(X_test, y_test), verbose=2)\n-        self.assertTrue(history.history['val_loss'][-1] < 0.75)\n+        self.assertTrue(history.history['val_loss'][-1] < 0.8)\n \n     def test_img_clf(self):\n         print('image classification data:')"
    },
    {
        "commit_id": "4bdb43f2444d5530585b7df3532bdb924a9bf402",
        "commit_message": "Merge pull request #639 from rodrigob/patch-1\n\nAdded reference for orthogonal initialization",
        "commit_url": "https://github.com/keras-team/keras/commit/4bdb43f2444d5530585b7df3532bdb924a9bf402",
        "buggy_code": "''' From Lasagne",
        "fixed_code": "''' From Lasagne. Reference: Saxe et al., http://arxiv.org/abs/1312.6120",
        "patch": "@@ -58,7 +58,7 @@ def he_uniform(shape):\n \n \n def orthogonal(shape, scale=1.1):\n-    ''' From Lasagne\n+    ''' From Lasagne. Reference: Saxe et al., http://arxiv.org/abs/1312.6120\n     '''\n     flat_shape = (shape[0], np.prod(shape[1:]))\n     a = np.random.normal(0.0, 1.0, flat_shape)"
    },
    {
        "commit_id": "06ab8dbd348d81b600f543db31da2160c792a581",
        "commit_message": "Merge pull request #650 from rodrigob/patch-2\n\nFix cPickle import for python3 support",
        "commit_url": "https://github.com/keras-team/keras/commit/06ab8dbd348d81b600f543db31da2160c792a581",
        "buggy_code": "import cPickle",
        "fixed_code": "from six.moves import cPickle",
        "patch": "@@ -1,5 +1,5 @@\n from __future__ import absolute_import\n-import cPickle\n+from six.moves import cPickle\n import gzip\n from .data_utils import get_file\n import random"
    },
    {
        "commit_id": "5040aa386d8d404bc26eddfca332c1b503ab304b",
        "commit_message": "Fix cPickle import for python3 support",
        "commit_url": "https://github.com/keras-team/keras/commit/5040aa386d8d404bc26eddfca332c1b503ab304b",
        "buggy_code": "import cPickle",
        "fixed_code": "from six.moves import cPickle",
        "patch": "@@ -1,5 +1,5 @@\n from __future__ import absolute_import\n-import cPickle\n+from six.moves import cPickle\n import gzip\n from .data_utils import get_file\n import random"
    },
    {
        "commit_id": "2e60c999240a5ec01365cbdc0ca35e2e9f207a92",
        "commit_message": "Merge pull request #642 from wuaalb/lr-scheduler\n\nFix typo LearningRateScheduler",
        "commit_url": "https://github.com/keras-team/keras/commit/2e60c999240a5ec01365cbdc0ca35e2e9f207a92",
        "buggy_code": "model.lr.set_value(self.schedule(epoch))",
        "fixed_code": "self.model.optimizer.lr.set_value(self.schedule(epoch))",
        "patch": "@@ -271,4 +271,4 @@ def __init__(self, schedule):\n         self.schedule = schedule\n \n     def on_epoch_begin(self, epoch, logs={}):\n-        model.lr.set_value(self.schedule(epoch))\n+        self.model.optimizer.lr.set_value(self.schedule(epoch))"
    },
    {
        "commit_id": "4bb6ac0b04838e8d82d14d7c0f001569f543518b",
        "commit_message": "Fix typo LearningRateScheduler",
        "commit_url": "https://github.com/keras-team/keras/commit/4bb6ac0b04838e8d82d14d7c0f001569f543518b",
        "buggy_code": "model.lr.set_value(self.schedule(epoch))",
        "fixed_code": "self.model.optimizer.lr.set_value(self.schedule(epoch))",
        "patch": "@@ -271,4 +271,4 @@ def __init__(self, schedule):\n         self.schedule = schedule\n \n     def on_epoch_begin(self, epoch, logs={}):\n-        model.lr.set_value(self.schedule(epoch))\n+        self.model.optimizer.lr.set_value(self.schedule(epoch))"
    },
    {
        "commit_id": "34999c865896642e25d46d6334200775008e1562",
        "commit_message": "Fix Poisson loss when target = 0",
        "commit_url": "https://github.com/keras-team/keras/commit/34999c865896642e25d46d6334200775008e1562",
        "buggy_code": "return T.mean(y_pred - y_true * T.log(y_pred), axis=-1)",
        "fixed_code": "return T.mean(y_pred - y_true * T.log(y_pred + epsilon), axis=-1)",
        "patch": "@@ -51,7 +51,7 @@ def binary_crossentropy(y_true, y_pred):\n \n \n def poisson_loss(y_true, y_pred):\n-    return T.mean(y_pred - y_true * T.log(y_pred), axis=-1)\n+    return T.mean(y_pred - y_true * T.log(y_pred + epsilon), axis=-1)\n \n # aliases\n mse = MSE = mean_squared_error"
    },
    {
        "commit_id": "0daf02a96dec39d37bc9d5f2548647167d10f6bf",
        "commit_message": "Merge pull request #586 from jerheff/patch-1\n\nFix documented form of parametric softplus",
        "commit_url": "https://github.com/keras-team/keras/commit/0daf02a96dec39d37bc9d5f2548647167d10f6bf",
        "buggy_code": "Parametric Softplus of the form: alpha * (1 + exp(beta * X))",
        "fixed_code": "Parametric Softplus of the form: alpha * log(1 + exp(beta * X))",
        "patch": "@@ -49,7 +49,7 @@ def get_config(self):\n \n class ParametricSoftplus(MaskedLayer):\n     '''\n-        Parametric Softplus of the form: alpha * (1 + exp(beta * X))\n+        Parametric Softplus of the form: alpha * log(1 + exp(beta * X))\n \n         Reference:\n             Inferring Nonlinear Neuronal Computation Based on Physiologically Plausible Inputs"
    },
    {
        "commit_id": "b498218d0b16ed1ca619b77332b6fccac32fc175",
        "commit_message": "Fix documented form of parametric softplus",
        "commit_url": "https://github.com/keras-team/keras/commit/b498218d0b16ed1ca619b77332b6fccac32fc175",
        "buggy_code": "Parametric Softplus of the form: alpha * (1 + exp(beta * X))",
        "fixed_code": "Parametric Softplus of the form: alpha * log(1 + exp(beta * X))",
        "patch": "@@ -49,7 +49,7 @@ def get_config(self):\n \n class ParametricSoftplus(MaskedLayer):\n     '''\n-        Parametric Softplus of the form: alpha * (1 + exp(beta * X))\n+        Parametric Softplus of the form: alpha * log(1 + exp(beta * X))\n \n         Reference:\n             Inferring Nonlinear Neuronal Computation Based on Physiologically Plausible Inputs"
    },
    {
        "commit_id": "5e9579aeac5c57d821c5a330a82e2592975fad96",
        "commit_message": "Merge pull request #547 from awentzonline/conn-map-dict\n\nFix Graph.set_previous with dict connection_map",
        "commit_url": "https://github.com/keras-team/keras/commit/5e9579aeac5c57d821c5a330a82e2592975fad96",
        "buggy_code": "for k, v in connection_map:",
        "fixed_code": "for k, v in connection_map.items():",
        "patch": "@@ -129,7 +129,7 @@ def set_previous(self, layer, connection_map={}):\n         else:\n             if not connection_map:\n                 raise Exception('Cannot attach multi-input layer: no connection_map provided.')\n-            for k, v in connection_map:\n+            for k, v in connection_map.items():\n                 if k in self.inputs and v in layer.outputs:\n                     self.inputs[k].set_previous(layer.outputs[v])\n                 else:"
    },
    {
        "commit_id": "c515dc90d4be04454193e1b774018de28c6bcf48",
        "commit_message": "Fix Graph.set_previous with dict connection_map",
        "commit_url": "https://github.com/keras-team/keras/commit/c515dc90d4be04454193e1b774018de28c6bcf48",
        "buggy_code": "for k, v in connection_map:",
        "fixed_code": "for k, v in connection_map.items():",
        "patch": "@@ -129,7 +129,7 @@ def set_previous(self, layer, connection_map={}):\n         else:\n             if not connection_map:\n                 raise Exception('Cannot attach multi-input layer: no connection_map provided.')\n-            for k, v in connection_map:\n+            for k, v in connection_map.items():\n                 if k in self.inputs and v in layer.outputs:\n                     self.inputs[k].set_previous(layer.outputs[v])\n                 else:"
    },
    {
        "commit_id": "97174dd298cf4b5be459e79b0181a124650d9148",
        "commit_message": "Fix batch normalization as first layer",
        "commit_url": "https://github.com/keras-team/keras/commit/97174dd298cf4b5be459e79b0181a124650d9148",
        "buggy_code": "self.input = ndim_tensor(len(self.input_shape))",
        "fixed_code": "self.input = ndim_tensor(len(self.input_shape) + 1)",
        "patch": "@@ -23,7 +23,7 @@ def __init__(self, input_shape, epsilon=1e-6, mode=0, momentum=0.9, weights=None\n         self.epsilon = epsilon\n         self.mode = mode\n         self.momentum = momentum\n-        self.input = ndim_tensor(len(self.input_shape))\n+        self.input = ndim_tensor(len(self.input_shape) + 1)\n \n         self.gamma = self.init((self.input_shape))\n         self.beta = shared_zeros(self.input_shape)"
    },
    {
        "commit_id": "9c58adfe4b47d87a9994056e24dea754ecddf76a",
        "commit_message": "Merge pull request #515 from bshickel/patch-1\n\nFixes IndexError when converting sequences to matrix with nb_words = None",
        "commit_url": "https://github.com/keras-team/keras/commit/9c58adfe4b47d87a9994056e24dea754ecddf76a",
        "buggy_code": "self.word_index = dict(list(zip(sorted_voc, list(range(1, len(sorted_voc)+1)))))",
        "fixed_code": "self.word_index = dict(list(zip(sorted_voc, list(range(0, len(sorted_voc))))))",
        "patch": "@@ -69,7 +69,7 @@ def fit_on_texts(self, texts):\n         wcounts = list(self.word_counts.items())\n         wcounts.sort(key = lambda x: x[1], reverse=True)\n         sorted_voc = [wc[0] for wc in wcounts]\n-        self.word_index = dict(list(zip(sorted_voc, list(range(1, len(sorted_voc)+1)))))\n+        self.word_index = dict(list(zip(sorted_voc, list(range(0, len(sorted_voc))))))\n \n         self.index_docs = {}\n         for w, c in list(self.word_docs.items()):"
    },
    {
        "commit_id": "aa2f8660831231d66c244ced7ce5d2581a4d1424",
        "commit_message": "Merge pull request #533 from lukedeo/fix\n\nfix: json dump to string",
        "commit_url": "https://github.com/keras-team/keras/commit/aa2f8660831231d66c244ced7ce5d2581a4d1424",
        "buggy_code": "return json.dump(config)",
        "fixed_code": "return json.dumps(config)",
        "patch": "@@ -327,7 +327,7 @@ def to_json(self):\n         # dump model configuration to json string\n         import json\n         config = self.get_config()\n-        return json.dump(config)\n+        return json.dumps(config)\n \n \n class Sequential(Model, containers.Sequential):"
    },
    {
        "commit_id": "9b4fe767ae257065ab8876176ac0640800ae163b",
        "commit_message": "fix: json dump to string",
        "commit_url": "https://github.com/keras-team/keras/commit/9b4fe767ae257065ab8876176ac0640800ae163b",
        "buggy_code": "return json.dump(config)",
        "fixed_code": "return json.dumps(config)",
        "patch": "@@ -327,7 +327,7 @@ def to_json(self):\n         # dump model configuration to json string\n         import json\n         config = self.get_config()\n-        return json.dump(config)\n+        return json.dumps(config)\n \n \n class Sequential(Model, containers.Sequential):"
    },
    {
        "commit_id": "9e7f67b6f9cd6f3646aa3c767abbf4a932d4f930",
        "commit_message": "Fix typo",
        "commit_url": "https://github.com/keras-team/keras/commit/9e7f67b6f9cd6f3646aa3c767abbf4a932d4f930",
        "buggy_code": "std = std = T.mean((X - m) ** 2 + self.epsilon, axis=0) ** 0.5",
        "fixed_code": "std = T.mean((X - m) ** 2 + self.epsilon, axis=0) ** 0.5",
        "patch": "@@ -37,7 +37,7 @@ def init_updates(self):\n         self.running_std = shared_ones((self.input_shape))\n         X = self.get_input(train=True)\n         m = X.mean(axis=0)\n-        std = std = T.mean((X - m) ** 2 + self.epsilon, axis=0) ** 0.5\n+        std = T.mean((X - m) ** 2 + self.epsilon, axis=0) ** 0.5\n         mean_update = self.momentum * self.running_mean + (1-self.momentum) * m\n         std_update = self.momentum * self.running_std + (1-self.momentum) * std\n         self.updates = [(self.running_mean, mean_update), (self.running_std, std_update)]"
    },
    {
        "commit_id": "1e3d9f7be11410a0eaf071b3ca68d4ca7bfad86b",
        "commit_message": "Fix Hualos callback",
        "commit_url": "https://github.com/keras-team/keras/commit/1e3d9f7be11410a0eaf071b3ca68d4ca7bfad86b",
        "buggy_code": "for k, v in self.logs:",
        "fixed_code": "for k, v in logs:",
        "patch": "@@ -255,7 +255,7 @@ def on_epoch_end(self, epoch, logs={}):\n \n         for k, v in self.totals.items():\n             send[k] = v / self.seen\n-        for k, v in self.logs:\n+        for k, v in logs:\n             send[k] = v\n \n         r = requests.post(self.root + '/publish/epoch/end/', {'data': json.dumps(send)})"
    },
    {
        "commit_id": "68f067747652a9e0a6326e6bdde9900e5befea67",
        "commit_message": "Merge pull request #441 from kenterao/master\n\nFix optimizer get/set state",
        "commit_url": "https://github.com/keras-team/keras/commit/68f067747652a9e0a6326e6bdde9900e5befea67",
        "buggy_code": "config.json.loads(json_string)",
        "fixed_code": "config = json.loads(json_string)",
        "patch": "@@ -102,7 +102,7 @@ def model_from_yaml(yaml_string):\n \n def model_from_json(json_string):\n     import json\n-    config.json.loads(json_string)\n+    config = json.loads(json_string)\n     return model_from_config(config)\n \n "
    },
    {
        "commit_id": "3a62cad7f50e9748787cf7783e32e9874bfad918",
        "commit_message": "fix model_from_json",
        "commit_url": "https://github.com/keras-team/keras/commit/3a62cad7f50e9748787cf7783e32e9874bfad918",
        "buggy_code": "config.json.loads(json_string)",
        "fixed_code": "config = json.loads(json_string)",
        "patch": "@@ -102,7 +102,7 @@ def model_from_yaml(yaml_string):\n \n def model_from_json(json_string):\n     import json\n-    config.json.loads(json_string)\n+    config = json.loads(json_string)\n     return model_from_config(config)\n \n "
    },
    {
        "commit_id": "b6aaeb35ee6b27b026e0495f1c04e830fe8c5db9",
        "commit_message": "Fix embedding test",
        "commit_url": "https://github.com/keras-team/keras/commit/b6aaeb35ee6b27b026e0495f1c04e830fe8c5db9",
        "buggy_code": "lookup.train(self.X1, np.array([[1], [0]], dtype='int32'))",
        "fixed_code": "lookup.train_on_batch(self.X1, np.array([[1], [0]], dtype='int32'))",
        "patch": "@@ -19,7 +19,7 @@ def test_unitnorm_constraint(self):\n         lookup.add(Dense(2, 1))\n         lookup.add(Activation('sigmoid'))\n         lookup.compile(loss='binary_crossentropy', optimizer='sgd', class_mode='binary')\n-        lookup.train(self.X1, np.array([[1], [0]], dtype='int32'))\n+        lookup.train_on_batch(self.X1, np.array([[1], [0]], dtype='int32'))\n         norm = np.linalg.norm(lookup.params[0].get_value(), axis=1)\n         self.assertTrue(np.allclose(norm, np.ones_like(norm).astype('float32')))\n "
    },
    {
        "commit_id": "4b6bf1dbfe0d0b49f876c701b95a6ff66e9f206d",
        "commit_message": "Fix Permute layer",
        "commit_url": "https://github.com/keras-team/keras/commit/4b6bf1dbfe0d0b49f876c701b95a6ff66e9f206d",
        "buggy_code": "return X.dimshuffle(self.dims)",
        "fixed_code": "return X.dimshuffle((0,) + self.dims)",
        "patch": "@@ -259,7 +259,7 @@ def __init__(self, dims):\n \n     def get_output(self, train):\n         X = self.get_input(train)\n-        return X.dimshuffle(self.dims)\n+        return X.dimshuffle((0,) + self.dims)\n \n     def get_config(self):\n         return {\"name\":self.__class__.__name__,"
    },
    {
        "commit_id": "5bf271858092e85164ecc309cd943d7eabdab9db",
        "commit_message": "Fix binary_crossentropy",
        "commit_url": "https://github.com/keras-team/keras/commit/5bf271858092e85164ecc309cd943d7eabdab9db",
        "buggy_code": "bce = T.nnet.binary_crossentropy(y_pred, y_true)",
        "fixed_code": "bce = T.nnet.binary_crossentropy(y_pred, y_true).mean(axis=-1)",
        "patch": "@@ -35,7 +35,7 @@ def categorical_crossentropy(y_true, y_pred):\n \n def binary_crossentropy(y_true, y_pred):\n     y_pred = T.clip(y_pred, epsilon, 1.0 - epsilon)\n-    bce = T.nnet.binary_crossentropy(y_pred, y_true)\n+    bce = T.nnet.binary_crossentropy(y_pred, y_true).mean(axis=-1)\n     return bce\n \n # aliases"
    },
    {
        "commit_id": "bc05a25b1b1b44f153eb47b0dbe5d213482d4dfe",
        "commit_message": "Fix tests, increase coverage",
        "commit_url": "https://github.com/keras-team/keras/commit/bc05a25b1b1b44f153eb47b0dbe5d213482d4dfe",
        "buggy_code": "assert(loss < 2.5)",
        "fixed_code": "assert(loss < 2.7)",
        "patch": "@@ -111,7 +111,7 @@ def test_2o_1i_weights(self):\n         loss = graph.train_on_batch({'input1':X_test, 'output1':y_test, 'output2':y2_test})\n         loss = graph.evaluate({'input1':X_test, 'output1':y_test, 'output2':y2_test})\n         print(loss)\n-        assert(loss < 2.5)\n+        assert(loss < 2.7)\n \n         print('test weight saving')\n         graph.save_weights('temp.h5', overwrite=True)"
    },
    {
        "commit_id": "c315b0d7a95b6677452300bdefd526b444951819",
        "commit_message": "fix GaussianNoise",
        "commit_url": "https://github.com/keras-team/keras/commit/c315b0d7a95b6677452300bdefd526b444951819",
        "buggy_code": "if train or self.sigma == 0:",
        "fixed_code": "if not train or self.sigma == 0:",
        "patch": "@@ -218,7 +218,7 @@ def __init__(self, sigma):\n \n     def get_output(self, train=False):\n         X = self.get_input(train)\n-        if train or self.sigma == 0:\n+        if not train or self.sigma == 0:\n             return X\n         else:\n             return X + srng.normal(size=X.shape, avg=0.0, std=self.sigma,"
    },
    {
        "commit_id": "63f9a7955d81894a643bc292bcd522b3a391676a",
        "commit_message": "Fix ModelCheckpoint callback",
        "commit_url": "https://github.com/keras-team/keras/commit/63f9a7955d81894a643bc292bcd522b3a391676a",
        "buggy_code": "self.monitor",
        "fixed_code": "self.monitor = monitor",
        "patch": "@@ -174,7 +174,7 @@ class ModelCheckpoint(Callback):\n     def __init__(self, filepath, monitor='val_loss', verbose=0, save_best_only=False):\n         super(Callback, self).__init__()\n         \n-        self.monitor\n+        self.monitor = monitor\n         self.verbose = verbose\n         self.filepath = filepath\n         self.save_best_only = save_best_only"
    },
    {
        "commit_id": "53a05b6e4c1e7ee2c6d13eda9826f5bc9a321391",
        "commit_message": "Fix metrics issue in evaluate",
        "commit_url": "https://github.com/keras-team/keras/commit/53a05b6e4c1e7ee2c6d13eda9826f5bc9a321391",
        "buggy_code": "outs[i] += batch_out",
        "fixed_code": "outs[i] += batch_out * len(batch_ids)",
        "patch": "@@ -207,7 +207,7 @@ def _test_loop(self, f, ins, batch_size=128, verbose=0):\n                     for batch_out in enumerate(batch_outs):\n                         outs.append(0.)\n                 for i, batch_out in enumerate(batch_outs):\n-                    outs[i] += batch_out\n+                    outs[i] += batch_out * len(batch_ids)\n             else:\n                 if batch_index == 0:\n                     outs.append(0.)"
    },
    {
        "commit_id": "32f483fe33fc9ff5474067b4a284616def479d8f",
        "commit_message": "Fix mape objective",
        "commit_url": "https://github.com/keras-team/keras/commit/32f483fe33fc9ff5474067b4a284616def479d8f",
        "buggy_code": "return T.abs_((y_true - y_pred) / y_true).mean() * 100",
        "fixed_code": "return T.abs_((y_true - y_pred) / y_true).mean(axis=-1) * 100",
        "patch": "@@ -13,7 +13,7 @@ def mean_absolute_error(y_true, y_pred):\n     return T.abs_(y_pred - y_true).mean(axis=-1)\n \n def mean_absolute_percentage_error(y_true, y_pred):\n-    return T.abs_((y_true - y_pred) / y_true).mean() * 100\n+    return T.abs_((y_true - y_pred) / y_true).mean(axis=-1) * 100\n \n def mean_squared_logarithmic_error(y_true, y_pred):\n     return T.sqr(T.log(T.clip(y_pred, epsilon, np.inf) + 1.) - T.log(T.clip(y_true, epsilon, np.inf) + 1.)).mean(axis=-1)"
    },
    {
        "commit_id": "bba53793057c0cdf068e67d17ae90e39b90ae24c",
        "commit_message": "Fix constraint tests",
        "commit_url": "https://github.com/keras-team/keras/commit/bba53793057c0cdf068e67d17ae90e39b90ae24c",
        "buggy_code": "return e / T.sqrt(T.sum(e**2, axis=-1, keepdims=True))",
        "fixed_code": "return p / T.sqrt(T.sum(p**2, axis=-1, keepdims=True))",
        "patch": "@@ -24,7 +24,7 @@ def __call__(self, p):\n \n class UnitNorm(Constraint):\n     def __call__(self, p):\n-        return e / T.sqrt(T.sum(e**2, axis=-1, keepdims=True))\n+        return p / T.sqrt(T.sum(p**2, axis=-1, keepdims=True))\n \n identity = Constraint\n maxnorm = MaxNorm"
    },
    {
        "commit_id": "bba53793057c0cdf068e67d17ae90e39b90ae24c",
        "commit_message": "Fix constraint tests",
        "commit_url": "https://github.com/keras-team/keras/commit/bba53793057c0cdf068e67d17ae90e39b90ae24c",
        "buggy_code": "lookup.add(Embedding(3, 2, weights=[self.W1], W_constraint=unitnorm))",
        "fixed_code": "lookup.add(Embedding(3, 2, weights=[self.W1], W_constraint=unitnorm()))",
        "patch": "@@ -14,7 +14,7 @@ def setUp(self):\n \n     def test_unitnorm_constraint(self):\n         lookup = Sequential()\n-        lookup.add(Embedding(3, 2, weights=[self.W1], W_constraint=unitnorm))\n+        lookup.add(Embedding(3, 2, weights=[self.W1], W_constraint=unitnorm()))\n         lookup.add(Flatten())\n         lookup.add(Dense(2, 1))\n         lookup.add(Activation('sigmoid'))"
    },
    {
        "commit_id": "ce659e568be435116981663d8743b406340c8e77",
        "commit_message": "Fix check for mask",
        "commit_url": "https://github.com/keras-team/keras/commit/ce659e568be435116981663d8743b406340c8e77",
        "buggy_code": "if layer.get_output_mask() is not None and not self.supports_masked_input():",
        "fixed_code": "if not hasattr(self, \"get_output_mask\") and layer.get_output_mask() is not None:",
        "patch": "@@ -20,7 +20,7 @@ def __init__(self):\n         self.params = []\n \n     def connect(self, layer):\n-        if layer.get_output_mask() is not None and not self.supports_masked_input():\n+        if not hasattr(self, \"get_output_mask\") and layer.get_output_mask() is not None:\n             raise Exception(\"Attached non-masking layer to layer with masked output\")\n         self.previous = layer\n "
    },
    {
        "commit_id": "499a05003bbfe050cd8a089a4e1452299dc317b8",
        "commit_message": "Fix regularisers/constraints tests",
        "commit_url": "https://github.com/keras-team/keras/commit/499a05003bbfe050cd8a089a4e1452299dc317b8",
        "buggy_code": "for reg in [regularizers.identity, regularizers.l1(), regularizers.l2(), regularizers.l1l2()]:",
        "fixed_code": "for reg in [regularizers.identity(), regularizers.l1(), regularizers.l2(), regularizers.l1l2()]:",
        "patch": "@@ -44,7 +44,7 @@ def create_model(weight_reg=None, activity_reg=None):\n \n class TestRegularizers(unittest.TestCase):\n     def test_W_reg(self):\n-        for reg in [regularizers.identity, regularizers.l1(), regularizers.l2(), regularizers.l1l2()]:\n+        for reg in [regularizers.identity(), regularizers.l1(), regularizers.l2(), regularizers.l1l2()]:\n             model = create_model(weight_reg=reg)\n             model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n             model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=0)"
    },
    {
        "commit_id": "499a05003bbfe050cd8a089a4e1452299dc317b8",
        "commit_message": "Fix regularisers/constraints tests",
        "commit_url": "https://github.com/keras-team/keras/commit/499a05003bbfe050cd8a089a4e1452299dc317b8",
        "buggy_code": "model.add(Dense(20, 20, W_constraint=nonneg))",
        "fixed_code": "model.add(Dense(20, 20, W_constraint=nonneg()))",
        "patch": "@@ -35,7 +35,7 @@\n model.add(Dense(784, 20, W_constraint=maxnorm(1)))\n model.add(Activation('relu'))\n model.add(Dropout(0.1))\n-model.add(Dense(20, 20, W_constraint=nonneg))\n+model.add(Dense(20, 20, W_constraint=nonneg()))\n model.add(Activation('relu'))\n model.add(Dropout(0.1))\n model.add(Dense(20, 10, W_constraint=maxnorm(1)))"
    },
    {
        "commit_id": "515c430f43ab4a9423069b20627e64d943e2a198",
        "commit_message": "Merge autoencoder fix",
        "commit_url": "https://github.com/keras-team/keras/commit/515c430f43ab4a9423069b20627e64d943e2a198",
        "buggy_code": "self.encoder.previous = node",
        "fixed_code": "self.encoder.connect(node)",
        "patch": "@@ -356,7 +356,7 @@ def __init__(self, encoder, decoder, output_reconstruction=True, tie_weights=Fal\n             self.set_weights(weights)\n \n     def connect(self, node):\n-        self.encoder.previous = node\n+        self.encoder.connect(node)\n \n     def get_weights(self):\n         weights = []"
    },
    {
        "commit_id": "c274cb990b33b77cc30d787e3c6705aa0695157b",
        "commit_message": "utils/generic_utils: fix unicode strings problem\n\nin get_from_module(), a unicode identifier should be treated as a str\ntype.\n\nSigned-off-by: Amit Beka <amit.beka@gmail.com>",
        "commit_url": "https://github.com/keras-team/keras/commit/c274cb990b33b77cc30d787e3c6705aa0695157b",
        "buggy_code": "if type(identifier) is str:",
        "fixed_code": "if isinstance(identifier, basestring):",
        "patch": "@@ -4,7 +4,7 @@\n import sys\n \n def get_from_module(identifier, module_params, module_name, instantiate=False):\n-    if type(identifier) is str:\n+    if isinstance(identifier, basestring):\n         res = module_params.get(identifier)\n         if not res:\n             raise Exception('Invalid ' + str(module_name) + ': ' + str(identifier))"
    },
    {
        "commit_id": "32c507eaf81063cee449e152459b85a7037614bc",
        "commit_message": "Fix for the GPU again",
        "commit_url": "https://github.com/keras-team/keras/commit/32c507eaf81063cee449e152459b85a7037614bc",
        "buggy_code": "mask_tm1 = alloc_zeros_matrix(*mask.shape)",
        "fixed_code": "mask_tm1 = alloc_zeros_matrix(*mask.shape).astype('int8')",
        "patch": "@@ -55,7 +55,7 @@ def get_output(self, train):\n         mask = T.neq(X, self.mask_val).sum(axis=2) > 0 # (time, nb_samples) matrix with a 1 for every unmasked entry\n         mask = T.addbroadcast(mask[:, :, np.newaxis], 2)\n \n-        mask_tm1 = alloc_zeros_matrix(*mask.shape)\n+        mask_tm1 = alloc_zeros_matrix(*mask.shape).astype('int8')\n         mask_tm1 = T.addbroadcast(T.set_subtensor(mask_tm1[1:, :, :], mask[:-1, :, :]), 2)\n \n         x = T.dot(X, self.W) + self.b"
    },
    {
        "commit_id": "8e5cdd16895cac4e3d24f81b456121dd2857b31e",
        "commit_message": "Merge pull request #238 from jfsantos/patch-1\n\nFix typo",
        "commit_url": "https://github.com/keras-team/keras/commit/8e5cdd16895cac4e3d24f81b456121dd2857b31e",
        "buggy_code": "print(\"Epoch %05d: valdidation loss improved from %0.5f to %0.5f, saving model to %s\"",
        "fixed_code": "print(\"Epoch %05d: validation loss improved from %0.5f to %0.5f, saving model to %s\"",
        "patch": "@@ -201,7 +201,7 @@ def on_epoch_end(self, epoch, logs={}):\n             self.val_loss.append(cur_val_loss)\n             if cur_val_loss < self.best_val_loss:\n                 if self.verbose > 0:\n-                    print(\"Epoch %05d: valdidation loss improved from %0.5f to %0.5f, saving model to %s\"\n+                    print(\"Epoch %05d: validation loss improved from %0.5f to %0.5f, saving model to %s\"\n                         % (epoch, self.best_val_loss, cur_val_loss, self.filepath))\n                 self.best_val_loss = cur_val_loss\n                 self.model.save_weights(self.filepath, overwrite=True)"
    },
    {
        "commit_id": "45775e36b1a911be13a7c30b8f4d3a9908115aa4",
        "commit_message": "Fix typo",
        "commit_url": "https://github.com/keras-team/keras/commit/45775e36b1a911be13a7c30b8f4d3a9908115aa4",
        "buggy_code": "print(\"Epoch %05d: valdidation loss improved from %0.5f to %0.5f, saving model to %s\"",
        "fixed_code": "print(\"Epoch %05d: validation loss improved from %0.5f to %0.5f, saving model to %s\"",
        "patch": "@@ -201,7 +201,7 @@ def on_epoch_end(self, epoch, logs={}):\n             self.val_loss.append(cur_val_loss)\n             if cur_val_loss < self.best_val_loss:\n                 if self.verbose > 0:\n-                    print(\"Epoch %05d: valdidation loss improved from %0.5f to %0.5f, saving model to %s\"\n+                    print(\"Epoch %05d: validation loss improved from %0.5f to %0.5f, saving model to %s\"\n                         % (epoch, self.best_val_loss, cur_val_loss, self.filepath))\n                 self.best_val_loss = cur_val_loss\n                 self.model.save_weights(self.filepath, overwrite=True)"
    },
    {
        "commit_id": "bf4822f675325f5cfc60911ee30878bdf9f2b98c",
        "commit_message": "Fix autoencoder issue",
        "commit_url": "https://github.com/keras-team/keras/commit/bf4822f675325f5cfc60911ee30878bdf9f2b98c",
        "buggy_code": "epsilon = 1.0e-15",
        "fixed_code": "epsilon = 1.0e-9",
        "patch": "@@ -4,7 +4,7 @@\n import numpy as np\n from six.moves import range\n \n-epsilon = 1.0e-15\n+epsilon = 1.0e-9\n \n def mean_squared_error(y_true, y_pred):\n     return T.sqr(y_pred - y_true).mean()"
    },
    {
        "commit_id": "829b7ab289b0ce2d927dfe79020b0fb1272c14ca",
        "commit_message": "fixed error in binary crossentropy obj",
        "commit_url": "https://github.com/keras-team/keras/commit/829b7ab289b0ce2d927dfe79020b0fb1272c14ca",
        "buggy_code": "bce = T.nnet.binary_crossentropy(y_pred, y_true).mean()",
        "fixed_code": "bce = T.nnet.binary_crossentropy(y_pred, y_true)",
        "patch": "@@ -45,7 +45,7 @@ def categorical_crossentropy(y_true, y_pred, weight=None):\n \n def binary_crossentropy(y_true, y_pred, weight=None):\n     y_pred = T.clip(y_pred, epsilon, 1.0 - epsilon)\n-    bce = T.nnet.binary_crossentropy(y_pred, y_true).mean()\n+    bce = T.nnet.binary_crossentropy(y_pred, y_true)\n     if weight is not None:\n         return (weight*bce).mean()\n     else:"
    },
    {
        "commit_id": "755728dbb0e1d66a08fdf498273b1531ac93089d",
        "commit_message": "fix sampling table lookup",
        "commit_url": "https://github.com/keras-team/keras/commit/755728dbb0e1d66a08fdf498273b1531ac93089d",
        "buggy_code": "if sampling_table[i] < random.random():",
        "fixed_code": "if sampling_table[wi] < random.random():",
        "patch": "@@ -69,7 +69,7 @@ def skipgrams(sequence, vocabulary_size,\n         if not wi:\n             continue\n         if sampling_table is not None:\n-            if sampling_table[i] < random.random():\n+            if sampling_table[wi] < random.random():\n                 continue\n \n         window_start = max(0, i-window_size)"
    },
    {
        "commit_id": "5b4a0631e60bd52285ab632f69a6dbcc55fd033f",
        "commit_message": "Merge pull request #154 from SimonSuster/skipgrams\n\nFix sampling table lookup in skipgrams",
        "commit_url": "https://github.com/keras-team/keras/commit/5b4a0631e60bd52285ab632f69a6dbcc55fd033f",
        "buggy_code": "if sampling_table[i] < random.random():",
        "fixed_code": "if sampling_table[wi] < random.random():",
        "patch": "@@ -69,7 +69,7 @@ def skipgrams(sequence, vocabulary_size,\n         if not wi:\n             continue\n         if sampling_table is not None:\n-            if sampling_table[i] < random.random():\n+            if sampling_table[wi] < random.random():\n                 continue\n \n         window_start = max(0, i-window_size)"
    },
    {
        "commit_id": "cc10c4d907d959eb9009ad502c727542a5259613",
        "commit_message": "fix sampling table lookup",
        "commit_url": "https://github.com/keras-team/keras/commit/cc10c4d907d959eb9009ad502c727542a5259613",
        "buggy_code": "if sampling_table[i] < random.random():",
        "fixed_code": "if sampling_table[wi] < random.random():",
        "patch": "@@ -69,7 +69,7 @@ def skipgrams(sequence, vocabulary_size,\n         if not wi:\n             continue\n         if sampling_table is not None:\n-            if sampling_table[i] < random.random():\n+            if sampling_table[wi] < random.random():\n                 continue\n \n         window_start = max(0, i-window_size)"
    },
    {
        "commit_id": "4ad874c9c40c27b3faaad086987e5232fe893048",
        "commit_message": "Fix progress bar issue in screen where output clobbered previous output",
        "commit_url": "https://github.com/keras-team/keras/commit/4ad874c9c40c27b3faaad086987e5232fe893048",
        "buggy_code": "sys.stdout.write(\"\\b\" * (self.total_width+1))",
        "fixed_code": "sys.stdout.write(\"\\b\" * prev_total_width)",
        "patch": "@@ -70,7 +70,7 @@ def update(self, current, values=[]):\n         now = time.time()\n         if self.verbose == 1:\n             prev_total_width = self.total_width\n-            sys.stdout.write(\"\\b\" * (self.total_width+1))\n+            sys.stdout.write(\"\\b\" * prev_total_width)\n             sys.stdout.write(\"\\r\")\n \n             numdigits = int(np.floor(np.log10(self.target))) + 1"
    },
    {
        "commit_id": "abedfa8a6483a0190a98aa68a5a25f20d983db6c",
        "commit_message": "Fix clipnorm",
        "commit_url": "https://github.com/keras-team/keras/commit/abedfa8a6483a0190a98aa68a5a25f20d983db6c",
        "buggy_code": "grads = [clip_norm(g, c, norm) for g in grads]",
        "fixed_code": "grads = [clip_norm(g, self.clipnorm, norm) for g in grads]",
        "patch": "@@ -24,7 +24,7 @@ def get_gradients(self, cost, params, regularizers):\n \n         if hasattr(self, 'clipnorm') and self.clipnorm > 0:\n             norm = T.sqrt(sum([T.sum(g**2) for g in grads]))\n-            grads = [clip_norm(g, c, norm) for g in grads]\n+            grads = [clip_norm(g, self.clipnorm, norm) for g in grads]\n \n         new_grads = []\n         for p, g, r in zip(params, grads, regularizers):"
    },
    {
        "commit_id": "9a45500de99dd22361aa992db5ad8e0904d1dbc2",
        "commit_message": "Fix init in SimpleDeepRNN",
        "commit_url": "https://github.com/keras-team/keras/commit/9a45500de99dd22361aa992db5ad8e0904d1dbc2",
        "buggy_code": "self.Us = [self.init((self.output_dim, self.output_dim)) for _ in range(self.depth)]",
        "fixed_code": "self.Us = [self.inner_init((self.output_dim, self.output_dim)) for _ in range(self.depth)]",
        "patch": "@@ -106,7 +106,7 @@ def __init__(self, input_dim, output_dim, depth=3,\n         self.input = T.tensor3()\n \n         self.W = self.init((self.input_dim, self.output_dim))\n-        self.Us = [self.init((self.output_dim, self.output_dim)) for _ in range(self.depth)]\n+        self.Us = [self.inner_init((self.output_dim, self.output_dim)) for _ in range(self.depth)]\n         self.b = shared_zeros((self.output_dim))\n         self.params = [self.W] + self.Us + [self.b]\n "
    },
    {
        "commit_id": "2fcbc5601cf6b3c1d57b5ad4951ed4ba1dda1353",
        "commit_message": "Merge pull request #110 from weilinear/fix_typo\n\nFix a typo in the kaggle otto exmaple.",
        "commit_url": "https://github.com/keras-team/keras/commit/2fcbc5601cf6b3c1d57b5ad4951ed4ba1dda1353",
        "buggy_code": "def preprocess_labels(y, encoder=None, categorical=True):",
        "fixed_code": "def preprocess_labels(labels, encoder=None, categorical=True):",
        "patch": "@@ -53,7 +53,7 @@ def preprocess_data(X, scaler=None):\n     X = scaler.transform(X)\n     return X, scaler\n \n-def preprocess_labels(y, encoder=None, categorical=True):\n+def preprocess_labels(labels, encoder=None, categorical=True):\n     if not encoder:\n         encoder = LabelEncoder()\n         encoder.fit(labels)"
    },
    {
        "commit_id": "c0691dfad9a8faff83764929caecefd0ffc6efc2",
        "commit_message": "Fix typo where label should be used. Original files work fine because `labels` is a global variable",
        "commit_url": "https://github.com/keras-team/keras/commit/c0691dfad9a8faff83764929caecefd0ffc6efc2",
        "buggy_code": "def preprocess_labels(y, encoder=None, categorical=True):",
        "fixed_code": "def preprocess_labels(labels, encoder=None, categorical=True):",
        "patch": "@@ -53,7 +53,7 @@ def preprocess_data(X, scaler=None):\n     X = scaler.transform(X)\n     return X, scaler\n \n-def preprocess_labels(y, encoder=None, categorical=True):\n+def preprocess_labels(labels, encoder=None, categorical=True):\n     if not encoder:\n         encoder = LabelEncoder()\n         encoder.fit(labels)"
    },
    {
        "commit_id": "083bf1c71d84561b3ac76cda4c4a2897830d95e0",
        "commit_message": "Fix image preprocessing normalization",
        "commit_url": "https://github.com/keras-team/keras/commit/083bf1c71d84561b3ac76cda4c4a2897830d95e0",
        "buggy_code": "self.std = np.std(X)",
        "fixed_code": "self.std = np.std(X, axis=0)",
        "patch": "@@ -229,7 +229,7 @@ def fit(self, X,\n             self.mean = np.mean(X, axis=0)\n             X -= self.mean\n         if self.featurewise_std_normalization:\n-            self.std = np.std(X)\n+            self.std = np.std(X, axis=0)\n             X /= self.std\n \n         if self.zca_whitening:"
    },
    {
        "commit_id": "c53c15dbd007480100920b692782e28f6f23c86f",
        "commit_message": "Fix Reuters example",
        "commit_url": "https://github.com/keras-team/keras/commit/c53c15dbd007480100920b692782e28f6f23c86f",
        "buggy_code": "X = np.zeros((len(sequences), nb_words+1))",
        "fixed_code": "X = np.zeros((len(sequences), nb_words))",
        "patch": "@@ -149,7 +149,7 @@ def sequences_to_matrix(self, sequences, mode=\"binary\"):\n         if mode == \"tfidf\" and not self.document_count:\n             raise Exception(\"Fit the Tokenizer on some data before using tfidf mode\")\n \n-        X = np.zeros((len(sequences), nb_words+1))\n+        X = np.zeros((len(sequences), nb_words))\n         for i, seq in enumerate(sequences):\n             if not seq:\n                 pass"
    },
    {
        "commit_id": "22012fdecc1deec6827624de1a6f4bf17e416b38",
        "commit_message": "Fix Otto example",
        "commit_url": "https://github.com/keras-team/keras/commit/22012fdecc1deec6827624de1a6f4bf17e416b38",
        "buggy_code": "X_test, _ = preprocess_data(X_test)",
        "fixed_code": "X_test, _ = preprocess_data(X_test, scaler)",
        "patch": "@@ -80,7 +80,7 @@ def make_submission(y_prob, ids, encoder, fname):\n y, encoder = preprocess_labels(labels)\n \n X_test, ids = load_data('test.csv', train=False)\n-X_test, _ = preprocess_data(X_test)\n+X_test, _ = preprocess_data(X_test, scaler)\n \n nb_classes = y.shape[1]\n print(nb_classes, 'classes')"
    },
    {
        "commit_id": "5d032cbf9ea40d813ea887182a214a5296172aac",
        "commit_message": "Fix sequence to matrix vectorization",
        "commit_url": "https://github.com/keras-team/keras/commit/5d032cbf9ea40d813ea887182a214a5296172aac",
        "buggy_code": "X = np.zeros((len(sequences), nb_words))",
        "fixed_code": "X = np.zeros((len(sequences), nb_words+1))",
        "patch": "@@ -149,7 +149,7 @@ def sequences_to_matrix(self, sequences, mode=\"binary\"):\n         if mode == \"tfidf\" and not self.document_count:\n             raise Exception(\"Fit the Tokenizer on some data before using tfidf mode\")\n \n-        X = np.zeros((len(sequences), nb_words))\n+        X = np.zeros((len(sequences), nb_words+1))\n         for i, seq in enumerate(sequences):\n             if not seq:\n                 pass"
    },
    {
        "commit_id": "5da6fb21160774eb8cdf4ae5aa9e4400c5976f0c",
        "commit_message": "Merge pull request #57 from capybaralet/fchollet_master\n\nfix verbose=2?",
        "commit_url": "https://github.com/keras-team/keras/commit/5da6fb21160774eb8cdf4ae5aa9e4400c5976f0c",
        "buggy_code": "print(\"loss: %.4f - acc.: %.4f\" % (loss, acc))",
        "fixed_code": "print(\"loss: %.4f - val. loss: %.4f\" % (loss, val_loss))",
        "patch": "@@ -157,7 +157,7 @@ def fit(self, X, y, batch_size=128, nb_epoch=100, verbose=1,\n                             if verbose==1:\n                                 progbar.update(batch_end, [('loss', loss), ('val. loss', val_loss)])\n                             if verbose==2:\n-                                print(\"loss: %.4f - acc.: %.4f\" % (loss, acc))\n+                                print(\"loss: %.4f - val. loss: %.4f\" % (loss, val_loss))\n \n             \n     def predict_proba(self, X, batch_size=128, verbose=1):"
    },
    {
        "commit_id": "254b7cb1ad7322e423dd636d85e47b1261a0e962",
        "commit_message": "fix verbose=2?",
        "commit_url": "https://github.com/keras-team/keras/commit/254b7cb1ad7322e423dd636d85e47b1261a0e962",
        "buggy_code": "print(\"loss: %.4f - acc.: %.4f\" % (loss, acc))",
        "fixed_code": "print(\"loss: %.4f - val. loss: %.4f\" % (loss, val_loss))",
        "patch": "@@ -157,7 +157,7 @@ def fit(self, X, y, batch_size=128, nb_epoch=100, verbose=1,\n                             if verbose==1:\n                                 progbar.update(batch_end, [('loss', loss), ('val. loss', val_loss)])\n                             if verbose==2:\n-                                print(\"loss: %.4f - acc.: %.4f\" % (loss, acc))\n+                                print(\"loss: %.4f - val. loss: %.4f\" % (loss, val_loss))\n \n             \n     def predict_proba(self, X, batch_size=128, verbose=1):"
    },
    {
        "commit_id": "5f25e2205ae61e5d7ce02d5ac14fb810561ea2c8",
        "commit_message": "Fix cifar10 example",
        "commit_url": "https://github.com/keras-team/keras/commit/5f25e2205ae61e5d7ce02d5ac14fb810561ea2c8",
        "buggy_code": "model.add(Flatten(64*8*8))",
        "fixed_code": "model.add(Flatten())",
        "patch": "@@ -53,7 +53,7 @@\n model.add(MaxPooling2D(poolsize=(2, 2)))\n model.add(Dropout(0.25))\n \n-model.add(Flatten(64*8*8))\n+model.add(Flatten())\n model.add(Dense(64*8*8, 512, init='normal'))\n model.add(Activation('relu'))\n model.add(Dropout(0.5))"
    },
    {
        "commit_id": "2662d81a9c925501831f0acb805c9e8adcde0a32",
        "commit_message": "Fix Adam to match the original paper",
        "commit_url": "https://github.com/keras-team/keras/commit/2662d81a9c925501831f0acb805c9e8adcde0a32",
        "buggy_code": "p_t = p - self.lr * m_b_t / (T.sqrt(v_t) + self.epsilon)",
        "fixed_code": "p_t = p - self.lr * m_b_t / (T.sqrt(v_b_t) + self.epsilon)",
        "patch": "@@ -160,7 +160,7 @@ def get_updates(self, params, cost):\n             m_b_t = m_t / (1 - beta_1_t)\n             v_b_t = v_t / (1 - beta_2_t)\n \n-            p_t = p - self.lr * m_b_t / (T.sqrt(v_t) + self.epsilon)\n+            p_t = p - self.lr * m_b_t / (T.sqrt(v_b_t) + self.epsilon)\n \n             updates.append((m, m_t))\n             updates.append((v, v_t))"
    },
    {
        "commit_id": "f6cd4c8314af339baa9f4c9e75382c98cca054a5",
        "commit_message": "Fix generic import exception message",
        "commit_url": "https://github.com/keras-team/keras/commit/f6cd4c8314af339baa9f4c9e75382c98cca054a5",
        "buggy_code": "raise Exception('Invalid', module_name, ': ' + identifier)",
        "fixed_code": "raise Exception('Invalid ' + str(module_name) + ': ' + str(identifier))",
        "patch": "@@ -6,7 +6,7 @@ def get_from_module(identifier, module_params, module_name, instantiate=False):\n     if type(identifier) is str:\n         res = module_params.get(identifier)\n         if not res:\n-            raise Exception('Invalid', module_name, ': ' + identifier)\n+            raise Exception('Invalid ' + str(module_name) + ': ' + str(identifier))\n         if instantiate:\n             return res()\n         else:"
    },
    {
        "commit_id": "9da5a0c6c9cc05cced5bf4d6e9af53fce182c5ff",
        "commit_message": "Merge pull request #5 from nagadomi/fix_untar\n\nFix untar",
        "commit_url": "https://github.com/keras-team/keras/commit/9da5a0c6c9cc05cced5bf4d6e9af53fce182c5ff",
        "buggy_code": "if os.path.exists(fpath):",
        "fixed_code": "if os.path.exists(untar_fpath):",
        "patch": "@@ -30,7 +30,7 @@ def dl_progress(count, block_size, total_size):\n         progbar = None\n \n     if untar:\n-        if os.path.exists(fpath):\n+        if os.path.exists(untar_fpath):\n             pass\n         else:\n             print 'Unraring file...'"
    },
    {
        "commit_id": "0ca14146ab678b2e26206d0bee920c7d5c43f3e5",
        "commit_message": "Fix untar",
        "commit_url": "https://github.com/keras-team/keras/commit/0ca14146ab678b2e26206d0bee920c7d5c43f3e5",
        "buggy_code": "if os.path.exists(fpath):",
        "fixed_code": "if os.path.exists(untar_fpath):",
        "patch": "@@ -30,7 +30,7 @@ def dl_progress(count, block_size, total_size):\n         progbar = None\n \n     if untar:\n-        if os.path.exists(fpath):\n+        if os.path.exists(untar_fpath):\n             pass\n         else:\n             print 'Unraring file...'"
    }
]