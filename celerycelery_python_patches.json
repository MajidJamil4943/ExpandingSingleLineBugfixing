[
    {
        "commit_id": "cc9e96de90a434a4901aaad9e3f9769339f3a3e4",
        "commit_message": "Fix typo for default of sig",
        "commit_url": "https://github.com/celery/celery/commit/cc9e96de90a434a4901aaad9e3f9769339f3a3e4",
        "buggy_code": "def _shutdown_handler(worker: Worker, sig='TERM', how='Warm', callback=None, exitcode=EX_OK, verbose=True):",
        "fixed_code": "def _shutdown_handler(worker: Worker, sig='SIGTERM', how='Warm', callback=None, exitcode=EX_OK, verbose=True):",
        "patch": "@@ -279,7 +279,7 @@ def set_process_status(self, info):\n         )\n \n \n-def _shutdown_handler(worker: Worker, sig='TERM', how='Warm', callback=None, exitcode=EX_OK, verbose=True):\n+def _shutdown_handler(worker: Worker, sig='SIGTERM', how='Warm', callback=None, exitcode=EX_OK, verbose=True):\n     \"\"\"Install signal handler for warm/cold shutdown.\n \n     The handler will run from the MainProcess."
    },
    {
        "commit_id": "1fbfeca8ad53c63a8380b904dcc6d8b3c3d752c7",
        "commit_message": "Unauthorized Changes Cleanup (#9528)\n\nReverting unauthorized code changes due to security incident #9525:\r\nhttps://github.com/celery/celery/discussions/9525\r\n\r\n* Revert \"Update canvas.rst to fix output result from chain object (#9502)\"\r\n\r\nThis reverts commit d5ebfc9d5a2d856413df1e7d14739ec58fae4dd3.\r\n\r\n* Revert \"Bump pytest-github-actions-annotate-failures from 0.2.0 to 0.3.0 (#9504)\"\r\n\r\nThis reverts commit dc6726eaaedf756a8441bb0257c437db3f461918.\r\n\r\n* Revert \"Link to the correct IRC network (#9509)\"\r\n\r\nThis reverts commit 3fdb466d0e413362379074d1c4348d13321af203.\r\n\r\n* Revert \"Replacing a task with a chain which contains a group now returns a result instead of hanging. (#9510)\"\r\n\r\nThis reverts commit 0c402b0b6a1e0e608d02c3a16453e39d8b1d9ef2.\r\n\r\n* Revert \"[pre-commit.ci] pre-commit autoupdate\"\r\n\r\nThis reverts commit fe761416f4d9269b780a13cc1131e2a16945937f.\r\n\r\n* Revert \"Replacing a task with a chain which contains a group now returns a result instead of hanging. (#9484)\"\r\n\r\nThis reverts commit 48aaadedfcde043fa973ff2176abbb5fec9691e5.\r\n\r\n* Revert \"fix(django): catch the right error when trying to close db connection (#9392)\"\r\n\r\nThis reverts commit 7315c436c194ed23f7620448f902924733b5fcef.\r\n\r\n* Revert \"Unroll group when chaining a group with a single item to another signature when using the | operator. (#9456)\"\r\n\r\nThis reverts commit 3ae15c1dfc80c102aed05ad9c1d38470218b2fc8.",
        "commit_url": "https://github.com/celery/celery/commit/1fbfeca8ad53c63a8380b904dcc6d8b3c3d752c7",
        "buggy_code": "c = group([self.mytask.s(), self.mytask.s()], app=self.app)",
        "fixed_code": "c = group([self.mytask.s()], app=self.app)",
        "patch": "@@ -1165,7 +1165,7 @@ def test_replace_with_chord(self):\n             self.mytask.replace(sig1)\n \n     def test_replace_callback(self):\n-        c = group([self.mytask.s(), self.mytask.s()], app=self.app)\n+        c = group([self.mytask.s()], app=self.app)\n         c.freeze = Mock(name='freeze')\n         c.delay = Mock(name='delay')\n         self.mytask.request.id = 'id'"
    },
    {
        "commit_id": "3ae15c1dfc80c102aed05ad9c1d38470218b2fc8",
        "commit_message": "Unroll group when chaining a group with a single item to another signature when using the | operator. (#9456)\n\nAdd documentation.\r\n\r\nFix tests.",
        "commit_url": "https://github.com/celery/celery/commit/3ae15c1dfc80c102aed05ad9c1d38470218b2fc8",
        "buggy_code": "c = group([self.mytask.s()], app=self.app)",
        "fixed_code": "c = group([self.mytask.s(), self.mytask.s()], app=self.app)",
        "patch": "@@ -1165,7 +1165,7 @@ def test_replace_with_chord(self):\n             self.mytask.replace(sig1)\n \n     def test_replace_callback(self):\n-        c = group([self.mytask.s()], app=self.app)\n+        c = group([self.mytask.s(), self.mytask.s()], app=self.app)\n         c.freeze = Mock(name='freeze')\n         c.delay = Mock(name='delay')\n         self.mytask.request.id = 'id'"
    },
    {
        "commit_id": "fa5d7ff09c93516c9d5712351f56db3d22876395",
        "commit_message": "Native Delayed Delivery in RabbitMQ (#9207)\n\n* Add the DelayedDelivery bootstep.\r\n\r\n* Comment POC code only\r\n\r\n* Add feature flag.\r\n\r\n* Add coverage for include_if.\r\n\r\n* Remove POC only code.\r\n\r\n* Added unit tests for delayed delivery implementation.\r\n\r\n* Autopep8.\r\n\r\n* Fix import sorting.\r\n\r\n* Add coverage for case when native delayed delivery is enabled but no eta or countdown were provided\r\n\r\n* formatting fix.\r\n\r\n* Add coverage for delayed delivery.\r\n\r\n* Formatting fix.\r\n\r\n* Adjust warning and disable qos global when using native delayed delivery.\r\n\r\n* Added basic smoke tests for native delayed delivery.\r\n\r\n* Added smoke tests that test the configuration of the native delayed delivery queues and exchanges.\r\n\r\n* Add condition for not handling countdowns in the past and direct exchanges\r\n\r\n* Add warning when native delayed delivery is enabled but the exchange is a direct exchange.\r\n\r\n* Fixed a bug where the delayed message would be published to celery_delayed_27 as well as the right queue.\r\n\r\n* Add broker_native_delayed_delivery setting to documentation.\r\n\r\n* Add title.\r\n\r\n* Added documentation for the broker_native_delayed_delivery setting.\r\n\r\n* Added the broker_native_delayed_delivery_queue_type setting.\r\n\r\n* Document quorum queues and limitations.\r\n\r\n* Add documentation regarding native delayed delivery.\r\n\r\n* Mention that confirmed publish must be set to true.\r\n\r\n* Cover both values of broker_native_delayed_delivery_queue_type in smoke tests.\r\n\r\n* Revert usage of broker_native_delayed_delivery_queue_type.\r\n\r\n* logger.warn is deprecated\r\n\r\n* Fix include_if condition to take failover into consideration.\r\n\r\n* Fix smoke tests.\r\n\r\n* Revert \"Revert usage of broker_native_delayed_delivery_queue_type.\"\r\n\r\nThis reverts commit ce3156005254a8576792bb23d377f261bebc6ca2.\r\n\r\n* Apply x-dead-letter-strategy only on quorum queues.\r\n\r\n* Fix unit tests.\r\n\r\n* Use kombu native delayed delivery API.\r\n\r\n* Add documentation.\r\n\r\n* Delayed native delivery queues can now be non-quorum queues.\r\n\r\n* Declare native delayed delivery queues on failover brokers as well.\r\n\r\n* Fix unit tests.\r\n\r\n* Use connection to check for the transport type.\r\n\r\n* Add versionadded to the documentation.\r\n\r\n* Add link to quorum queues migration guide.\r\n\r\n* Fix failover when connection is refused.\r\n\r\n* Change native delayed delivery queue type default to quorum.\r\n\r\n* Remove warning.\r\n\r\n* Use native delayed delivery automatically when quorum queues are detected.\r\n\r\n* Remove the broker_native_delayed_delivery configuration setting.\r\n\r\n* Use fixtures and extract common test code.\r\n\r\n* Adjust documentation.",
        "commit_url": "https://github.com/celery/celery/commit/fa5d7ff09c93516c9d5712351f56db3d22876395",
        "buggy_code": "\"ReturnValues\" : \"UPDATED_NEW\",",
        "fixed_code": "\"ReturnValues\": \"UPDATED_NEW\",",
        "patch": "@@ -504,7 +504,7 @@ def _prepare_inc_count_request(self, key: str) -> Dict[str, Any]:\n             \"ExpressionAttributeValues\": {\n                 \":num\": {\"N\": \"1\"},\n             },\n-            \"ReturnValues\" : \"UPDATED_NEW\",\n+            \"ReturnValues\": \"UPDATED_NEW\",\n         }\n \n     def _item_to_dict(self, raw_response):"
    },
    {
        "commit_id": "fa5d7ff09c93516c9d5712351f56db3d22876395",
        "commit_message": "Native Delayed Delivery in RabbitMQ (#9207)\n\n* Add the DelayedDelivery bootstep.\r\n\r\n* Comment POC code only\r\n\r\n* Add feature flag.\r\n\r\n* Add coverage for include_if.\r\n\r\n* Remove POC only code.\r\n\r\n* Added unit tests for delayed delivery implementation.\r\n\r\n* Autopep8.\r\n\r\n* Fix import sorting.\r\n\r\n* Add coverage for case when native delayed delivery is enabled but no eta or countdown were provided\r\n\r\n* formatting fix.\r\n\r\n* Add coverage for delayed delivery.\r\n\r\n* Formatting fix.\r\n\r\n* Adjust warning and disable qos global when using native delayed delivery.\r\n\r\n* Added basic smoke tests for native delayed delivery.\r\n\r\n* Added smoke tests that test the configuration of the native delayed delivery queues and exchanges.\r\n\r\n* Add condition for not handling countdowns in the past and direct exchanges\r\n\r\n* Add warning when native delayed delivery is enabled but the exchange is a direct exchange.\r\n\r\n* Fixed a bug where the delayed message would be published to celery_delayed_27 as well as the right queue.\r\n\r\n* Add broker_native_delayed_delivery setting to documentation.\r\n\r\n* Add title.\r\n\r\n* Added documentation for the broker_native_delayed_delivery setting.\r\n\r\n* Added the broker_native_delayed_delivery_queue_type setting.\r\n\r\n* Document quorum queues and limitations.\r\n\r\n* Add documentation regarding native delayed delivery.\r\n\r\n* Mention that confirmed publish must be set to true.\r\n\r\n* Cover both values of broker_native_delayed_delivery_queue_type in smoke tests.\r\n\r\n* Revert usage of broker_native_delayed_delivery_queue_type.\r\n\r\n* logger.warn is deprecated\r\n\r\n* Fix include_if condition to take failover into consideration.\r\n\r\n* Fix smoke tests.\r\n\r\n* Revert \"Revert usage of broker_native_delayed_delivery_queue_type.\"\r\n\r\nThis reverts commit ce3156005254a8576792bb23d377f261bebc6ca2.\r\n\r\n* Apply x-dead-letter-strategy only on quorum queues.\r\n\r\n* Fix unit tests.\r\n\r\n* Use kombu native delayed delivery API.\r\n\r\n* Add documentation.\r\n\r\n* Delayed native delivery queues can now be non-quorum queues.\r\n\r\n* Declare native delayed delivery queues on failover brokers as well.\r\n\r\n* Fix unit tests.\r\n\r\n* Use connection to check for the transport type.\r\n\r\n* Add versionadded to the documentation.\r\n\r\n* Add link to quorum queues migration guide.\r\n\r\n* Fix failover when connection is refused.\r\n\r\n* Change native delayed delivery queue type default to quorum.\r\n\r\n* Remove warning.\r\n\r\n* Use native delayed delivery automatically when quorum queues are detected.\r\n\r\n* Remove the broker_native_delayed_delivery configuration setting.\r\n\r\n* Use fixtures and extract common test code.\r\n\r\n* Adjust documentation.",
        "commit_url": "https://github.com/celery/celery/commit/fa5d7ff09c93516c9d5712351f56db3d22876395",
        "buggy_code": "if isinstance(exc , elasticsearch.exceptions.TransportError):",
        "fixed_code": "if isinstance(exc, elasticsearch.exceptions.TransportError):",
        "patch": "@@ -97,7 +97,7 @@ def exception_safe_to_retry(self, exc):\n             # N/A: Low level exception (i.e. socket exception)\n             if exc.status_code in {401, 409, 500, 502, 504, 'N/A'}:\n                 return True\n-        if isinstance(exc , elasticsearch.exceptions.TransportError):\n+        if isinstance(exc, elasticsearch.exceptions.TransportError):\n             return True\n         return False\n "
    },
    {
        "commit_id": "21f73b8e8f09d999af411006ebc6126992f5fd9c",
        "commit_message": "Correct the error description in exception message when validate soft_time_limit (#9246)\n\n* Correct the error description in exception message when validate soft_time_limit\r\n\r\n* Update celery/app/task.py\r\n\r\n---------\r\n\r\nCo-authored-by: Asif Saif Uddin <auvipy@gmail.com>",
        "commit_url": "https://github.com/celery/celery/commit/21f73b8e8f09d999af411006ebc6126992f5fd9c",
        "buggy_code": "with pytest.raises(ValueError, match='soft_time_limit must be greater than or equal to time_limit'):",
        "fixed_code": "with pytest.raises(ValueError, match='soft_time_limit must be less than or equal to time_limit'):",
        "patch": "@@ -477,7 +477,7 @@ def test_properties(self, celery_session_worker):\n     @flaky\n     def test_soft_time_limit_exceeding_time_limit(self):\n \n-        with pytest.raises(ValueError, match='soft_time_limit must be greater than or equal to time_limit'):\n+        with pytest.raises(ValueError, match='soft_time_limit must be less than or equal to time_limit'):\n             result = soft_time_limit_must_exceed_time_limit.apply_async()\n             result.get(timeout=5)\n "
    },
    {
        "commit_id": "21f73b8e8f09d999af411006ebc6126992f5fd9c",
        "commit_message": "Correct the error description in exception message when validate soft_time_limit (#9246)\n\n* Correct the error description in exception message when validate soft_time_limit\r\n\r\n* Update celery/app/task.py\r\n\r\n---------\r\n\r\nCo-authored-by: Asif Saif Uddin <auvipy@gmail.com>",
        "commit_url": "https://github.com/celery/celery/commit/21f73b8e8f09d999af411006ebc6126992f5fd9c",
        "buggy_code": "with pytest.raises(ValueError, match=\"soft_time_limit must be greater than or equal to time_limit\"):",
        "fixed_code": "with pytest.raises(ValueError, match=\"soft_time_limit must be less than or equal to time_limit\"):",
        "patch": "@@ -140,5 +140,5 @@ def test_soft_time_limit_lower_than_time_limit(self, celery_setup: CeleryTestSet\n \n     def test_soft_time_limit_must_exceed_time_limit(self, celery_setup: CeleryTestSetup):\n         sig = soft_time_limit_must_exceed_time_limit.s()\n-        with pytest.raises(ValueError, match=\"soft_time_limit must be greater than or equal to time_limit\"):\n+        with pytest.raises(ValueError, match=\"soft_time_limit must be less than or equal to time_limit\"):\n             sig.apply_async(queue=celery_setup.worker.worker_queue)"
    },
    {
        "commit_id": "21f73b8e8f09d999af411006ebc6126992f5fd9c",
        "commit_message": "Correct the error description in exception message when validate soft_time_limit (#9246)\n\n* Correct the error description in exception message when validate soft_time_limit\r\n\r\n* Update celery/app/task.py\r\n\r\n---------\r\n\r\nCo-authored-by: Asif Saif Uddin <auvipy@gmail.com>",
        "commit_url": "https://github.com/celery/celery/commit/21f73b8e8f09d999af411006ebc6126992f5fd9c",
        "buggy_code": "assert str(e) == 'soft_time_limit must be greater than or equal to time_limit'",
        "fixed_code": "assert str(e) == 'soft_time_limit must be less than or equal to time_limit'",
        "patch": "@@ -1421,7 +1421,7 @@ def yyy():\n \n             assert yyy_result.state == 'FAILURE'\n         except ValueError as e:\n-            assert str(e) == 'soft_time_limit must be greater than or equal to time_limit'\n+            assert str(e) == 'soft_time_limit must be less than or equal to time_limit'\n \n \n class test_apply_task(TasksCase):"
    },
    {
        "commit_id": "71e8db96fbff455b346dd47a3fe617864b0d6697",
        "commit_message": "fix: passes current request context when pushing to request_stack (#9208)\n\nthe _install_stack_protection worker optimisation patches the\r\nBaseTask.__call__ method to call `task.run` directly.\r\nwhen it does not call the `task.run` directly it instead calls\r\nthe BaseTask.__call__ which pushes the new request to the stack,\r\nbut only passes the `args,kwargs` of the task bypassing all the\r\noptions.\r\n(https://github.com/celery/celery/blob/78c06af57ec0bc4afe84bf21289d2c0b50dcb313/celery/app/trace.py#L737)\r\n\r\nthe tracer is properly generating the `request` context based on\r\nall the options passed and directly pushes to the task stack.\r\nalso the tracer skips the `__call__` method\r\n(https://github.com/celery/celery/blob/78c06af57ec0bc4afe84bf21289d2c0b50dcb313/celery/app/trace.py#L324-L327)\r\n\r\nthe combination of the above leads to the tracer calling the task\r\nwith only the args and kwargs of the task.\r\n\r\nthis commit enhances the push_request method to generate a new context\r\nbased on the `task.request` which should include all the options\r\nrequired.\r\n\r\nSigned-off-by: Nikos Atlas <nikatlas@gmail.com>",
        "commit_url": "https://github.com/celery/celery/commit/71e8db96fbff455b346dd47a3fe617864b0d6697",
        "buggy_code": "self.request_stack.push(Context(*args, **kwargs))",
        "fixed_code": "self.request_stack.push(Context(*args, **{**self.request.__dict__, **kwargs}))",
        "patch": "@@ -1114,7 +1114,7 @@ def add_trail(self, result):\n         return result\n \n     def push_request(self, *args, **kwargs):\n-        self.request_stack.push(Context(*args, **kwargs))\n+        self.request_stack.push(Context(*args, **{**self.request.__dict__, **kwargs}))\n \n     def pop_request(self):\n         self.request_stack.pop()"
    },
    {
        "commit_id": "15a63eac5ec22764a8e03a7c254ac2d601bd82b6",
        "commit_message": "Fix typos discovered by codespell",
        "commit_url": "https://github.com/celery/celery/commit/15a63eac5ec22764a8e03a7c254ac2d601bd82b6",
        "buggy_code": "connection (kombu.Connection): Re-use existing broker connection",
        "fixed_code": "connection (kombu.Connection): Reuse existing broker connection",
        "patch": "@@ -466,7 +466,7 @@ def apply_async(self, args=None, kwargs=None, task_id=None, producer=None,\n             shadow (str): Override task name used in logs/monitoring.\n                 Default is retrieved from :meth:`shadow_name`.\n \n-            connection (kombu.Connection): Re-use existing broker connection\n+            connection (kombu.Connection): Reuse existing broker connection\n                 instead of acquiring one from the connection pool.\n \n             retry (bool): If enabled sending of the task message will be"
    },
    {
        "commit_id": "15a63eac5ec22764a8e03a7c254ac2d601bd82b6",
        "commit_message": "Fix typos discovered by codespell",
        "commit_url": "https://github.com/celery/celery/commit/15a63eac5ec22764a8e03a7c254ac2d601bd82b6",
        "buggy_code": "Try to fetch deamonization option from applications settings.",
        "fixed_code": "Try to fetch daemonization option from applications settings.",
        "patch": "@@ -181,7 +181,7 @@ def __init__(self, *args, **kwargs):\n \n     def daemon_setting(self, ctx: Context, opt: CeleryOption, value: Any) -> Any:\n         \"\"\"\n-        Try to fetch deamonization option from applications settings.\n+        Try to fetch daemonization option from applications settings.\n         Use the daemon command name as prefix (eg. `worker` -> `worker_pidfile`)\n         \"\"\"\n         return value or getattr(ctx.obj.app.conf, f\"{ctx.command.name}_{self.name}\", None)"
    },
    {
        "commit_id": "15a63eac5ec22764a8e03a7c254ac2d601bd82b6",
        "commit_message": "Fix typos discovered by codespell",
        "commit_url": "https://github.com/celery/celery/commit/15a63eac5ec22764a8e03a7c254ac2d601bd82b6",
        "buggy_code": "\"\"\"Set flag signifiying that we're inside a signal handler.\"\"\"",
        "fixed_code": "\"\"\"Set flag signifying that we're inside a signal handler.\"\"\"",
        "patch": "@@ -37,7 +37,7 @@\n \n \n def set_in_sighandler(value):\n-    \"\"\"Set flag signifiying that we're inside a signal handler.\"\"\"\n+    \"\"\"Set flag signifying that we're inside a signal handler.\"\"\"\n     global _in_sighandler\n     _in_sighandler = value\n "
    },
    {
        "commit_id": "ee90bed1df866c8a266ac353f7e6eae8ab8a5d72",
        "commit_message": "Fix certificate validity check (#9037)\n\n* Fix certificate validity check\r\n\r\nUse 'not_valid_after_utc' instead of 'not_valid_after' when checking for certificate validity to prevent errors with avare/naive timedates\r\n\r\nFixes error:\r\n\r\nFile \"<>\\site-packages\\celery\\security\\certificate.py\", line 46, in has_expired\r\n    return datetime.datetime.now(datetime.timezone.utc) >= self._cert.not_valid_after\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nTypeError: can't compare offset-naive and offset-aware datetimes\r\n\r\n* Fix tests",
        "commit_url": "https://github.com/celery/celery/commit/ee90bed1df866c8a266ac353f7e6eae8ab8a5d72",
        "buggy_code": "return datetime.datetime.now(datetime.timezone.utc) >= self._cert.not_valid_after",
        "fixed_code": "return datetime.datetime.now(datetime.timezone.utc) >= self._cert.not_valid_after_utc",
        "patch": "@@ -43,7 +43,7 @@ def __init__(self, cert: str) -> None:\n \n     def has_expired(self) -> bool:\n         \"\"\"Check if the certificate has expired.\"\"\"\n-        return datetime.datetime.now(datetime.timezone.utc) >= self._cert.not_valid_after\n+        return datetime.datetime.now(datetime.timezone.utc) >= self._cert.not_valid_after_utc\n \n     def get_pubkey(self) -> (\n         DSAPublicKey | EllipticCurvePublicKey | Ed448PublicKey | Ed25519PublicKey | RSAPublicKey"
    },
    {
        "commit_id": "bfbdcbaf60cd8c1653ebe5b58ac41526b5e1965a",
        "commit_message": "Fix typos and grammar (#8915)\n\nCo-authored-by: Carlos Pe\u00f1a <carlos@hiplead.com>",
        "commit_url": "https://github.com/celery/celery/commit/bfbdcbaf60cd8c1653ebe5b58ac41526b5e1965a",
        "buggy_code": ":param hub_method: the method to call with with each fd and kwargs",
        "fixed_code": ":param hub_method: the method to call with each fd and kwargs",
        "patch": "@@ -194,7 +194,7 @@ def iterate_file_descriptors_safely(fds_iter, source_data,\n     or possibly other reasons, so safely manage our lists of FDs.\n     :param fds_iter: the file descriptors to iterate and apply hub_method\n     :param source_data: data source to remove FD if it renders OSError\n-    :param hub_method: the method to call with with each fd and kwargs\n+    :param hub_method: the method to call with each fd and kwargs\n     :*args to pass through to the hub_method;\n     with a special syntax string '*fd*' represents a substitution\n     for the current fd object in the iteration (for some callers)."
    },
    {
        "commit_id": "bfbdcbaf60cd8c1653ebe5b58ac41526b5e1965a",
        "commit_message": "Fix typos and grammar (#8915)\n\nCo-authored-by: Carlos Pe\u00f1a <carlos@hiplead.com>",
        "commit_url": "https://github.com/celery/celery/commit/bfbdcbaf60cd8c1653ebe5b58ac41526b5e1965a",
        "buggy_code": "but doesn't modifies logging settings and additionally shutdown",
        "fixed_code": "but doesn't modify logging settings and additionally shutdown",
        "patch": "@@ -48,7 +48,7 @@ def embed_worker(app,\n     Helper embedded worker for testing.\n \n     It's based on a :func:`celery.contrib.testing.worker.start_worker`,\n-    but doesn't modifies logging settings and additionally shutdown\n+    but doesn't modify logging settings and additionally shutdown\n     worker pool.\n     \"\"\"\n     # prepare application for worker"
    },
    {
        "commit_id": "bfbdcbaf60cd8c1653ebe5b58ac41526b5e1965a",
        "commit_message": "Fix typos and grammar (#8915)\n\nCo-authored-by: Carlos Pe\u00f1a <carlos@hiplead.com>",
        "commit_url": "https://github.com/celery/celery/commit/bfbdcbaf60cd8c1653ebe5b58ac41526b5e1965a",
        "buggy_code": "\"\"\"Context that verifes signal is called before exiting.\"\"\"",
        "fixed_code": "\"\"\"Context that verifies signal is called before exiting.\"\"\"",
        "patch": "@@ -106,7 +106,7 @@ def reset_cache_backend_state(celery_app):\n \n @contextmanager\n def assert_signal_called(signal, **expected):\n-    \"\"\"Context that verifes signal is called before exiting.\"\"\"\n+    \"\"\"Context that verifies signal is called before exiting.\"\"\"\n     handler = Mock()\n \n     def on_call(**kwargs):"
    },
    {
        "commit_id": "af898ac41fe1b2491f93ad0e4258dfe06f2d3f2a",
        "commit_message": "Bugfix in test_prefetch_count_restored() and other enhancements  (#8580)\n\n* Fixed bug in test: test_prefetch_count_restored()\r\n\r\n* Changed all smoke tests workers log level from INFO to DEBUG\r\n\r\n* Changed usage of wait_for_log() -> assert_log_exists()",
        "commit_url": "https://github.com/celery/celery/commit/af898ac41fe1b2491f93ad0e4258dfe06f2d3f2a",
        "buggy_code": "return \"INFO\"",
        "fixed_code": "return \"DEBUG\"",
        "patch": "@@ -19,7 +19,7 @@ def version(cls) -> str:\n \n     @classmethod\n     def log_level(cls) -> str:\n-        return \"INFO\"\n+        return \"DEBUG\"\n \n     @classmethod\n     def worker_name(cls) -> str:"
    },
    {
        "commit_id": "af898ac41fe1b2491f93ad0e4258dfe06f2d3f2a",
        "commit_message": "Bugfix in test_prefetch_count_restored() and other enhancements  (#8580)\n\n* Fixed bug in test: test_prefetch_count_restored()\r\n\r\n* Changed all smoke tests workers log level from INFO to DEBUG\r\n\r\n* Changed usage of wait_for_log() -> assert_log_exists()",
        "commit_url": "https://github.com/celery/celery/commit/af898ac41fe1b2491f93ad0e4258dfe06f2d3f2a",
        "buggy_code": "return \"INFO\"",
        "fixed_code": "return \"DEBUG\"",
        "patch": "@@ -14,7 +14,7 @@ def client(self) -> Any:\n \n     @classmethod\n     def log_level(cls) -> str:\n-        return \"INFO\"\n+        return \"DEBUG\"\n \n     @classmethod\n     def worker_name(cls) -> str:"
    },
    {
        "commit_id": "af898ac41fe1b2491f93ad0e4258dfe06f2d3f2a",
        "commit_message": "Bugfix in test_prefetch_count_restored() and other enhancements  (#8580)\n\n* Fixed bug in test: test_prefetch_count_restored()\r\n\r\n* Changed all smoke tests workers log level from INFO to DEBUG\r\n\r\n* Changed usage of wait_for_log() -> assert_log_exists()",
        "commit_url": "https://github.com/celery/celery/commit/af898ac41fe1b2491f93ad0e4258dfe06f2d3f2a",
        "buggy_code": "return \"INFO\"",
        "fixed_code": "return \"DEBUG\"",
        "patch": "@@ -18,7 +18,7 @@ def version(cls) -> str:\n \n     @classmethod\n     def log_level(cls) -> str:\n-        return \"INFO\"\n+        return \"DEBUG\"\n \n     @classmethod\n     def worker_name(cls) -> str:"
    },
    {
        "commit_id": "7a27725cc9bd8d6e7b930a748e854f2d00379d47",
        "commit_message": "Fix DeprecationWarning: datetime.datetime.utcnow() (#8726)\n\n> lib/python3.12/site-packages/celery/app/base.py:940: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\r\n    now_in_utc = to_utc(datetime.utcnow())",
        "commit_url": "https://github.com/celery/celery/commit/7a27725cc9bd8d6e7b930a748e854f2d00379d47",
        "buggy_code": "return datetime.datetime.utcnow() >= self._cert.not_valid_after",
        "fixed_code": "return datetime.datetime.now(datetime.timezone.utc) >= self._cert.not_valid_after",
        "patch": "@@ -43,7 +43,7 @@ def __init__(self, cert: str) -> None:\n \n     def has_expired(self) -> bool:\n         \"\"\"Check if the certificate has expired.\"\"\"\n-        return datetime.datetime.utcnow() >= self._cert.not_valid_after\n+        return datetime.datetime.now(datetime.timezone.utc) >= self._cert.not_valid_after\n \n     def get_pubkey(self) -> (\n         DSAPublicKey | EllipticCurvePublicKey | Ed448PublicKey | Ed25519PublicKey | RSAPublicKey"
    },
    {
        "commit_id": "7a27725cc9bd8d6e7b930a748e854f2d00379d47",
        "commit_message": "Fix DeprecationWarning: datetime.datetime.utcnow() (#8726)\n\n> lib/python3.12/site-packages/celery/app/base.py:940: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\r\n    now_in_utc = to_utc(datetime.utcnow())",
        "commit_url": "https://github.com/celery/celery/commit/7a27725cc9bd8d6e7b930a748e854f2d00379d47",
        "buggy_code": "now = now or datetime.utcnow()",
        "fixed_code": "now = now or datetime.now(datetime_timezone.utc)",
        "patch": "@@ -217,7 +217,7 @@ def remaining(\n     Returns:\n         ~datetime.timedelta: Remaining time.\n     \"\"\"\n-    now = now or datetime.utcnow()\n+    now = now or datetime.now(datetime_timezone.utc)\n     if str(\n             start.tzinfo) == str(\n             now.tzinfo) and now.utcoffset() != start.utcoffset():"
    },
    {
        "commit_id": "7a27725cc9bd8d6e7b930a748e854f2d00379d47",
        "commit_message": "Fix DeprecationWarning: datetime.datetime.utcnow() (#8726)\n\n> lib/python3.12/site-packages/celery/app/base.py:940: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\r\n    now_in_utc = to_utc(datetime.utcnow())",
        "commit_url": "https://github.com/celery/celery/commit/7a27725cc9bd8d6e7b930a748e854f2d00379d47",
        "buggy_code": "now = datetime.datetime.utcnow()",
        "fixed_code": "now = datetime.datetime.now(datetime.timezone.utc)",
        "patch": "@@ -74,7 +74,7 @@ def gen_private_key(self):\n     def gen_certificate(self, key, common_name, issuer=None, sign_key=None):\n         \"\"\"generate a certificate with cryptography\"\"\"\n \n-        now = datetime.datetime.utcnow()\n+        now = datetime.datetime.now(datetime.timezone.utc)\n \n         certificate = x509.CertificateBuilder().subject_name(\n             x509.Name(["
    },
    {
        "commit_id": "7a27725cc9bd8d6e7b930a748e854f2d00379d47",
        "commit_message": "Fix DeprecationWarning: datetime.datetime.utcnow() (#8726)\n\n> lib/python3.12/site-packages/celery/app/base.py:940: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\r\n    now_in_utc = to_utc(datetime.utcnow())",
        "commit_url": "https://github.com/celery/celery/commit/7a27725cc9bd8d6e7b930a748e854f2d00379d47",
        "buggy_code": "now = datetime.datetime.utcnow()",
        "fixed_code": "now = datetime.datetime.now(datetime.timezone.utc)",
        "patch": "@@ -210,7 +210,7 @@ def test_backend_cleanup(self):\n         self.backend.cleanup()\n         self.backend.db.AQLQuery.assert_not_called()\n \n-        now = datetime.datetime.utcnow()\n+        now = datetime.datetime.now(datetime.timezone.utc)\n         self.backend.app.now = Mock(return_value=now)\n         self.backend.expires = 86400\n         expected_checkpoint = (now - self.backend.expires_delta).isoformat()"
    },
    {
        "commit_id": "709c5e7b1b6d916e42af17037f841425947b138c",
        "commit_message": "Fix non-zero exit code when receiving remote shutdown (#8650)",
        "commit_url": "https://github.com/celery/celery/commit/709c5e7b1b6d916e42af17037f841425947b138c",
        "buggy_code": "raise WorkerShutdown(msg)",
        "fixed_code": "raise WorkerShutdown(0)",
        "patch": "@@ -580,7 +580,7 @@ def autoscale(state, max=None, min=None):\n def shutdown(state, msg='Got shutdown from remote', **kwargs):\n     \"\"\"Shutdown worker(s).\"\"\"\n     logger.warning(msg)\n-    raise WorkerShutdown(msg)\n+    raise WorkerShutdown(0)\n \n \n # -- Queues"
    },
    {
        "commit_id": "c08e811b383f72157b98e21e178c5c42762d671d",
        "commit_message": "Revert \"Fix eager tasks does not populate name field (#8383)\" (#8476)\n\nThis reverts commit 1c363876147325a196c474e757e355c451a0cdff.",
        "commit_url": "https://github.com/celery/celery/commit/c08e811b383f72157b98e21e178c5c42762d671d",
        "buggy_code": "yield EagerResult('some_id', 'test-task', value, 'FAILURE')",
        "fixed_code": "yield EagerResult('some_id', value, 'FAILURE')",
        "patch": "@@ -46,7 +46,7 @@ def join(self, propagate=True, **kwargs):\n     def _failed_join_report(self):\n         for value in self.value:\n             if isinstance(value, Exception):\n-                yield EagerResult('some_id', 'test-task', value, 'FAILURE')\n+                yield EagerResult('some_id', value, 'FAILURE')\n \n \n class TSRNoReport(TSR):"
    },
    {
        "commit_id": "372a7a38c1dcf5f893e78ef034b864099fed35bb",
        "commit_message": "Tox v4.9 has fixed a bug where unsupported environments\ndid not raise an error but now they do. As our tox.ini\nonly implement unit tests config for tox-gh-actions, since\ntox v4.9 our integration tests fail on GitHub. This change limits\ntox to v4.9 until we can fix it correctly as it breaks the\ntesting environment for now",
        "commit_url": "https://github.com/celery/celery/commit/372a7a38c1dcf5f893e78ef034b864099fed35bb",
        "buggy_code": "def test_nested_chain_group_lone(self, manager):",
        "fixed_code": "def test_nested_chain_group_lone(self, manager):  # Fails with Redis 5.x",
        "patch": "@@ -506,7 +506,7 @@ def test_chain_of_a_chord_and_three_tasks_and_a_group(self, manager):\n         assert res.get(timeout=TIMEOUT) == [8, 8]\n \n     @pytest.mark.xfail(raises=TimeoutError, reason=\"Task is timeout\")\n-    def test_nested_chain_group_lone(self, manager):\n+    def test_nested_chain_group_lone(self, manager):  # Fails with Redis 5.x\n         \"\"\"\n         Test that a lone group in a chain completes.\n         \"\"\""
    },
    {
        "commit_id": "1c363876147325a196c474e757e355c451a0cdff",
        "commit_message": "Fix eager tasks does not populate name field (#8383)\n\n* Add task name to eager request\r\n\r\n* Add task name to eager result\r\n\r\n* Adjust tests",
        "commit_url": "https://github.com/celery/celery/commit/1c363876147325a196c474e757e355c451a0cdff",
        "buggy_code": "yield EagerResult('some_id', value, 'FAILURE')",
        "fixed_code": "yield EagerResult('some_id', 'test-task', value, 'FAILURE')",
        "patch": "@@ -46,7 +46,7 @@ def join(self, propagate=True, **kwargs):\n     def _failed_join_report(self):\n         for value in self.value:\n             if isinstance(value, Exception):\n-                yield EagerResult('some_id', value, 'FAILURE')\n+                yield EagerResult('some_id', 'test-task', value, 'FAILURE')\n \n \n class TSRNoReport(TSR):"
    },
    {
        "commit_id": "148fecb85a833295ed64182b636140bf910f6e7f",
        "commit_message": "fix: copyright year",
        "commit_url": "https://github.com/celery/celery/commit/148fecb85a833295ed64182b636140bf910f6e7f",
        "buggy_code": "copyright='2009-2021',",
        "fixed_code": "copyright='2009-2023',",
        "patch": "@@ -10,7 +10,7 @@\n     github_project='celery/celery',\n     author='Ask Solem & contributors',\n     author_name='Ask Solem',\n-    copyright='2009-2021',\n+    copyright='2009-2023',\n     publisher='Celery Project',\n     html_logo='images/celery_512.png',\n     html_favicon='images/favicon.ico',"
    },
    {
        "commit_id": "1eee438df66000de4ceeb9f95756b33baa7f6bf2",
        "commit_message": "Fix exc_type being the exception instance rather\nthan the exception type",
        "commit_url": "https://github.com/celery/celery/commit/1eee438df66000de4ceeb9f95756b33baa7f6bf2",
        "buggy_code": "exc_type = get_pickleable_etype(orig_exc)",
        "fixed_code": "exc_type = get_pickleable_etype(type(orig_exc))",
        "patch": "@@ -222,7 +222,7 @@ def handle_failure(self, task, req, store_errors=True, call_errbacks=True):\n             # a traceback.\n             _, _, exc.__traceback__ = sys.exc_info()\n \n-        exc_type = get_pickleable_etype(orig_exc)\n+        exc_type = get_pickleable_etype(type(orig_exc))\n \n         # make sure we only send pickleable exceptions back to parent.\n         einfo = ExceptionInfo(exc_info=(exc_type, exc, exc.__traceback__))"
    },
    {
        "commit_id": "c8b25394f0237972aea06e5e2e5e9be8a2bea868",
        "commit_message": "Deprecate pytz and use zoneinfo (#8159)\n\n* Initial test coverage update\r\n\r\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\r\n\r\nfor more information, see https://pre-commit.ci\r\n\r\n* Fully remove pytz\r\n\r\n* remove from dependencies\r\n\r\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\r\n\r\nfor more information, see https://pre-commit.ci\r\n\r\n* bug fix\r\n\r\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\r\n\r\nfor more information, see https://pre-commit.ci\r\n\r\n* test fixes\r\n\r\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\r\n\r\nfor more information, see https://pre-commit.ci\r\n\r\n* fix app test\r\n\r\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\r\n\r\nfor more information, see https://pre-commit.ci\r\n\r\n* noqa\r\n\r\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\r\n\r\nfor more information, see https://pre-commit.ci\r\n\r\n* fix\r\n\r\n* small change\r\n\r\n* Add tzdata for windows\r\n\r\n* Test case\r\n\r\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\r\n\r\nfor more information, see https://pre-commit.ci\r\n\r\n* Fix formatting\r\n\r\n* Improved documentation\r\n\r\n* Fix\r\n\r\n* remove\r\n\r\n* Fix\r\n\r\n* Fix\r\n\r\n* more accurate\r\n\r\n* Comment\r\n\r\n* docstrings\r\n\r\n* future import\r\n\r\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\r\n\r\nfor more information, see https://pre-commit.ci\r\n\r\n* pre-commit\r\n\r\n* Fix\r\n\r\n* fix\r\n\r\n* docstring fix\r\n\r\n* comment\r\n\r\n* pre-commit\r\n\r\n* trailing whitespace fix\r\n\r\n* Update documentation\r\n\r\n* Update celery/utils/time.py\r\n\r\n* Update celery/utils/time.py\r\n\r\n* Update celery/utils/time.py\r\n\r\n* Update celery/utils/time.py\r\n\r\n* Update celery/utils/time.py\r\n\r\n---------\r\n\r\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\r\nCo-authored-by: Asif Saif Uddin <auvipy@gmail.com>",
        "commit_url": "https://github.com/celery/celery/commit/c8b25394f0237972aea06e5e2e5e9be8a2bea868",
        "buggy_code": "def pluralize(n: int, text: str, suffix: str = 's') -> str:",
        "fixed_code": "def pluralize(n: float, text: str, suffix: str = 's') -> str:",
        "patch": "@@ -93,7 +93,7 @@ def truncate(s: str, maxlen: int = 128, suffix: str = '...') -> str:\n     return s\n \n \n-def pluralize(n: int, text: str, suffix: str = 's') -> str:\n+def pluralize(n: float, text: str, suffix: str = 's') -> str:\n     \"\"\"Pluralize term when n is greater than one.\"\"\"\n     if n != 1:\n         return text + suffix"
    },
    {
        "commit_id": "738caba02f7ee564b0a4a6947d5d8efff288b0b3",
        "commit_message": "Hotfix for retrying a task with stamps (Original fix that introduced new bug: #8120) (#8158)",
        "commit_url": "https://github.com/celery/celery/commit/738caba02f7ee564b0a4a6947d5d8efff288b0b3",
        "buggy_code": "assert sig.options['stamps'] == {'stamp': 'value'}",
        "fixed_code": "assert sig.options['stamp'] == 'value'",
        "patch": "@@ -1242,4 +1242,4 @@ def test_retry_stamping(self):\n         self.retry_task.request.stamps = {'stamp': 'value'}\n         sig = self.retry_task.signature_from_request()\n         assert sig.options['stamped_headers'] == ['stamp']\n-        assert sig.options['stamps'] == {'stamp': 'value'}\n+        assert sig.options['stamp'] == 'value'"
    },
    {
        "commit_id": "ab34d34fecf0becc8f2b578fe769eefb74110ace",
        "commit_message": "Fix worker crash on un-pickleable exceptions (#8133)\n\n* Fix worker crash on unpickleable exceptions\r\n\r\n* Move logic to wrap unpicklable exception into the Retry class (revert modifications to handle_retry)\r\n\r\n* Add test and fix handle_ignore not representing the wrapped exception correctly\r\n\r\n---------\r\n\r\nCo-authored-by: Alessio Bogon <alessio.bogon@b2c2.com>",
        "commit_url": "https://github.com/celery/celery/commit/ab34d34fecf0becc8f2b578fe769eefb74110ace",
        "buggy_code": "einfo.exception = get_pickleable_exception(einfo.exception)",
        "fixed_code": "einfo.exception.exc = get_pickleable_exception(einfo.exception.exc)",
        "patch": "@@ -219,7 +219,7 @@ def handle_failure(self, task, req, store_errors=True, call_errbacks=True):\n             exc = self.retval\n             # make sure we only send pickleable exceptions back to parent.\n             einfo = ExceptionInfo()\n-            einfo.exception = get_pickleable_exception(einfo.exception)\n+            einfo.exception.exc = get_pickleable_exception(einfo.exception.exc)\n             einfo.type = get_pickleable_etype(einfo.type)\n \n             task.backend.mark_as_failure("
    },
    {
        "commit_id": "b22a34f96ddbf1fc2a6995832505be30c2ba89de",
        "commit_message": "Fix potential AttributeError on 'stamps'",
        "commit_url": "https://github.com/celery/celery/commit/b22a34f96ddbf1fc2a6995832505be30c2ba89de",
        "buggy_code": "if getattr(request, 'stamps'):",
        "fixed_code": "if getattr(request, 'stamps', None):",
        "patch": "@@ -491,7 +491,7 @@ def _get_result_meta(self, result,\n                     if hasattr(request, 'delivery_info') and\n                     request.delivery_info else None,\n                 }\n-                if getattr(request, 'stamps'):\n+                if getattr(request, 'stamps', None):\n                     request_meta['stamped_headers'] = request.stamped_headers\n                     request_meta.update(request.stamps)\n "
    },
    {
        "commit_id": "fcd8fdd725f7766d7b9d28f4fc828b18b05fb19d",
        "commit_message": "Fix few typos, provide configuration + workflow for codespell to catch any new (#8023)\n\n* Rudimentary codespellrc configuration\r\n\r\n* [DATALAD RUNCMD] Make misspelling reserv to be called as a full task_reserved it patches\r\n\r\n=== Do not change lines below ===\r\n{\r\n \"chain\": [],\r\n \"cmd\": \"sed -i -e 's,reserv\\\\>,task_reserved,g' t/unit/worker/test_consumer.py\",\r\n \"exit\": 0,\r\n \"extra_inputs\": [],\r\n \"inputs\": [],\r\n \"outputs\": [],\r\n \"pwd\": \".\"\r\n}\r\n^^^ Do not change lines above ^^^\r\n\r\n* [DATALAD RUNCMD] Rename passt into pass_value to not confuse codespell\r\n\r\n=== Do not change lines below ===\r\n{\r\n \"chain\": [],\r\n \"cmd\": \"sed -i -e 's,passt\\\\>,pass_value,g' ./t/unit/tasks/test_canvas.py ./t/unit/tasks/test_chord.py ./t/unit/tasks/test_context.py ./t/unit/tasks/test_result.py ./t/unit/tasks/test_states.py ./t/unit/tasks/test_tasks.py ./t/unit/tasks/test_trace.py\",\r\n \"exit\": 0,\r\n \"extra_inputs\": [],\r\n \"inputs\": [],\r\n \"outputs\": [],\r\n \"pwd\": \".\"\r\n}\r\n^^^ Do not change lines above ^^^\r\n\r\n* strat -> strategy, padd -> pad, custom typo\r\n\r\n* [DATALAD RUNCMD] Run codespell -w\r\n\r\n=== Do not change lines below ===\r\n{\r\n \"chain\": [],\r\n \"cmd\": \"codespell -w\",\r\n \"exit\": 0,\r\n \"extra_inputs\": [],\r\n \"inputs\": [],\r\n \"outputs\": [],\r\n \"pwd\": \".\"\r\n}\r\n^^^ Do not change lines above ^^^",
        "commit_url": "https://github.com/celery/celery/commit/fcd8fdd725f7766d7b9d28f4fc828b18b05fb19d",
        "buggy_code": "chord_body (Signature): The body of the chord, used to syncronize with the chain's",
        "fixed_code": "chord_body (Signature): The body of the chord, used to synchronize with the chain's",
        "patch": "@@ -1104,7 +1104,7 @@ def prepare_steps(self, args, kwargs, tasks,\n             app (Celery): The Celery app instance.\n             last_task_id (str): The id of the last task in the chain.\n             group_id (str): The id of the group that the chain is a part of.\n-            chord_body (Signature): The body of the chord, used to syncronize with the chain's\n+            chord_body (Signature): The body of the chord, used to synchronize with the chain's\n                 last task and the chord's body when used together.\n             clone (bool): Whether to clone the chain's tasks before modifying them.\n             from_dict (Callable): A function that takes a dict and returns a Signature."
    },
    {
        "commit_id": "cd3486d5f54e9fa7b3ac2d76432ce0b1400e476b",
        "commit_message": "Fix bug in TraceInfo._log_error() where the real exception obj was hiding behind 'ExceptionWithTraceback' (#7930)\n\n* Fix bug in TraceInfo._log_error() where the real exception obj was hiding behind 'ExceptionWithTraceback'\n\n* Commit 629bc63cb516031fdbe360b69de9b60fbe3a2034 introduced a bug in test_execute_jail_failure.\nThis reverts the bug in the test, now that the real bug is fixed in the TraceInfo._log_error() method",
        "commit_url": "https://github.com/celery/celery/commit/cd3486d5f54e9fa7b3ac2d76432ce0b1400e476b",
        "buggy_code": "assert ret.exception.exc.args == (4,)",
        "fixed_code": "assert ret.exception.args == (4,)",
        "patch": "@@ -155,7 +155,7 @@ def test_execute_jail_failure(self):\n             self.app, uuid(), self.mytask_raising.name, {}, [4], {},\n         )\n         assert isinstance(ret, ExceptionInfo)\n-        assert ret.exception.exc.args == (4,)\n+        assert ret.exception.args == (4,)\n \n     def test_execute_task_ignore_result(self):\n         @self.app.task(shared=False, ignore_result=True)"
    },
    {
        "commit_id": "c918a6dfeb6cbb840fe7865178b792731e6ca1ec",
        "commit_message": "Fixed bug in the stamping visitor mechanism where the request was lacking the stamps in the 'stamps' property (#7928)\n\n* Added integration test: test_task_received_has_access_to_stamps()\n\n* Fixed bug in Request.stamps property where the 'stamps' key wasn't used to access the stamps",
        "commit_url": "https://github.com/celery/celery/commit/c918a6dfeb6cbb840fe7865178b792731e6ca1ec",
        "buggy_code": "return {header: self._request_dict[header] for header in self.stamped_headers}",
        "fixed_code": "return {header: self._request_dict['stamps'][header] for header in self.stamped_headers}",
        "patch": "@@ -327,7 +327,7 @@ def stamped_headers(self) -> list:\n \n     @property\n     def stamps(self) -> dict:\n-        return {header: self._request_dict[header] for header in self.stamped_headers}\n+        return {header: self._request_dict['stamps'][header] for header in self.stamped_headers}\n \n     @property\n     def correlation_id(self):"
    },
    {
        "commit_id": "b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "commit_message": "Fix test warnings (#7906)\n\n* Ensure all implementations of BasePool._get_info() use the super()\r\nresults as a base.\r\n\r\n* Have BasePool._get_info() report the implementation class of the pool\r\nusing the standard Celery class naming convention.\r\n\r\n* Allow for an out-of-tree worker pool implementation. This is used as follows:\r\n\r\n  - Set the environment variable CELERY_CUSTOM_WORKER_POOL to the name of\r\n    an implementation of :class:`celery.concurrency.base.BasePool` in the\r\n    standard Celery format of \"package:class\".\r\n  - Select this pool using '--pool custom'.\r\n\r\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\r\n\r\nfor more information, see https://pre-commit.ci\r\n\r\n* Fixes for missed test breakage.\r\n\r\n* Silence test code deprecation warnings (warning count reduced from 1674 to 45).\r\n\r\nThe deprecations were of the form:\r\n\r\n=======\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:900: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `setup(self)`\r\n  To remove this warning, rename it to `setup_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    fixture_result = next(generator)\r\n\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:916: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `teardown(self)`\r\n  To remove this warning, rename it to `teardown_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    next(it)\r\n=======\r\n\r\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>",
        "commit_url": "https://github.com/celery/celery/commit/b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "buggy_code": "def setup(self):",
        "fixed_code": "def setup_method(self):",
        "patch": "@@ -206,7 +206,7 @@ def test_as_task_message_without_utc(self):\n \n \n class test_AMQP_Base:\n-    def setup(self):\n+    def setup_method(self):\n         self.simple_message = self.app.amqp.as_task_v2(\n             uuid(), 'foo', create_sent_event=True,\n         )"
    },
    {
        "commit_id": "b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "commit_message": "Fix test warnings (#7906)\n\n* Ensure all implementations of BasePool._get_info() use the super()\r\nresults as a base.\r\n\r\n* Have BasePool._get_info() report the implementation class of the pool\r\nusing the standard Celery class naming convention.\r\n\r\n* Allow for an out-of-tree worker pool implementation. This is used as follows:\r\n\r\n  - Set the environment variable CELERY_CUSTOM_WORKER_POOL to the name of\r\n    an implementation of :class:`celery.concurrency.base.BasePool` in the\r\n    standard Celery format of \"package:class\".\r\n  - Select this pool using '--pool custom'.\r\n\r\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\r\n\r\nfor more information, see https://pre-commit.ci\r\n\r\n* Fixes for missed test breakage.\r\n\r\n* Silence test code deprecation warnings (warning count reduced from 1674 to 45).\r\n\r\nThe deprecations were of the form:\r\n\r\n=======\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:900: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `setup(self)`\r\n  To remove this warning, rename it to `setup_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    fixture_result = next(generator)\r\n\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:916: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `teardown(self)`\r\n  To remove this warning, rename it to `teardown_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    next(it)\r\n=======\r\n\r\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>",
        "commit_url": "https://github.com/celery/celery/commit/b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "buggy_code": "def setup(self):",
        "fixed_code": "def setup_method(self):",
        "patch": "@@ -8,7 +8,7 @@ class MyAnnotation:\n \n class AnnotationCase:\n \n-    def setup(self):\n+    def setup_method(self):\n         @self.app.task(shared=False)\n         def add(x, y):\n             return x + y"
    },
    {
        "commit_id": "b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "commit_message": "Fix test warnings (#7906)\n\n* Ensure all implementations of BasePool._get_info() use the super()\r\nresults as a base.\r\n\r\n* Have BasePool._get_info() report the implementation class of the pool\r\nusing the standard Celery class naming convention.\r\n\r\n* Allow for an out-of-tree worker pool implementation. This is used as follows:\r\n\r\n  - Set the environment variable CELERY_CUSTOM_WORKER_POOL to the name of\r\n    an implementation of :class:`celery.concurrency.base.BasePool` in the\r\n    standard Celery format of \"package:class\".\r\n  - Select this pool using '--pool custom'.\r\n\r\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\r\n\r\nfor more information, see https://pre-commit.ci\r\n\r\n* Fixes for missed test breakage.\r\n\r\n* Silence test code deprecation warnings (warning count reduced from 1674 to 45).\r\n\r\nThe deprecations were of the form:\r\n\r\n=======\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:900: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `setup(self)`\r\n  To remove this warning, rename it to `setup_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    fixture_result = next(generator)\r\n\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:916: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `teardown(self)`\r\n  To remove this warning, rename it to `teardown_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    next(it)\r\n=======\r\n\r\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>",
        "commit_url": "https://github.com/celery/celery/commit/b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "buggy_code": "def setup(self):",
        "fixed_code": "def setup_method(self):",
        "patch": "@@ -71,7 +71,7 @@ def test_task_join_will_block(self, patching):\n \n class test_App:\n \n-    def setup(self):\n+    def setup_method(self):\n         self.app.add_defaults(deepcopy(self.CELERY_TEST_CONFIG))\n \n     def test_now(self):"
    },
    {
        "commit_id": "b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "commit_message": "Fix test warnings (#7906)\n\n* Ensure all implementations of BasePool._get_info() use the super()\r\nresults as a base.\r\n\r\n* Have BasePool._get_info() report the implementation class of the pool\r\nusing the standard Celery class naming convention.\r\n\r\n* Allow for an out-of-tree worker pool implementation. This is used as follows:\r\n\r\n  - Set the environment variable CELERY_CUSTOM_WORKER_POOL to the name of\r\n    an implementation of :class:`celery.concurrency.base.BasePool` in the\r\n    standard Celery format of \"package:class\".\r\n  - Select this pool using '--pool custom'.\r\n\r\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\r\n\r\nfor more information, see https://pre-commit.ci\r\n\r\n* Fixes for missed test breakage.\r\n\r\n* Silence test code deprecation warnings (warning count reduced from 1674 to 45).\r\n\r\nThe deprecations were of the form:\r\n\r\n=======\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:900: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `setup(self)`\r\n  To remove this warning, rename it to `setup_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    fixture_result = next(generator)\r\n\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:916: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `teardown(self)`\r\n  To remove this warning, rename it to `teardown_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    next(it)\r\n=======\r\n\r\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>",
        "commit_url": "https://github.com/celery/celery/commit/b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "buggy_code": "def setup(self):",
        "fixed_code": "def setup_method(self):",
        "patch": "@@ -23,7 +23,7 @@ def test_unpickle_v2(self, app):\n \n class test_TaskRegistry:\n \n-    def setup(self):\n+    def setup_method(self):\n         self.mytask = self.app.task(name='A', shared=False)(returns)\n         self.missing_name_task = self.app.task(\n             name=None, shared=False)(returns)"
    },
    {
        "commit_id": "b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "commit_message": "Fix test warnings (#7906)\n\n* Ensure all implementations of BasePool._get_info() use the super()\r\nresults as a base.\r\n\r\n* Have BasePool._get_info() report the implementation class of the pool\r\nusing the standard Celery class naming convention.\r\n\r\n* Allow for an out-of-tree worker pool implementation. This is used as follows:\r\n\r\n  - Set the environment variable CELERY_CUSTOM_WORKER_POOL to the name of\r\n    an implementation of :class:`celery.concurrency.base.BasePool` in the\r\n    standard Celery format of \"package:class\".\r\n  - Select this pool using '--pool custom'.\r\n\r\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\r\n\r\nfor more information, see https://pre-commit.ci\r\n\r\n* Fixes for missed test breakage.\r\n\r\n* Silence test code deprecation warnings (warning count reduced from 1674 to 45).\r\n\r\nThe deprecations were of the form:\r\n\r\n=======\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:900: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `setup(self)`\r\n  To remove this warning, rename it to `setup_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    fixture_result = next(generator)\r\n\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:916: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `teardown(self)`\r\n  To remove this warning, rename it to `teardown_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    next(it)\r\n=======\r\n\r\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>",
        "commit_url": "https://github.com/celery/celery/commit/b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "buggy_code": "def setup(self):",
        "fixed_code": "def setup_method(self):",
        "patch": "@@ -27,7 +27,7 @@ def set_queues(app, **queues):\n \n class RouteCase:\n \n-    def setup(self):\n+    def setup_method(self):\n         self.a_queue = {\n             'exchange': 'fooexchange',\n             'exchange_type': 'fanout',"
    },
    {
        "commit_id": "b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "commit_message": "Fix test warnings (#7906)\n\n* Ensure all implementations of BasePool._get_info() use the super()\r\nresults as a base.\r\n\r\n* Have BasePool._get_info() report the implementation class of the pool\r\nusing the standard Celery class naming convention.\r\n\r\n* Allow for an out-of-tree worker pool implementation. This is used as follows:\r\n\r\n  - Set the environment variable CELERY_CUSTOM_WORKER_POOL to the name of\r\n    an implementation of :class:`celery.concurrency.base.BasePool` in the\r\n    standard Celery format of \"package:class\".\r\n  - Select this pool using '--pool custom'.\r\n\r\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\r\n\r\nfor more information, see https://pre-commit.ci\r\n\r\n* Fixes for missed test breakage.\r\n\r\n* Silence test code deprecation warnings (warning count reduced from 1674 to 45).\r\n\r\nThe deprecations were of the form:\r\n\r\n=======\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:900: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `setup(self)`\r\n  To remove this warning, rename it to `setup_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    fixture_result = next(generator)\r\n\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:916: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `teardown(self)`\r\n  To remove this warning, rename it to `teardown_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    next(it)\r\n=======\r\n\r\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>",
        "commit_url": "https://github.com/celery/celery/commit/b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "buggy_code": "def setup(self):",
        "fixed_code": "def setup_method(self):",
        "patch": "@@ -19,7 +19,7 @@\n \n class test_ArangoDbBackend:\n \n-    def setup(self):\n+    def setup_method(self):\n         self.backend = ArangoDbBackend(app=self.app)\n \n     def test_init_no_arangodb(self):"
    },
    {
        "commit_id": "b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "commit_message": "Fix test warnings (#7906)\n\n* Ensure all implementations of BasePool._get_info() use the super()\r\nresults as a base.\r\n\r\n* Have BasePool._get_info() report the implementation class of the pool\r\nusing the standard Celery class naming convention.\r\n\r\n* Allow for an out-of-tree worker pool implementation. This is used as follows:\r\n\r\n  - Set the environment variable CELERY_CUSTOM_WORKER_POOL to the name of\r\n    an implementation of :class:`celery.concurrency.base.BasePool` in the\r\n    standard Celery format of \"package:class\".\r\n  - Select this pool using '--pool custom'.\r\n\r\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\r\n\r\nfor more information, see https://pre-commit.ci\r\n\r\n* Fixes for missed test breakage.\r\n\r\n* Silence test code deprecation warnings (warning count reduced from 1674 to 45).\r\n\r\nThe deprecations were of the form:\r\n\r\n=======\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:900: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `setup(self)`\r\n  To remove this warning, rename it to `setup_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    fixture_result = next(generator)\r\n\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:916: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `teardown(self)`\r\n  To remove this warning, rename it to `teardown_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    next(it)\r\n=======\r\n\r\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>",
        "commit_url": "https://github.com/celery/celery/commit/b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "buggy_code": "def setup(self):",
        "fixed_code": "def setup_method(self):",
        "patch": "@@ -18,7 +18,7 @@\n \n class test_CassandraBackend:\n \n-    def setup(self):\n+    def setup_method(self):\n         self.app.conf.update(\n             cassandra_servers=['example.com'],\n             cassandra_keyspace='celery',"
    },
    {
        "commit_id": "b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "commit_message": "Fix test warnings (#7906)\n\n* Ensure all implementations of BasePool._get_info() use the super()\r\nresults as a base.\r\n\r\n* Have BasePool._get_info() report the implementation class of the pool\r\nusing the standard Celery class naming convention.\r\n\r\n* Allow for an out-of-tree worker pool implementation. This is used as follows:\r\n\r\n  - Set the environment variable CELERY_CUSTOM_WORKER_POOL to the name of\r\n    an implementation of :class:`celery.concurrency.base.BasePool` in the\r\n    standard Celery format of \"package:class\".\r\n  - Select this pool using '--pool custom'.\r\n\r\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\r\n\r\nfor more information, see https://pre-commit.ci\r\n\r\n* Fixes for missed test breakage.\r\n\r\n* Silence test code deprecation warnings (warning count reduced from 1674 to 45).\r\n\r\nThe deprecations were of the form:\r\n\r\n=======\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:900: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `setup(self)`\r\n  To remove this warning, rename it to `setup_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    fixture_result = next(generator)\r\n\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:916: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `teardown(self)`\r\n  To remove this warning, rename it to `teardown_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    next(it)\r\n=======\r\n\r\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>",
        "commit_url": "https://github.com/celery/celery/commit/b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "buggy_code": "def setup(self):",
        "fixed_code": "def setup_method(self):",
        "patch": "@@ -9,7 +9,7 @@\n \n class test_ConsulBackend:\n \n-    def setup(self):\n+    def setup_method(self):\n         self.backend = ConsulBackend(\n             app=self.app, url='consul://localhost:800')\n "
    },
    {
        "commit_id": "b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "commit_message": "Fix test warnings (#7906)\n\n* Ensure all implementations of BasePool._get_info() use the super()\r\nresults as a base.\r\n\r\n* Have BasePool._get_info() report the implementation class of the pool\r\nusing the standard Celery class naming convention.\r\n\r\n* Allow for an out-of-tree worker pool implementation. This is used as follows:\r\n\r\n  - Set the environment variable CELERY_CUSTOM_WORKER_POOL to the name of\r\n    an implementation of :class:`celery.concurrency.base.BasePool` in the\r\n    standard Celery format of \"package:class\".\r\n  - Select this pool using '--pool custom'.\r\n\r\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\r\n\r\nfor more information, see https://pre-commit.ci\r\n\r\n* Fixes for missed test breakage.\r\n\r\n* Silence test code deprecation warnings (warning count reduced from 1674 to 45).\r\n\r\nThe deprecations were of the form:\r\n\r\n=======\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:900: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `setup(self)`\r\n  To remove this warning, rename it to `setup_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    fixture_result = next(generator)\r\n\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:916: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `teardown(self)`\r\n  To remove this warning, rename it to `teardown_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    next(it)\r\n=======\r\n\r\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>",
        "commit_url": "https://github.com/celery/celery/commit/b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "buggy_code": "def setup(self):",
        "fixed_code": "def setup_method(self):",
        "patch": "@@ -13,7 +13,7 @@\n \n \n class test_DocumentDBBackend:\n-    def setup(self):\n+    def setup_method(self):\n         self.url = \"cosmosdbsql://:key@endpoint\"\n         self.backend = CosmosDBSQLBackend(app=self.app, url=self.url)\n "
    },
    {
        "commit_id": "b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "commit_message": "Fix test warnings (#7906)\n\n* Ensure all implementations of BasePool._get_info() use the super()\r\nresults as a base.\r\n\r\n* Have BasePool._get_info() report the implementation class of the pool\r\nusing the standard Celery class naming convention.\r\n\r\n* Allow for an out-of-tree worker pool implementation. This is used as follows:\r\n\r\n  - Set the environment variable CELERY_CUSTOM_WORKER_POOL to the name of\r\n    an implementation of :class:`celery.concurrency.base.BasePool` in the\r\n    standard Celery format of \"package:class\".\r\n  - Select this pool using '--pool custom'.\r\n\r\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\r\n\r\nfor more information, see https://pre-commit.ci\r\n\r\n* Fixes for missed test breakage.\r\n\r\n* Silence test code deprecation warnings (warning count reduced from 1674 to 45).\r\n\r\nThe deprecations were of the form:\r\n\r\n=======\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:900: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `setup(self)`\r\n  To remove this warning, rename it to `setup_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    fixture_result = next(generator)\r\n\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:916: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `teardown(self)`\r\n  To remove this warning, rename it to `teardown_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    next(it)\r\n=======\r\n\r\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>",
        "commit_url": "https://github.com/celery/celery/commit/b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "buggy_code": "def setup(self):",
        "fixed_code": "def setup_method(self):",
        "patch": "@@ -22,7 +22,7 @@\n \n class test_CouchbaseBackend:\n \n-    def setup(self):\n+    def setup_method(self):\n         self.backend = CouchbaseBackend(app=self.app)\n \n     def test_init_no_couchbase(self):"
    },
    {
        "commit_id": "b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "commit_message": "Fix test warnings (#7906)\n\n* Ensure all implementations of BasePool._get_info() use the super()\r\nresults as a base.\r\n\r\n* Have BasePool._get_info() report the implementation class of the pool\r\nusing the standard Celery class naming convention.\r\n\r\n* Allow for an out-of-tree worker pool implementation. This is used as follows:\r\n\r\n  - Set the environment variable CELERY_CUSTOM_WORKER_POOL to the name of\r\n    an implementation of :class:`celery.concurrency.base.BasePool` in the\r\n    standard Celery format of \"package:class\".\r\n  - Select this pool using '--pool custom'.\r\n\r\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\r\n\r\nfor more information, see https://pre-commit.ci\r\n\r\n* Fixes for missed test breakage.\r\n\r\n* Silence test code deprecation warnings (warning count reduced from 1674 to 45).\r\n\r\nThe deprecations were of the form:\r\n\r\n=======\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:900: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `setup(self)`\r\n  To remove this warning, rename it to `setup_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    fixture_result = next(generator)\r\n\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:916: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `teardown(self)`\r\n  To remove this warning, rename it to `teardown_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    next(it)\r\n=======\r\n\r\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>",
        "commit_url": "https://github.com/celery/celery/commit/b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "buggy_code": "def setup(self):",
        "fixed_code": "def setup_method(self):",
        "patch": "@@ -20,7 +20,7 @@\n \n class test_CouchBackend:\n \n-    def setup(self):\n+    def setup_method(self):\n         self.Server = self.patching('pycouchdb.Server')\n         self.backend = CouchBackend(app=self.app)\n "
    },
    {
        "commit_id": "b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "commit_message": "Fix test warnings (#7906)\n\n* Ensure all implementations of BasePool._get_info() use the super()\r\nresults as a base.\r\n\r\n* Have BasePool._get_info() report the implementation class of the pool\r\nusing the standard Celery class naming convention.\r\n\r\n* Allow for an out-of-tree worker pool implementation. This is used as follows:\r\n\r\n  - Set the environment variable CELERY_CUSTOM_WORKER_POOL to the name of\r\n    an implementation of :class:`celery.concurrency.base.BasePool` in the\r\n    standard Celery format of \"package:class\".\r\n  - Select this pool using '--pool custom'.\r\n\r\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\r\n\r\nfor more information, see https://pre-commit.ci\r\n\r\n* Fixes for missed test breakage.\r\n\r\n* Silence test code deprecation warnings (warning count reduced from 1674 to 45).\r\n\r\nThe deprecations were of the form:\r\n\r\n=======\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:900: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `setup(self)`\r\n  To remove this warning, rename it to `setup_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    fixture_result = next(generator)\r\n\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:916: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `teardown(self)`\r\n  To remove this warning, rename it to `teardown_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    next(it)\r\n=======\r\n\r\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>",
        "commit_url": "https://github.com/celery/celery/commit/b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "buggy_code": "def setup(self):",
        "fixed_code": "def setup_method(self):",
        "patch": "@@ -12,7 +12,7 @@\n \n \n class test_DynamoDBBackend:\n-    def setup(self):\n+    def setup_method(self):\n         self._static_timestamp = Decimal(1483425566.52)\n         self.app.conf.result_backend = 'dynamodb://'\n "
    },
    {
        "commit_id": "b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "commit_message": "Fix test warnings (#7906)\n\n* Ensure all implementations of BasePool._get_info() use the super()\r\nresults as a base.\r\n\r\n* Have BasePool._get_info() report the implementation class of the pool\r\nusing the standard Celery class naming convention.\r\n\r\n* Allow for an out-of-tree worker pool implementation. This is used as follows:\r\n\r\n  - Set the environment variable CELERY_CUSTOM_WORKER_POOL to the name of\r\n    an implementation of :class:`celery.concurrency.base.BasePool` in the\r\n    standard Celery format of \"package:class\".\r\n  - Select this pool using '--pool custom'.\r\n\r\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\r\n\r\nfor more information, see https://pre-commit.ci\r\n\r\n* Fixes for missed test breakage.\r\n\r\n* Silence test code deprecation warnings (warning count reduced from 1674 to 45).\r\n\r\nThe deprecations were of the form:\r\n\r\n=======\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:900: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `setup(self)`\r\n  To remove this warning, rename it to `setup_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    fixture_result = next(generator)\r\n\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:916: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `teardown(self)`\r\n  To remove this warning, rename it to `teardown_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    next(it)\r\n=======\r\n\r\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>",
        "commit_url": "https://github.com/celery/celery/commit/b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "buggy_code": "def setup(self):",
        "fixed_code": "def setup_method(self):",
        "patch": "@@ -31,7 +31,7 @@\n \n class test_ElasticsearchBackend:\n \n-    def setup(self):\n+    def setup_method(self):\n         self.backend = ElasticsearchBackend(app=self.app)\n \n     def test_init_no_elasticsearch(self):"
    },
    {
        "commit_id": "b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "commit_message": "Fix test warnings (#7906)\n\n* Ensure all implementations of BasePool._get_info() use the super()\r\nresults as a base.\r\n\r\n* Have BasePool._get_info() report the implementation class of the pool\r\nusing the standard Celery class naming convention.\r\n\r\n* Allow for an out-of-tree worker pool implementation. This is used as follows:\r\n\r\n  - Set the environment variable CELERY_CUSTOM_WORKER_POOL to the name of\r\n    an implementation of :class:`celery.concurrency.base.BasePool` in the\r\n    standard Celery format of \"package:class\".\r\n  - Select this pool using '--pool custom'.\r\n\r\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\r\n\r\nfor more information, see https://pre-commit.ci\r\n\r\n* Fixes for missed test breakage.\r\n\r\n* Silence test code deprecation warnings (warning count reduced from 1674 to 45).\r\n\r\nThe deprecations were of the form:\r\n\r\n=======\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:900: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `setup(self)`\r\n  To remove this warning, rename it to `setup_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    fixture_result = next(generator)\r\n\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:916: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `teardown(self)`\r\n  To remove this warning, rename it to `teardown_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    next(it)\r\n=======\r\n\r\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>",
        "commit_url": "https://github.com/celery/celery/commit/b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "buggy_code": "def setup(self):",
        "fixed_code": "def setup_method(self):",
        "patch": "@@ -17,7 +17,7 @@\n @t.skip.if_win32\n class test_FilesystemBackend:\n \n-    def setup(self):\n+    def setup_method(self):\n         self.directory = tempfile.mkdtemp()\n         self.url = 'file://' + self.directory\n         self.path = self.directory.encode('ascii')"
    },
    {
        "commit_id": "b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "commit_message": "Fix test warnings (#7906)\n\n* Ensure all implementations of BasePool._get_info() use the super()\r\nresults as a base.\r\n\r\n* Have BasePool._get_info() report the implementation class of the pool\r\nusing the standard Celery class naming convention.\r\n\r\n* Allow for an out-of-tree worker pool implementation. This is used as follows:\r\n\r\n  - Set the environment variable CELERY_CUSTOM_WORKER_POOL to the name of\r\n    an implementation of :class:`celery.concurrency.base.BasePool` in the\r\n    standard Celery format of \"package:class\".\r\n  - Select this pool using '--pool custom'.\r\n\r\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\r\n\r\nfor more information, see https://pre-commit.ci\r\n\r\n* Fixes for missed test breakage.\r\n\r\n* Silence test code deprecation warnings (warning count reduced from 1674 to 45).\r\n\r\nThe deprecations were of the form:\r\n\r\n=======\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:900: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `setup(self)`\r\n  To remove this warning, rename it to `setup_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    fixture_result = next(generator)\r\n\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:916: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `teardown(self)`\r\n  To remove this warning, rename it to `teardown_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    next(it)\r\n=======\r\n\r\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>",
        "commit_url": "https://github.com/celery/celery/commit/b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "buggy_code": "def setup(self):",
        "fixed_code": "def setup_method(self):",
        "patch": "@@ -77,7 +77,7 @@ class test_MongoBackend:\n         'hostname.dom/database?replicaSet=rs'\n     )\n \n-    def setup(self):\n+    def setup_method(self):\n         self.patching('celery.backends.mongodb.MongoBackend.encode')\n         self.patching('celery.backends.mongodb.MongoBackend.decode')\n         self.patching('celery.backends.mongodb.Binary')"
    },
    {
        "commit_id": "b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "commit_message": "Fix test warnings (#7906)\n\n* Ensure all implementations of BasePool._get_info() use the super()\r\nresults as a base.\r\n\r\n* Have BasePool._get_info() report the implementation class of the pool\r\nusing the standard Celery class naming convention.\r\n\r\n* Allow for an out-of-tree worker pool implementation. This is used as follows:\r\n\r\n  - Set the environment variable CELERY_CUSTOM_WORKER_POOL to the name of\r\n    an implementation of :class:`celery.concurrency.base.BasePool` in the\r\n    standard Celery format of \"package:class\".\r\n  - Select this pool using '--pool custom'.\r\n\r\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\r\n\r\nfor more information, see https://pre-commit.ci\r\n\r\n* Fixes for missed test breakage.\r\n\r\n* Silence test code deprecation warnings (warning count reduced from 1674 to 45).\r\n\r\nThe deprecations were of the form:\r\n\r\n=======\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:900: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `setup(self)`\r\n  To remove this warning, rename it to `setup_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    fixture_result = next(generator)\r\n\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:916: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `teardown(self)`\r\n  To remove this warning, rename it to `teardown_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    next(it)\r\n=======\r\n\r\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>",
        "commit_url": "https://github.com/celery/celery/commit/b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "buggy_code": "def setup(self):",
        "fixed_code": "def setup_method(self):",
        "patch": "@@ -23,7 +23,7 @@ def test_drain_events_before_start(self):\n \n class test_RPCBackend:\n \n-    def setup(self):\n+    def setup_method(self):\n         self.b = RPCBackend(app=self.app)\n \n     def test_oid(self):"
    },
    {
        "commit_id": "b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "commit_message": "Fix test warnings (#7906)\n\n* Ensure all implementations of BasePool._get_info() use the super()\r\nresults as a base.\r\n\r\n* Have BasePool._get_info() report the implementation class of the pool\r\nusing the standard Celery class naming convention.\r\n\r\n* Allow for an out-of-tree worker pool implementation. This is used as follows:\r\n\r\n  - Set the environment variable CELERY_CUSTOM_WORKER_POOL to the name of\r\n    an implementation of :class:`celery.concurrency.base.BasePool` in the\r\n    standard Celery format of \"package:class\".\r\n  - Select this pool using '--pool custom'.\r\n\r\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\r\n\r\nfor more information, see https://pre-commit.ci\r\n\r\n* Fixes for missed test breakage.\r\n\r\n* Silence test code deprecation warnings (warning count reduced from 1674 to 45).\r\n\r\nThe deprecations were of the form:\r\n\r\n=======\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:900: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `setup(self)`\r\n  To remove this warning, rename it to `setup_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    fixture_result = next(generator)\r\n\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:916: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `teardown(self)`\r\n  To remove this warning, rename it to `teardown_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    next(it)\r\n=======\r\n\r\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>",
        "commit_url": "https://github.com/celery/celery/commit/b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "buggy_code": "def setup(self):",
        "fixed_code": "def setup_method(self):",
        "patch": "@@ -24,7 +24,7 @@ def raise_something(i):\n \n class test_TaskPool:\n \n-    def setup(self):\n+    def setup_method(self):\n         from celery.concurrency.prefork import TaskPool\n         self.TaskPool = TaskPool\n "
    },
    {
        "commit_id": "b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "commit_message": "Fix test warnings (#7906)\n\n* Ensure all implementations of BasePool._get_info() use the super()\r\nresults as a base.\r\n\r\n* Have BasePool._get_info() report the implementation class of the pool\r\nusing the standard Celery class naming convention.\r\n\r\n* Allow for an out-of-tree worker pool implementation. This is used as follows:\r\n\r\n  - Set the environment variable CELERY_CUSTOM_WORKER_POOL to the name of\r\n    an implementation of :class:`celery.concurrency.base.BasePool` in the\r\n    standard Celery format of \"package:class\".\r\n  - Select this pool using '--pool custom'.\r\n\r\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\r\n\r\nfor more information, see https://pre-commit.ci\r\n\r\n* Fixes for missed test breakage.\r\n\r\n* Silence test code deprecation warnings (warning count reduced from 1674 to 45).\r\n\r\nThe deprecations were of the form:\r\n\r\n=======\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:900: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `setup(self)`\r\n  To remove this warning, rename it to `setup_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    fixture_result = next(generator)\r\n\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:916: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `teardown(self)`\r\n  To remove this warning, rename it to `teardown_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    next(it)\r\n=======\r\n\r\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>",
        "commit_url": "https://github.com/celery/celery/commit/b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "buggy_code": "def setup(self):",
        "fixed_code": "def setup_method(self):",
        "patch": "@@ -3,7 +3,7 @@\n \n class test_AbortableTask:\n \n-    def setup(self):\n+    def setup_method(self):\n         @self.app.task(base=AbortableTask, shared=False)\n         def abortable():\n             return True"
    },
    {
        "commit_id": "b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "commit_message": "Fix test warnings (#7906)\n\n* Ensure all implementations of BasePool._get_info() use the super()\r\nresults as a base.\r\n\r\n* Have BasePool._get_info() report the implementation class of the pool\r\nusing the standard Celery class naming convention.\r\n\r\n* Allow for an out-of-tree worker pool implementation. This is used as follows:\r\n\r\n  - Set the environment variable CELERY_CUSTOM_WORKER_POOL to the name of\r\n    an implementation of :class:`celery.concurrency.base.BasePool` in the\r\n    standard Celery format of \"package:class\".\r\n  - Select this pool using '--pool custom'.\r\n\r\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\r\n\r\nfor more information, see https://pre-commit.ci\r\n\r\n* Fixes for missed test breakage.\r\n\r\n* Silence test code deprecation warnings (warning count reduced from 1674 to 45).\r\n\r\nThe deprecations were of the form:\r\n\r\n=======\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:900: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `setup(self)`\r\n  To remove this warning, rename it to `setup_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    fixture_result = next(generator)\r\n\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:916: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `teardown(self)`\r\n  To remove this warning, rename it to `teardown_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    next(it)\r\n=======\r\n\r\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>",
        "commit_url": "https://github.com/celery/celery/commit/b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "buggy_code": "def setup(self):",
        "fixed_code": "def setup_method(self):",
        "patch": "@@ -8,7 +8,7 @@\n \n \n class test_worker:\n-    def setup(self):\n+    def setup_method(self):\n         self.app = Celery('celerytest', backend='cache+memory://', broker='memory://',)\n \n         @self.app.task"
    },
    {
        "commit_id": "b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "commit_message": "Fix test warnings (#7906)\n\n* Ensure all implementations of BasePool._get_info() use the super()\r\nresults as a base.\r\n\r\n* Have BasePool._get_info() report the implementation class of the pool\r\nusing the standard Celery class naming convention.\r\n\r\n* Allow for an out-of-tree worker pool implementation. This is used as follows:\r\n\r\n  - Set the environment variable CELERY_CUSTOM_WORKER_POOL to the name of\r\n    an implementation of :class:`celery.concurrency.base.BasePool` in the\r\n    standard Celery format of \"package:class\".\r\n  - Select this pool using '--pool custom'.\r\n\r\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\r\n\r\nfor more information, see https://pre-commit.ci\r\n\r\n* Fixes for missed test breakage.\r\n\r\n* Silence test code deprecation warnings (warning count reduced from 1674 to 45).\r\n\r\nThe deprecations were of the form:\r\n\r\n=======\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:900: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `setup(self)`\r\n  To remove this warning, rename it to `setup_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    fixture_result = next(generator)\r\n\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:916: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `teardown(self)`\r\n  To remove this warning, rename it to `teardown_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    next(it)\r\n=======\r\n\r\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>",
        "commit_url": "https://github.com/celery/celery/commit/b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "buggy_code": "def setup(self):",
        "fixed_code": "def setup_method(self):",
        "patch": "@@ -11,7 +11,7 @@ def getmaxyx(self):\n \n class test_CursesDisplay:\n \n-    def setup(self):\n+    def setup_method(self):\n         from celery.events import cursesmon\n         self.monitor = cursesmon.CursesMonitor(object(), app=self.app)\n         self.win = MockWindow()"
    },
    {
        "commit_id": "b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "commit_message": "Fix test warnings (#7906)\n\n* Ensure all implementations of BasePool._get_info() use the super()\r\nresults as a base.\r\n\r\n* Have BasePool._get_info() report the implementation class of the pool\r\nusing the standard Celery class naming convention.\r\n\r\n* Allow for an out-of-tree worker pool implementation. This is used as follows:\r\n\r\n  - Set the environment variable CELERY_CUSTOM_WORKER_POOL to the name of\r\n    an implementation of :class:`celery.concurrency.base.BasePool` in the\r\n    standard Celery format of \"package:class\".\r\n  - Select this pool using '--pool custom'.\r\n\r\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\r\n\r\nfor more information, see https://pre-commit.ci\r\n\r\n* Fixes for missed test breakage.\r\n\r\n* Silence test code deprecation warnings (warning count reduced from 1674 to 45).\r\n\r\nThe deprecations were of the form:\r\n\r\n=======\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:900: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `setup(self)`\r\n  To remove this warning, rename it to `setup_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    fixture_result = next(generator)\r\n\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:916: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `teardown(self)`\r\n  To remove this warning, rename it to `teardown_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    next(it)\r\n=======\r\n\r\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>",
        "commit_url": "https://github.com/celery/celery/commit/b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "buggy_code": "def setup(self):",
        "fixed_code": "def setup_method(self):",
        "patch": "@@ -3,5 +3,5 @@\n \n class SecurityCase:\n \n-    def setup(self):\n+    def setup_method(self):\n         pytest.importorskip('cryptography')"
    },
    {
        "commit_id": "b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "commit_message": "Fix test warnings (#7906)\n\n* Ensure all implementations of BasePool._get_info() use the super()\r\nresults as a base.\r\n\r\n* Have BasePool._get_info() report the implementation class of the pool\r\nusing the standard Celery class naming convention.\r\n\r\n* Allow for an out-of-tree worker pool implementation. This is used as follows:\r\n\r\n  - Set the environment variable CELERY_CUSTOM_WORKER_POOL to the name of\r\n    an implementation of :class:`celery.concurrency.base.BasePool` in the\r\n    standard Celery format of \"package:class\".\r\n  - Select this pool using '--pool custom'.\r\n\r\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\r\n\r\nfor more information, see https://pre-commit.ci\r\n\r\n* Fixes for missed test breakage.\r\n\r\n* Silence test code deprecation warnings (warning count reduced from 1674 to 45).\r\n\r\nThe deprecations were of the form:\r\n\r\n=======\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:900: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `setup(self)`\r\n  To remove this warning, rename it to `setup_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    fixture_result = next(generator)\r\n\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:916: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `teardown(self)`\r\n  To remove this warning, rename it to `teardown_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    next(it)\r\n=======\r\n\r\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>",
        "commit_url": "https://github.com/celery/celery/commit/b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "buggy_code": "def teardown(self):",
        "fixed_code": "def teardown_method(self):",
        "patch": "@@ -33,7 +33,7 @@\n \n class test_security(SecurityCase):\n \n-    def teardown(self):\n+    def teardown_method(self):\n         registry._disabled_content_types.clear()\n         registry._set_default_serializer('json')\n         try:"
    },
    {
        "commit_id": "b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "commit_message": "Fix test warnings (#7906)\n\n* Ensure all implementations of BasePool._get_info() use the super()\r\nresults as a base.\r\n\r\n* Have BasePool._get_info() report the implementation class of the pool\r\nusing the standard Celery class naming convention.\r\n\r\n* Allow for an out-of-tree worker pool implementation. This is used as follows:\r\n\r\n  - Set the environment variable CELERY_CUSTOM_WORKER_POOL to the name of\r\n    an implementation of :class:`celery.concurrency.base.BasePool` in the\r\n    standard Celery format of \"package:class\".\r\n  - Select this pool using '--pool custom'.\r\n\r\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\r\n\r\nfor more information, see https://pre-commit.ci\r\n\r\n* Fixes for missed test breakage.\r\n\r\n* Silence test code deprecation warnings (warning count reduced from 1674 to 45).\r\n\r\nThe deprecations were of the form:\r\n\r\n=======\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:900: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `setup(self)`\r\n  To remove this warning, rename it to `setup_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    fixture_result = next(generator)\r\n\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:916: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `teardown(self)`\r\n  To remove this warning, rename it to `teardown_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    next(it)\r\n=======\r\n\r\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>",
        "commit_url": "https://github.com/celery/celery/commit/b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "buggy_code": "def setup(self):",
        "fixed_code": "def setup_method(self):",
        "patch": "@@ -44,7 +44,7 @@ def test_when_no_len_and_no_length_hint(self):\n \n class CanvasCase:\n \n-    def setup(self):\n+    def setup_method(self):\n         @self.app.task(shared=False)\n         def add(x, y):\n             return x + y"
    },
    {
        "commit_id": "b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "commit_message": "Fix test warnings (#7906)\n\n* Ensure all implementations of BasePool._get_info() use the super()\r\nresults as a base.\r\n\r\n* Have BasePool._get_info() report the implementation class of the pool\r\nusing the standard Celery class naming convention.\r\n\r\n* Allow for an out-of-tree worker pool implementation. This is used as follows:\r\n\r\n  - Set the environment variable CELERY_CUSTOM_WORKER_POOL to the name of\r\n    an implementation of :class:`celery.concurrency.base.BasePool` in the\r\n    standard Celery format of \"package:class\".\r\n  - Select this pool using '--pool custom'.\r\n\r\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\r\n\r\nfor more information, see https://pre-commit.ci\r\n\r\n* Fixes for missed test breakage.\r\n\r\n* Silence test code deprecation warnings (warning count reduced from 1674 to 45).\r\n\r\nThe deprecations were of the form:\r\n\r\n=======\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:900: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `setup(self)`\r\n  To remove this warning, rename it to `setup_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    fixture_result = next(generator)\r\n\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:916: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `teardown(self)`\r\n  To remove this warning, rename it to `teardown_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    next(it)\r\n=======\r\n\r\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>",
        "commit_url": "https://github.com/celery/celery/commit/b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "buggy_code": "def setup(self):",
        "fixed_code": "def setup_method(self):",
        "patch": "@@ -60,7 +60,7 @@ class TaskWithRetryButForTypeError(Task):\n \n class TasksCase:\n \n-    def setup(self):\n+    def setup_method(self):\n         self.mytask = self.app.task(shared=False)(return_True)\n \n         @self.app.task(bind=True, count=0, shared=False)"
    },
    {
        "commit_id": "b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "commit_message": "Fix test warnings (#7906)\n\n* Ensure all implementations of BasePool._get_info() use the super()\r\nresults as a base.\r\n\r\n* Have BasePool._get_info() report the implementation class of the pool\r\nusing the standard Celery class naming convention.\r\n\r\n* Allow for an out-of-tree worker pool implementation. This is used as follows:\r\n\r\n  - Set the environment variable CELERY_CUSTOM_WORKER_POOL to the name of\r\n    an implementation of :class:`celery.concurrency.base.BasePool` in the\r\n    standard Celery format of \"package:class\".\r\n  - Select this pool using '--pool custom'.\r\n\r\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\r\n\r\nfor more information, see https://pre-commit.ci\r\n\r\n* Fixes for missed test breakage.\r\n\r\n* Silence test code deprecation warnings (warning count reduced from 1674 to 45).\r\n\r\nThe deprecations were of the form:\r\n\r\n=======\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:900: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `setup(self)`\r\n  To remove this warning, rename it to `setup_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    fixture_result = next(generator)\r\n\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:916: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `teardown(self)`\r\n  To remove this warning, rename it to `teardown_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    next(it)\r\n=======\r\n\r\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>",
        "commit_url": "https://github.com/celery/celery/commit/b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "buggy_code": "def setup(self):",
        "fixed_code": "def setup_method(self):",
        "patch": "@@ -28,7 +28,7 @@ def trace(\n \n \n class TraceCase:\n-    def setup(self):\n+    def setup_method(self):\n         @self.app.task(shared=False)\n         def add(x, y):\n             return x + y"
    },
    {
        "commit_id": "b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "commit_message": "Fix test warnings (#7906)\n\n* Ensure all implementations of BasePool._get_info() use the super()\r\nresults as a base.\r\n\r\n* Have BasePool._get_info() report the implementation class of the pool\r\nusing the standard Celery class naming convention.\r\n\r\n* Allow for an out-of-tree worker pool implementation. This is used as follows:\r\n\r\n  - Set the environment variable CELERY_CUSTOM_WORKER_POOL to the name of\r\n    an implementation of :class:`celery.concurrency.base.BasePool` in the\r\n    standard Celery format of \"package:class\".\r\n  - Select this pool using '--pool custom'.\r\n\r\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\r\n\r\nfor more information, see https://pre-commit.ci\r\n\r\n* Fixes for missed test breakage.\r\n\r\n* Silence test code deprecation warnings (warning count reduced from 1674 to 45).\r\n\r\nThe deprecations were of the form:\r\n\r\n=======\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:900: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `setup(self)`\r\n  To remove this warning, rename it to `setup_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    fixture_result = next(generator)\r\n\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:916: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `teardown(self)`\r\n  To remove this warning, rename it to `teardown_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    next(it)\r\n=======\r\n\r\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>",
        "commit_url": "https://github.com/celery/celery/commit/b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "buggy_code": "def setup(self):",
        "fixed_code": "def setup_method(self):",
        "patch": "@@ -52,7 +52,7 @@ def test_items(self):\n \n class test_ConfigurationView:\n \n-    def setup(self):\n+    def setup_method(self):\n         self.view = ConfigurationView(\n             {'changed_key': 1, 'both': 2},\n             ["
    },
    {
        "commit_id": "b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "commit_message": "Fix test warnings (#7906)\n\n* Ensure all implementations of BasePool._get_info() use the super()\r\nresults as a base.\r\n\r\n* Have BasePool._get_info() report the implementation class of the pool\r\nusing the standard Celery class naming convention.\r\n\r\n* Allow for an out-of-tree worker pool implementation. This is used as follows:\r\n\r\n  - Set the environment variable CELERY_CUSTOM_WORKER_POOL to the name of\r\n    an implementation of :class:`celery.concurrency.base.BasePool` in the\r\n    standard Celery format of \"package:class\".\r\n  - Select this pool using '--pool custom'.\r\n\r\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\r\n\r\nfor more information, see https://pre-commit.ci\r\n\r\n* Fixes for missed test breakage.\r\n\r\n* Silence test code deprecation warnings (warning count reduced from 1674 to 45).\r\n\r\nThe deprecations were of the form:\r\n\r\n=======\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:900: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `setup(self)`\r\n  To remove this warning, rename it to `setup_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    fixture_result = next(generator)\r\n\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:916: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `teardown(self)`\r\n  To remove this warning, rename it to `teardown_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    next(it)\r\n=======\r\n\r\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>",
        "commit_url": "https://github.com/celery/celery/commit/b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "buggy_code": "def setup(self):",
        "fixed_code": "def setup_method(self):",
        "patch": "@@ -73,7 +73,7 @@ def test_info_without_event_loop(self):\n \n class test_Autoscaler:\n \n-    def setup(self):\n+    def setup_method(self):\n         self.pool = MockPool(3)\n \n     def test_stop(self):"
    },
    {
        "commit_id": "b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "commit_message": "Fix test warnings (#7906)\n\n* Ensure all implementations of BasePool._get_info() use the super()\r\nresults as a base.\r\n\r\n* Have BasePool._get_info() report the implementation class of the pool\r\nusing the standard Celery class naming convention.\r\n\r\n* Allow for an out-of-tree worker pool implementation. This is used as follows:\r\n\r\n  - Set the environment variable CELERY_CUSTOM_WORKER_POOL to the name of\r\n    an implementation of :class:`celery.concurrency.base.BasePool` in the\r\n    standard Celery format of \"package:class\".\r\n  - Select this pool using '--pool custom'.\r\n\r\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\r\n\r\nfor more information, see https://pre-commit.ci\r\n\r\n* Fixes for missed test breakage.\r\n\r\n* Silence test code deprecation warnings (warning count reduced from 1674 to 45).\r\n\r\nThe deprecations were of the form:\r\n\r\n=======\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:900: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `setup(self)`\r\n  To remove this warning, rename it to `setup_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    fixture_result = next(generator)\r\n\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:916: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `teardown(self)`\r\n  To remove this warning, rename it to `teardown_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    next(it)\r\n=======\r\n\r\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>",
        "commit_url": "https://github.com/celery/celery/commit/b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "buggy_code": "def setup(self):",
        "fixed_code": "def setup_method(self):",
        "patch": "@@ -22,7 +22,7 @@ def test_create__eventloop(self):\n \n class test_Hub:\n \n-    def setup(self):\n+    def setup_method(self):\n         self.w = Mock(name='w')\n         self.hub = Hub(self.w)\n         self.w.hub = Mock(name='w.hub')"
    },
    {
        "commit_id": "b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "commit_message": "Fix test warnings (#7906)\n\n* Ensure all implementations of BasePool._get_info() use the super()\r\nresults as a base.\r\n\r\n* Have BasePool._get_info() report the implementation class of the pool\r\nusing the standard Celery class naming convention.\r\n\r\n* Allow for an out-of-tree worker pool implementation. This is used as follows:\r\n\r\n  - Set the environment variable CELERY_CUSTOM_WORKER_POOL to the name of\r\n    an implementation of :class:`celery.concurrency.base.BasePool` in the\r\n    standard Celery format of \"package:class\".\r\n  - Select this pool using '--pool custom'.\r\n\r\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\r\n\r\nfor more information, see https://pre-commit.ci\r\n\r\n* Fixes for missed test breakage.\r\n\r\n* Silence test code deprecation warnings (warning count reduced from 1674 to 45).\r\n\r\nThe deprecations were of the form:\r\n\r\n=======\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:900: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `setup(self)`\r\n  To remove this warning, rename it to `setup_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    fixture_result = next(generator)\r\n\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:916: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `teardown(self)`\r\n  To remove this warning, rename it to `teardown_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    next(it)\r\n=======\r\n\r\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>",
        "commit_url": "https://github.com/celery/celery/commit/b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "buggy_code": "def setup(self):",
        "fixed_code": "def setup_method(self):",
        "patch": "@@ -41,7 +41,7 @@ def get_consumer(self, no_hub=False, **kwargs):\n \n \n class test_Consumer(ConsumerTestCase):\n-    def setup(self):\n+    def setup_method(self):\n         @self.app.task(shared=False)\n         def add(x, y):\n             return x + y"
    },
    {
        "commit_id": "b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "commit_message": "Fix test warnings (#7906)\n\n* Ensure all implementations of BasePool._get_info() use the super()\r\nresults as a base.\r\n\r\n* Have BasePool._get_info() report the implementation class of the pool\r\nusing the standard Celery class naming convention.\r\n\r\n* Allow for an out-of-tree worker pool implementation. This is used as follows:\r\n\r\n  - Set the environment variable CELERY_CUSTOM_WORKER_POOL to the name of\r\n    an implementation of :class:`celery.concurrency.base.BasePool` in the\r\n    standard Celery format of \"package:class\".\r\n  - Select this pool using '--pool custom'.\r\n\r\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\r\n\r\nfor more information, see https://pre-commit.ci\r\n\r\n* Fixes for missed test breakage.\r\n\r\n* Silence test code deprecation warnings (warning count reduced from 1674 to 45).\r\n\r\nThe deprecations were of the form:\r\n\r\n=======\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:900: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `setup(self)`\r\n  To remove this warning, rename it to `setup_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    fixture_result = next(generator)\r\n\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:916: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `teardown(self)`\r\n  To remove this warning, rename it to `teardown_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    next(it)\r\n=======\r\n\r\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>",
        "commit_url": "https://github.com/celery/celery/commit/b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "buggy_code": "def setup(self):",
        "fixed_code": "def setup_method(self):",
        "patch": "@@ -116,7 +116,7 @@ def se(*args, **kwargs):\n \n class test_ControlPanel:\n \n-    def setup(self):\n+    def setup_method(self):\n         self.panel = self.create_panel(consumer=Consumer(self.app))\n \n         @self.app.task(name='c.unittest.mytask', rate_limit=200, shared=False)"
    },
    {
        "commit_id": "b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "commit_message": "Fix test warnings (#7906)\n\n* Ensure all implementations of BasePool._get_info() use the super()\r\nresults as a base.\r\n\r\n* Have BasePool._get_info() report the implementation class of the pool\r\nusing the standard Celery class naming convention.\r\n\r\n* Allow for an out-of-tree worker pool implementation. This is used as follows:\r\n\r\n  - Set the environment variable CELERY_CUSTOM_WORKER_POOL to the name of\r\n    an implementation of :class:`celery.concurrency.base.BasePool` in the\r\n    standard Celery format of \"package:class\".\r\n  - Select this pool using '--pool custom'.\r\n\r\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\r\n\r\nfor more information, see https://pre-commit.ci\r\n\r\n* Fixes for missed test breakage.\r\n\r\n* Silence test code deprecation warnings (warning count reduced from 1674 to 45).\r\n\r\nThe deprecations were of the form:\r\n\r\n=======\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:900: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `setup(self)`\r\n  To remove this warning, rename it to `setup_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    fixture_result = next(generator)\r\n\r\nt/unit/worker/test_worker.py::test_WorkController::test_Pool_create\r\n  /main/srhaque/kdedev/celery/.eggs/pytest-7.2.0-py3.10.egg/_pytest/fixtures.py:916: PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\r\n  t/unit/worker/test_worker.py::test_WorkController::test_Pool_create is using nose-specific method: `teardown(self)`\r\n  To remove this warning, rename it to `teardown_method(self)`\r\n  See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\r\n    next(it)\r\n=======\r\n\r\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>",
        "commit_url": "https://github.com/celery/celery/commit/b5bc40f04aad9cbff5e0c605103009cf9cb0e282",
        "buggy_code": "def teardown(self):",
        "fixed_code": "def teardown_method(self):",
        "patch": "@@ -45,7 +45,7 @@ class MyPersistent(state.Persistent):\n \n class test_maybe_shutdown:\n \n-    def teardown(self):\n+    def teardown_method(self):\n         state.should_stop = None\n         state.should_terminate = None\n "
    },
    {
        "commit_id": "6f1691b42d1df02c5657f700fe7b13e4ebde5332",
        "commit_message": "fix typos in optional tests (#7876)\n\n* Update test_schedules.py\r\n\r\n* Update test_cache.py",
        "commit_url": "https://github.com/celery/celery/commit/6f1691b42d1df02c5657f700fe7b13e4ebde5332",
        "buggy_code": "pytest.importorskip('ephem0')",
        "fixed_code": "pytest.importorskip('ephem')",
        "patch": "@@ -26,7 +26,7 @@ def patch_crontab_nowfun(cls, retval):\n class test_solar:\n \n     def setup(self):\n-        pytest.importorskip('ephem0')\n+        pytest.importorskip('ephem')\n         self.s = solar('sunrise', 60, 30, app=self.app)\n \n     def test_reduce(self):"
    },
    {
        "commit_id": "6f1691b42d1df02c5657f700fe7b13e4ebde5332",
        "commit_message": "fix typos in optional tests (#7876)\n\n* Update test_schedules.py\r\n\r\n* Update test_cache.py",
        "commit_url": "https://github.com/celery/celery/commit/6f1691b42d1df02c5657f700fe7b13e4ebde5332",
        "buggy_code": "pytest.importorskip('memcached')",
        "fixed_code": "pytest.importorskip('memcache')",
        "patch": "@@ -143,7 +143,7 @@ def test_as_uri_multiple_servers(self):\n         assert b.as_uri() == backend\n \n     def test_regression_worker_startup_info(self):\n-        pytest.importorskip('memcached')\n+        pytest.importorskip('memcache')\n         self.app.conf.result_backend = (\n             'cache+memcached://127.0.0.1:11211;127.0.0.2:11211;127.0.0.3/'\n         )"
    },
    {
        "commit_id": "eee997513092c26eff5a7678674a6d0f6a02c44c",
        "commit_message": "Fix typo",
        "commit_url": "https://github.com/celery/celery/commit/eee997513092c26eff5a7678674a6d0f6a02c44c",
        "buggy_code": "\"\"\"An lazy function declared in 'beat_schedule' and called before sending to worker.",
        "fixed_code": "\"\"\"A lazy function declared in 'beat_schedule' and called before sending to worker.",
        "patch": "@@ -46,7 +46,7 @@ class SchedulingError(Exception):\n \n \n class BeatLazyFunc:\n-    \"\"\"An lazy function declared in 'beat_schedule' and called before sending to worker.\n+    \"\"\"A lazy function declared in 'beat_schedule' and called before sending to worker.\n \n     Example:\n "
    },
    {
        "commit_id": "53dd65e3275eac017070f350ace9fc2326c0a8d0",
        "commit_message": "StampingVisitor `on_signature()` required returning a key with the list of stamped header\nkeys. It will now implicity assume all given keys are the stamped header keys, if not\noverriden by an explicit \"stamped_headers\" key in the returned value (like it required\nbefore this patch)",
        "commit_url": "https://github.com/celery/celery/commit/53dd65e3275eac017070f350ace9fc2326c0a8d0",
        "buggy_code": "return {'monitoring_id': target_monitoring_id, 'stamped_headers': ['monitoring_id']}",
        "fixed_code": "return {'monitoring_id': target_monitoring_id}",
        "patch": "@@ -204,7 +204,7 @@ def test_revoked_by_headers_simple_canvas(self, manager):\n \n         class MonitoringIdStampingVisitor(StampingVisitor):\n             def on_signature(self, sig, **headers) -> dict:\n-                return {'monitoring_id': target_monitoring_id, 'stamped_headers': ['monitoring_id']}\n+                return {'monitoring_id': target_monitoring_id}\n \n         for monitoring_id in [target_monitoring_id, uuid4().hex, 4242, None]:\n             stamped_task = add.si(1, 1)"
    },
    {
        "commit_id": "13d545b2155ebe9ee0ffad9e9d9ffc09a39185df",
        "commit_message": "Fix grammar typos on the whole project",
        "commit_url": "https://github.com/celery/celery/commit/13d545b2155ebe9ee0ffad9e9d9ffc09a39185df",
        "buggy_code": "\"\"\"Return a utc timestamp, make sure heapq in currect order.\"\"\"",
        "fixed_code": "\"\"\"Return a utc timestamp, make sure heapq in correct order.\"\"\"",
        "patch": "@@ -293,7 +293,7 @@ def is_due(self, entry):\n         return entry.is_due()\n \n     def _when(self, entry, next_time_to_run, mktime=timegm):\n-        \"\"\"Return a utc timestamp, make sure heapq in currect order.\"\"\"\n+        \"\"\"Return a utc timestamp, make sure heapq in correct order.\"\"\"\n         adjust = self.adjust\n \n         as_now = maybe_make_aware(entry.default_now())"
    },
    {
        "commit_id": "13d545b2155ebe9ee0ffad9e9d9ffc09a39185df",
        "commit_message": "Fix grammar typos on the whole project",
        "commit_url": "https://github.com/celery/celery/commit/13d545b2155ebe9ee0ffad9e9d9ffc09a39185df",
        "buggy_code": "but there's a chaning `.set` method that returns the signature:",
        "fixed_code": "but there's a chaining `.set` method that returns the signature:",
        "patch": "@@ -230,7 +230,7 @@ class Signature(dict):\n             >>> add.s(1, kw=2)\n \n     - the ``.s()`` shortcut does not allow you to specify execution options\n-      but there's a chaning `.set` method that returns the signature:\n+      but there's a chaining `.set` method that returns the signature:\n \n         .. code-block:: pycon\n "
    },
    {
        "commit_id": "13d545b2155ebe9ee0ffad9e9d9ffc09a39185df",
        "commit_message": "Fix grammar typos on the whole project",
        "commit_url": "https://github.com/celery/celery/commit/13d545b2155ebe9ee0ffad9e9d9ffc09a39185df",
        "buggy_code": "I.e. process does not respons to signal.",
        "fixed_code": "I.e. process does not respond to signal.",
        "patch": "@@ -186,7 +186,7 @@ def remove(self):\n     def remove_if_stale(self):\n         \"\"\"Remove the lock if the process isn't running.\n \n-        I.e. process does not respons to signal.\n+        I.e. process does not respond to signal.\n         \"\"\"\n         try:\n             pid = self.read_pid()"
    },
    {
        "commit_id": "13d545b2155ebe9ee0ffad9e9d9ffc09a39185df",
        "commit_message": "Fix grammar typos on the whole project",
        "commit_url": "https://github.com/celery/celery/commit/13d545b2155ebe9ee0ffad9e9d9ffc09a39185df",
        "buggy_code": "\"\"\"Integration tests fo app.control.inspect() API\"\"\"",
        "fixed_code": "\"\"\"Integration tests to app.control.inspect() API\"\"\"",
        "patch": "@@ -26,7 +26,7 @@ def inspect(manager):\n \n \n class test_Inspect:\n-    \"\"\"Integration tests fo app.control.inspect() API\"\"\"\n+    \"\"\"Integration tests to app.control.inspect() API\"\"\"\n \n     @flaky\n     def test_ping(self, inspect):"
    },
    {
        "commit_id": "13d545b2155ebe9ee0ffad9e9d9ffc09a39185df",
        "commit_message": "Fix grammar typos on the whole project",
        "commit_url": "https://github.com/celery/celery/commit/13d545b2155ebe9ee0ffad9e9d9ffc09a39185df",
        "buggy_code": "QTEV('succeded', tC, 'w2', name='tC', clock=offset + 12),",
        "fixed_code": "QTEV('succeeded', tC, 'w2', name='tC', clock=offset + 12),",
        "patch": "@@ -126,7 +126,7 @@ def setup(self):\n             QTEV('succeeded', tB, 'w2', name='tB', clock=offset + 9),\n             QTEV('started', tC, 'w2', name='tC', clock=offset + 10),\n             QTEV('received', tA, 'w3', name='tA', clock=offset + 13),\n-            QTEV('succeded', tC, 'w2', name='tC', clock=offset + 12),\n+            QTEV('succeeded', tC, 'w2', name='tC', clock=offset + 12),\n             QTEV('started', tA, 'w3', name='tA', clock=offset + 14),\n             QTEV('succeeded', tA, 'w3', name='TA', clock=offset + 16),\n         ]"
    },
    {
        "commit_id": "392f7034eae52438fdb30bb2c6ec61746acb3722",
        "commit_message": "Fixed bug where a chord with header of type `tuple` was not supported in the link_error flow for task_allow_error_cb_on_chord_header flag (#7772)",
        "commit_url": "https://github.com/celery/celery/commit/392f7034eae52438fdb30bb2c6ec61746acb3722",
        "buggy_code": "if isinstance(self.tasks, list):",
        "fixed_code": "if isinstance(self.tasks, (list, tuple)):",
        "patch": "@@ -1809,7 +1809,7 @@ def link(self, callback):\n     def link_error(self, errback):\n         if self.app.conf.task_allow_error_cb_on_chord_header:\n             # self.tasks can be a list of the chord header workflow.\n-            if isinstance(self.tasks, list):\n+            if isinstance(self.tasks, (list, tuple)):\n                 for task in self.tasks:\n                     task.link_error(errback)\n             else:"
    },
    {
        "commit_id": "e6e0cd72ac49b7968f4557d5fc6a2665093e4cd6",
        "commit_message": "Fixed a bug where stamping a chord body would not use the correct stamping method (#7722)",
        "commit_url": "https://github.com/celery/celery/commit/e6e0cd72ac49b7968f4557d5fc6a2665093e4cd6",
        "buggy_code": "return self.on_signature(chord.body, **header)",
        "fixed_code": "return {}",
        "patch": "@@ -176,7 +176,7 @@ def on_chord_body(self, chord, **header) -> dict:\n          Returns:\n              Dict: headers to update.\n         \"\"\"\n-        return self.on_signature(chord.body, **header)\n+        return {}\n \n \n class GroupStampingVisitor(StampingVisitor):"
    },
    {
        "commit_id": "bdbf6d6ae1aca9addd81800b5dd2e8c3477afb18",
        "commit_message": "Fix unknown task error typo",
        "commit_url": "https://github.com/celery/celery/commit/bdbf6d6ae1aca9addd81800b5dd2e8c3477afb18",
        "buggy_code": "Thw full contents of the message headers:",
        "fixed_code": "The full contents of the message headers:",
        "patch": "@@ -81,7 +81,7 @@\n The full contents of the message body was:\n %s\n \n-Thw full contents of the message headers:\n+The full contents of the message headers:\n %s\n \n The delivery info for this task is:"
    },
    {
        "commit_id": "6f8c2dff4fcc4e46f3ef774d8f770656c23bd256",
        "commit_message": "Fix honor Django's TIME_ZONE setting\n\nSee #4006",
        "commit_url": "https://github.com/celery/celery/commit/6f8c2dff4fcc4e46f3ef774d8f770656c23bd256",
        "buggy_code": "return self.first('timezone', 'time_zone')",
        "fixed_code": "return self.first('timezone', 'TIME_ZONE')",
        "patch": "@@ -128,7 +128,7 @@ def task_default_routing_key(self):\n     @property\n     def timezone(self):\n         # this way we also support django's time zone.\n-        return self.first('timezone', 'time_zone')\n+        return self.first('timezone', 'TIME_ZONE')\n \n     def without_defaults(self):\n         \"\"\"Return the current configuration, but without defaults.\"\"\""
    },
    {
        "commit_id": "617a757c7b5d99c811713867013818827f46a4d0",
        "commit_message": "Worker should exit with ctx.exit to get the right exitcode for non-zero cases (#7544)\n\n* Worker should exit with ctx.exit to get the right exitcode for non-zero cases\r\n\r\n* Add fast-fail coverage to worker\r\n\r\n* Add unit test for celery worker exit\r\n\r\n* Fix non-encapsulated test app\r\n\r\n* Use test celery project\r\n\r\n* Use solo pool to try and fix windows thread issues\r\n\r\n* Disable capture to aid test debug",
        "commit_url": "https://github.com/celery/celery/commit/617a757c7b5d99c811713867013818827f46a4d0",
        "buggy_code": "return worker.exitcode",
        "fixed_code": "ctx.exit(worker.exitcode)",
        "patch": "@@ -351,7 +351,7 @@ def worker(ctx, hostname=None, pool_cls=None, app=None, uid=None, gid=None,\n             quiet=ctx.obj.quiet,\n             **kwargs)\n         worker.start()\n-        return worker.exitcode\n+        ctx.exit(worker.exitcode)\n     except SecurityError as e:\n         ctx.obj.error(e.args[0])\n         ctx.exit(1)"
    },
    {
        "commit_id": "ab2bcc096a9013a9147a3be1a2699d2312f93d1f",
        "commit_message": " Fix issue probably-meant-fstring found at https://codereview.doctor",
        "commit_url": "https://github.com/celery/celery/commit/ab2bcc096a9013a9147a3be1a2699d2312f93d1f",
        "buggy_code": "'TTL must be a number; got \"{ttl}\"',",
        "fixed_code": "f'TTL must be a number; got \"{ttl}\"',",
        "patch": "@@ -128,7 +128,7 @@ def __init__(self, url=None, table_name=None, *args, **kwargs):\n                     self.time_to_live_seconds = int(ttl)\n                 except ValueError as e:\n                     logger.error(\n-                        'TTL must be a number; got \"{ttl}\"',\n+                        f'TTL must be a number; got \"{ttl}\"',\n                         exc_info=e\n                     )\n                     raise e"
    },
    {
        "commit_id": "9e324caaa6b175d8e51d3582378b78757e66a12d",
        "commit_message": "Integration test fix (#7460)\n\n* Integration debugging\r\n\r\n* Integration debugging\r\n\r\n* Integration debugging\r\n\r\n* Commented tasks that aren't working\r\n\r\n* Fixed test_inspect.py\r\n\r\n* Fixed serialization test_canvas.py\r\n\r\n* Request fixes\r\n\r\n* Setup full pipeline\r\n\r\n* Setup full pipeline\r\n\r\n* Setup full pipeline\r\n\r\n* Setup python-package.yml\r\n\r\n* Setup python-package.yml\r\n\r\n* Added 3.10 to integration tests\r\n\r\n* test_task.py fixed\r\n\r\n* test_generator fixed\r\n\r\n* Added parametrization to test_generation\r\n\r\n* fixed test_generator\r\n\r\n* Reverted encoding in test_canvas.py\r\n\r\n* Rollback codecov\r\n\r\n* Retries now respect additional options.\r\n\r\nPreviously, expires and other options were not merged with\r\nthe current task's options. This commit fixes the issue.\r\n\r\nCo-authored-by: Omer Katz <omer.katz@kcg.tech>",
        "commit_url": "https://github.com/celery/celery/commit/9e324caaa6b175d8e51d3582378b78757e66a12d",
        "buggy_code": "options = request.as_execution_options()",
        "fixed_code": "options = {**request.as_execution_options(), **extra_options}",
        "patch": "@@ -604,7 +604,7 @@ def signature_from_request(self, request=None, args=None, kwargs=None,\n         request = self.request if request is None else request\n         args = request.args if args is None else args\n         kwargs = request.kwargs if kwargs is None else kwargs\n-        options = request.as_execution_options()\n+        options = {**request.as_execution_options(), **extra_options}\n         delivery_info = request.delivery_info or {}\n         priority = delivery_info.get('priority')\n         if priority is not None:"
    },
    {
        "commit_id": "9e324caaa6b175d8e51d3582378b78757e66a12d",
        "commit_message": "Integration test fix (#7460)\n\n* Integration debugging\r\n\r\n* Integration debugging\r\n\r\n* Integration debugging\r\n\r\n* Commented tasks that aren't working\r\n\r\n* Fixed test_inspect.py\r\n\r\n* Fixed serialization test_canvas.py\r\n\r\n* Request fixes\r\n\r\n* Setup full pipeline\r\n\r\n* Setup full pipeline\r\n\r\n* Setup full pipeline\r\n\r\n* Setup python-package.yml\r\n\r\n* Setup python-package.yml\r\n\r\n* Added 3.10 to integration tests\r\n\r\n* test_task.py fixed\r\n\r\n* test_generator fixed\r\n\r\n* Added parametrization to test_generation\r\n\r\n* fixed test_generator\r\n\r\n* Reverted encoding in test_canvas.py\r\n\r\n* Rollback codecov\r\n\r\n* Retries now respect additional options.\r\n\r\nPreviously, expires and other options were not merged with\r\nthe current task's options. This commit fixes the issue.\r\n\r\nCo-authored-by: Omer Katz <omer.katz@kcg.tech>",
        "commit_url": "https://github.com/celery/celery/commit/9e324caaa6b175d8e51d3582378b78757e66a12d",
        "buggy_code": "celery_session_app.tasks.register(class_task)",
        "fixed_code": "celery_session_app.register_task(class_task)",
        "patch": "@@ -98,7 +98,7 @@ def celery_session_worker(\n         for module in celery_includes:\n             celery_session_app.loader.import_task_module(module)\n         for class_task in celery_class_tasks:\n-            celery_session_app.tasks.register(class_task)\n+            celery_session_app.register_task(class_task)\n         with worker.start_worker(celery_session_app,\n                                  pool=celery_worker_pool,\n                                  **celery_worker_parameters) as w:"
    },
    {
        "commit_id": "9e324caaa6b175d8e51d3582378b78757e66a12d",
        "commit_message": "Integration test fix (#7460)\n\n* Integration debugging\r\n\r\n* Integration debugging\r\n\r\n* Integration debugging\r\n\r\n* Commented tasks that aren't working\r\n\r\n* Fixed test_inspect.py\r\n\r\n* Fixed serialization test_canvas.py\r\n\r\n* Request fixes\r\n\r\n* Setup full pipeline\r\n\r\n* Setup full pipeline\r\n\r\n* Setup full pipeline\r\n\r\n* Setup python-package.yml\r\n\r\n* Setup python-package.yml\r\n\r\n* Added 3.10 to integration tests\r\n\r\n* test_task.py fixed\r\n\r\n* test_generator fixed\r\n\r\n* Added parametrization to test_generation\r\n\r\n* fixed test_generator\r\n\r\n* Reverted encoding in test_canvas.py\r\n\r\n* Rollback codecov\r\n\r\n* Retries now respect additional options.\r\n\r\nPreviously, expires and other options were not merged with\r\nthe current task's options. This commit fixes the issue.\r\n\r\nCo-authored-by: Omer Katz <omer.katz@kcg.tech>",
        "commit_url": "https://github.com/celery/celery/commit/9e324caaa6b175d8e51d3582378b78757e66a12d",
        "buggy_code": "'redelivered': delivery_info.get('redelivered'),",
        "fixed_code": "'redelivered': delivery_info.get('redelivered', False),",
        "patch": "@@ -154,7 +154,7 @@ def __init__(self, message, on_ack=noop,\n             'exchange': delivery_info.get('exchange'),\n             'routing_key': delivery_info.get('routing_key'),\n             'priority': properties.get('priority'),\n-            'redelivered': delivery_info.get('redelivered'),\n+            'redelivered': delivery_info.get('redelivered', False),\n         }\n         self._request_dict.update({\n             'properties': properties,"
    },
    {
        "commit_id": "55c8ca185f5fe4a156cf59aa01404e123757b981",
        "commit_message": "load_extension_class_names - correct module_name (#7406)\n\n95015a changed over to using importlib rather than pkg_resources,\r\nunfortunately the object is not exactly the same.\r\n\r\nAttempting to start up a celery instance with `django-celery-results`\r\ninstalled results in an exception during `load_extension_class_names`;\r\n\r\n```\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.10/site-packages/celery/worker/worker.py\", line 203, in start\r\n    self.blueprint.start(self)\r\n  File \"/usr/lib/python3.10/site-packages/celery/bootsteps.py\", line 112, in start\r\n    self.on_start()\r\n  File \"/usr/lib/python3.10/site-packages/celery/apps/worker.py\", line 136, in on_start\r\n    self.emit_banner()\r\n  File \"/usr/lib/python3.10/site-packages/celery/apps/worker.py\", line 170, in emit_banner\r\n    ' \\n', self.startup_info(artlines=not use_image))),\r\n  File \"/usr/lib/python3.10/site-packages/celery/apps/worker.py\", line 232, in startup_info\r\n    results=self.app.backend.as_uri(),\r\n  File \"/usr/lib/python3.10/site-packages/celery/app/base.py\", line 1252, in backend\r\n    self._local.backend = new_backend = self._get_backend()\r\n  File \"/usr/lib/python3.10/site-packages/celery/app/base.py\", line 955, in _get_backend\r\n    backend, url = backends.by_url(\r\n  File \"/usr/lib/python3.10/site-packages/celery/app/backends.py\", line 69, in by_url\r\n    return by_name(backend, loader), url\r\n  File \"/usr/lib/python3.10/site-packages/celery/app/backends.py\", line 47, in by_name\r\n    aliases.update(load_extension_class_names(extension_namespace))\r\n  File \"/usr/lib/python3.10/site-packages/celery/utils/imports.py\", line 146, in load_extension_class_names\r\n    yield ep.name, ':'.join([ep.module_name, ep.attrs[0]])\r\nAttributeError: 'EntryPoint' object has no attribute 'module_name'\r\n```\r\n\r\nMove over to using the direct value should resolve this issue;\r\n\r\n```\r\n>>> from pkg_resources import iter_entry_points\r\n>>> list(iter_entry_points('celery.result_backends'))[0].__dict__\r\n{'name': 'django-cache', 'module_name': 'django_celery_results.backends', 'attrs': ('CacheBackend',), 'extras': (), 'dist': django-celery-results 2.3.0 (/usr/lib/python3.10/site-packages)}\r\n```\r\nvs\r\n```\r\n>>> from importlib.metadata import entry_points\r\n>>> entry_points().get('celery.result_backends')[0]\r\nEntryPoint(name='django-cache', value='django_celery_results.backends:CacheBackend', group='celery.result_backends')\r\n```",
        "commit_url": "https://github.com/celery/celery/commit/55c8ca185f5fe4a156cf59aa01404e123757b981",
        "buggy_code": "yield ep.name, ':'.join([ep.module_name, ep.attrs[0]])",
        "fixed_code": "yield ep.name, ep.value",
        "patch": "@@ -143,7 +143,7 @@ def gen_task_name(app, name, module_name):\n \n def load_extension_class_names(namespace):\n     for ep in entry_points().get(namespace, []):\n-        yield ep.name, ':'.join([ep.module_name, ep.attrs[0]])\n+        yield ep.name, ep.value\n \n \n def load_extension_classes(namespace):"
    },
    {
        "commit_id": "ba68cd734a0d1b240121c8be48e58d95e93b47ad",
        "commit_message": "Backport #7406 to 5.2 (#7431)\n\n* load_extension_class_names - correct module_name\r\n\r\n95015a changed over to using importlib rather than pkg_resources,\r\nunfortunately the object is not exactly the same.\r\n\r\nAttempting to start up a celery instance with `django-celery-results`\r\ninstalled results in an exception during `load_extension_class_names`;\r\n\r\n```\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.10/site-packages/celery/worker/worker.py\", line 203, in start\r\n    self.blueprint.start(self)\r\n  File \"/usr/lib/python3.10/site-packages/celery/bootsteps.py\", line 112, in start\r\n    self.on_start()\r\n  File \"/usr/lib/python3.10/site-packages/celery/apps/worker.py\", line 136, in on_start\r\n    self.emit_banner()\r\n  File \"/usr/lib/python3.10/site-packages/celery/apps/worker.py\", line 170, in emit_banner\r\n    ' \\n', self.startup_info(artlines=not use_image))),\r\n  File \"/usr/lib/python3.10/site-packages/celery/apps/worker.py\", line 232, in startup_info\r\n    results=self.app.backend.as_uri(),\r\n  File \"/usr/lib/python3.10/site-packages/celery/app/base.py\", line 1252, in backend\r\n    self._local.backend = new_backend = self._get_backend()\r\n  File \"/usr/lib/python3.10/site-packages/celery/app/base.py\", line 955, in _get_backend\r\n    backend, url = backends.by_url(\r\n  File \"/usr/lib/python3.10/site-packages/celery/app/backends.py\", line 69, in by_url\r\n    return by_name(backend, loader), url\r\n  File \"/usr/lib/python3.10/site-packages/celery/app/backends.py\", line 47, in by_name\r\n    aliases.update(load_extension_class_names(extension_namespace))\r\n  File \"/usr/lib/python3.10/site-packages/celery/utils/imports.py\", line 146, in load_extension_class_names\r\n    yield ep.name, ':'.join([ep.module_name, ep.attrs[0]])\r\nAttributeError: 'EntryPoint' object has no attribute 'module_name'\r\n```\r\n\r\nMove over to using the direct value should resolve this issue;\r\n\r\n```\r\n>>> from pkg_resources import iter_entry_points\r\n>>> list(iter_entry_points('celery.result_backends'))[0].__dict__\r\n{'name': 'django-cache', 'module_name': 'django_celery_results.backends', 'attrs': ('CacheBackend',), 'extras': (), 'dist': django-celery-results 2.3.0 (/usr/lib/python3.10/site-packages)}\r\n```\r\nvs\r\n```\r\n>>> from importlib.metadata import entry_points\r\n>>> entry_points().get('celery.result_backends')[0]\r\nEntryPoint(name='django-cache', value='django_celery_results.backends:CacheBackend', group='celery.result_backends')\r\n```\r\n\r\n* Update changelog.\r\n\r\nCo-authored-by: Damian Zaremba <damian@damianzaremba.co.uk>\r\nCo-authored-by: Omer Katz <omer.katz@kcg.tech>",
        "commit_url": "https://github.com/celery/celery/commit/ba68cd734a0d1b240121c8be48e58d95e93b47ad",
        "buggy_code": "yield ep.name, ':'.join([ep.module_name, ep.attrs[0]])",
        "fixed_code": "yield ep.name, ep.value",
        "patch": "@@ -143,7 +143,7 @@ def gen_task_name(app, name, module_name):\n \n def load_extension_class_names(namespace):\n     for ep in entry_points().get(namespace, []):\n-        yield ep.name, ':'.join([ep.module_name, ep.attrs[0]])\n+        yield ep.name, ep.value\n \n \n def load_extension_classes(namespace):"
    },
    {
        "commit_id": "aedd30b2186718e81fbd935d84f4d145a3fa0bca",
        "commit_message": "doc: fix broken reference to schedule.is_due method\n\nSigned-off-by: Oleg Hoefling <oleg.hoefling@gmail.com>",
        "commit_url": "https://github.com/celery/celery/commit/aedd30b2186718e81fbd935d84f4d145a3fa0bca",
        "buggy_code": "\"\"\"See :meth:`~celery.schedule.schedule.is_due`.\"\"\"",
        "fixed_code": "\"\"\"See :meth:`~celery.schedules.schedule.is_due`.\"\"\"",
        "patch": "@@ -157,7 +157,7 @@ def update(self, other):\n         })\n \n     def is_due(self):\n-        \"\"\"See :meth:`~celery.schedule.schedule.is_due`.\"\"\"\n+        \"\"\"See :meth:`~celery.schedules.schedule.is_due`.\"\"\"\n         return self.schedule.is_due(self.last_run_at)\n \n     def __iter__(self):"
    },
    {
        "commit_id": "744ef43c4d83e190d85c034a8e5cb4ca7b7a22e0",
        "commit_message": "Add `security_key_password` option (#7292)\n\n* Expose password argument on PrivateKey\r\n\r\n* Added base.setup_security `security_key_password` keyword argument\r\n\r\n* Added Option for `security_key_password`\r\n\r\n* Ensure Bytes on PrivateKey password argument\r\n\r\n* Added Documentation for `security_key_password` usage\r\n\r\n* Added tests for `security_key_password`\r\n\r\n* Updated CONTRIBUTORS.txt\r\n\r\n* [fix] Updated `versionadded` to 5.3.0",
        "commit_url": "https://github.com/celery/celery/commit/744ef43c4d83e190d85c034a8e5cb4ca7b7a22e0",
        "buggy_code": "password=password,",
        "fixed_code": "password=ensure_bytes(password),",
        "patch": "@@ -18,7 +18,7 @@ def __init__(self, key, password=None):\n         ):\n             self._key = serialization.load_pem_private_key(\n                 ensure_bytes(key),\n-                password=password,\n+                password=ensure_bytes(password),\n                 backend=default_backend())\n \n     def sign(self, data, digest):"
    },
    {
        "commit_id": "744ef43c4d83e190d85c034a8e5cb4ca7b7a22e0",
        "commit_message": "Add `security_key_password` option (#7292)\n\n* Expose password argument on PrivateKey\r\n\r\n* Added base.setup_security `security_key_password` keyword argument\r\n\r\n* Added Option for `security_key_password`\r\n\r\n* Ensure Bytes on PrivateKey password argument\r\n\r\n* Added Documentation for `security_key_password` usage\r\n\r\n* Added tests for `security_key_password`\r\n\r\n* Updated CONTRIBUTORS.txt\r\n\r\n* [fix] Updated `versionadded` to 5.3.0",
        "commit_url": "https://github.com/celery/celery/commit/744ef43c4d83e190d85c034a8e5cb4ca7b7a22e0",
        "buggy_code": "register_auth(KEY1, CERT1, '')",
        "fixed_code": "register_auth(KEY1, None, CERT1, '')",
        "patch": "@@ -55,7 +55,7 @@ def test_separate_ends(self):\n         assert s2.deserialize(s1.serialize('foo')) == 'foo'\n \n     def test_register_auth(self):\n-        register_auth(KEY1, CERT1, '')\n+        register_auth(KEY1, None, CERT1, '')\n         assert 'application/data' in registry._decoders\n \n     def test_lots_of_sign(self):"
    },
    {
        "commit_id": "f36c16f2debd65c2f9c011b07ca72a77b300db4e",
        "commit_message": "fix typo in exception",
        "commit_url": "https://github.com/celery/celery/commit/f36c16f2debd65c2f9c011b07ca72a77b300db4e",
        "buggy_code": "raise ValueError(\"Exception information must include\"",
        "fixed_code": "raise ValueError(\"Exception information must include \"",
        "patch": "@@ -358,7 +358,7 @@ def exception_to_python(self, exc):\n         try:\n             exc_type = exc['exc_type']\n         except KeyError as e:\n-            raise ValueError(\"Exception information must include\"\n+            raise ValueError(\"Exception information must include \"\n                              \"the exception type\") from e\n         if exc_module is None:\n             cls = create_exception_cls("
    },
    {
        "commit_id": "5d68d781de807b4576cf5f574e5ba0aaf0d17388",
        "commit_message": "Fix typos",
        "commit_url": "https://github.com/celery/celery/commit/5d68d781de807b4576cf5f574e5ba0aaf0d17388",
        "buggy_code": "\"\"\"Functional-style utilties.\"\"\"",
        "fixed_code": "\"\"\"Functional-style utilities.\"\"\"",
        "patch": "@@ -1,4 +1,4 @@\n-\"\"\"Functional-style utilties.\"\"\"\n+\"\"\"Functional-style utilities.\"\"\"\n import inspect\n import sys\n from collections import UserList"
    },
    {
        "commit_id": "5d68d781de807b4576cf5f574e5ba0aaf0d17388",
        "commit_message": "Fix typos",
        "commit_url": "https://github.com/celery/celery/commit/5d68d781de807b4576cf5f574e5ba0aaf0d17388",
        "buggy_code": "This is the indentifer the local objects use internally",
        "fixed_code": "This is the identifier the local objects use internally",
        "patch": "@@ -282,7 +282,7 @@ def __init__(self, locals=None, ident_func=None):\n     def get_ident(self):\n         \"\"\"Return context identifier.\n \n-        This is the indentifer the local objects use internally\n+        This is the identifier the local objects use internally\n         for this context.  You cannot override this method to change the\n         behavior but use it to link other context local objects (such as\n         SQLAlchemy's scoped sessions) to the Werkzeug locals."
    },
    {
        "commit_id": "5d68d781de807b4576cf5f574e5ba0aaf0d17388",
        "commit_message": "Fix typos",
        "commit_url": "https://github.com/celery/celery/commit/5d68d781de807b4576cf5f574e5ba0aaf0d17388",
        "buggy_code": "msg=\"Validate body group indicies count from 0 after freezing\"",
        "fixed_code": "msg=\"Validate body group indices count from 0 after freezing\"",
        "patch": "@@ -1251,7 +1251,7 @@ def test_freeze_tasks_body_is_group(self, subtests):\n         # When we freeze the chord, its body will be cloned and options set\n         top_group.freeze()\n         with subtests.test(\n-            msg=\"Validate body group indicies count from 0 after freezing\"\n+            msg=\"Validate body group indices count from 0 after freezing\"\n         ):\n             assert all(\n                 embedded_body_elem is not body_elem"
    },
    {
        "commit_id": "6405ebc62348d4c1c48334cd4dff5e21233bea2f",
        "commit_message": "Allow using non-true values in app kwargs\n\nTrying to instantiate Celery app with non-true kwargs will not work\nfor those configs which have True as default, for example,\nthis will not have effect:\n\n>>> app = Celery(task_create_missing_queues=False)\n>>> app.conf['task_create_missing_queues']\nTrue\n\nThis fix simply changes the filtering which from now on will discard\nNone values only.\n\nFixes: #6865",
        "commit_url": "https://github.com/celery/celery/commit/6405ebc62348d4c1c48334cd4dff5e21233bea2f",
        "buggy_code": "if value:",
        "fixed_code": "if value is not None:",
        "patch": "@@ -323,7 +323,7 @@ def on_init(self):\n         \"\"\"Optional callback called at init.\"\"\"\n \n     def __autoset(self, key, value):\n-        if value:\n+        if value is not None:\n             self._preconf[key] = value\n             self._preconf_set_by_auto.add(key)\n "
    },
    {
        "commit_id": "3cf5072ee5f95744024f60e0f4a77eb2edb8959f",
        "commit_message": "Remove celery.task references in modules, docs (#6869)\n\n* Complete celery.task removal\r\n\r\n* Update docs to remove celery.tasks\r\n\r\n* docs/userguide/application: Correct reference\r\n\r\n* Fix bad @Signature references",
        "commit_url": "https://github.com/celery/celery/commit/3cf5072ee5f95744024f60e0f4a77eb2edb8959f",
        "buggy_code": "see :attr:`celery.task.base.Task.rate_limit` for",
        "fixed_code": "see :attr:`celery.app.task.Task.rate_limit` for",
        "patch": "@@ -536,7 +536,7 @@ def rate_limit(self, task_name, rate_limit, destination=None, **kwargs):\n             task_name (str): Name of task to change rate limit for.\n             rate_limit (int, str): The rate limit as tasks per second,\n                 or a rate limit string (`'100/m'`, etc.\n-                see :attr:`celery.task.base.Task.rate_limit` for\n+                see :attr:`celery.app.task.Task.rate_limit` for\n                 more information).\n \n         See Also:"
    },
    {
        "commit_id": "3cf5072ee5f95744024f60e0f4a77eb2edb8959f",
        "commit_message": "Remove celery.task references in modules, docs (#6869)\n\n* Complete celery.task removal\r\n\r\n* Update docs to remove celery.tasks\r\n\r\n* docs/userguide/application: Correct reference\r\n\r\n* Fix bad @Signature references",
        "commit_url": "https://github.com/celery/celery/commit/3cf5072ee5f95744024f60e0f4a77eb2edb8959f",
        "buggy_code": ":class:`celery.task.base.Task` with a valid `name` attribute.",
        "fixed_code": ":class:`celery.app.task.Task` with a valid `name` attribute.",
        "patch": "@@ -36,7 +36,7 @@ def unregister(self, name):\n \n         Arguments:\n             name (str): name of the task to unregister, or a\n-                :class:`celery.task.base.Task` with a valid `name` attribute.\n+                :class:`celery.app.task.Task` with a valid `name` attribute.\n \n         Raises:\n             celery.exceptions.NotRegistered: if the task is not registered."
    },
    {
        "commit_id": "3cf5072ee5f95744024f60e0f4a77eb2edb8959f",
        "commit_message": "Remove celery.task references in modules, docs (#6869)\n\n* Complete celery.task removal\r\n\r\n* Update docs to remove celery.tasks\r\n\r\n* docs/userguide/application: Correct reference\r\n\r\n* Fix bad @Signature references",
        "commit_url": "https://github.com/celery/celery/commit/3cf5072ee5f95744024f60e0f4a77eb2edb8959f",
        "buggy_code": ":attr:`celery.task.base.Task.rate_limit`.",
        "fixed_code": ":attr:`celery.app.task.Task.rate_limit`.",
        "patch": "@@ -187,7 +187,7 @@ def rate_limit(state, task_name, rate_limit, **kwargs):\n     \"\"\"Tell worker(s) to modify the rate limit for a task by type.\n \n     See Also:\n-        :attr:`celery.task.base.Task.rate_limit`.\n+        :attr:`celery.app.task.Task.rate_limit`.\n \n     Arguments:\n         task_name (str): Type of task to set rate limit for."
    },
    {
        "commit_id": "98fdcd749b0c4d3ec1ad0cfae058d193595413e1",
        "commit_message": "Fix typo in mark_as_failure",
        "commit_url": "https://github.com/celery/celery/commit/98fdcd749b0c4d3ec1ad0cfae058d193595413e1",
        "buggy_code": "if self.store_result and state in states.PROPAGATE_STATES:",
        "fixed_code": "if store_result and state in states.PROPAGATE_STATES:",
        "patch": "@@ -190,7 +190,7 @@ def mark_as_failure(self, task_id, exc,\n                 # elements of the chain. This is only truly important so\n                 # that the last chain element which controls completion of\n                 # the chain itself is marked as completed to avoid stalls.\n-                if self.store_result and state in states.PROPAGATE_STATES:\n+                if store_result and state in states.PROPAGATE_STATES:\n                     try:\n                         chained_task_id = chain_elem_opts['task_id']\n                     except KeyError:"
    },
    {
        "commit_id": "7b5a44d646f43288fb546da10a1141347b01543b",
        "commit_message": "Fix setting worker concurrency option after signal\n\nAllow to set \"worker_concurrency\" option through\n\"user_preload_options\" signal mechanism.\n\nCurrent behaviour:\n\n1. \"click.option\" decorator for \"--concurrency\" option is executed,\n   its callback returns \"0\" when evaluating \"value or\n   ctx.obj.app.conf.worker_concurrency\" (None or 0). This default \"0\"\n   comes from \"app.defaults\".\n\n2. Celery \"user_preload_options\" signal is processed, then\n   \"app.conf.worker_concurrency\" value is correctly updated through\n   \"Settings.update\".\n\n3. Celery \"worker.worker.WorkController.setup_defaults\" kicks off\n   and \"concurrency\" attribute is resolved with\n   \"either('worker_concurrency', concurrency)\"\n\n4. \"either\" method (app.base) chains calls to \"first\" function with\n   \"None\" as predicate (returns the first item that's not \"None\"),\n   in our case \"first(None, defaults)\" (defaults=(0,)) will take\n   precedence and and \"0\" will be returned, whatever value is in\n   \"app.conf.worker_concurrency\".\n\nThis fix changes \"worker_concurrency\" default from \"0\" to \"None\"\nallowing \"either\" method to correctly resolve in favor\nof \"app.conf.worker_concurrency\" value.\n\nThe final value used as concurrency is resolved in \"worker.worker\"\nwith conditional \"if not self.concurrency\" thus having \"None\"\nas default value for \"self.concurrency\" doesn't break things.\n\nFixes #6836",
        "commit_url": "https://github.com/celery/celery/commit/7b5a44d646f43288fb546da10a1141347b01543b",
        "buggy_code": "concurrency=Option(0, type='int'),",
        "fixed_code": "concurrency=Option(None, type='int'),",
        "patch": "@@ -294,7 +294,7 @@ def __repr__(self):\n         cancel_long_running_tasks_on_connection_loss=Option(\n             False, type='bool'\n         ),\n-        concurrency=Option(0, type='int'),\n+        concurrency=Option(None, type='int'),\n         consumer=Option('celery.worker.consumer:Consumer', type='string'),\n         direct=Option(False, type='bool', old={'celery_worker_direct'}),\n         disable_rate_limits=Option("
    },
    {
        "commit_id": "030e71b2624ad6f8d5458b3820efe3ef815318c6",
        "commit_message": "style: Fix flake8 lint in tests",
        "commit_url": "https://github.com/celery/celery/commit/030e71b2624ad6f8d5458b3820efe3ef815318c6",
        "buggy_code": "group = self.patching('celery.group')",
        "fixed_code": "self.patching('celery.group')",
        "patch": "@@ -543,7 +543,7 @@ class ExpectedException(Exception):\n         callback.keys.return_value = []\n         task = self.app.tasks[callback.task] = Mock()\n         b.fail_from_current_stack = Mock()\n-        group = self.patching('celery.group')\n+        self.patching('celery.group')\n         with patch.object(\n             b, \"_call_task_errbacks\", side_effect=ExpectedException()\n         ) as mock_call_errbacks:"
    },
    {
        "commit_id": "030e71b2624ad6f8d5458b3820efe3ef815318c6",
        "commit_message": "style: Fix flake8 lint in tests",
        "commit_url": "https://github.com/celery/celery/commit/030e71b2624ad6f8d5458b3820efe3ef815318c6",
        "buggy_code": "import pytest_subtests",
        "fixed_code": "import pytest_subtests  # noqa: F401",
        "patch": "@@ -1,7 +1,7 @@\n import collections\n \n import pytest\n-import pytest_subtests\n+import pytest_subtests  # noqa: F401\n from kombu.utils.functional import lazy\n \n from celery.utils.functional import (DummyContext, first, firstmethod,"
    },
    {
        "commit_id": "117cd9ca410e8879f71bd84be27b8e69e462c56a",
        "commit_message": "Fixes build for PyPy3 (#6635)\n\n* installs packages the same way docker does\r\n\r\n* removes couchbase dependency for PyPy\r\n\r\n* removes ephem dependency for PyPy\r\n\r\n* fixes mongo unit tests for PyPy3\r\n\r\nMocking `datetime.datetime` was causing an issue with\r\n`datetime.utcnow()`.  This mock doesn't appear to be needed.\r\nSee https://github.com/celery/celery/pull/6635/checks?check_run_id=1944166896.\r\n\r\n* fix: Avoid shadowing `Thread` attributes\r\n\r\nFixes #6489\r\n\r\n* ci: Install default deps for pypy3 toxenvs\r\n\r\n* ci: Run unit tests with `tox`\r\n\r\n* ci: Lint source in separate action using `tox`\r\n\r\n* ci: Redent codecov action\r\n\r\n* test: Rework some mocking in `test_platforms.py`\r\n\r\nAlso fix some flakes which may have been added by some other\r\nautoformatter in #6804. The 4 space non-visual-indentation should keep\r\nmost formatters fairly happy.\r\n\r\n* style: Fix some flakes\r\n\r\nCo-authored-by: maybe-sybr <58414429+maybe-sybr@users.noreply.github.com>",
        "commit_url": "https://github.com/celery/celery/commit/117cd9ca410e8879f71bd84be27b8e69e462c56a",
        "buggy_code": "\"\"\"",
        "fixed_code": "\"\"\"  # noqa: E501",
        "patch": "@@ -119,7 +119,7 @@\n These tasks cannot be acknowledged as the connection is gone, and the tasks are automatically redelivered back to the queue.\n You can enable this behavior using the worker_cancel_long_running_tasks_on_connection_loss setting.\n In Celery 5.1 it is set to False by default. The setting will be set to True by default in Celery 6.0.\n-\"\"\"\n+\"\"\"  # noqa: E501\n \n \n def dump_body(m, body):"
    },
    {
        "commit_id": "5d72aeedb6329b609469c63998e9335e017bd204",
        "commit_message": "fix: Preserve call/errbacks of replaced tasks (#6770)\n\n* style: Remove unused var from canvas unit tests\r\n\r\n* test: Check task ID re-freeze on replacement\r\n\r\n* refac: Remove duped task ID preservation logic\r\n\r\n* test: Rework canvas call/errback integration tests\r\n\r\nThis change modifies a bunch of the tests to use unique keys for the\r\n`redis_echo` and `redis_count` tasks which are used to validate that\r\ncallbacks and errbacks are made. We also introduce helper functions for\r\nvalidating that messages/counts are seen to reduce duplicate code.\r\n\r\n* fix: Preserve call/errbacks of replaced tasks\r\n\r\nFixes #6441\r\n\r\n* fix: Ensure replacement tasks get the group index\r\n\r\nThis change adds some tests to ensure that when a task is replaced, it\r\nruns as expected. This exposed a bug where the group index of a task\r\nwould be lost when replaced with a chain since chains would not pass\r\ntheir `group_index` option down to the final task when applied. This\r\nmanifested as the results of chords being mis-ordered on the redis\r\nbackend since the group index would default to `+inf`. Other backends\r\nmay have had similar issues.",
        "commit_url": "https://github.com/celery/celery/commit/5d72aeedb6329b609469c63998e9335e017bd204",
        "buggy_code": "res_obj = group_sig.apply_async()",
        "fixed_code": "group_sig.apply_async()",
        "patch": "@@ -854,7 +854,7 @@ def test_apply_contains_chords_containing_empty_chain(self):\n         # This is an invalid setup because we can't complete a chord header if\n         # there are no actual tasks which will run in it. However, the current\n         # behaviour of an `IndexError` isn't particularly helpful to a user.\n-        res_obj = group_sig.apply_async()\n+        group_sig.apply_async()\n \n     def test_apply_contains_chords_containing_chain_with_empty_tail(self):\n         ggchild_count = 42"
    },
    {
        "commit_id": "bb18e1b95a0c8dcc4e80c29075932cf3c77c845f",
        "commit_message": "Fix '--pool=threads' support in command line options parsing (#6787)\n\n* Fix '--pool=threads' support in command line options parsing\r\n\r\n* Add unit tests for concurrency.get_available_pool_names",
        "commit_url": "https://github.com/celery/celery/commit/bb18e1b95a0c8dcc4e80c29075932cf3c77c845f",
        "buggy_code": "super().__init__(('prefork', 'eventlet', 'gevent', 'solo'))",
        "fixed_code": "super().__init__(concurrency.get_available_pool_names())",
        "patch": "@@ -40,7 +40,7 @@ class WorkersPool(click.Choice):\n \n     def __init__(self):\n         \"\"\"Initialize the workers pool option with the relevant choices.\"\"\"\n-        super().__init__(('prefork', 'eventlet', 'gevent', 'solo'))\n+        super().__init__(concurrency.get_available_pool_names())\n \n     def convert(self, value, param, ctx):\n         # Pools like eventlet/gevent needs to patch libs as early"
    },
    {
        "commit_id": "e737fbb82b7eec41aa42491e8a331bcc45f9df81",
        "commit_message": "Add What's new for v5.1.0 (#6762)\n\n* Add What's new for v5.1.0\r\n\r\n* Update docs\r\n\r\n* Update index.\r\n\r\n* Fix title formatting.\r\n\r\n* Update the title in the migration guide.\r\n\r\n* Fix typo.\r\n\r\n* Update codename.\r\n\r\n* Format code example correctly.\r\n\r\n* Update codename in readme file.\r\n\r\n* Describe azure 7.0.0 changes\r\n\r\n* Fix formatting.\r\n\r\n* Update changelog.\r\n\r\n* Readd the whats new docs for 5.0.\r\n\r\nCo-authored-by: Omer Katz <omer.drow@gmail.com>",
        "commit_url": "https://github.com/celery/celery/commit/e737fbb82b7eec41aa42491e8a331bcc45f9df81",
        "buggy_code": "SERIES = 'singularity'",
        "fixed_code": "SERIES = 'sun-harmonics'",
        "patch": "@@ -15,7 +15,7 @@\n # Lazy loading\n from . import local  # noqa\n \n-SERIES = 'singularity'\n+SERIES = 'sun-harmonics'\n \n __version__ = '5.1.0b2'\n __author__ = 'Ask Solem'"
    },
    {
        "commit_id": "6dd385258297c89843bfe73299e5f7eebf0e98e2",
        "commit_message": "fix: Error propagation and errback calling for group-like signatures (#6746)\n\n* fix: Use chord kwarg over request in group.apply\r\n\r\n* fix: Propagate errors from failed chain tasks\r\n\r\nFixes #6220\r\n\r\nCo-authored-by: Maximilian Friedersdorff <max@friedersdorff.com>\r\nCo-authored-by: maybe-sybr <58414429+maybe-sybr@users.noreply.github.com>\r\n\r\n* fix: Ensure all subtasks of a group get errbacks\r\n\r\nGiving a linked task callback to the 0th task in a group is fine, but\r\nfor errbacks it's not an appropriate choice since any task in the group\r\ncould fail. This ensures that if any task other than the 0th one fails,\r\nthe errback will be called. This opens the possibility for an errback to\r\nbe called more than once when linked to a group, but generally we expect\r\nthat they should be design to be idempotent so no warning is issued for\r\nthe changed behaviour.\r\n\r\n* test: Add tests for child error propagation\r\n\r\n* test: Add regression tests for group errback dupes\r\n\r\nThese tests simply encode the currently expected behaviour where\r\nerrbacks linked to a group will be called once for each failed task, as\r\nwell as the consequences for chords which turn their header into a group\r\nif it is not one already.\r\n\r\n* doc: Add extra docs for canvas call/errback usage\r\n\r\nCo-authored-by: Crawford, Jordan <Jordan.Crawford@msci.com>\r\nCo-authored-by: Maximilian Friedersdorff <max@friedersdorff.com>",
        "commit_url": "https://github.com/celery/celery/commit/6dd385258297c89843bfe73299e5f7eebf0e98e2",
        "buggy_code": "from unittest.mock import MagicMock, Mock, call, patch, sentinel, ANY",
        "fixed_code": "from unittest.mock import ANY, MagicMock, Mock, call, patch, sentinel",
        "patch": "@@ -1,5 +1,5 @@\n import json\n-from unittest.mock import MagicMock, Mock, call, patch, sentinel, ANY\n+from unittest.mock import ANY, MagicMock, Mock, call, patch, sentinel\n \n import pytest\n import pytest_subtests  # noqa: F401"
    },
    {
        "commit_id": "b0326ab0e249288e8e551e78fcb88ab2c2b84bcb",
        "commit_message": "#6748 Fix Retry.__reduce__ method (#6749)\n\n* #6748 Fix Retry.__reduce__ method\r\n\r\n* #6748 ensure that Retry.exc is pickleable in __reduce__\r\n\r\n* #6748 fix maximum recursion for pypy, remove pickleable exception.\r\n\r\nget_pickleable_exception introduces circular import\r\n\r\n* #6748 remove arguments missing in pickled Retry instance\r\n\r\n* #6748 optimize imports",
        "commit_url": "https://github.com/celery/celery/commit/b0326ab0e249288e8e551e78fcb88ab2c2b84bcb",
        "buggy_code": "return self.__class__, (self.message, self.excs, self.when)",
        "fixed_code": "return self.__class__, (self.message, self.exc, self.when)",
        "patch": "@@ -180,7 +180,7 @@ def __str__(self):\n         return f'Retry {self.humanize()}'\n \n     def __reduce__(self):\n-        return self.__class__, (self.message, self.excs, self.when)\n+        return self.__class__, (self.message, self.exc, self.when)\n \n \n RetryTaskError = Retry  # noqa: E305 XXX compat"
    },
    {
        "commit_id": "8d6778810c5153c9e4667eed618de2d0bf72663e",
        "commit_message": "Deduplicate successful tasks (#6722)\n\n* Deduplicate successful tasks.\r\n\r\nThis feature allows the user to deduplicate successful tasks which acks late.\r\n\r\nThe trace function fetches the metadata from the backend each time it receives a task and compares its state.\r\nIf the state is SUCCESS we log and bail instead of executing the task.\r\nThe task is acknowledged and everything proceeds normally.\r\n\r\n* Fix test to cover a backend error.\r\n\r\n* Added a local cache of successful task.\r\n\r\nInstead of hitting the backend every time, we first check if the task was successfully executed in this worker.\r\n\r\nThe local cache is limited to 1000 tasks so our memory usage won't grow dramatically over time.\r\n\r\n* Only deduplicate when task is redelivered.\r\n\r\n* Don't deduplicate when backend is not persistent.\r\n\r\n* Added documentation.\r\n\r\n* Push the task into the stack only after checking that it is not a duplicate.\r\n\r\n* Adjust unit tests.",
        "commit_url": "https://github.com/celery/celery/commit/8d6778810c5153c9e4667eed618de2d0bf72663e",
        "buggy_code": "task_ready(self)",
        "fixed_code": "task_ready(self, successful=True)",
        "patch": "@@ -497,7 +497,7 @@ def on_success(self, failed__retval__runtime, **kwargs):\n             if isinstance(retval.exception, (SystemExit, KeyboardInterrupt)):\n                 raise retval.exception\n             return self.on_failure(retval, return_ok=True)\n-        task_ready(self)\n+        task_ready(self, successful=True)\n \n         if self.task.acks_late:\n             self.acknowledge()"
    },
    {
        "commit_id": "1901ea8594185c015d1518d89f3b90180275c0b9",
        "commit_message": "fix AttributeError regression in #6619",
        "commit_url": "https://github.com/celery/celery/commit/1901ea8594185c015d1518d89f3b90180275c0b9",
        "buggy_code": "for v in entry_args.args",
        "fixed_code": "for v in entry_args",
        "patch": "@@ -208,7 +208,7 @@ def _evaluate_entry_args(entry_args):\n         return []\n     return [\n         v() if isinstance(v, BeatLazyFunc) else v\n-        for v in entry_args.args\n+        for v in entry_args\n     ]\n \n "
    },
    {
        "commit_id": "fc55f2afa4121567acc9217a0da065c293c1fb9e",
        "commit_message": "Fix typo.",
        "commit_url": "https://github.com/celery/celery/commit/fc55f2afa4121567acc9217a0da065c293c1fb9e",
        "buggy_code": "simple test sanity check that such a tsk structure can be completed.",
        "fixed_code": "simple test sanity check that such a task structure can be completed.",
        "patch": "@@ -1252,7 +1252,7 @@ def test_nested_chord_group_chain_group_tail(self, manager):\n         Sanity check that a deeply nested group is completed as expected.\n \n         Groups at the end of chains nested in chords have had issues and this\n-        simple test sanity check that such a tsk structure can be completed.\n+        simple test sanity check that such a task structure can be completed.\n         \"\"\"\n         try:\n             manager.app.backend.ensure_chords_allowed()"
    },
    {
        "commit_id": "1f3c98149bc791874063c870048067d3a0f2c674",
        "commit_message": "Fix checking expiration of X.509 certificates (#6678)\n\n`not_valid_after` is a na\u00efve datetime representing a moment in UTC. It should not be compared to a na\u00efve datetime representing the current local date and time.\r\n\r\nAlso, the value is inclusive.\r\n\r\nhttps://cryptography.io/en/3.4.6/x509/reference.html#cryptography.x509.Certificate.not_valid_after",
        "commit_url": "https://github.com/celery/celery/commit/1f3c98149bc791874063c870048067d3a0f2c674",
        "buggy_code": "return datetime.datetime.now() > self._cert.not_valid_after",
        "fixed_code": "return datetime.datetime.utcnow() >= self._cert.not_valid_after",
        "patch": "@@ -27,7 +27,7 @@ def __init__(self, cert):\n \n     def has_expired(self):\n         \"\"\"Check if the certificate has expired.\"\"\"\n-        return datetime.datetime.now() > self._cert.not_valid_after\n+        return datetime.datetime.utcnow() >= self._cert.not_valid_after\n \n     def get_pubkey(self):\n         \"\"\"Get public key from certificate.\"\"\""
    },
    {
        "commit_id": "023afc1aabe899b189a45499aa469afa39222736",
        "commit_message": "Fix a typo in a docstring.",
        "commit_url": "https://github.com/celery/celery/commit/023afc1aabe899b189a45499aa469afa39222736",
        "buggy_code": "\"\"\"An issue writing from the backend.\"\"\"",
        "fixed_code": "\"\"\"An issue writing to the backend.\"\"\"",
        "patch": "@@ -288,7 +288,7 @@ def __repr__(self):\n \n \n class BackendStoreError(BackendError):\n-    \"\"\"An issue writing from the backend.\"\"\"\n+    \"\"\"An issue writing to the backend.\"\"\"\n \n     def __init__(self, *args, **kwargs):\n         self.state = kwargs.get('state', \"\")"
    },
    {
        "commit_id": "84951b1441ef242c75fe48e2100783b3081487c0",
        "commit_message": "Fix example.\n\nFixes #6459.",
        "commit_url": "https://github.com/celery/celery/commit/84951b1441ef242c75fe48e2100783b3081487c0",
        "buggy_code": "backend='amqp://',",
        "fixed_code": "backend='rpc://',",
        "patch": "@@ -2,7 +2,7 @@\n \n app = Celery('proj',\n              broker='amqp://',\n-             backend='amqp://',\n+             backend='rpc://',\n              include=['proj.tasks'])\n \n # Optional configuration, see the application user guide."
    },
    {
        "commit_id": "9b78de840d74d3e5cd6d4d7701ad64ba4a43fbe6",
        "commit_message": "Fix `celery shell` command",
        "commit_url": "https://github.com/celery/celery/commit/9b78de840d74d3e5cd6d4d7701ad64ba4a43fbe6",
        "buggy_code": "import celery.task.base",
        "fixed_code": "import celery",
        "patch": "@@ -130,7 +130,7 @@ def shell(ctx, ipython=False, bpython=False,\n         import_module('celery.concurrency.eventlet')\n     if gevent:\n         import_module('celery.concurrency.gevent')\n-    import celery.task.base\n+    import celery\n     app = ctx.obj.app\n     app.loader.import_default_modules()\n "
    },
    {
        "commit_id": "ce4f759a5766331285c779ed87b724a755d18b74",
        "commit_message": "bugfix: when set config result_expires = 0, chord.get will hang. (#6373)\n\n* bugfix: when set config result_expires = 0, chord.get will hang.\r\n\r\n`EXPIRE key 0` will delete a key in redis, then chord will never get the\r\nresult.\r\n\r\nfix: https://github.com/celery/celery/issues/5237\r\n\r\n* test: add testcase for expire when set config with zero.",
        "commit_url": "https://github.com/celery/celery/commit/ce4f759a5766331285c779ed87b724a755d18b74",
        "buggy_code": "if self.expires is not None:",
        "fixed_code": "if self.expires:",
        "patch": "@@ -436,7 +436,7 @@ def on_chord_part_return(self, request, state, result,\n                 if self._chord_zset\n                 else pipe.rpush(jkey, encoded).llen(jkey)\n             ).get(tkey)\n-            if self.expires is not None:\n+            if self.expires:\n                 pipeline = pipeline \\\n                     .expire(jkey, self.expires) \\\n                     .expire(tkey, self.expires)"
    },
    {
        "commit_id": "d28e340370daafb8b4550555a71089224a2442b3",
        "commit_message": "Fix the broken celery upgrade settings command.",
        "commit_url": "https://github.com/celery/celery/commit/d28e340370daafb8b4550555a71089224a2442b3",
        "buggy_code": "def _compat_key(self, key, namespace='CELERY'):",
        "fixed_code": "def _compat_key(key, namespace='CELERY'):",
        "patch": "@@ -20,7 +20,7 @@ def _slurp(filename):\n         return [line for line in read_fh]\n \n \n-def _compat_key(self, key, namespace='CELERY'):\n+def _compat_key(key, namespace='CELERY'):\n     key = key.upper()\n     if not key.startswith(namespace):\n         key = '_'.join([namespace, key])"
    },
    {
        "commit_id": "1f4af2d6c19ba83ec751fa2d71adc3ea232d0c21",
        "commit_message": "fix flaky test_add_chord_to_chord\n\nFixes #6256\nrelated https://github.com/celery/celery/pull/6218/files#diff-2ae8afebeb9ba0fd1534a70264a2ac68R621",
        "commit_url": "https://github.com/celery/celery/commit/1f4af2d6c19ba83ec751fa2d71adc3ea232d0c21",
        "buggy_code": "assert res.get() == [0, 5 + 6 + 7]",
        "fixed_code": "assert sorted(res.get()) == [0, 5 + 6 + 7]",
        "patch": "@@ -630,7 +630,7 @@ def test_add_chord_to_chord(self, manager):\n \n         c = group([add_chord_to_chord.s([1, 2, 3], 4)]) | identity.s()\n         res = c()\n-        assert res.get() == [0, 5 + 6 + 7]\n+        assert sorted(res.get()) == [0, 5 + 6 + 7]\n \n     @flaky\n     def test_eager_chord_inside_task(self, manager):"
    },
    {
        "commit_id": "e0d865c56cb43827db85f7418d02fbfb746d7f7b",
        "commit_message": "treat internal errors as failure\n\nthis way, task may be rejected and not acknowledged in case of\nunrecoverable error by the backend or any other celery components.\n\nHandle result correctly in request direct execution outside a pool",
        "commit_url": "https://github.com/celery/celery/commit/e0d865c56cb43827db85f7418d02fbfb746d7f7b",
        "buggy_code": "return trace_ok_t(report_internal_error(task, exc), None, 0.0, None)",
        "fixed_code": "return trace_ok_t(report_internal_error(task, exc), TraceInfo(FAILURE, exc), 0.0, None)",
        "patch": "@@ -543,7 +543,7 @@ def trace_task(task, uuid, args, kwargs, request=None, **opts):\n         return task.__trace__(uuid, args, kwargs, request)\n     except Exception as exc:\n         _signal_internal_error(task, uuid, args, kwargs, request, exc)\n-        return trace_ok_t(report_internal_error(task, exc), None, 0.0, None)\n+        return trace_ok_t(report_internal_error(task, exc), TraceInfo(FAILURE, exc), 0.0, None)\n \n \n def _signal_internal_error(task, uuid, args, kwargs, request, exc):"
    },
    {
        "commit_id": "40b5069d59a46c393026bbc56b248aae4bc4f5c2",
        "commit_message": "fix pydocstyle",
        "commit_url": "https://github.com/celery/celery/commit/40b5069d59a46c393026bbc56b248aae4bc4f5c2",
        "buggy_code": "\"\"\"Returns as a list of task IDs.\"\"\"",
        "fixed_code": "\"\"\"Return as a list of task IDs.\"\"\"",
        "patch": "@@ -130,7 +130,7 @@ def as_tuple(self):\n         return (self.id, parent and parent.as_tuple()), None\n \n     def as_list(self):\n-        \"\"\"Returns as a list of task IDs.\"\"\"\n+        \"\"\"Return as a list of task IDs.\"\"\"\n         results = []\n         parent = self.parent\n         results.append(self.id)"
    },
    {
        "commit_id": "e8bbc26832b790d16bdda07ff17dd20a314b277c",
        "commit_message": "fix pydocstyle errors",
        "commit_url": "https://github.com/celery/celery/commit/e8bbc26832b790d16bdda07ff17dd20a314b277c",
        "buggy_code": "\"\"\"  Returns as a list of task IDs. \"\"\"",
        "fixed_code": "\"\"\"Returns as a list of task IDs.\"\"\"",
        "patch": "@@ -130,7 +130,7 @@ def as_tuple(self):\n         return (self.id, parent and parent.as_tuple()), None\n \n     def as_list(self):\n-        \"\"\"  Returns as a list of task IDs. \"\"\"\n+        \"\"\"Returns as a list of task IDs.\"\"\"\n         results = []\n         parent = self.parent\n         results.append(self.id)"
    },
    {
        "commit_id": "93e000db08e1953dacb4c6f6ca0e645ed7077992",
        "commit_message": "Fix autoscale test",
        "commit_url": "https://github.com/celery/celery/commit/93e000db08e1953dacb4c6f6ca0e645ed7077992",
        "buggy_code": "x.keepalive = 0",
        "fixed_code": "x.keepalive = -1",
        "patch": "@@ -154,7 +154,7 @@ def test_update(self):\n         worker = Mock(name='worker')\n         x = autoscale.Autoscaler(self.pool, 10, 3, worker=worker)\n         x.worker.consumer.prefetch_multiplier = 1\n-        x.keepalive = 0\n+        x.keepalive = -1\n         assert x.processes == 3\n         x.scale_up(5)\n         x.update(7, None)"
    },
    {
        "commit_id": "4e2a59afd8c8ef70bfe387e470531e8bf87c1587",
        "commit_message": "fix flake8 error",
        "commit_url": "https://github.com/celery/celery/commit/4e2a59afd8c8ef70bfe387e470531e8bf87c1587",
        "buggy_code": "from .base import KeyValueStoreBackend, Backend",
        "fixed_code": "from .base import KeyValueStoreBackend",
        "patch": "@@ -11,7 +11,7 @@\n from celery.exceptions import ImproperlyConfigured\n from celery.five import items\n \n-from .base import KeyValueStoreBackend, Backend\n+from .base import KeyValueStoreBackend\n \n try:\n     import elasticsearch"
    },
    {
        "commit_id": "12a643ce2668deb17d586e9480aca5b2d3bca18a",
        "commit_message": "ElasticSearch: Retry index if document was deleted between index and update (#6140)\n\n* ElasticSearch: Retry index if document was deleted between index and update\r\n\r\n* Elasticsearch increase coverage to 100%\r\n\r\n* Fix pydocstyle",
        "commit_url": "https://github.com/celery/celery/commit/12a643ce2668deb17d586e9480aca5b2d3bca18a",
        "buggy_code": "\"\"\"Send a special `internal_error` signal to the app for outside body errors\"\"\"",
        "fixed_code": "\"\"\"Send a special `internal_error` signal to the app for outside body errors.\"\"\"",
        "patch": "@@ -547,7 +547,7 @@ def trace_task(task, uuid, args, kwargs, request=None, **opts):\n \n \n def _signal_internal_error(task, uuid, args, kwargs, request, exc):\n-    \"\"\"Send a special `internal_error` signal to the app for outside body errors\"\"\"\n+    \"\"\"Send a special `internal_error` signal to the app for outside body errors.\"\"\"\n     try:\n         _, _, tb = sys.exc_info()\n         einfo = ExceptionInfo()"
    },
    {
        "commit_id": "704896a333722215b4cf25093af79af93ce42153",
        "commit_message": "Add integration tests for Elasticsearch and fix _update",
        "commit_url": "https://github.com/celery/celery/commit/704896a333722215b4cf25093af79af93ce42153",
        "buggy_code": "body=body,",
        "fixed_code": "body={'doc': body},",
        "patch": "@@ -153,7 +153,7 @@ def _update(self, id, body, **kwargs):\n                 res = self.server.update(\n                     id=bytes_to_str(id),\n                     index=self.index,\n-                    body=body,\n+                    body={'doc': body},\n                     params={'if_primary_term': prim_term, 'if_seq_no': seq_no},\n                     **kwargs\n                 )"
    },
    {
        "commit_id": "fae3336612a1cae9b94acc8b2d0cb637e5fb6c3c",
        "commit_message": "Fix windows build (#6104)\n\n* do not load memcache nor couchbase lib during windows build\r\n\r\nthose libraries depends on native libraries libcouchbase and libmemcached\r\nthat are not installed on Appveyor.\r\nAs only unit tests runs on Appveyor, it should be fine\r\n\r\n* Add python 3.8 workaround for app trap\r\n\r\n* skip tests file_descriptor_safety tests on windows\r\n\r\nAsyncPool is not supported on Windows so Pool does have _fileno_to_outq\r\nattribute, making the test fail\r\n\r\n* Fix crossplatform log and pid files in multi mode\r\n\r\nit relates to #6017\r\n\r\n* Use tox to build and test on windows\r\n\r\n* remove tox_install_command\r\n\r\n* drop python 2.7 from windows build",
        "commit_url": "https://github.com/celery/celery/commit/fae3336612a1cae9b94acc8b2d0cb637e5fb6c3c",
        "buggy_code": "if name == '_is_coroutine':",
        "fixed_code": "if name == '_is_coroutine' or name == '__func__':",
        "patch": "@@ -32,7 +32,7 @@ class Trap(object):\n     def __getattr__(self, name):\n         # Workaround to allow unittest.mock to patch this object\n         # in Python 3.8 and above.\n-        if name == '_is_coroutine':\n+        if name == '_is_coroutine' or name == '__func__':\n             return None\n         print(name)\n         raise RuntimeError('Test depends on current_app')"
    },
    {
        "commit_id": "976cd8d3e40eb785423403deb2ce15ea1307579b",
        "commit_message": "Always requeue while worker lost regardless of the redelivered flag (#6103)\n\n* #5598 fix, always redelivery while WorkerLostError\r\n\r\n* fix, change the requeue flag so the task will remain PENDING",
        "commit_url": "https://github.com/celery/celery/commit/976cd8d3e40eb785423403deb2ce15ea1307579b",
        "buggy_code": "requeue = not self.delivery_info.get('redelivered')",
        "fixed_code": "requeue = True",
        "patch": "@@ -505,7 +505,7 @@ def on_failure(self, exc_info, send_failed_event=True, return_ok=False):\n             )\n             ack = self.task.acks_on_failure_or_timeout\n             if reject:\n-                requeue = not self.delivery_info.get('redelivered')\n+                requeue = True\n                 self.reject(requeue=requeue)\n                 send_failed_event = False\n             elif ack:"
    },
    {
        "commit_id": "976cd8d3e40eb785423403deb2ce15ea1307579b",
        "commit_message": "Always requeue while worker lost regardless of the redelivered flag (#6103)\n\n* #5598 fix, always redelivery while WorkerLostError\r\n\r\n* fix, change the requeue flag so the task will remain PENDING",
        "commit_url": "https://github.com/celery/celery/commit/976cd8d3e40eb785423403deb2ce15ea1307579b",
        "buggy_code": "assert self.mytask.backend.get_status(job.id) == states.FAILURE",
        "fixed_code": "assert self.mytask.backend.get_status(job.id) == states.PENDING",
        "patch": "@@ -653,7 +653,7 @@ def test_on_failure_acks_late_reject_on_worker_lost_enabled(self):\n         job.delivery_info['redelivered'] = True\n         job.on_failure(exc_info)\n \n-        assert self.mytask.backend.get_status(job.id) == states.FAILURE\n+        assert self.mytask.backend.get_status(job.id) == states.PENDING\n \n     def test_on_failure_acks_late(self):\n         job = self.xRequest()"
    },
    {
        "commit_id": "4c2e832014ca58ebfc52bfce5e31e0c5f2070b8d",
        "commit_message": "Fix all flake8 lint errors",
        "commit_url": "https://github.com/celery/celery/commit/4c2e832014ca58ebfc52bfce5e31e0c5f2070b8d",
        "buggy_code": "print('-- process {0} tasks: {1}s total, {2} tasks/s} '.format(",
        "fixed_code": "print('-- process {0} tasks: {1}s total, {2} tasks/s'.format(",
        "patch": "@@ -60,7 +60,7 @@ def it(_, n):\n     elif i > n - 2:\n         total = tdiff(it.time_start)\n         print('({0} so far: {1}s)'.format(i, tdiff(it.subt)), file=sys.stderr)\n-        print('-- process {0} tasks: {1}s total, {2} tasks/s} '.format(\n+        print('-- process {0} tasks: {1}s total, {2} tasks/s'.format(\n             n, total, n / (total + .0),\n         ))\n         import os"
    },
    {
        "commit_id": "163d09f20a72550fb86e1787978291278e90b58a",
        "commit_message": "Fix autoscale when prefetch_multiplier is 1",
        "commit_url": "https://github.com/celery/celery/commit/163d09f20a72550fb86e1787978291278e90b58a",
        "buggy_code": "prefetch_count = max(w.min_concurrency, 1) * w.prefetch_multiplier",
        "fixed_code": "prefetch_count = max(w.max_concurrency, 1) * w.prefetch_multiplier",
        "patch": "@@ -223,7 +223,7 @@ class Consumer(bootsteps.StartStopStep):\n \n     def create(self, w):\n         if w.max_concurrency:\n-            prefetch_count = max(w.min_concurrency, 1) * w.prefetch_multiplier\n+            prefetch_count = max(w.max_concurrency, 1) * w.prefetch_multiplier\n         else:\n             prefetch_count = w.concurrency * w.prefetch_multiplier\n         c = w.consumer = self.instantiate("
    },
    {
        "commit_id": "20b7a808398b7b865651a5cf0fd7aa2b74be3a4b",
        "commit_message": "exceptions: NotRegistered: fix up language\n\nMinor fix to the language.",
        "commit_url": "https://github.com/celery/celery/commit/20b7a808398b7b865651a5cf0fd7aa2b74be3a4b",
        "buggy_code": "\"\"\"The task ain't registered.\"\"\"",
        "fixed_code": "\"\"\"The task is not registered.\"\"\"",
        "patch": "@@ -205,7 +205,7 @@ class IncompleteStream(TaskError):\n \n @python_2_unicode_compatible\n class NotRegistered(KeyError, TaskError):\n-    \"\"\"The task ain't registered.\"\"\"\n+    \"\"\"The task is not registered.\"\"\"\n \n     def __repr__(self):\n         return UNREGISTERED_FMT.format(self)"
    },
    {
        "commit_id": "7cf08574449f7c051fca7fac44f41d56385466a7",
        "commit_message": "Fix typo in celery.bin.multi document",
        "commit_url": "https://github.com/celery/celery/commit/7cf08574449f7c051fca7fac44f41d56385466a7",
        "buggy_code": "$ # Additional options are added to each celery worker' comamnd,",
        "fixed_code": "$ # Additional options are added to each celery worker' command,",
        "patch": "@@ -62,7 +62,7 @@\n     $ celery multi show 10 -l INFO -Q:1-3 images,video -Q:4,5 data\n         -Q default -L:4,5 DEBUG\n \n-    $ # Additional options are added to each celery worker' comamnd,\n+    $ # Additional options are added to each celery worker' command,\n     $ # but you can also modify the options for ranges of, or specific workers\n \n     $ # 3 workers: Two with 3 processes, and one with 10 processes."
    },
    {
        "commit_id": "8f55e5853b516ebac5fbc64850e19e3f41ed537b",
        "commit_message": "Fix: Accept and swallow `kwargs` to handle unexpected keyword arguments",
        "commit_url": "https://github.com/celery/celery/commit/8f55e5853b516ebac5fbc64850e19e3f41ed537b",
        "buggy_code": "def _iter_meta(self):",
        "fixed_code": "def _iter_meta(self, **kwargs):",
        "patch": "@@ -414,7 +414,7 @@ def _get_task_meta(self):\n             return self._maybe_set_cache(self.backend.get_task_meta(self.id))\n         return self._cache\n \n-    def _iter_meta(self):\n+    def _iter_meta(self, **kwargs):\n         return iter([self._get_task_meta()])\n \n     def _set_cache(self, d):"
    },
    {
        "commit_id": "3b564c7c2ffbc8e215ca46e5606023d56785c2a0",
        "commit_message": "Pass `interval` to `get_many` (#5931)\n\n* Pass `interval` to `get_many`\r\n\r\n* Fix: Syntax error for py2.7\r\n\r\n* Fix: Syntax error for py2.7",
        "commit_url": "https://github.com/celery/celery/commit/3b564c7c2ffbc8e215ca46e5606023d56785c2a0",
        "buggy_code": "for meta in result._iter_meta():",
        "fixed_code": "for meta in result._iter_meta(**kwargs):",
        "patch": "@@ -114,7 +114,7 @@ def start(self, initial_task_id, **kwargs):\n         self._consume_from(initial_task_id)\n \n     def on_wait_for_pending(self, result, **kwargs):\n-        for meta in result._iter_meta():\n+        for meta in result._iter_meta(**kwargs):\n             if meta is not None:\n                 self.on_state_change(meta, None)\n "
    },
    {
        "commit_id": "8911ea9a328871005eb6ca72e834a44611bc93ae",
        "commit_message": "Added a default value for retries in worker.strategy. (#5945)\n\n* Added a default value for retries in worker.strategy.\r\n\r\nI was facing an issue when adding tasks directly to rabbitmq\r\nusing pika instead of calling task.apply_async. The issue was\r\nthe self.retry mechanisum was failing. In app/tasks.py the line\r\n`retries = request.retries + 1` was causing the issue. On further\r\ntracing I figured out that it was because the default .get value\r\n(None) was getting passed through this function and was raising\r\nTypeError: unsupported operand type(s) for +: 'NoneType' and 'int'\r\n\r\n* Add test cases for default and custom retries value",
        "commit_url": "https://github.com/celery/celery/commit/8911ea9a328871005eb6ca72e834a44611bc93ae",
        "buggy_code": "'retries': body.get('retries'),",
        "fixed_code": "'retries': body.get('retries', 0),",
        "patch": "@@ -48,7 +48,7 @@ def hybrid_to_proto2(message, body):\n         'shadow': body.get('shadow'),\n         'eta': body.get('eta'),\n         'expires': body.get('expires'),\n-        'retries': body.get('retries'),\n+        'retries': body.get('retries', 0),\n         'timelimit': body.get('timelimit', (None, None)),\n         'argsrepr': body.get('argsrepr'),\n         'kwargsrepr': body.get('kwargsrepr'),"
    },
    {
        "commit_id": "d0563058f8f47f347ac1b56c44f833f569764482",
        "commit_message": "Fix raise issue to make exception message more friendly (#5912)\n\nSigned-off-by: Chenyang Yan <memory.yancy@gmail.com>",
        "commit_url": "https://github.com/celery/celery/commit/d0563058f8f47f347ac1b56c44f833f569764482",
        "buggy_code": "raise AttributeError()",
        "fixed_code": "raise AttributeError(\"attribute 'celery' is the celery module not the instance of celery\")",
        "patch": "@@ -383,7 +383,7 @@ def find_app(app, symbol_by_name=symbol_by_name, imp=import_from_cwd):\n             try:\n                 found = sym.celery\n                 if isinstance(found, ModuleType):\n-                    raise AttributeError()\n+                    raise AttributeError(\"attribute 'celery' is the celery module not the instance of celery\")\n             except AttributeError:\n                 if getattr(sym, '__path__', None):\n                     try:"
    },
    {
        "commit_id": "ddca6351a06cc58c63354a32159c9d816552380f",
        "commit_message": "Correcting Attribute Name for Task Name (#5752)\n\n* Correcting Attribute Name for Task Name\r\n\r\nAs per Celery issue #5714, the attribute name is incorrect, resulting in \r\n`None` being stored in place of the task name.\r\n\r\n* Adjusting Context to Match Actual Values",
        "commit_url": "https://github.com/celery/celery/commit/ddca6351a06cc58c63354a32159c9d816552380f",
        "buggy_code": "task.name = getattr(request, 'task_name', None)",
        "fixed_code": "task.name = getattr(request, 'task', None)",
        "patch": "@@ -132,7 +132,7 @@ def _update_result(self, task, result, state, traceback=None,\n         task.status = state\n         task.traceback = traceback\n         if self.app.conf.find_value_for_key('extended', 'result'):\n-            task.name = getattr(request, 'task_name', None)\n+            task.name = getattr(request, 'task', None)\n             task.args = ensure_bytes(\n                 self.encode(getattr(request, 'args', None))\n             )"
    },
    {
        "commit_id": "ddca6351a06cc58c63354a32159c9d816552380f",
        "commit_message": "Correcting Attribute Name for Task Name (#5752)\n\n* Correcting Attribute Name for Task Name\r\n\r\nAs per Celery issue #5714, the attribute name is incorrect, resulting in \r\n`None` being stored in place of the task name.\r\n\r\n* Adjusting Context to Match Actual Values",
        "commit_url": "https://github.com/celery/celery/commit/ddca6351a06cc58c63354a32159c9d816552380f",
        "buggy_code": "task_name='mytask', retries=2,",
        "fixed_code": "task='mytask', retries=2,",
        "patch": "@@ -231,7 +231,7 @@ def test_store_result(self, result_serializer, args, kwargs):\n         tid = uuid()\n \n         request = Context(args=args, kwargs=kwargs,\n-                          task_name='mytask', retries=2,\n+                          task='mytask', retries=2,\n                           hostname='celery@worker_1',\n                           delivery_info={'routing_key': 'celery'})\n "
    },
    {
        "commit_id": "51d38a67cd5f7178dba798eba0df1d4b9d987cf5",
        "commit_message": "Fixes #5106: Retry WorkerLostError fix for canvas (#5700)\n\n* 5106 fixes tasks that are requeued, by not marking them as failed\r\n\r\n* Removed unused import\r\n\r\n* #5106 added unit test",
        "commit_url": "https://github.com/celery/celery/commit/51d38a67cd5f7178dba798eba0df1d4b9d987cf5",
        "buggy_code": "from case import Mock, call, patch, skip, MagicMock",
        "fixed_code": "from case import Mock, call, patch, skip",
        "patch": "@@ -7,7 +7,7 @@\n \n import pytest\n \n-from case import Mock, call, patch, skip, MagicMock\n+from case import Mock, call, patch, skip\n from celery import states, uuid\n from celery.app.task import Context\n from celery.backends.base import SyncBackendMixin"
    },
    {
        "commit_id": "f5c493dc71e7b75ef0a407927a7e0ce03c5d76fc",
        "commit_message": "Fixed a bug where canvases with a group and tasks in the middle followed by a group fails to complete and indefinitely hangs. (#5681)\n\nFixes #5512, fixes #5354, fixes #2573.",
        "commit_url": "https://github.com/celery/celery/commit/f5c493dc71e7b75ef0a407927a7e0ce03c5d76fc",
        "buggy_code": "\"\"\"Sum an iterable of numbers\"\"\"",
        "fixed_code": "\"\"\"Sum an iterable of numbers.\"\"\"",
        "patch": "@@ -68,7 +68,7 @@ def delayed_sum_with_soft_guard(numbers, pause_time=1):\n \n @shared_task\n def tsum(nums):\n-    \"\"\"Sum an iterable of numbers\"\"\"\n+    \"\"\"Sum an iterable of numbers.\"\"\"\n     return sum(nums)\n \n "
    },
    {
        "commit_id": "98ca22e1b4817f9470db27fa8ef0dc0f16add143",
        "commit_message": "Fix migrate task to work with both v1 and v2 of the message protocol (#5110)\n\n* Fix migrate task to work with both version 1 and 2 of the message protocol",
        "commit_url": "https://github.com/celery/celery/commit/98ca22e1b4817f9470db27fa8ef0dc0f16add143",
        "buggy_code": "return map.get(body['id'])",
        "fixed_code": "return map.get(message.properties['correlation_id'])",
        "patch": "@@ -382,7 +382,7 @@ def move_by_idmap(map, **kwargs):\n         ...   queues=['hipri'])\n     \"\"\"\n     def task_id_in_map(body, message):\n-        return map.get(body['id'])\n+        return map.get(message.properties['correlation_id'])\n \n     # adding the limit means that we don't have to consume any more\n     # when we've found everything."
    },
    {
        "commit_id": "a8b535bb8db0d2f232c5e88f4f62f4a9c54c31da",
        "commit_message": "Avoid serializing datetime (#5606)\n\n* Save date_done as iso string and parse it when retrieving.\r\n\r\n* Use None instead of empty string for date_done.\r\n\r\n* Test date_done is None if result is pending\r\n\r\n* Make AsyncResult.date_done handle both string/unicode and datetime objects\r\n\r\n* tests\r\n\r\n* date_done docstring, fix test requirements, flake8\r\n\r\n* pydocstyle fix\r\n\r\n* fix requirements - move requirements only needed by tests to test.txt",
        "commit_url": "https://github.com/celery/celery/commit/a8b535bb8db0d2f232c5e88f4f62f4a9c54c31da",
        "buggy_code": "date_done = datetime.datetime.utcnow()",
        "fixed_code": "date_done = datetime.datetime.utcnow().isoformat()",
        "patch": "@@ -685,7 +685,7 @@ def _store_result(self, task_id, result, state,\n                       traceback=None, request=None, **kwargs):\n \n         if state in self.READY_STATES:\n-            date_done = datetime.datetime.utcnow()\n+            date_done = datetime.datetime.utcnow().isoformat()\n         else:\n             date_done = None\n "
    },
    {
        "commit_id": "a8b535bb8db0d2f232c5e88f4f62f4a9c54c31da",
        "commit_message": "Avoid serializing datetime (#5606)\n\n* Save date_done as iso string and parse it when retrieving.\r\n\r\n* Use None instead of empty string for date_done.\r\n\r\n* Test date_done is None if result is pending\r\n\r\n* Make AsyncResult.date_done handle both string/unicode and datetime objects\r\n\r\n* tests\r\n\r\n* date_done docstring, fix test requirements, flake8\r\n\r\n* pydocstyle fix\r\n\r\n* fix requirements - move requirements only needed by tests to test.txt",
        "commit_url": "https://github.com/celery/celery/commit/a8b535bb8db0d2f232c5e88f4f62f4a9c54c31da",
        "buggy_code": "'date_done': date_done.strftime('%Y-%m-%dT%H:%M:%SZ'),",
        "fixed_code": "'date_done': date_done,",
        "patch": "@@ -223,7 +223,7 @@ def _get_task_meta_for(self, task_id):\n             'task_id': task_id,\n             'status': status,\n             'result': self.decode(result),\n-            'date_done': date_done.strftime('%Y-%m-%dT%H:%M:%SZ'),\n+            'date_done': date_done,\n             'traceback': self.decode(traceback),\n             'children': self.decode(children),\n         })"
    },
    {
        "commit_id": "240ef1f64c8340bfffc31359f842ea4a6c8c493a",
        "commit_message": "Fix typo (#5601)\n\n* Fix typo\r\n\r\n* Revert function name to pre typo fixing 'next_ocurrance'\r\n\r\n* Revert function name to pre typo fixing 'next_ocurrance'",
        "commit_url": "https://github.com/celery/celery/commit/240ef1f64c8340bfffc31359f842ea4a6c8c493a",
        "buggy_code": "by :meth:`kombu.entitiy.Queue.from_dict`.",
        "fixed_code": "by :meth:`kombu.entity.Queue.from_dict`.",
        "patch": "@@ -305,7 +305,7 @@ def add_consumer(self, queue,\n                 command to, when empty broadcast to all workers.\n             routing_key (str): Optional routing key.\n             options (Dict): Additional options as supported\n-                by :meth:`kombu.entitiy.Queue.from_dict`.\n+                by :meth:`kombu.entity.Queue.from_dict`.\n \n         See Also:\n             :meth:`broadcast` for supported keyword arguments."
    },
    {
        "commit_id": "240ef1f64c8340bfffc31359f842ea4a6c8c493a",
        "commit_message": "Fix typo (#5601)\n\n* Fix typo\r\n\r\n* Revert function name to pre typo fixing 'next_ocurrance'\r\n\r\n* Revert function name to pre typo fixing 'next_ocurrance'",
        "commit_url": "https://github.com/celery/celery/commit/240ef1f64c8340bfffc31359f842ea4a6c8c493a",
        "buggy_code": "\"\"\"Decribes a Celery configuration option.\"\"\"",
        "fixed_code": "\"\"\"Describes a Celery configuration option.\"\"\"",
        "patch": "@@ -55,7 +55,7 @@ def old_ns(ns):\n \n @python_2_unicode_compatible\n class Option(object):\n-    \"\"\"Decribes a Celery configuration option.\"\"\"\n+    \"\"\"Describes a Celery configuration option.\"\"\"\n \n     alt = None\n     deprecate_by = None"
    },
    {
        "commit_id": "240ef1f64c8340bfffc31359f842ea4a6c8c493a",
        "commit_message": "Fix typo (#5601)\n\n* Fix typo\r\n\r\n* Revert function name to pre typo fixing 'next_ocurrance'\r\n\r\n* Revert function name to pre typo fixing 'next_ocurrance'",
        "commit_url": "https://github.com/celery/celery/commit/240ef1f64c8340bfffc31359f842ea4a6c8c493a",
        "buggy_code": "or a :class:`~kombu.entitiy.Queue` instance.",
        "fixed_code": "or a :class:`~kombu.entity.Queue` instance.",
        "patch": "@@ -182,7 +182,7 @@ def transform(value):\n     Note:\n         The predicate may also return a tuple of ``(exchange, routing_key)``\n         to specify the destination to where the task should be moved,\n-        or a :class:`~kombu.entitiy.Queue` instance.\n+        or a :class:`~kombu.entity.Queue` instance.\n         Any other true value means that the task will be moved to the\n         default exchange/routing_key.\n     \"\"\""
    },
    {
        "commit_id": "240ef1f64c8340bfffc31359f842ea4a6c8c493a",
        "commit_message": "Fix typo (#5601)\n\n* Fix typo\r\n\r\n* Revert function name to pre typo fixing 'next_ocurrance'\r\n\r\n* Revert function name to pre typo fixing 'next_ocurrance'",
        "commit_url": "https://github.com/celery/celery/commit/240ef1f64c8340bfffc31359f842ea4a6c8c493a",
        "buggy_code": "Hostname to bind to.  Default is '127.0.0.1' (only accessable from",
        "fixed_code": "Hostname to bind to.  Default is '127.0.0.1' (only accessible from",
        "patch": "@@ -29,7 +29,7 @@ def add(x, y):\n ``CELERY_RDB_HOST``\n -------------------\n \n-    Hostname to bind to.  Default is '127.0.0.1' (only accessable from\n+    Hostname to bind to.  Default is '127.0.0.1' (only accessible from\n     localhost).\n \n .. envvar:: CELERY_RDB_PORT"
    },
    {
        "commit_id": "240ef1f64c8340bfffc31359f842ea4a6c8c493a",
        "commit_message": "Fix typo (#5601)\n\n* Fix typo\r\n\r\n* Revert function name to pre typo fixing 'next_ocurrance'\r\n\r\n* Revert function name to pre typo fixing 'next_ocurrance'",
        "commit_url": "https://github.com/celery/celery/commit/240ef1f64c8340bfffc31359f842ea4a6c8c493a",
        "buggy_code": "conn (kombu.Connection): Connection used for sending/receving events.",
        "fixed_code": "conn (kombu.Connection): Connection used for sending/receiving events.",
        "patch": "@@ -49,7 +49,7 @@ def get_exchange(conn, name=EVENT_EXCHANGE_NAME):\n     \"\"\"Get exchange used for sending events.\n \n     Arguments:\n-        conn (kombu.Connection): Connection used for sending/receving events.\n+        conn (kombu.Connection): Connection used for sending/receiving events.\n         name (str): Name of the exchange. Default is ``celeryev``.\n \n     Note:"
    },
    {
        "commit_id": "8cf8fae70630954cff3448485588bbe2a77ff3ab",
        "commit_message": "Make CI GREEN (#5600)\n\n* Fix some tests\r\n\r\n* Do linting first\r\n\r\n* Fix beat.py linting\r\n\r\n* Fix flake8\r\n\r\n* Revert to linting after tests",
        "commit_url": "https://github.com/celery/celery/commit/8cf8fae70630954cff3448485588bbe2a77ff3ab",
        "buggy_code": "fdmax = patching('celery.platforms.get_fdmax')",
        "fixed_code": "fdmax = patching('billiard.compat.get_fdmax')",
        "patch": "@@ -60,7 +60,7 @@ def test_fd_by_path():\n \n def test_close_open_fds(patching):\n     _close = patching('os.close')\n-    fdmax = patching('celery.platforms.get_fdmax')\n+    fdmax = patching('billiard.compat.get_fdmax')\n     with patch('os.closerange', create=True) as closerange:\n         fdmax.return_value = 3\n         close_open_fds()"
    },
    {
        "commit_id": "3078fc0394772c2d4f75adc23f1d5211d62dff10",
        "commit_message": "Fix Chain Exceptions propagations (#5587)\n\n* Add missing underscore on on_interval\r\n\r\n* Add test\r\n\r\n* Be explicit\r\n\r\n* Fix tests",
        "commit_url": "https://github.com/celery/celery/commit/3078fc0394772c2d4f75adc23f1d5211d62dff10",
        "buggy_code": "on_interval = promise(self._maybe_reraise_parent_error, weak=True)",
        "fixed_code": "_on_interval = promise(self._maybe_reraise_parent_error, weak=True)",
        "patch": "@@ -205,7 +205,7 @@ def get(self, timeout=None, propagate=True, interval=0.5,\n             assert_will_not_block()\n         _on_interval = promise()\n         if follow_parents and propagate and self.parent:\n-            on_interval = promise(self._maybe_reraise_parent_error, weak=True)\n+            _on_interval = promise(self._maybe_reraise_parent_error, weak=True)\n             self._maybe_reraise_parent_error()\n         if on_interval:\n             _on_interval.then(on_interval)"
    },
    {
        "commit_id": "713a2f1281c4fb5693beee144e7813bc473649b1",
        "commit_message": "Fix mogodb backend authentication and add unittests (#5527)",
        "commit_url": "https://github.com/celery/celery/commit/713a2f1281c4fb5693beee144e7813bc473649b1",
        "buggy_code": "MONGODB_USER, MONGODB_PASSWORD)",
        "fixed_code": "MONGODB_USER, MONGODB_PASSWORD, source=self.backend.database_name)",
        "patch": "@@ -235,7 +235,7 @@ def test_get_database_no_existing(self, mock_get_connection):\n         assert database is mock_database\n         assert self.backend.__dict__['database'] is mock_database\n         mock_database.authenticate.assert_called_once_with(\n-            MONGODB_USER, MONGODB_PASSWORD)\n+            MONGODB_USER, MONGODB_PASSWORD, source=self.backend.database_name)\n \n     @patch('celery.backends.mongodb.MongoBackend._get_connection')\n     def test_get_database_no_existing_no_auth(self, mock_get_connection):"
    },
    {
        "commit_id": "6514fed13ef2f992b2846116f9b2d1237aac8298",
        "commit_message": "Fix pytest deprecation warning.",
        "commit_url": "https://github.com/celery/celery/commit/6514fed13ef2f992b2846116f9b2d1237aac8298",
        "buggy_code": "message=\"Test depends on current_app\"):",
        "fixed_code": "match=\"Test depends on current_app\"):",
        "patch": "@@ -759,7 +759,7 @@ def test_restore_current_app_fallback(self):\n         ts = self.app.GroupResult(uuid(), subs)\n         ts.save()\n         with pytest.raises(RuntimeError,\n-                           message=\"Test depends on current_app\"):\n+                           match=\"Test depends on current_app\"):\n             GroupResult.restore(ts.id)\n \n     def test_join_native(self):"
    },
    {
        "commit_id": "b17278ab18987e512ef78d401529f13a12a0fc07",
        "commit_message": "Attribute Error should be caught when celery fails to find the correct exception (#5435)\n\nadding simple unit test",
        "commit_url": "https://github.com/celery/celery/commit/b17278ab18987e512ef78d401529f13a12a0fc07",
        "buggy_code": "except KeyError:",
        "fixed_code": "except (KeyError, AttributeError):",
        "patch": "@@ -274,7 +274,7 @@ def exception_to_python(self, exc):\n                     exc_type = from_utf8(exc['exc_type'])\n                     try:\n                         cls = getattr(sys.modules[exc_module], exc_type)\n-                    except KeyError:\n+                    except (KeyError, AttributeError):\n                         cls = create_exception_cls(exc_type,\n                                                    celery.exceptions.__name__)\n                 exc_msg = exc['exc_message']"
    },
    {
        "commit_id": "e257646136e6fae73186d7385317f4e20cd36130",
        "commit_message": "Fix call to list.prepend to use list.insert (#5356)",
        "commit_url": "https://github.com/celery/celery/commit/e257646136e6fae73186d7385317f4e20cd36130",
        "buggy_code": "sys.path.prepend(os.getcwd())",
        "fixed_code": "sys.path.insert(0, os.getcwd())",
        "patch": "@@ -60,7 +60,7 @@ def install(self):\n         # Need to add project directory to path.\n         # The project directory has precedence over system modules,\n         # so we prepend it to the path.\n-        sys.path.prepend(os.getcwd())\n+        sys.path.insert(0, os.getcwd())\n \n         self._settings = symbol_by_name('django.conf:settings')\n         self.app.loader.now = self.now"
    },
    {
        "commit_id": "e257646136e6fae73186d7385317f4e20cd36130",
        "commit_message": "Fix call to list.prepend to use list.insert (#5356)",
        "commit_url": "https://github.com/celery/celery/commit/e257646136e6fae73186d7385317f4e20cd36130",
        "buggy_code": "self.p.prepend.assert_called_with('/opt/vandelay')",
        "fixed_code": "self.p.insert.assert_called_with(0, '/opt/vandelay')",
        "patch": "@@ -91,7 +91,7 @@ def test_install(self, patching):\n             f.install()\n             self.sigs.worker_init.connect.assert_called_with(f.on_worker_init)\n             assert self.app.loader.now == f.now\n-            self.p.prepend.assert_called_with('/opt/vandelay')\n+            self.p.insert.assert_called_with(0, '/opt/vandelay')\n \n     def test_now(self):\n         with self.fixup_context(self.app) as (f, _, _):"
    },
    {
        "commit_id": "0736cff9d908c0519e07babe4de9c399c87cb32b",
        "commit_message": "WIP: 4.3 Release (#5331)\n\n* Initial effort for completing 4.3.\r\n\r\n* Fix documentation fixers list.\r\n\r\n* Added a note about riak not supported on Python 3.7.\r\n\r\n* Lot's of changelog...\r\n\r\n* Fix typo.\r\n\r\n* More changelog.\r\n\r\n* isort.\r\n\r\n* isort.\r\n\r\n* Added a note about likely drop of 3.4 support.\r\n\r\n* Rephrase Kombu section and mention billiard bump,\r\n\r\n* Mention fixes for several memory leaks.\r\n\r\n* Added categories. Minor fixes...\r\n\r\n* Fix style.\r\n\r\n* Fix styling.\r\n\r\n* Upgrade sphinx_celery.\r\n\r\n* Fix wrong usage of quotes.\r\n\r\n* Autopep8.\r\n\r\n* isort.\r\n\r\n* Updated changelog.\r\n\r\n* Elaborate.\r\n\r\n* Fix.\r\n\r\n* Elaborate.\r\n\r\n* More changelog.\r\n\r\n* Elaborate.\r\n\r\n* Elaborate.\r\n\r\n* Elaborate.\r\n\r\n* Elaborate.\r\n\r\n* Elaborate.\r\n\r\n* Elaborate.\r\n\r\n* Elaborate.\r\n\r\n* Fix warning.\r\n\r\n* Fix style.",
        "commit_url": "https://github.com/celery/celery/commit/0736cff9d908c0519e07babe4de9c399c87cb32b",
        "buggy_code": "SERIES = 'windowlicker'",
        "fixed_code": "SERIES = 'rhubarb'",
        "patch": "@@ -12,7 +12,7 @@\n import sys\n from collections import namedtuple\n \n-SERIES = 'windowlicker'\n+SERIES = 'rhubarb'\n \n __version__ = '4.2.0'\n __author__ = 'Ask Solem'"
    },
    {
        "commit_id": "0736cff9d908c0519e07babe4de9c399c87cb32b",
        "commit_message": "WIP: 4.3 Release (#5331)\n\n* Initial effort for completing 4.3.\r\n\r\n* Fix documentation fixers list.\r\n\r\n* Added a note about riak not supported on Python 3.7.\r\n\r\n* Lot's of changelog...\r\n\r\n* Fix typo.\r\n\r\n* More changelog.\r\n\r\n* isort.\r\n\r\n* isort.\r\n\r\n* Added a note about likely drop of 3.4 support.\r\n\r\n* Rephrase Kombu section and mention billiard bump,\r\n\r\n* Mention fixes for several memory leaks.\r\n\r\n* Added categories. Minor fixes...\r\n\r\n* Fix style.\r\n\r\n* Fix styling.\r\n\r\n* Upgrade sphinx_celery.\r\n\r\n* Fix wrong usage of quotes.\r\n\r\n* Autopep8.\r\n\r\n* isort.\r\n\r\n* Updated changelog.\r\n\r\n* Elaborate.\r\n\r\n* Fix.\r\n\r\n* Elaborate.\r\n\r\n* More changelog.\r\n\r\n* Elaborate.\r\n\r\n* Elaborate.\r\n\r\n* Elaborate.\r\n\r\n* Elaborate.\r\n\r\n* Elaborate.\r\n\r\n* Elaborate.\r\n\r\n* Elaborate.\r\n\r\n* Fix warning.\r\n\r\n* Fix style.",
        "commit_url": "https://github.com/celery/celery/commit/0736cff9d908c0519e07babe4de9c399c87cb32b",
        "buggy_code": "from .defaults import find_deprecated_settings, DEFAULT_SECURITY_DIGEST",
        "fixed_code": "from .defaults import DEFAULT_SECURITY_DIGEST, find_deprecated_settings",
        "patch": "@@ -42,7 +42,7 @@\n from . import builtins  # noqa\n from . import backends\n from .annotations import prepare as prepare_annotations\n-from .defaults import find_deprecated_settings, DEFAULT_SECURITY_DIGEST\n+from .defaults import DEFAULT_SECURITY_DIGEST, find_deprecated_settings\n from .registry import TaskRegistry\n from .utils import (AppPickler, Settings, _new_key_to_old, _old_key_to_new,\n                     _unpickle_app, _unpickle_app_v2, appstr, bugreport,"
    },
    {
        "commit_id": "0736cff9d908c0519e07babe4de9c399c87cb32b",
        "commit_message": "WIP: 4.3 Release (#5331)\n\n* Initial effort for completing 4.3.\r\n\r\n* Fix documentation fixers list.\r\n\r\n* Added a note about riak not supported on Python 3.7.\r\n\r\n* Lot's of changelog...\r\n\r\n* Fix typo.\r\n\r\n* More changelog.\r\n\r\n* isort.\r\n\r\n* isort.\r\n\r\n* Added a note about likely drop of 3.4 support.\r\n\r\n* Rephrase Kombu section and mention billiard bump,\r\n\r\n* Mention fixes for several memory leaks.\r\n\r\n* Added categories. Minor fixes...\r\n\r\n* Fix style.\r\n\r\n* Fix styling.\r\n\r\n* Upgrade sphinx_celery.\r\n\r\n* Fix wrong usage of quotes.\r\n\r\n* Autopep8.\r\n\r\n* isort.\r\n\r\n* Updated changelog.\r\n\r\n* Elaborate.\r\n\r\n* Fix.\r\n\r\n* Elaborate.\r\n\r\n* More changelog.\r\n\r\n* Elaborate.\r\n\r\n* Elaborate.\r\n\r\n* Elaborate.\r\n\r\n* Elaborate.\r\n\r\n* Elaborate.\r\n\r\n* Elaborate.\r\n\r\n* Elaborate.\r\n\r\n* Fix warning.\r\n\r\n* Fix style.",
        "commit_url": "https://github.com/celery/celery/commit/0736cff9d908c0519e07babe4de9c399c87cb32b",
        "buggy_code": "from kombu.exceptions import DecodeError, ContentDisallowed",
        "fixed_code": "from kombu.exceptions import ContentDisallowed, DecodeError",
        "patch": "@@ -16,7 +16,7 @@\n from billiard.common import restart_state\n from billiard.exceptions import RestartFreqExceeded\n from kombu.asynchronous.semaphore import DummyLock\n-from kombu.exceptions import DecodeError, ContentDisallowed\n+from kombu.exceptions import ContentDisallowed, DecodeError\n from kombu.utils.compat import _detect_environment\n from kombu.utils.encoding import bytes_t, safe_repr\n from kombu.utils.limits import TokenBucket"
    },
    {
        "commit_id": "0736cff9d908c0519e07babe4de9c399c87cb32b",
        "commit_message": "WIP: 4.3 Release (#5331)\n\n* Initial effort for completing 4.3.\r\n\r\n* Fix documentation fixers list.\r\n\r\n* Added a note about riak not supported on Python 3.7.\r\n\r\n* Lot's of changelog...\r\n\r\n* Fix typo.\r\n\r\n* More changelog.\r\n\r\n* isort.\r\n\r\n* isort.\r\n\r\n* Added a note about likely drop of 3.4 support.\r\n\r\n* Rephrase Kombu section and mention billiard bump,\r\n\r\n* Mention fixes for several memory leaks.\r\n\r\n* Added categories. Minor fixes...\r\n\r\n* Fix style.\r\n\r\n* Fix styling.\r\n\r\n* Upgrade sphinx_celery.\r\n\r\n* Fix wrong usage of quotes.\r\n\r\n* Autopep8.\r\n\r\n* isort.\r\n\r\n* Updated changelog.\r\n\r\n* Elaborate.\r\n\r\n* Fix.\r\n\r\n* Elaborate.\r\n\r\n* More changelog.\r\n\r\n* Elaborate.\r\n\r\n* Elaborate.\r\n\r\n* Elaborate.\r\n\r\n* Elaborate.\r\n\r\n* Elaborate.\r\n\r\n* Elaborate.\r\n\r\n* Elaborate.\r\n\r\n* Fix warning.\r\n\r\n* Fix style.",
        "commit_url": "https://github.com/celery/celery/commit/0736cff9d908c0519e07babe4de9c399c87cb32b",
        "buggy_code": "from kombu.exceptions import DecodeError, ContentDisallowed",
        "fixed_code": "from kombu.exceptions import ContentDisallowed, DecodeError",
        "patch": "@@ -8,7 +8,7 @@\n \n from kombu import Consumer\n from kombu.asynchronous.semaphore import DummyLock\n-from kombu.exceptions import DecodeError, ContentDisallowed\n+from kombu.exceptions import ContentDisallowed, DecodeError\n \n from celery import bootsteps\n from celery.five import values"
    },
    {
        "commit_id": "648738f26c6c80387f7fc409c52ba402236b049b",
        "commit_message": "attempt to make flake8 happy (#5323)\n\n* attempt to make flake8 happy\r\n\r\n* fix F632 use ==/!= to compare str, bytes, and int literals",
        "commit_url": "https://github.com/celery/celery/commit/648738f26c6c80387f7fc409c52ba402236b049b",
        "buggy_code": "assert x.get_leaf() is 2",
        "fixed_code": "assert x.get_leaf() == 2",
        "patch": "@@ -183,7 +183,7 @@ def test_build_graph_get_leaf_collect(self):\n         )\n         x.backend.READY_STATES = states.READY_STATES\n         assert x.graph\n-        assert x.get_leaf() is 2\n+        assert x.get_leaf() == 2\n \n         it = x.collect()\n         assert list(it) == ["
    },
    {
        "commit_id": "9b39fc41998c708c6612f0c7bf4393bf48f72e9b",
        "commit_message": "Improved message signing (fixed #5056) (#5091)\n\n* FIX: Check for sane security settings when using app.setup_security()\r\n\r\nfor celery/celery#5056\r\n\r\n* FIX: Catch ContentDisallowed Error to prevent worker from crashing\r\n\r\nfor celery/celery#5056\r\n\r\n* FIX: Deprecation Warning for pyOpenSSL Certificate verify expects bytes, not str\r\n\r\ncelery/celery/security/certificate.py:46: DeprecationWarning: str for data is no longer accepted, use bytes\r\n\r\n* FEATURE: Add Example Secure App\r\n\r\n* FEATURE: Update Configuration and Unittests\r\n\r\n* Default Security Digest is now sha256\r\n* Updated Unittests\r\n\r\n* FIX: reenable auth tests\r\n\r\n* FIX: Catch Decode and ContentDisallowed error for the gossip protocol\r\n\r\nfor celery/celery#5056\r\n\r\n* DOCS: Add some docs about security_digest\r\n\r\n* FIX: Remove security digest from example app\r\n\r\n* DOCS: rst reference for security_digest\r\n\r\n* FIX: repair failing test case\r\n\r\n* key and cert was an empty string ''\r\n* kill side effects of setup_security() by restore default serializer json (instead of auth)\r\n\r\n* FEATURE: add integration test for security\r\n\r\n* FEATURE: replace pyOpenSSL with cryptography\r\n\r\nfor celery/celery#5056\r\n\r\n* FIX: integration test generates own cert/keys\r\n\r\n* FIX: remove type hints because it only works for python3\r\n\r\n* FIX: enable extras/auth.txt for integration tests\r\n\r\n* CLEANUP: remove pyOpenSSL, add cryptography to requirements and restore original app exapmle\r\n\r\n* FIX: Restore bytes_if_py2 for security digest\r\n\r\nin python2.7, the openssl lib function\r\n`_lib.EVP_get_digestbyname(_byte_string(digest))`\r\nexpects a bytes not unicode.\r\n\r\n* FIX: Add extras/auth.txt to test-ci-base.txt for TOXENV=pypy-unit PYPY_VERSION=\"pypy2.7-6.0.0\"\r\n\r\n* FIX: security integration test now uses pytest fixtures\r\n\r\n* FIX: Update Example ssl cert location\r\n\r\n* DOC: Clarify bit shift 3\r\n\r\n* STYLE: flake, apicheck and pydocstyle\r\n\r\n* DOC: replace openssl in documentation with cryptography\r\n\r\n* Reduce offset calculations.\r\n\r\n* Fix off by sep_len.\r\n\r\n* Fix error.\r\n\r\n* TESTS: enable `result_accept_content` for security integration tests\r\n\r\nre-trigger travis\r\n\r\n* Mark as xfail for now.",
        "commit_url": "https://github.com/celery/celery/commit/9b39fc41998c708c6612f0c7bf4393bf48f72e9b",
        "buggy_code": "@skip.unless_module('OpenSSL.crypto', name='pyOpenSSL')",
        "fixed_code": "@skip.unless_module('cryptography')",
        "patch": "@@ -3,6 +3,6 @@\n from case import skip\n \n \n-@skip.unless_module('OpenSSL.crypto', name='pyOpenSSL')\n+@skip.unless_module('cryptography')\n class SecurityCase:\n     pass"
    },
    {
        "commit_id": "9b39fc41998c708c6612f0c7bf4393bf48f72e9b",
        "commit_message": "Improved message signing (fixed #5056) (#5091)\n\n* FIX: Check for sane security settings when using app.setup_security()\r\n\r\nfor celery/celery#5056\r\n\r\n* FIX: Catch ContentDisallowed Error to prevent worker from crashing\r\n\r\nfor celery/celery#5056\r\n\r\n* FIX: Deprecation Warning for pyOpenSSL Certificate verify expects bytes, not str\r\n\r\ncelery/celery/security/certificate.py:46: DeprecationWarning: str for data is no longer accepted, use bytes\r\n\r\n* FEATURE: Add Example Secure App\r\n\r\n* FEATURE: Update Configuration and Unittests\r\n\r\n* Default Security Digest is now sha256\r\n* Updated Unittests\r\n\r\n* FIX: reenable auth tests\r\n\r\n* FIX: Catch Decode and ContentDisallowed error for the gossip protocol\r\n\r\nfor celery/celery#5056\r\n\r\n* DOCS: Add some docs about security_digest\r\n\r\n* FIX: Remove security digest from example app\r\n\r\n* DOCS: rst reference for security_digest\r\n\r\n* FIX: repair failing test case\r\n\r\n* key and cert was an empty string ''\r\n* kill side effects of setup_security() by restore default serializer json (instead of auth)\r\n\r\n* FEATURE: add integration test for security\r\n\r\n* FEATURE: replace pyOpenSSL with cryptography\r\n\r\nfor celery/celery#5056\r\n\r\n* FIX: integration test generates own cert/keys\r\n\r\n* FIX: remove type hints because it only works for python3\r\n\r\n* FIX: enable extras/auth.txt for integration tests\r\n\r\n* CLEANUP: remove pyOpenSSL, add cryptography to requirements and restore original app exapmle\r\n\r\n* FIX: Restore bytes_if_py2 for security digest\r\n\r\nin python2.7, the openssl lib function\r\n`_lib.EVP_get_digestbyname(_byte_string(digest))`\r\nexpects a bytes not unicode.\r\n\r\n* FIX: Add extras/auth.txt to test-ci-base.txt for TOXENV=pypy-unit PYPY_VERSION=\"pypy2.7-6.0.0\"\r\n\r\n* FIX: security integration test now uses pytest fixtures\r\n\r\n* FIX: Update Example ssl cert location\r\n\r\n* DOC: Clarify bit shift 3\r\n\r\n* STYLE: flake, apicheck and pydocstyle\r\n\r\n* DOC: replace openssl in documentation with cryptography\r\n\r\n* Reduce offset calculations.\r\n\r\n* Fix off by sep_len.\r\n\r\n* Fix error.\r\n\r\n* TESTS: enable `result_accept_content` for security integration tests\r\n\r\nre-trigger travis\r\n\r\n* Mark as xfail for now.",
        "commit_url": "https://github.com/celery/celery/commit/9b39fc41998c708c6612f0c7bf4393bf48f72e9b",
        "buggy_code": "class test_SecureSerializer(SecurityCase):",
        "fixed_code": "class test_secureserializer(SecurityCase):",
        "patch": "@@ -16,7 +16,7 @@\n from .case import SecurityCase\n \n \n-class test_SecureSerializer(SecurityCase):\n+class test_secureserializer(SecurityCase):\n \n     def _get_s(self, key, cert, certs):\n         store = CertStore()"
    },
    {
        "commit_id": "443875f2162368435e15112a2664ca6567db070b",
        "commit_message": "Fix typo. (#5167)",
        "commit_url": "https://github.com/celery/celery/commit/443875f2162368435e15112a2664ca6567db070b",
        "buggy_code": "Hostname to bind to.  Default is '127.0.01' (only accessable from",
        "fixed_code": "Hostname to bind to.  Default is '127.0.0.1' (only accessable from",
        "patch": "@@ -29,7 +29,7 @@ def add(x, y):\n ``CELERY_RDB_HOST``\n -------------------\n \n-    Hostname to bind to.  Default is '127.0.01' (only accessable from\n+    Hostname to bind to.  Default is '127.0.0.1' (only accessable from\n     localhost).\n \n .. envvar:: CELERY_RDB_PORT"
    },
    {
        "commit_id": "611e63ccc4b06addd41a634903a37b420a5765aa",
        "commit_message": "Fix flake8 due latest release (#5141)\n\n* Fix flake8 due latest release\r\n\r\n* Fix flake8 F841 unused variables",
        "commit_url": "https://github.com/celery/celery/commit/611e63ccc4b06addd41a634903a37b420a5765aa",
        "buggy_code": "except BaseException as exc:",
        "fixed_code": "except BaseException:",
        "patch": "@@ -394,7 +394,7 @@ def trace_task(uuid, args, kwargs, request=None):\n                         task_request, exc, uuid, RETRY, call_errbacks=False)\n                 except Exception as exc:\n                     I, R, state, retval = on_error(task_request, exc, uuid)\n-                except BaseException as exc:\n+                except BaseException:\n                     raise\n                 else:\n                     try:"
    },
    {
        "commit_id": "611e63ccc4b06addd41a634903a37b420a5765aa",
        "commit_message": "Fix flake8 due latest release (#5141)\n\n* Fix flake8 due latest release\r\n\r\n* Fix flake8 F841 unused variables",
        "commit_url": "https://github.com/celery/celery/commit/611e63ccc4b06addd41a634903a37b420a5765aa",
        "buggy_code": "except (AttributeError, KeyError) as exc:",
        "fixed_code": "except (AttributeError, KeyError):",
        "patch": "@@ -280,7 +280,7 @@ def onecmd(self, line):\n         self.counter = next(self.inc_counter)\n         try:\n             self.respond(self.dispatch(cmd, arg))\n-        except (AttributeError, KeyError) as exc:\n+        except (AttributeError, KeyError):\n             self.default(line)\n         except Exception as exc:  # pylint: disable=broad-except\n             self.say(exc)"
    },
    {
        "commit_id": "97fd3acac6515a9b783c73d9ab5575644a79449c",
        "commit_message": "Allow Extraction of Chord Results On Error (#4888)\n\n* Keep group ID in task results\r\n\r\n* Don't delete group results on error\r\n\r\n* Tolerant group persistance in result storage\r\n\r\nNot everything that gets passed here has a group attribute, and even\r\nRequest objects sometimes don't have the necessary data in their dict\r\n\r\n* Test using stored group ID to recover chord result\r\n\r\n* Accept all args to chord error callback\r\n\r\n* isort-check fix for chord error handling test\r\n\r\n* Fix test_chord_on_error fail in full integration\r\n\r\npropagate=False stops working?\r\n\r\n* Require redis for chord error handling test\r\n\r\n* Explain test structure more\r\n\r\n* Test storage of group_id in result meta",
        "commit_url": "https://github.com/celery/celery/commit/97fd3acac6515a9b783c73d9ab5575644a79449c",
        "buggy_code": "return self.request_dict['group']",
        "fixed_code": "return self.request_dict.get('group')",
        "patch": "@@ -498,7 +498,7 @@ def errbacks(self):\n     def group(self):\n         # used by backend.on_chord_part_return when failures reported\n         # by parent process\n-        return self.request_dict['group']\n+        return self.request_dict.get('group')\n \n \n def create_request_cls(base, task, pool, hostname, eventer,"
    },
    {
        "commit_id": "845df9b88c1e5d70f098ecc20a1b7e8835bb832c",
        "commit_message": "Fix minor typo in multi.py (#4889)",
        "commit_url": "https://github.com/celery/celery/commit/845df9b88c1e5d70f098ecc20a1b7e8835bb832c",
        "buggy_code": "--logfile=/var/run/celery/%n%I.log",
        "fixed_code": "--logfile=/var/log/celery/%n%I.log",
        "patch": "@@ -22,7 +22,7 @@\n     $ # You need to add the same arguments when you restart,\n     $ # as these aren't persisted anywhere.\n     $ celery multi restart Leslie -E --pidfile=/var/run/celery/%n.pid\n-                                     --logfile=/var/run/celery/%n%I.log\n+                                     --logfile=/var/log/celery/%n%I.log\n \n     $ # To stop the node, you need to specify the same pidfile.\n     $ celery multi stop Leslie --pidfile=/var/run/celery/%n.pid"
    },
    {
        "commit_id": "c0947b3a7ddcccb3d4c1d813fcbde180408ba228",
        "commit_message": "Fix crontab documentation (#4880)\n\n* Fix rst border alignment\r\n\r\nA misaligned pipe character on the crontab examples table meant that the\r\nentire table was not being rendered on the documentation.\r\n\r\n* Fixes #4020 Update crontab pattern",
        "commit_url": "https://github.com/celery/celery/commit/c0947b3a7ddcccb3d4c1d813fcbde180408ba228",
        "buggy_code": "advanced, such as ``day_of_month='2-30/3'`` (for every even",
        "fixed_code": "advanced, such as ``day_of_month='2-30/2'`` (for every even",
        "patch": "@@ -361,7 +361,7 @@ class crontab(BaseSchedule):\n         - A (list of) integers from 1-31 that represents the days of the\n           month that execution should occur.\n         - A string representing a Crontab pattern.  This may get pretty\n-          advanced, such as ``day_of_month='2-30/3'`` (for every even\n+          advanced, such as ``day_of_month='2-30/2'`` (for every even\n           numbered day) or ``day_of_month='1-7,15-21'`` (for the first and\n           third weeks of the month).\n "
    },
    {
        "commit_id": "47ca2b462f22a8d48ed8d80c2f9bf8b9dc4a4de6",
        "commit_message": "Fix hybrid_to_proto2 with missing timelimit (#4850)\n\n* Fix hybrid_to_proto2 with missing timelimit\r\n\r\nIf `timelimit` is not defined in `body`, it will default to `None` value. Which will cause result in a crash here:\r\nhttps://github.com/celery/celery/blob/master/celery/worker/request.py#L188 (`'NoneType' object is not iterable`).\r\n\r\nDefaulting to `(None, None)` instead should fix it.\r\n\r\n* add testcase\r\n\r\n* flake8 and isort",
        "commit_url": "https://github.com/celery/celery/commit/47ca2b462f22a8d48ed8d80c2f9bf8b9dc4a4de6",
        "buggy_code": "'timelimit': body.get('timelimit'),",
        "fixed_code": "'timelimit': body.get('timelimit', (None, None)),",
        "patch": "@@ -48,7 +48,7 @@ def hybrid_to_proto2(message, body):\n         'eta': body.get('eta'),\n         'expires': body.get('expires'),\n         'retries': body.get('retries'),\n-        'timelimit': body.get('timelimit'),\n+        'timelimit': body.get('timelimit', (None, None)),\n         'argsrepr': body.get('argsrepr'),\n         'kwargsrepr': body.get('kwargsrepr'),\n         'origin': body.get('origin'),"
    },
    {
        "commit_id": "eeda18611ceed2560145f95ada4977a1b825d282",
        "commit_message": "Minor documentation tweaks for broken links (#4770)\n\n* Minor doc tweaks to broken links\r\n\r\nSome internal documentation link references were broken. For example,\r\nthe `app` parameter in [celery.schedules documentation](http://docs.celeryproject.org/en/master/reference/celery.schedules.html#celery-schedules) links to ~@Celery,\r\nwhich in the browser attempts to open an email client. Alternatively,\r\nthe [tasks userguide](http://docs.celeryproject.org/en/master/userguide/tasks.html#automatic-retry-for-known-exceptions) was also suffering from a similar reference error,\r\nbut in this case, produces no hyperlink.\r\n\r\n* Update two more broken hyperlink instances\r\n\r\n* Internal `AsyncResult` argument parameter\r\n* `datetime` reference in celery.schedules nowfun\r\n  paramater description",
        "commit_url": "https://github.com/celery/celery/commit/eeda18611ceed2560145f95ada4977a1b825d282",
        "buggy_code": "result_cls (~@AsyncResult): Specify custom result class.",
        "fixed_code": "result_cls (AsyncResult): Specify custom result class.",
        "patch": "@@ -699,7 +699,7 @@ def send_task(self, name, args=None, kwargs=None, countdown=None,\n \n         Arguments:\n             name (str): Name of task to call (e.g., `\"tasks.add\"`).\n-            result_cls (~@AsyncResult): Specify custom result class.\n+            result_cls (AsyncResult): Specify custom result class.\n         \"\"\"\n         parent = have_parent = None\n         amqp = self.amqp"
    },
    {
        "commit_id": "eeda18611ceed2560145f95ada4977a1b825d282",
        "commit_message": "Minor documentation tweaks for broken links (#4770)\n\n* Minor doc tweaks to broken links\r\n\r\nSome internal documentation link references were broken. For example,\r\nthe `app` parameter in [celery.schedules documentation](http://docs.celeryproject.org/en/master/reference/celery.schedules.html#celery-schedules) links to ~@Celery,\r\nwhich in the browser attempts to open an email client. Alternatively,\r\nthe [tasks userguide](http://docs.celeryproject.org/en/master/userguide/tasks.html#automatic-retry-for-known-exceptions) was also suffering from a similar reference error,\r\nbut in this case, produces no hyperlink.\r\n\r\n* Update two more broken hyperlink instances\r\n\r\n* Internal `AsyncResult` argument parameter\r\n* `datetime` reference in celery.schedules nowfun\r\n  paramater description",
        "commit_url": "https://github.com/celery/celery/commit/eeda18611ceed2560145f95ada4977a1b825d282",
        "buggy_code": "app (~@Celery): The app to use.",
        "fixed_code": "app (Celery): The app to use.",
        "patch": "@@ -144,7 +144,7 @@ class Command(object):\n     \"\"\"Base class for command-line applications.\n \n     Arguments:\n-        app (~@Celery): The app to use.\n+        app (Celery): The app to use.\n         get_app (Callable): Fucntion returning the current app\n             when no app provided.\n     \"\"\""
    },
    {
        "commit_id": "ab1aac794cfd7c5c6e2e167939de836bc7ac37e2",
        "commit_message": "Fix typo (#4779)",
        "commit_url": "https://github.com/celery/celery/commit/ab1aac794cfd7c5c6e2e167939de836bc7ac37e2",
        "buggy_code": "or object.  Attributes may include any setings described in",
        "fixed_code": "or object.  Attributes may include any settings described in",
        "patch": "@@ -170,7 +170,7 @@ class Celery(object):\n         fixups (List[str]): List of fix-up plug-ins (e.g., see\n             :mod:`celery.fixups.django`).\n         config_source (Union[str, type]): Take configuration from a class,\n-            or object.  Attributes may include any setings described in\n+            or object.  Attributes may include any settings described in\n             the documentation.\n     \"\"\"\n "
    },
    {
        "commit_id": "022f447dd13af16f4407c557a737a0afee1e839a",
        "commit_message": "Fix gevent import (#4754)\n\n`GreenletExit` is not in `__all__` in greenlet.py which can not be imported by Python 3.6.",
        "commit_url": "https://github.com/celery/celery/commit/022f447dd13af16f4407c557a737a0afee1e839a",
        "buggy_code": "from gevent.greenlet import Greenlet, GreenletExit",
        "fixed_code": "from gevent import Greenlet, GreenletExit",
        "patch": "@@ -34,7 +34,7 @@ def apply_timeout(target, args=(), kwargs={}, callback=None,\n class Timer(_timer.Timer):\n \n     def __init__(self, *args, **kwargs):\n-        from gevent.greenlet import Greenlet, GreenletExit\n+        from gevent import Greenlet, GreenletExit\n \n         class _Greenlet(Greenlet):\n             cancel = Greenlet.kill"
    },
    {
        "commit_id": "c8ef7ad60b72a194654c58beb04a1d65cd0435ad",
        "commit_message": "Last remaining fix.",
        "commit_url": "https://github.com/celery/celery/commit/c8ef7ad60b72a194654c58beb04a1d65cd0435ad",
        "buggy_code": "self._conninfo.transport.implements.async and",
        "fixed_code": "self._conninfo.transport.implements.asynchronous and",
        "patch": "@@ -240,7 +240,7 @@ def signal_consumer_close(self):\n \n     def should_use_eventloop(self):\n         return (detect_environment() == 'default' and\n-                self._conninfo.transport.implements.async and\n+                self._conninfo.transport.implements.asynchronous and\n                 not self.app.IS_WINDOWS)\n \n     def stop(self, in_sighandler=False, exitcode=None):"
    },
    {
        "commit_id": "1a941f97ad9f19fe86c241072d21d1e3e6e19a73",
        "commit_message": "[WIP] import from asynchronous instead of async and fix python 3.7 compat issues (#4679)\n\n* imported from renamed asynchronous module of kombu\r\n\r\n* imported from renamed asynchronous module of kombu\r\n\r\n* imported from renamed asynchronous module of kombu in utils timer2\r\n\r\n* update minimum kombu version",
        "commit_url": "https://github.com/celery/celery/commit/1a941f97ad9f19fe86c241072d21d1e3e6e19a73",
        "buggy_code": "from kombu.async import ERR, WRITE",
        "fixed_code": "from kombu.asynchronous import ERR, WRITE",
        "patch": "@@ -34,7 +34,7 @@\n from billiard.compat import buf_t, isblocking, setblocking\n from billiard.pool import ACK, NACK, RUN, TERMINATE, WorkersJoined\n from billiard.queues import _SimpleQueue\n-from kombu.async import ERR, WRITE\n+from kombu.asynchronous import ERR, WRITE\n from kombu.serialization import pickle as _pickle\n from kombu.utils.eventio import SELECT_BAD_FD\n from kombu.utils.functional import fxrange"
    },
    {
        "commit_id": "1a941f97ad9f19fe86c241072d21d1e3e6e19a73",
        "commit_message": "[WIP] import from asynchronous instead of async and fix python 3.7 compat issues (#4679)\n\n* imported from renamed asynchronous module of kombu\r\n\r\n* imported from renamed asynchronous module of kombu\r\n\r\n* imported from renamed asynchronous module of kombu in utils timer2\r\n\r\n* update minimum kombu version",
        "commit_url": "https://github.com/celery/celery/commit/1a941f97ad9f19fe86c241072d21d1e3e6e19a73",
        "buggy_code": "from kombu.async import timer as _timer  # noqa",
        "fixed_code": "from kombu.asynchronous import timer as _timer  # noqa",
        "patch": "@@ -4,7 +4,7 @@\n \n import sys\n \n-from kombu.async import timer as _timer  # noqa\n+from kombu.asynchronous import timer as _timer  # noqa\n from kombu.five import monotonic\n \n from celery import signals  # noqa"
    },
    {
        "commit_id": "1a941f97ad9f19fe86c241072d21d1e3e6e19a73",
        "commit_message": "[WIP] import from asynchronous instead of async and fix python 3.7 compat issues (#4679)\n\n* imported from renamed asynchronous module of kombu\r\n\r\n* imported from renamed asynchronous module of kombu\r\n\r\n* imported from renamed asynchronous module of kombu in utils timer2\r\n\r\n* update minimum kombu version",
        "commit_url": "https://github.com/celery/celery/commit/1a941f97ad9f19fe86c241072d21d1e3e6e19a73",
        "buggy_code": "from kombu.async import timer as _timer",
        "fixed_code": "from kombu.asynchronous import timer as _timer",
        "patch": "@@ -2,7 +2,7 @@\n \"\"\"Gevent execution pool.\"\"\"\n from __future__ import absolute_import, unicode_literals\n \n-from kombu.async import timer as _timer\n+from kombu.asynchronous import timer as _timer\n from kombu.five import monotonic\n \n from . import base"
    },
    {
        "commit_id": "1a941f97ad9f19fe86c241072d21d1e3e6e19a73",
        "commit_message": "[WIP] import from asynchronous instead of async and fix python 3.7 compat issues (#4679)\n\n* imported from renamed asynchronous module of kombu\r\n\r\n* imported from renamed asynchronous module of kombu\r\n\r\n* imported from renamed asynchronous module of kombu in utils timer2\r\n\r\n* update minimum kombu version",
        "commit_url": "https://github.com/celery/celery/commit/1a941f97ad9f19fe86c241072d21d1e3e6e19a73",
        "buggy_code": "from kombu.async.semaphore import DummyLock",
        "fixed_code": "from kombu.asynchronous.semaphore import DummyLock",
        "patch": "@@ -14,7 +14,7 @@\n import threading\n from time import sleep\n \n-from kombu.async.semaphore import DummyLock\n+from kombu.asynchronous.semaphore import DummyLock\n \n from celery import bootsteps\n from celery.five import monotonic"
    },
    {
        "commit_id": "1a941f97ad9f19fe86c241072d21d1e3e6e19a73",
        "commit_message": "[WIP] import from asynchronous instead of async and fix python 3.7 compat issues (#4679)\n\n* imported from renamed asynchronous module of kombu\r\n\r\n* imported from renamed asynchronous module of kombu\r\n\r\n* imported from renamed asynchronous module of kombu in utils timer2\r\n\r\n* update minimum kombu version",
        "commit_url": "https://github.com/celery/celery/commit/1a941f97ad9f19fe86c241072d21d1e3e6e19a73",
        "buggy_code": "from kombu.async.semaphore import DummyLock",
        "fixed_code": "from kombu.asynchronous.semaphore import DummyLock",
        "patch": "@@ -15,7 +15,7 @@\n \n from billiard.common import restart_state\n from billiard.exceptions import RestartFreqExceeded\n-from kombu.async.semaphore import DummyLock\n+from kombu.asynchronous.semaphore import DummyLock\n from kombu.utils.compat import _detect_environment\n from kombu.utils.encoding import bytes_t, safe_repr\n from kombu.utils.limits import TokenBucket"
    },
    {
        "commit_id": "1a941f97ad9f19fe86c241072d21d1e3e6e19a73",
        "commit_message": "[WIP] import from asynchronous instead of async and fix python 3.7 compat issues (#4679)\n\n* imported from renamed asynchronous module of kombu\r\n\r\n* imported from renamed asynchronous module of kombu\r\n\r\n* imported from renamed asynchronous module of kombu in utils timer2\r\n\r\n* update minimum kombu version",
        "commit_url": "https://github.com/celery/celery/commit/1a941f97ad9f19fe86c241072d21d1e3e6e19a73",
        "buggy_code": "from kombu.async.semaphore import DummyLock",
        "fixed_code": "from kombu.asynchronous.semaphore import DummyLock",
        "patch": "@@ -7,7 +7,7 @@\n from operator import itemgetter\n \n from kombu import Consumer\n-from kombu.async.semaphore import DummyLock\n+from kombu.asynchronous.semaphore import DummyLock\n \n from celery import bootsteps\n from celery.five import values"
    },
    {
        "commit_id": "1a941f97ad9f19fe86c241072d21d1e3e6e19a73",
        "commit_message": "[WIP] import from asynchronous instead of async and fix python 3.7 compat issues (#4679)\n\n* imported from renamed asynchronous module of kombu\r\n\r\n* imported from renamed asynchronous module of kombu\r\n\r\n* imported from renamed asynchronous module of kombu in utils timer2\r\n\r\n* update minimum kombu version",
        "commit_url": "https://github.com/celery/celery/commit/1a941f97ad9f19fe86c241072d21d1e3e6e19a73",
        "buggy_code": "timer (kombu.async.timer.Timer): Timer to use.",
        "fixed_code": "timer (kombu.asynchronous.timer.Timer): Timer to use.",
        "patch": "@@ -18,7 +18,7 @@ class Heart(object):\n     \"\"\"Timer sending heartbeats at regular intervals.\n \n     Arguments:\n-        timer (kombu.async.timer.Timer): Timer to use.\n+        timer (kombu.asynchronous.timer.Timer): Timer to use.\n         eventer (celery.events.EventDispatcher): Event dispatcher\n             to use.\n         interval (float): Time in seconds between sending"
    },
    {
        "commit_id": "1a941f97ad9f19fe86c241072d21d1e3e6e19a73",
        "commit_message": "[WIP] import from asynchronous instead of async and fix python 3.7 compat issues (#4679)\n\n* imported from renamed asynchronous module of kombu\r\n\r\n* imported from renamed asynchronous module of kombu\r\n\r\n* imported from renamed asynchronous module of kombu in utils timer2\r\n\r\n* update minimum kombu version",
        "commit_url": "https://github.com/celery/celery/commit/1a941f97ad9f19fe86c241072d21d1e3e6e19a73",
        "buggy_code": "from kombu.async.timer import to_timestamp",
        "fixed_code": "from kombu.asynchronous.timer import to_timestamp",
        "patch": "@@ -4,7 +4,7 @@\n \n import logging\n \n-from kombu.async.timer import to_timestamp\n+from kombu.asynchronous.timer import to_timestamp\n from kombu.five import buffer_t\n \n from celery.exceptions import InvalidTaskError"
    },
    {
        "commit_id": "59d140082f8a826e84256df14610fcf1fba4c2a8",
        "commit_message": "Add docker-compose and base dockerfile for development (#4482)\n\n* Add docker-compose and base dockerfile for development\r\n\r\n* Change to base jessie docker image and setup pyenv\r\n\r\n* Add in aliases for pyenv, fix entrypoint for docker\r\n\r\n* Update dockerfile to be non-root and fix encoding problems with tox\r\n\r\n* Add convenience method to get redis connection for tests\r\n\r\n* Add pypy to install commands\r\n\r\n* Force worker to pick up broker url from environment\r\n\r\n* Move pypy comment to above apt-get install, default python to 3.6, add in flag to prevent bytecode\r\n\r\n* Add documentation\r\n\r\n* Fix links\r\n\r\n* Update docs\r\n\r\n* Add to contributors\r\n\r\n* Address feedback: improve documentation, separate dockerfile into scripts, remove redundancy in pyenv setup, add in .env file\r\n\r\n* Setup pyenv environments correctly in dockerfile\r\n\r\n* Update capitalization\r\n\r\n* Change CELERY_USER to ARG in dockerfile and pass build argument in build\r\n\r\n* Change default worker loglevel to debug in docker-compose",
        "commit_url": "https://github.com/celery/celery/commit/59d140082f8a826e84256df14610fcf1fba4c2a8",
        "buggy_code": "with app.connection() as conn:",
        "fixed_code": "with app.connection(hostname=os.environ.get('TEST_BROKER')) as conn:",
        "patch": "@@ -102,7 +102,7 @@ def _start_worker_thread(app,\n     setup_app_for_worker(app, loglevel, logfile)\n     assert 'celery.ping' in app.tasks\n     # Make sure we can connect to the broker\n-    with app.connection() as conn:\n+    with app.connection(hostname=os.environ.get('TEST_BROKER')) as conn:\n         conn.default_channel.queue_declare\n \n     worker = WorkController("
    },
    {
        "commit_id": "339dba04bbbbddce4a9b6a862ae79434d6a221c1",
        "commit_message": "Put back undoc-members option in sphinx test (#4586)\n\nThe test will fail without this due to the bug explained in #4584.",
        "commit_url": "https://github.com/celery/celery/commit/339dba04bbbbddce4a9b6a862ae79434d6a221c1",
        "buggy_code": "autodoc_default_flags = ['members']",
        "fixed_code": "autodoc_default_flags = ['members', 'undoc-members']",
        "patch": "@@ -4,7 +4,7 @@\n import sys\n \n extensions = ['celery.contrib.sphinx', 'sphinx.ext.autodoc']\n-autodoc_default_flags = ['members']\n+autodoc_default_flags = ['members', 'undoc-members']\n autosummary_generate = True\n \n sys.path.insert(0, os.path.abspath('.'))"
    },
    {
        "commit_id": "4c8efed81cb9f1058f8c710833b84adf12bcaac9",
        "commit_message": "Fix isort errors (#4504)",
        "commit_url": "https://github.com/celery/celery/commit/4c8efed81cb9f1058f8c710833b84adf12bcaac9",
        "buggy_code": "from .imports import qualname",
        "fixed_code": "from . imports import qualname",
        "patch": "@@ -54,7 +54,7 @@ def _inner(fun):\n \n         @wraps(fun)\n         def __inner(*args, **kwargs):\n-            from .imports import qualname\n+            from . imports import qualname\n             warn(description=description or qualname(fun),\n                  deprecation=deprecation,\n                  removal=removal,"
    },
    {
        "commit_id": "ebd98fa4d36bb8003c2f46dbd16e9888af13720f",
        "commit_message": "Parallel doc lints (#4435)\n\n* Bump sphinx.\r\n\r\n* Update copyright year. Mark the celerydocs & the celery.contrib.sphinx extensions as read_parallel_safe.\r\n\r\n* Install from git for now :(\r\n\r\n* Fix flake8 errors.",
        "commit_url": "https://github.com/celery/celery/commit/ebd98fa4d36bb8003c2f46dbd16e9888af13720f",
        "buggy_code": "copyright='2009-2016',",
        "fixed_code": "copyright='2009-2017',",
        "patch": "@@ -13,7 +13,7 @@\n     github_project='celery/celery',\n     author='Ask Solem & contributors',\n     author_name='Ask Solem',\n-    copyright='2009-2016',\n+    copyright='2009-2017',\n     publisher='Celery Project',\n     html_logo='images/celery_512.png',\n     html_favicon='images/favicon.ico',"
    },
    {
        "commit_id": "1d8b64ef0d094287a0ed7934f77aa93574913760",
        "commit_message": "fix(typo): Fix typo in documentation (#4365)",
        "commit_url": "https://github.com/celery/celery/commit/1d8b64ef0d094287a0ed7934f77aa93574913760",
        "buggy_code": "Then calling ``app.autodiscover_tasks(['foo', bar', 'baz'])`` will",
        "fixed_code": "Then calling ``app.autodiscover_tasks(['foo', 'bar', 'baz'])`` will",
        "patch": "@@ -656,7 +656,7 @@ def autodiscover_tasks(self, packages=None,\n             baz/__init__.py\n                 models.py\n \n-        Then calling ``app.autodiscover_tasks(['foo', bar', 'baz'])`` will\n+        Then calling ``app.autodiscover_tasks(['foo', 'bar', 'baz'])`` will\n         result in the modules ``foo.tasks`` and ``bar.tasks`` being imported.\n \n         Arguments:"
    },
    {
        "commit_id": "2f422c52bdd3dece65f05c1e7015b335e8bd0175",
        "commit_message": "Fix link in documentation\n\n`~@AsyncResult` results in `mailto:~@AsyncResult` link in the doc instead of a proper link to AsyncResult class\r\n\r\nhttp://docs.celeryproject.org/en/master/reference/celery.app.task.html?highlight=retry#celery.app.task.Task.apply_async",
        "commit_url": "https://github.com/celery/celery/commit/2f422c52bdd3dece65f05c1e7015b335e8bd0175",
        "buggy_code": "~@AsyncResult: Promise of future evaluation.",
        "fixed_code": "celery.result.AsyncResult: Promise of future evaluation.",
        "patch": "@@ -499,7 +499,7 @@ def apply_async(self, args=None, kwargs=None, task_id=None, producer=None,\n             headers (Dict): Message headers to be included in the message.\n \n         Returns:\n-            ~@AsyncResult: Promise of future evaluation.\n+            celery.result.AsyncResult: Promise of future evaluation.\n \n         Raises:\n             TypeError: If not enough arguments are passed, or too many"
    },
    {
        "commit_id": "6b6117faa2c733e400f68debd87d06dc73a3d47b",
        "commit_message": "Fix typo in retry docstring.",
        "commit_url": "https://github.com/celery/celery/commit/6b6117faa2c733e400f68debd87d06dc73a3d47b",
        "buggy_code": "eta (~datetime.dateime): Explicit time and date to run the",
        "fixed_code": "eta (~datetime.datetime): Explicit time and date to run the",
        "patch": "@@ -619,7 +619,7 @@ def retry(self, args=None, kwargs=None, exc=None, throw=True,\n                 If no exception was raised it will raise the ``exc``\n                 argument provided.\n             countdown (float): Time in seconds to delay the retry for.\n-            eta (~datetime.dateime): Explicit time and date to run the\n+            eta (~datetime.datetime): Explicit time and date to run the\n                 retry at.\n             max_retries (int): If set, overrides the default retry limit for\n                 this execution.  Changes to this parameter don't propagate to"
    },
    {
        "commit_id": "27a686fd3c2ded4f8d0eeefb3c725b8d775eb70c",
        "commit_message": "Beat: fixed entry._default_now() not used everywhere\n\nI'm using custom scheduler entries with an overridden ``is_due()`` method that do not require a schedule (``entry.schedule``) to be set. Judging from the ``entry._default_now()`` method, this seems to be supported by the scheduler in Celery 4.1.0, however that method is not used everywhere, leading to an AttributeError in my use case.\r\n\r\nThis change just uses ``_default_now()`` everywhere which fixes the issue. It shouldn't have any impact on the default implementation.",
        "commit_url": "https://github.com/celery/celery/commit/27a686fd3c2ded4f8d0eeefb3c725b8d775eb70c",
        "buggy_code": "return (mktime(entry.schedule.now().timetuple()) +",
        "fixed_code": "return (mktime(entry._default_now().timetuple()) +",
        "patch": "@@ -237,7 +237,7 @@ def is_due(self, entry):\n     def _when(self, entry, next_time_to_run, mktime=time.mktime):\n         adjust = self.adjust\n \n-        return (mktime(entry.schedule.now().timetuple()) +\n+        return (mktime(entry._default_now().timetuple()) +\n                 (adjust(next_time_to_run) or 0))\n \n     def populate_heap(self, event_t=event_t, heapify=heapq.heapify):"
    },
    {
        "commit_id": "5f2141af2edfb70333763476c78893fbfb8890cf",
        "commit_message": "Fix grammar typo in docstring",
        "commit_url": "https://github.com/celery/celery/commit/5f2141af2edfb70333763476c78893fbfb8890cf",
        "buggy_code": "\"\"\"List the task queues a worker are currently consuming from.\"\"\"",
        "fixed_code": "\"\"\"List the task queues a worker is currently consuming from.\"\"\"",
        "patch": "@@ -555,7 +555,7 @@ def cancel_consumer(state, queue, **_):\n \n @inspect_command()\n def active_queues(state):\n-    \"\"\"List the task queues a worker are currently consuming from.\"\"\"\n+    \"\"\"List the task queues a worker is currently consuming from.\"\"\"\n     if state.consumer.task_consumer:\n         return [dict(queue.as_dict(recurse=True))\n                 for queue in state.consumer.task_consumer.queues]"
    },
    {
        "commit_id": "cd89518cf2ef18aaf739eac06aaf28a2e3d0fffa",
        "commit_message": "Handle possibility there are no workers (#4074)\n\nFixes issue where an exception is raised if eg `celery graph workers` is invoked when there are no workers at all.",
        "commit_url": "https://github.com/celery/celery/commit/cd89518cf2ef18aaf739eac06aaf28a2e3d0fffa",
        "buggy_code": "replies = self.app.control.inspect().stats()",
        "fixed_code": "replies = self.app.control.inspect().stats() or {}",
        "patch": "@@ -161,7 +161,7 @@ def maybe_abbr(l, name, max=Wmax):\n             workers = args['nodes']\n             threads = args.get('threads') or []\n         except KeyError:\n-            replies = self.app.control.inspect().stats()\n+            replies = self.app.control.inspect().stats() or {}\n             workers, threads = [], []\n             for worker, reply in items(replies):\n                 workers.append(worker)"
    },
    {
        "commit_id": "c7b163a5601140fe1e1bd58d8868d11b903bdeab",
        "commit_message": "Fix grammar, update .gitignore (#3887)\n\n* gitignore: Ignore .eggs directory\r\n\r\n* docs: Fix typos/grammar",
        "commit_url": "https://github.com/celery/celery/commit/c7b163a5601140fe1e1bd58d8868d11b903bdeab",
        "buggy_code": "\"\"\"Represents a abortable result.",
        "fixed_code": "\"\"\"Represents an abortable result.",
        "patch": "@@ -107,7 +107,7 @@ def myview(request):\n \n \n class AbortableAsyncResult(AsyncResult):\n-    \"\"\"Represents a abortable result.\n+    \"\"\"Represents an abortable result.\n \n     Specifically, this gives the `AsyncResult` a :meth:`abort()` method,\n     that sets the state of the underlying Task to `'ABORTED'`."
    },
    {
        "commit_id": "f68b63c03d39bfe1d475f2411bad3b2aa6b03c63",
        "commit_message": "Fix typo from \"restart limit\" to \"retry limit\" (#3807)",
        "commit_url": "https://github.com/celery/celery/commit/f68b63c03d39bfe1d475f2411bad3b2aa6b03c63",
        "buggy_code": "exc (Exception): Custom exception to report when the max restart",
        "fixed_code": "exc (Exception): Custom exception to report when the max retry",
        "patch": "@@ -605,7 +605,7 @@ def retry(self, args=None, kwargs=None, exc=None, throw=True,\n         Arguments:\n             args (Tuple): Positional arguments to retry with.\n             kwargs (Dict): Keyword arguments to retry with.\n-            exc (Exception): Custom exception to report when the max restart\n+            exc (Exception): Custom exception to report when the max retry\n                 limit has been exceeded (default:\n                 :exc:`~@MaxRetriesExceededError`).\n "
    },
    {
        "commit_id": "9c950b47eca2b4e93fd2fe52cf80f158e6cf97ad",
        "commit_message": "AWS DynamoDB result backend (#3736)\n\n* Add result backend for AWS DynamoDB\r\n\r\n* Dependencies for DynamoDB result backend\r\n\r\n* Add DynamoDB backend in aliases\r\n\r\n* Test cases for DynamoDB result backend\r\n\r\n* Documentation for DynamoDB backend\r\n\r\n* Configurable endpoint URL for DynamoDB local instance\r\n\r\n* Enable integration tests for DynamoDB result backend\r\n\r\n- Run before_install script only for integration environments\r\n\r\n* Fix invalid type error for primary key in Python3\r\n\r\n* Add Python 3.6 in Travis CI build matrix\r\n\r\n- Instruct Travis CI to include Python 3.6 interpreter in jobs\r\n- Optimize Travis CI build matrix\r\n\r\n* Optimize Travis CI build matrix\r\n\r\n* Fix endless loop in logger_isa (Python 3.6)\r\n\r\n* Add test cases for AWS client construction\r\n\r\n- Add/improve log messages during table initialization\r\n- Enable skipped unit tests due to missing dependency boto3\r\n\r\n* Use explicit hash seed value for apicheck tox environment\r\n\r\n- Related Sphinx issue: https://github.com/sphinx-doc/sphinx/issues/2324",
        "commit_url": "https://github.com/celery/celery/commit/9c950b47eca2b4e93fd2fe52cf80f158e6cf97ad",
        "buggy_code": "'Logger {0!r} parents recursive'.format(l),",
        "fixed_code": "'Logger {0!r} parents recursive'.format(l.name),",
        "patch": "@@ -82,7 +82,7 @@ def logger_isa(l, p, max=1000):\n         else:\n             if this in seen:\n                 raise RuntimeError(\n-                    'Logger {0!r} parents recursive'.format(l),\n+                    'Logger {0!r} parents recursive'.format(l.name),\n                 )\n             seen.add(this)\n             this = this.parent"
    },
    {
        "commit_id": "9d2566e9c0764ab7467db47610ccb3ee5f4303ff",
        "commit_message": "Fix #3726 - Chaining of replaced tasks (#3730)\n\n* Add add_replaced test task\r\n\r\n* Make test_complex_chain fail by adding a replaced task\r\n\r\n- Update expected output\r\n\r\n* Copy replaced task's request chain in reverse\r\n\r\n- Make t/integration/test_canvas.py::test_chain::test_complex_chain pass",
        "commit_url": "https://github.com/celery/celery/commit/9d2566e9c0764ab7467db47610ccb3ee5f4303ff",
        "buggy_code": "for t in self.request.chain:",
        "fixed_code": "for t in reversed(self.request.chain):",
        "patch": "@@ -850,7 +850,7 @@ def replace(self, sig):\n             chord = None\n \n         if self.request.chain:\n-            for t in self.request.chain:\n+            for t in reversed(self.request.chain):\n                 sig |= signature(t, app=self.app)\n \n         sig.freeze(self.request.id,"
    },
    {
        "commit_id": "1992cb07f1d4de44ab80ff7ee8ab93614517d7ae",
        "commit_message": "fix #3678 (#3693)",
        "commit_url": "https://github.com/celery/celery/commit/1992cb07f1d4de44ab80ff7ee8ab93614517d7ae",
        "buggy_code": "fun = ('def f(foo, *args, bar=\"\"):'",
        "fixed_code": "fun = ('def f(foo, *args, bar=\"\", **kwargs):'",
        "patch": "@@ -165,7 +165,7 @@ def f(x, y, kwarg=1):\n     @skip.unless_python3()\n     def test_regression_3678(self):\n         local = {}\n-        fun = ('def f(foo, *args, bar=\"\"):'\n+        fun = ('def f(foo, *args, bar=\"\", **kwargs):'\n                '    return foo, args, bar')\n         exec(fun, {}, local)\n "
    },
    {
        "commit_id": "0697b5ec4879c9bea03d94512dfa069fa2b69e86",
        "commit_message": "fix typo (#3717)",
        "commit_url": "https://github.com/celery/celery/commit/0697b5ec4879c9bea03d94512dfa069fa2b69e86",
        "buggy_code": "\"\"\"Return true if any of the tasks are incomplate.",
        "fixed_code": "\"\"\"Return true if any of the tasks are incomplete.",
        "patch": "@@ -535,7 +535,7 @@ def maybe_throw(self, callback=None, propagate=True):\n     maybe_reraise = maybe_throw  # XXX compat alias.\n \n     def waiting(self):\n-        \"\"\"Return true if any of the tasks are incomplate.\n+        \"\"\"Return true if any of the tasks are incomplete.\n \n         Returns:\n             bool: true if one of the tasks are still"
    },
    {
        "commit_id": "ad78f7317c502436e00a1d1922117d5983f007c2",
        "commit_message": "Stop generate a new field every time when a new result is being put (#3708)\n\n* stop generate a new field every time when a new result is being put\r\n\r\nThe current elasticsearch backend generate a new field every time\r\na new result is being put. This is really inefficient for elasticsearch.\r\n\r\nSwitch to use the same field every time since the key is already stored in\r\nelasticsearch's _id field.\r\n\r\n* fix test cases for elasticsearch backend",
        "commit_url": "https://github.com/celery/celery/commit/ad78f7317c502436e00a1d1922117d5983f007c2",
        "buggy_code": "r = dict(found=True, _source={sentinel.task_id: sentinel.result})",
        "fixed_code": "r = dict(found=True, _source={'result': sentinel.result})",
        "patch": "@@ -26,7 +26,7 @@ def test_get(self):\n         x._server = Mock()\n         x._server.get = Mock()\n         # expected result\n-        r = dict(found=True, _source={sentinel.task_id: sentinel.result})\n+        r = dict(found=True, _source={'result': sentinel.result})\n         x._server.get.return_value = r\n         dict_result = x.get(sentinel.task_id)\n "
    },
    {
        "commit_id": "bacb387e8aa7cb2ef782b3f0292d3263ea722932",
        "commit_message": "Fix app import from celery.py in proj tasks examples (#3671)",
        "commit_url": "https://github.com/celery/celery/commit/bacb387e8aa7cb2ef782b3f0292d3263ea722932",
        "buggy_code": "from . import app",
        "fixed_code": "from .celery import app",
        "patch": "@@ -1,5 +1,5 @@\n from __future__ import absolute_import, unicode_literals\n-from . import app\n+from .celery import app\n \n \n @app.task"
    },
    {
        "commit_id": "195a33ef0d3e78d1c92c628162204de42f8d4dca",
        "commit_message": "Fix app import from celery.py in proj tasks examples (#3671)",
        "commit_url": "https://github.com/celery/celery/commit/195a33ef0d3e78d1c92c628162204de42f8d4dca",
        "buggy_code": "from . import app",
        "fixed_code": "from .celery import app",
        "patch": "@@ -1,5 +1,5 @@\n from __future__ import absolute_import, unicode_literals\n-from . import app\n+from .celery import app\n \n \n @app.task"
    },
    {
        "commit_id": "fe2c47d4e62c36d3b78b57ad41518fbf6748a708",
        "commit_message": "Fix ValueError in chord with single task header (#3608)",
        "commit_url": "https://github.com/celery/celery/commit/fe2c47d4e62c36d3b78b57ad41518fbf6748a708",
        "buggy_code": "return (self.tasks[0].set(task_id=task_id) | body).apply_async(",
        "fixed_code": "return (self.tasks[0] | body).set(task_id=task_id).apply_async(",
        "patch": "@@ -1242,7 +1242,7 @@ def apply_async(self, args=(), kwargs={}, task_id=None,\n         if len(self.tasks) == 1:\n             # chord([A], B) can be optimized as A | B\n             # - Issue #3323\n-            return (self.tasks[0].set(task_id=task_id) | body).apply_async(\n+            return (self.tasks[0] | body).set(task_id=task_id).apply_async(\n                 args, kwargs, **options)\n         # chord([A, B, ...], C)\n         return self.run(tasks, body, args, task_id=task_id, **options)"
    },
    {
        "commit_id": "86e7eed314a167ec0f2fa377f36f0f373a334d77",
        "commit_message": "Soft time limit error showed Trues instead of the timeout in seconds",
        "commit_url": "https://github.com/celery/celery/commit/86e7eed314a167ec0f2fa377f36f0f373a334d77",
        "buggy_code": "soft, self.name, self.id)",
        "fixed_code": "timeout, self.name, self.id)",
        "patch": "@@ -303,7 +303,7 @@ def on_timeout(self, soft, timeout):\n         task_ready(self)\n         if soft:\n             warn('Soft time limit (%ss) exceeded for %s[%s]',\n-                 soft, self.name, self.id)\n+                 timeout, self.name, self.id)\n             exc = SoftTimeLimitExceeded(soft)\n         else:\n             error('Hard time limit (%ss) exceeded for %s[%s]',"
    },
    {
        "commit_id": "0f87321df385c5f3dca717ec2a4a9c0d25f88054",
        "commit_message": "Fix pypy3 build failure",
        "commit_url": "https://github.com/celery/celery/commit/0f87321df385c5f3dca717ec2a4a9c0d25f88054",
        "buggy_code": "if IS_PY3:",
        "fixed_code": "if hasattr(inspect, 'signature'):",
        "patch": "@@ -284,7 +284,7 @@ def fun_takes_argument(name, fun, position=None):\n     )\n \n \n-if IS_PY3:\n+if hasattr(inspect, 'signature'):\n     def fun_accepts_kwargs(fun):\n         \"\"\"Return true if function accepts arbitrary keyword arguments.\"\"\"\n         return any("
    },
    {
        "commit_id": "4c4f5d8dd07b71b1348bfe618281885fe7da9fbd",
        "commit_message": "Chord counter to use result_expires and is touched (#3573)\n\nChord counter keeps track of chord tasks that have finished. This needs\r\nto be compatible with result_expires so that if a chord task result is\r\nstill in cache, chord will be able finish and join (unlock). Otherwise\r\nwe see that the chord counter has expired while the chord task result\r\nstill in cache. Incrementing an expired chord counter returns None and\r\ncomparing that to dependent task number throws an error.\r\n\r\nCounter's timeout also needs to be refreshed on every chord part return.\r\nMemcached backend didn't implement `expire` using client's `touch`, so\r\nthis is implemented here as well.",
        "commit_url": "https://github.com/celery/celery/commit/4c4f5d8dd07b71b1348bfe618281885fe7da9fbd",
        "buggy_code": "self.expire(key, 86400)",
        "fixed_code": "self.expire(key, self.expires)",
        "patch": "@@ -750,7 +750,7 @@ def on_chord_part_return(self, request, state, result, **kwargs):\n                 deps.delete()\n                 self.client.delete(key)\n         else:\n-            self.expire(key, 86400)\n+            self.expire(key, self.expires)\n \n \n class KeyValueStoreBackend(BaseKeyValueStoreBackend, SyncBackendMixin):"
    },
    {
        "commit_id": "6d4ff8689b2128a2e95e52857d9e346b1ad9827a",
        "commit_message": "Redis Backend: Increases default socket timeout from 5 to 120 (Issue #3363)",
        "commit_url": "https://github.com/celery/celery/commit/6d4ff8689b2128a2e95e52857d9e346b1ad9827a",
        "buggy_code": "socket_timeout=Option(5.0, type='float'),",
        "fixed_code": "socket_timeout=Option(120.0, type='float'),",
        "patch": "@@ -155,7 +155,7 @@ def __repr__(self):\n         max_connections=Option(type='int'),\n         password=Option(type='string'),\n         port=Option(type='int'),\n-        socket_timeout=Option(5.0, type='float'),\n+        socket_timeout=Option(120.0, type='float'),\n     ),\n     result=Namespace(\n         __old__=old_ns('celery_result'),"
    },
    {
        "commit_id": "ca6b4b53832ae663e236d1b424c32661f058fecd",
        "commit_message": "Fix check for default app to succeed even if proxy (#3482)",
        "commit_url": "https://github.com/celery/celery/commit/ca6b4b53832ae663e236d1b424c32661f058fecd",
        "buggy_code": "if default_app is None:",
        "fixed_code": "if not default_app:",
        "patch": "@@ -46,7 +46,7 @@ class DjangoFixup(object):\n \n     def __init__(self, app):\n         self.app = app\n-        if default_app is None:\n+        if not default_app:\n             self.app.set_default()\n         self._worker_fixup = None\n "
    },
    {
        "commit_id": "24f7b9462ed53c7098c7995066d5acc74f8631fd",
        "commit_message": "Reject, not ack, messageswith invalid ETA value (Issue #3431)",
        "commit_url": "https://github.com/celery/celery/commit/24f7b9462ed53c7098c7995066d5acc74f8631fd",
        "buggy_code": "req.acknowledge()",
        "fixed_code": "req.reject(requeue=False)",
        "patch": "@@ -121,7 +121,7 @@ def task_message_handler(message, body, ack, reject, callbacks,\n             except OverflowError as exc:\n                 error(\"Couldn't convert ETA %r to timestamp: %r. Task: %r\",\n                       req.eta, exc, req.info(safe=True), exc_info=True)\n-                req.acknowledge()\n+                req.reject(requeue=False)\n             else:\n                 consumer.qos.increment_eventually()\n                 call_at(eta, apply_eta_task, (req,), priority=6)"
    },
    {
        "commit_id": "3f048b7670e237096df4c1a8fff86cdae310ccd7",
        "commit_message": "Attempt to fix weird pytest-cov build issue",
        "commit_url": "https://github.com/celery/celery/commit/3f048b7670e237096df4c1a8fff86cdae310ccd7",
        "buggy_code": "def test_start_stop_process(self):",
        "fixed_code": "def xxx_start_stop_process(self):",
        "patch": "@@ -485,7 +485,7 @@ def test_start_manages_one_tick_before_shutdown(self):\n class test_EmbeddedService:\n \n     @skip.unless_module('_multiprocessing', name='multiprocessing')\n-    def test_start_stop_process(self):\n+    def xxx_start_stop_process(self):\n         from billiard.process import Process\n \n         s = beat.EmbeddedService(self.app)"
    },
    {
        "commit_id": "9c2a012068ef0d01167de10befcb511dcee37cf5",
        "commit_message": "Merge pull request #3334 from mabouels/patch-1\n\nUpdate sphinx.py",
        "commit_url": "https://github.com/celery/celery/commit/9c2a012068ef0d01167de10befcb511dcee37cf5",
        "buggy_code": "wrapped = getattr(self.object, '__wrapped__')",
        "fixed_code": "wrapped = getattr(self.object, '__wrapped__', None)",
        "patch": "@@ -48,7 +48,7 @@ def can_document_member(cls, member, membername, isattr, parent):\n         return isinstance(member, BaseTask) and getattr(member, '__wrapped__')\n \n     def format_args(self):\n-        wrapped = getattr(self.object, '__wrapped__')\n+        wrapped = getattr(self.object, '__wrapped__', None)\n         if wrapped is not None:\n             argspec = getfullargspec(wrapped)\n             fmt = formatargspec(*argspec)"
    },
    {
        "commit_id": "25a0c8459afa9eba94ae3c3f42ec1e9611254ad6",
        "commit_message": "Build: Attempt to fix",
        "commit_url": "https://github.com/celery/celery/commit/25a0c8459afa9eba94ae3c3f42ec1e9611254ad6",
        "buggy_code": "@patch('celery.worker.control.logger.debug')",
        "fixed_code": "@patch('celery.worker.logger.debug')",
        "patch": "@@ -554,7 +554,7 @@ def test_pool_restart(self):\n         consumer.controller.consumer = None\n         panel.handle('pool_restart', {'reloader': _reload})\n \n-    @patch('celery.worker.control.logger.debug')\n+    @patch('celery.worker.logger.debug')\n     def test_pool_restart_import_modules(self, _debug):\n         consumer = Consumer(self.app)\n         consumer.controller = _WC(app=self.app)"
    },
    {
        "commit_id": "0140a47b2d14c7b5a09dda50a86fe568780a4f43",
        "commit_message": "Merge pull request #3285 from bbgwilbur/master\n\nFix typo in worker.py",
        "commit_url": "https://github.com/celery/celery/commit/0140a47b2d14c7b5a09dda50a86fe568780a4f43",
        "buggy_code": "uopts.options_list.extend(user_options)",
        "fixed_code": "uopts.option_list.extend(user_options)",
        "patch": "@@ -340,7 +340,7 @@ def prepare_arguments(self, parser):\n         user_options = self.app.user_options['worker']\n         if user_options:\n             uopts = OptionGroup(parser, 'User Options')\n-            uopts.options_list.extend(user_options)\n+            uopts.option_list.extend(user_options)\n             parser.add_option_group(uopts)\n \n "
    },
    {
        "commit_id": "876e6bdc499ffcda10e118a28d3b1ee22170f2aa",
        "commit_message": "Fix typo in worker.py\n\nThe attribute in OptionGroup is called option_list, not options_list",
        "commit_url": "https://github.com/celery/celery/commit/876e6bdc499ffcda10e118a28d3b1ee22170f2aa",
        "buggy_code": "uopts.options_list.extend(user_options)",
        "fixed_code": "uopts.option_list.extend(user_options)",
        "patch": "@@ -340,7 +340,7 @@ def prepare_arguments(self, parser):\n         user_options = self.app.user_options['worker']\n         if user_options:\n             uopts = OptionGroup(parser, 'User Options')\n-            uopts.options_list.extend(user_options)\n+            uopts.option_list.extend(user_options)\n             parser.add_option_group(uopts)\n \n "
    },
    {
        "commit_id": "b97e164131137a72d11c46c7b07df1a88fb3c016",
        "commit_message": "Fixes requests memory leak in master (Issue #3205)",
        "commit_url": "https://github.com/celery/celery/commit/b97e164131137a72d11c46c7b07df1a88fb3c016",
        "buggy_code": "remove_request(request, None)",
        "fixed_code": "remove_request(request.id, None)",
        "patch": "@@ -103,7 +103,7 @@ def task_ready(request,\n                discard_active_request=active_requests.discard,\n                discard_reserved_request=reserved_requests.discard):\n     \"\"\"Updates global state when a task is ready.\"\"\"\n-    remove_request(request, None)\n+    remove_request(request.id, None)\n     discard_active_request(request)\n     discard_reserved_request(request)\n "
    },
    {
        "commit_id": "320777611a0e349f08f4bb3ca2d36c9036eda330",
        "commit_message": "[asynpool] Fixed typo in on_stop_not_started possibly extending shutdown time (Issue #2606)",
        "commit_url": "https://github.com/celery/celery/commit/320777611a0e349f08f4bb3ca2d36c9036eda330",
        "buggy_code": "fd, pending_remove_fd.discard, fileno_to_outq,",
        "fixed_code": "fd, pending_remove_fd.add, fileno_to_outq,",
        "patch": "@@ -319,7 +319,7 @@ def on_stop_not_started(self):\n             pending_remove_fd = set()\n             for fd in outqueues:\n                 self._flush_outqueue(\n-                    fd, pending_remove_fd.discard, fileno_to_outq,\n+                    fd, pending_remove_fd.add, fileno_to_outq,\n                     on_state_change,\n                 )\n                 try:"
    },
    {
        "commit_id": "381d2d0615f4318fe71a46d49fa6f5361f56a8aa",
        "commit_message": "Merge pull request #3125 from tgwizard/fix-link-pyamqp\n\nUpdate and fix links to external pages",
        "commit_url": "https://github.com/celery/celery/commit/381d2d0615f4318fe71a46d49fa6f5361f56a8aa",
        "buggy_code": "See http://en.wikipedia.org/wiki/Topological_sorting",
        "fixed_code": "See https://en.wikipedia.org/wiki/Topological_sorting",
        "patch": "@@ -232,7 +232,7 @@ def edges(self):\n     def _khan62(self):\n         \"\"\"Khans simple topological sort algorithm from '62\n \n-        See http://en.wikipedia.org/wiki/Topological_sorting\n+        See https://en.wikipedia.org/wiki/Topological_sorting\n \n         \"\"\"\n         count = defaultdict(lambda: 0)"
    },
    {
        "commit_id": "381d2d0615f4318fe71a46d49fa6f5361f56a8aa",
        "commit_message": "Merge pull request #3125 from tgwizard/fix-link-pyamqp\n\nUpdate and fix links to external pages",
        "commit_url": "https://github.com/celery/celery/commit/381d2d0615f4318fe71a46d49fa6f5361f56a8aa",
        "buggy_code": "LINKCODE_URL = 'http://github.com/{proj}/tree/{branch}/{filename}.py'",
        "fixed_code": "LINKCODE_URL = 'https://github.com/{proj}/tree/{branch}/{filename}.py'",
        "patch": "@@ -26,7 +26,7 @@\n               'celerydocs']\n \n \n-LINKCODE_URL = 'http://github.com/{proj}/tree/{branch}/{filename}.py'\n+LINKCODE_URL = 'https://github.com/{proj}/tree/{branch}/{filename}.py'\n GITHUB_PROJECT = 'celery/celery'\n GITHUB_BRANCH = 'master'\n "
    },
    {
        "commit_id": "381d2d0615f4318fe71a46d49fa6f5361f56a8aa",
        "commit_message": "Merge pull request #3125 from tgwizard/fix-link-pyamqp\n\nUpdate and fix links to external pages",
        "commit_url": "https://github.com/celery/celery/commit/381d2d0615f4318fe71a46d49fa6f5361f56a8aa",
        "buggy_code": "url='http://github.com/celery/celery',",
        "fixed_code": "url='https://github.com/celery/celery',",
        "patch": "@@ -42,7 +42,7 @@ def run(self, *args, **kwargs):\n     description='Functional test suite for Celery',\n     author='Ask Solem',\n     author_email='ask@celeryproject.org',\n-    url='http://github.com/celery/celery',\n+    url='https://github.com/celery/celery',\n     platforms=['any'],\n     packages=[],\n     data_files=[],"
    },
    {
        "commit_id": "5f62a7c7b41de76075b99419c965eaa844ad11c5",
        "commit_message": "[Travis] Attempt to fix build #2",
        "commit_url": "https://github.com/celery/celery/commit/5f62a7c7b41de76075b99419c965eaa844ad11c5",
        "buggy_code": "'task_id': task_id}",
        "fixed_code": "'task_id': bytes_to_str(task_id)}",
        "patch": "@@ -581,7 +581,7 @@ def _store_result(self, task_id, result, state,\n                       traceback=None, request=None, **kwargs):\n         meta = {'status': state, 'result': result, 'traceback': traceback,\n                 'children': self.current_task_children(request),\n-                'task_id': task_id}\n+                'task_id': bytes_to_str(task_id)}\n         self.set(self.get_key_for_task(task_id), self.encode(meta))\n         return result\n "
    },
    {
        "commit_id": "b24fadcec6b530342ab533e47b05ed5dfb2d642c",
        "commit_message": "[examples][app] Fixes restructuredtext error",
        "commit_url": "https://github.com/celery/celery/commit/b24fadcec6b530342ab533e47b05ed5dfb2d642c",
        "buggy_code": "Usage:",
        "fixed_code": "Usage::",
        "patch": "@@ -1,6 +1,6 @@\n \"\"\"myapp.py\n \n-Usage:\n+Usage::\n \n    (window1)$ python myapp.py worker -l info\n "
    },
    {
        "commit_id": "0b751092e6b12b084536b4131041a7147239f2a8",
        "commit_message": "[datastructures] Fix LimitedSet.discard()\n\nThis was raising ValueError every time it was called, because the\nargument order was backward, resulting in unbounded memory growth for\ncallers using discard() to remove items from LimitedSet.\n\nCloses #3087",
        "commit_url": "https://github.com/celery/celery/commit/0b751092e6b12b084536b4131041a7147239f2a8",
        "buggy_code": "self._heap.remove((value, itime))",
        "fixed_code": "self._heap.remove((itime, value))",
        "patch": "@@ -633,7 +633,7 @@ def discard(self, value):\n         except KeyError:\n             return\n         try:\n-            self._heap.remove((value, itime))\n+            self._heap.remove((itime, value))\n         except ValueError:\n             pass\n         self._data.pop(value, None)"
    },
    {
        "commit_id": "9364a9ec8939c32b879fc4333dddd5cbaa192439",
        "commit_message": "Cosmetics for Elasticsearch result backend (Issue #2828)",
        "commit_url": "https://github.com/celery/celery/commit/9364a9ec8939c32b879fc4333dddd5cbaa192439",
        "buggy_code": "'auth', 'cassandra', 'memcache', 'couchbase', 'threads',",
        "fixed_code": "'auth', 'cassandra', 'elasticsearch', 'memcache', 'couchbase', 'threads',",
        "patch": "@@ -196,7 +196,7 @@ def extras(*p):\n \n # Celery specific\n features = set([\n-    'auth', 'cassandra', 'memcache', 'couchbase', 'threads',\n+    'auth', 'cassandra', 'elasticsearch', 'memcache', 'couchbase', 'threads',\n     'eventlet', 'gevent', 'msgpack', 'yaml', 'redis',\n     'mongodb', 'sqs', 'couchdb', 'riak', 'beanstalk', 'zookeeper',\n     'zeromq', 'sqlalchemy', 'librabbitmq', 'pyro', 'slmq',"
    },
    {
        "commit_id": "fa6fbd192bfd40ef6140caed3d85c22a6dd8772a",
        "commit_message": "[canvas] Remove unused localized argument (Issue #3043)",
        "commit_url": "https://github.com/celery/celery/commit/fa6fbd192bfd40ef6140caed3d85c22a6dd8772a",
        "buggy_code": "def _prepared(self, tasks, partial_args, group_id, root_id, app, dict=dict,",
        "fixed_code": "def _prepared(self, tasks, partial_args, group_id, root_id, app,",
        "patch": "@@ -713,7 +713,7 @@ def from_dict(self, d, app=None):\n     def __len__(self):\n         return len(self.tasks)\n \n-    def _prepared(self, tasks, partial_args, group_id, root_id, app, dict=dict,\n+    def _prepared(self, tasks, partial_args, group_id, root_id, app,\n                   CallableSignature=abstract.CallableSignature,\n                   from_dict=Signature.from_dict):\n         for task in tasks:"
    },
    {
        "commit_id": "b8cac297c36de8b37884acb76d57d6bf911c2404",
        "commit_message": "Merge pull request #3038 from WorldException/patch-1\n\nFix eventlet example",
        "commit_url": "https://github.com/celery/celery/commit/b8cac297c36de8b37884acb76d57d6bf911c2404",
        "buggy_code": "self.callback = None",
        "fixed_code": "self.callback = callback",
        "patch": "@@ -10,7 +10,7 @@ class Receipt(object):\n     result = None\n \n     def __init__(self, callback=None):\n-        self.callback = None\n+        self.callback = callback\n         self.ready = Event()\n \n     def finished(self, result):"
    },
    {
        "commit_id": "54049ea21c36771fdadc19c020d353524f52cef6",
        "commit_message": "bug in __init__",
        "commit_url": "https://github.com/celery/celery/commit/54049ea21c36771fdadc19c020d353524f52cef6",
        "buggy_code": "self.callback = None",
        "fixed_code": "self.callback = callback",
        "patch": "@@ -10,7 +10,7 @@ class Receipt(object):\n     result = None\n \n     def __init__(self, callback=None):\n-        self.callback = None\n+        self.callback = callback\n         self.ready = Event()\n \n     def finished(self, result):"
    },
    {
        "commit_id": "78b053c720ba942c9a37a1db81a3f6de0ffcb275",
        "commit_message": "Error mail: Sets charset to utf-8 by default (Issue #2737)",
        "commit_url": "https://github.com/celery/celery/commit/78b053c720ba942c9a37a1db81a3f6de0ffcb275",
        "buggy_code": "charset=Option('us-ascii'),",
        "fixed_code": "charset=Option('utf-8'),",
        "patch": "@@ -139,7 +139,7 @@ def __repr__(self):\n         backend_settings=Option(None, type='dict'),\n     ),\n     email=Namespace(\n-        charset=Option('us-ascii'),\n+        charset=Option('utf-8'),\n         host=Option('localhost'),\n         host_user=Option(),\n         host_password=Option(),"
    },
    {
        "commit_id": "78b053c720ba942c9a37a1db81a3f6de0ffcb275",
        "commit_message": "Error mail: Sets charset to utf-8 by default (Issue #2737)",
        "commit_url": "https://github.com/celery/celery/commit/78b053c720ba942c9a37a1db81a3f6de0ffcb275",
        "buggy_code": "body=None, charset='us-ascii'):",
        "fixed_code": "body=None, charset='utf-8'):",
        "patch": "@@ -42,7 +42,7 @@ class SendmailWarning(UserWarning):\n class Message(object):\n \n     def __init__(self, to=None, sender=None, subject=None,\n-                 body=None, charset='us-ascii'):\n+                 body=None, charset='utf-8'):\n         self.to = maybe_list(to)\n         self.sender = sender\n         self.subject = subject"
    },
    {
        "commit_id": "7824d0d4ddccdecab5a4b630bd815f77e5eb437f",
        "commit_message": "[Database result backend] Fixes JSON serialization of exceptions (Issue #2441)",
        "commit_url": "https://github.com/celery/celery/commit/7824d0d4ddccdecab5a4b630bd815f77e5eb437f",
        "buggy_code": "return task.to_dict()",
        "fixed_code": "return self.meta_from_decoded(task.to_dict())",
        "patch": "@@ -134,7 +134,7 @@ def _get_task_meta_for(self, task_id):\n                 task = Task(task_id)\n                 task.status = states.PENDING\n                 task.result = None\n-            return task.to_dict()\n+            return self.meta_from_decoded(task.to_dict())\n \n     @retry\n     def _save_group(self, group_id, result):"
    },
    {
        "commit_id": "151696c5166f68539c0bf661d6a2837e43677d23",
        "commit_message": "Disables the local client result cache by default (Issue #2461)",
        "commit_url": "https://github.com/celery/celery/commit/151696c5166f68539c0bf661d6a2837e43677d23",
        "buggy_code": "100,",
        "fixed_code": "-1,",
        "patch": "@@ -173,7 +173,7 @@ def __repr__(self):\n \n         backend=Option(type='string'),\n         cache_max=Option(\n-            100,\n+            -1,\n             type='int', old={'celery_max_cached_results'},\n         ),\n         compression=Option(type='str'),"
    },
    {
        "commit_id": "7b876989921968897c06d690e04d2025576d56f0",
        "commit_message": "Fixes bug with configuration key prefix",
        "commit_url": "https://github.com/celery/celery/commit/7b876989921968897c06d690e04d2025576d56f0",
        "buggy_code": "app.config_from_object('django.conf:settings', namespace='CELERY_')",
        "fixed_code": "app.config_from_object('django.conf:settings', namespace='CELERY')",
        "patch": "@@ -11,7 +11,7 @@\n \n # Using a string here means the worker will not have to\n # pickle the object when using Windows.\n-app.config_from_object('django.conf:settings', namespace='CELERY_')\n+app.config_from_object('django.conf:settings', namespace='CELERY')\n \n # load task modules from all registered Django app configs.\n app.autodiscover_tasks()"
    },
    {
        "commit_id": "93fb98f0897065bcb878c8e5f714464037813032",
        "commit_message": "Batches example missing passing request to mark_as_done.  Issue #2861",
        "commit_url": "https://github.com/celery/celery/commit/93fb98f0897065bcb878c8e5f714464037813032",
        "buggy_code": "app.backend.mark_as_done(request.id, response)",
        "fixed_code": "app.backend.mark_as_done(request.id, response, request)",
        "patch": "@@ -57,7 +57,7 @@ def wot_api(requests):\n         )\n         # use mark_as_done to manually return response data\n         for response, request in zip(reponses, requests):\n-            app.backend.mark_as_done(request.id, response)\n+            app.backend.mark_as_done(request.id, response, request)\n \n \n     def wot_api_real(urls):"
    },
    {
        "commit_id": "66e94b8abbd913ffd0a2a6a96d283ec367152345",
        "commit_message": "Fixes bug with argument parsing in master",
        "commit_url": "https://github.com/celery/celery/commit/66e94b8abbd913ffd0a2a6a96d283ec367152345",
        "buggy_code": "parser.option_list.extend(self.app.user_options['beat'])",
        "fixed_code": "parser.add_options(self.app.user_options['beat'])",
        "patch": "@@ -86,7 +86,7 @@ def prepare_arguments(self, parser):\n         parser.add_option('-S', '--scheduler', dest='scheduler_cls')\n         parser.add_option('-l', '--loglevel', default='WARN')\n         daemon_options(parser, default_pidfile='celerybeat.pid')\n-        parser.option_list.extend(self.app.user_options['beat'])\n+        parser.add_options(self.app.user_options['beat'])\n \n \n def main(app=None):"
    },
    {
        "commit_id": "66e94b8abbd913ffd0a2a6a96d283ec367152345",
        "commit_message": "Fixes bug with argument parsing in master",
        "commit_url": "https://github.com/celery/celery/commit/66e94b8abbd913ffd0a2a6a96d283ec367152345",
        "buggy_code": "parser.option_list.extend(self.app.user_options['events'])",
        "fixed_code": "parser.add_options(self.app.user_options['events'])",
        "patch": "@@ -126,7 +126,7 @@ def prepare_arguments(self, parser):\n         parser.add_option('-r', '--maxrate')\n         parser.add_option('-l', '--loglevel', default='INFO')\n         daemon_options(parser, default_pidfile='celeryev.pid')\n-        parser.option_list.extend(self.app.user_options['events'])\n+        parser.add_options(self.app.user_options['events'])\n \n \n def main():"
    },
    {
        "commit_id": "757678a59a72cc79599332b71953d6eec79c33c4",
        "commit_message": "Worker: Also send task-failed event on unregistered task (Issue #2791)",
        "commit_url": "https://github.com/celery/celery/commit/757678a59a72cc79599332b71953d6eec79c33c4",
        "buggy_code": "'message', 'exc',",
        "fixed_code": "'message', 'exc', 'name', 'id',",
        "patch": "@@ -54,7 +54,7 @@\n     'message', 'exc',\n ])\n task_unknown = Signal(providing_args=[\n-    'message', 'exc',\n+    'message', 'exc', 'name', 'id',\n ])\n celeryd_init = Signal(providing_args=['instance', 'conf', 'options'])\n celeryd_after_setup = Signal(providing_args=['instance', 'conf'])"
    },
    {
        "commit_id": "53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "commit_message": "Lowercase settings and settings cleanup (radical, but backwards compatible)\n\nAll settings are now in lowercase, and most of them have been renamed.\n\nWhen loading settings the loader will look at the settings in the config\nand decide if it's using old or new settings.\nThe settings will autmatically convert between old and new settings keys, depending\non the format the settings is in.\n\n- It's not legal to mix new setting names and old setting names, that is unless\n  the setting have two alternatives (old and new).\n\n    An ImproperlyConfigured exceptions is rasised in this case, with help telling\n    user exactly how to fix the problem.\n\n- To support loading configuration from Django settings a new ``namespace``\n  argument has been added to ``Celery`` and ``config_from_object``.\n\n    This can be used from Django::\n\n        app = Celery()\n        app.config_from_object('django.conf:settings', namespace='CELERY_')\n\n        # settings.py:\n        CELERY_BROKER_URL = 'amqp://'\n        CELERY_TASK_PROTOCOL = 2\n        CELERY_TASK_ALWAYS_EAGER = True\n\n    Or other apps wanting a prefix for some reason::\n\n        app = Celery(namespace='celery_')\n        app.conf.celery_task_always_eager = True\n        app.conf.celery_task_routes = {'proj.tasks.add': 'math.yo'}\n\n- Initial configuration directly on the app object is now lazy!\n\n    You can set keys on an unfinalized app, without causing the tasks\n    or the rest of the app to be evaluated:\n\n        app = Celery()\n        app.conf.update(\n            task_default_delivery_mode=1,\n            task_default_queue='default',\n            task_default_exchange='default',\n            task_default_routing_key='default',\n        )\n        app.conf.task_always_eager = True\n        assert not app.configured  # <-- still not finalized\n\n        app.config_from_object('celeryconfig')\n        assert not app.configured  # <-- even now\n\n        app.finalize()\n        assert app.finalized       # <-- but now we are\n\n        # and the config done first remains, unlike older versions of Celery.\n        assert app.conf.task.default_queue == 'default'\n\n        app.config_from_object(object())\n        # but calling config_from_* again will reset everything.\n        assert app.conf.task_default_queue == 'celery'\n\n- ``config_from_*`` methods no longer override configuration set manually\n  before the app was finalized.\n\n    But calling again after the app is finalized, will clean out old\n    configuration.",
        "commit_url": "https://github.com/celery/celery/commit/53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "buggy_code": "default_propagate = app.conf.CELERY_CHORD_PROPAGATES",
        "fixed_code": "default_propagate = app.conf.chord_propagates",
        "patch": "@@ -54,7 +54,7 @@ def add_unlock_chord_task(app):\n     from celery.exceptions import ChordError\n     from celery.result import allow_join_result, result_from_tuple\n \n-    default_propagate = app.conf.CELERY_CHORD_PROPAGATES\n+    default_propagate = app.conf.chord_propagates\n \n     @app.task(name='celery.chord_unlock', max_retries=None, shared=False,\n               default_retry_delay=1, ignore_result=True, lazy=False, bind=True)"
    },
    {
        "commit_id": "53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "commit_message": "Lowercase settings and settings cleanup (radical, but backwards compatible)\n\nAll settings are now in lowercase, and most of them have been renamed.\n\nWhen loading settings the loader will look at the settings in the config\nand decide if it's using old or new settings.\nThe settings will autmatically convert between old and new settings keys, depending\non the format the settings is in.\n\n- It's not legal to mix new setting names and old setting names, that is unless\n  the setting have two alternatives (old and new).\n\n    An ImproperlyConfigured exceptions is rasised in this case, with help telling\n    user exactly how to fix the problem.\n\n- To support loading configuration from Django settings a new ``namespace``\n  argument has been added to ``Celery`` and ``config_from_object``.\n\n    This can be used from Django::\n\n        app = Celery()\n        app.config_from_object('django.conf:settings', namespace='CELERY_')\n\n        # settings.py:\n        CELERY_BROKER_URL = 'amqp://'\n        CELERY_TASK_PROTOCOL = 2\n        CELERY_TASK_ALWAYS_EAGER = True\n\n    Or other apps wanting a prefix for some reason::\n\n        app = Celery(namespace='celery_')\n        app.conf.celery_task_always_eager = True\n        app.conf.celery_task_routes = {'proj.tasks.add': 'math.yo'}\n\n- Initial configuration directly on the app object is now lazy!\n\n    You can set keys on an unfinalized app, without causing the tasks\n    or the rest of the app to be evaluated:\n\n        app = Celery()\n        app.conf.update(\n            task_default_delivery_mode=1,\n            task_default_queue='default',\n            task_default_exchange='default',\n            task_default_routing_key='default',\n        )\n        app.conf.task_always_eager = True\n        assert not app.configured  # <-- still not finalized\n\n        app.config_from_object('celeryconfig')\n        assert not app.configured  # <-- even now\n\n        app.finalize()\n        assert app.finalized       # <-- but now we are\n\n        # and the config done first remains, unlike older versions of Celery.\n        assert app.conf.task.default_queue == 'default'\n\n        app.config_from_object(object())\n        # but calling config_from_* again will reset everything.\n        assert app.conf.task_default_queue == 'celery'\n\n- ``config_from_*`` methods no longer override configuration set manually\n  before the app was finalized.\n\n    But calling again after the app is finalized, will clean out old\n    configuration.",
        "commit_url": "https://github.com/celery/celery/commit/53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "buggy_code": "config = self.app.conf.get('CELERY_COUCHBASE_BACKEND_SETTINGS', None)",
        "fixed_code": "config = self.app.conf.get('couchbase_backend_settings', None)",
        "patch": "@@ -63,7 +63,7 @@ def __init__(self, url=None, *args, **kwargs):\n             _, uhost, uport, uname, upass, ubucket, _ = _parse_url(url)\n             ubucket = ubucket.strip('/') if ubucket else None\n \n-        config = self.app.conf.get('CELERY_COUCHBASE_BACKEND_SETTINGS', None)\n+        config = self.app.conf.get('couchbase_backend_settings', None)\n         if config is not None:\n             if not isinstance(config, dict):\n                 raise ImproperlyConfigured("
    },
    {
        "commit_id": "53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "commit_message": "Lowercase settings and settings cleanup (radical, but backwards compatible)\n\nAll settings are now in lowercase, and most of them have been renamed.\n\nWhen loading settings the loader will look at the settings in the config\nand decide if it's using old or new settings.\nThe settings will autmatically convert between old and new settings keys, depending\non the format the settings is in.\n\n- It's not legal to mix new setting names and old setting names, that is unless\n  the setting have two alternatives (old and new).\n\n    An ImproperlyConfigured exceptions is rasised in this case, with help telling\n    user exactly how to fix the problem.\n\n- To support loading configuration from Django settings a new ``namespace``\n  argument has been added to ``Celery`` and ``config_from_object``.\n\n    This can be used from Django::\n\n        app = Celery()\n        app.config_from_object('django.conf:settings', namespace='CELERY_')\n\n        # settings.py:\n        CELERY_BROKER_URL = 'amqp://'\n        CELERY_TASK_PROTOCOL = 2\n        CELERY_TASK_ALWAYS_EAGER = True\n\n    Or other apps wanting a prefix for some reason::\n\n        app = Celery(namespace='celery_')\n        app.conf.celery_task_always_eager = True\n        app.conf.celery_task_routes = {'proj.tasks.add': 'math.yo'}\n\n- Initial configuration directly on the app object is now lazy!\n\n    You can set keys on an unfinalized app, without causing the tasks\n    or the rest of the app to be evaluated:\n\n        app = Celery()\n        app.conf.update(\n            task_default_delivery_mode=1,\n            task_default_queue='default',\n            task_default_exchange='default',\n            task_default_routing_key='default',\n        )\n        app.conf.task_always_eager = True\n        assert not app.configured  # <-- still not finalized\n\n        app.config_from_object('celeryconfig')\n        assert not app.configured  # <-- even now\n\n        app.finalize()\n        assert app.finalized       # <-- but now we are\n\n        # and the config done first remains, unlike older versions of Celery.\n        assert app.conf.task.default_queue == 'default'\n\n        app.config_from_object(object())\n        # but calling config_from_* again will reset everything.\n        assert app.conf.task_default_queue == 'celery'\n\n- ``config_from_*`` methods no longer override configuration set manually\n  before the app was finalized.\n\n    But calling again after the app is finalized, will clean out old\n    configuration.",
        "commit_url": "https://github.com/celery/celery/commit/53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "buggy_code": "config = self.app.conf.get('CELERY_MONGODB_BACKEND_SETTINGS')",
        "fixed_code": "config = self.app.conf.get('mongodb_backend_settings')",
        "patch": "@@ -98,7 +98,7 @@ def __init__(self, app=None, url=None, **kwargs):\n             self.options.update(uri_data['options'])\n \n         # update conf with specific settings\n-        config = self.app.conf.get('CELERY_MONGODB_BACKEND_SETTINGS')\n+        config = self.app.conf.get('mongodb_backend_settings')\n         if config is not None:\n             if not isinstance(config, dict):\n                 raise ImproperlyConfigured("
    },
    {
        "commit_id": "53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "commit_message": "Lowercase settings and settings cleanup (radical, but backwards compatible)\n\nAll settings are now in lowercase, and most of them have been renamed.\n\nWhen loading settings the loader will look at the settings in the config\nand decide if it's using old or new settings.\nThe settings will autmatically convert between old and new settings keys, depending\non the format the settings is in.\n\n- It's not legal to mix new setting names and old setting names, that is unless\n  the setting have two alternatives (old and new).\n\n    An ImproperlyConfigured exceptions is rasised in this case, with help telling\n    user exactly how to fix the problem.\n\n- To support loading configuration from Django settings a new ``namespace``\n  argument has been added to ``Celery`` and ``config_from_object``.\n\n    This can be used from Django::\n\n        app = Celery()\n        app.config_from_object('django.conf:settings', namespace='CELERY_')\n\n        # settings.py:\n        CELERY_BROKER_URL = 'amqp://'\n        CELERY_TASK_PROTOCOL = 2\n        CELERY_TASK_ALWAYS_EAGER = True\n\n    Or other apps wanting a prefix for some reason::\n\n        app = Celery(namespace='celery_')\n        app.conf.celery_task_always_eager = True\n        app.conf.celery_task_routes = {'proj.tasks.add': 'math.yo'}\n\n- Initial configuration directly on the app object is now lazy!\n\n    You can set keys on an unfinalized app, without causing the tasks\n    or the rest of the app to be evaluated:\n\n        app = Celery()\n        app.conf.update(\n            task_default_delivery_mode=1,\n            task_default_queue='default',\n            task_default_exchange='default',\n            task_default_routing_key='default',\n        )\n        app.conf.task_always_eager = True\n        assert not app.configured  # <-- still not finalized\n\n        app.config_from_object('celeryconfig')\n        assert not app.configured  # <-- even now\n\n        app.finalize()\n        assert app.finalized       # <-- but now we are\n\n        # and the config done first remains, unlike older versions of Celery.\n        assert app.conf.task.default_queue == 'default'\n\n        app.config_from_object(object())\n        # but calling config_from_* again will reset everything.\n        assert app.conf.task_default_queue == 'celery'\n\n- ``config_from_*`` methods no longer override configuration set manually\n  before the app was finalized.\n\n    But calling again after the app is finalized, will clean out old\n    configuration.",
        "commit_url": "https://github.com/celery/celery/commit/53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "buggy_code": "config = self.app.conf.get('CELERY_RIAK_BACKEND_SETTINGS', None)",
        "fixed_code": "config = self.app.conf.get('riak_backend_settings', None)",
        "patch": "@@ -85,7 +85,7 @@ def __init__(self, host=None, port=None, bucket_name=None, protocol=None,\n             if ubucket:\n                 ubucket = ubucket.strip('/')\n \n-        config = self.app.conf.get('CELERY_RIAK_BACKEND_SETTINGS', None)\n+        config = self.app.conf.get('riak_backend_settings', None)\n         if config is not None:\n             if not isinstance(config, dict):\n                 raise ImproperlyConfigured("
    },
    {
        "commit_id": "53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "commit_message": "Lowercase settings and settings cleanup (radical, but backwards compatible)\n\nAll settings are now in lowercase, and most of them have been renamed.\n\nWhen loading settings the loader will look at the settings in the config\nand decide if it's using old or new settings.\nThe settings will autmatically convert between old and new settings keys, depending\non the format the settings is in.\n\n- It's not legal to mix new setting names and old setting names, that is unless\n  the setting have two alternatives (old and new).\n\n    An ImproperlyConfigured exceptions is rasised in this case, with help telling\n    user exactly how to fix the problem.\n\n- To support loading configuration from Django settings a new ``namespace``\n  argument has been added to ``Celery`` and ``config_from_object``.\n\n    This can be used from Django::\n\n        app = Celery()\n        app.config_from_object('django.conf:settings', namespace='CELERY_')\n\n        # settings.py:\n        CELERY_BROKER_URL = 'amqp://'\n        CELERY_TASK_PROTOCOL = 2\n        CELERY_TASK_ALWAYS_EAGER = True\n\n    Or other apps wanting a prefix for some reason::\n\n        app = Celery(namespace='celery_')\n        app.conf.celery_task_always_eager = True\n        app.conf.celery_task_routes = {'proj.tasks.add': 'math.yo'}\n\n- Initial configuration directly on the app object is now lazy!\n\n    You can set keys on an unfinalized app, without causing the tasks\n    or the rest of the app to be evaluated:\n\n        app = Celery()\n        app.conf.update(\n            task_default_delivery_mode=1,\n            task_default_queue='default',\n            task_default_exchange='default',\n            task_default_routing_key='default',\n        )\n        app.conf.task_always_eager = True\n        assert not app.configured  # <-- still not finalized\n\n        app.config_from_object('celeryconfig')\n        assert not app.configured  # <-- even now\n\n        app.finalize()\n        assert app.finalized       # <-- but now we are\n\n        # and the config done first remains, unlike older versions of Celery.\n        assert app.conf.task.default_queue == 'default'\n\n        app.config_from_object(object())\n        # but calling config_from_* again will reset everything.\n        assert app.conf.task_default_queue == 'celery'\n\n- ``config_from_*`` methods no longer override configuration set manually\n  before the app was finalized.\n\n    But calling again after the app is finalized, will clean out old\n    configuration.",
        "commit_url": "https://github.com/celery/celery/commit/53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "buggy_code": "namespace = 'celery'",
        "fixed_code": "namespace = None",
        "patch": "@@ -219,7 +219,7 @@ class Command(object):\n     enable_config_from_cmdline = False\n \n     #: Default configuration namespace.\n-    namespace = 'celery'\n+    namespace = None\n \n     #: Text to print at end of --help\n     epilog = None"
    },
    {
        "commit_id": "53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "commit_message": "Lowercase settings and settings cleanup (radical, but backwards compatible)\n\nAll settings are now in lowercase, and most of them have been renamed.\n\nWhen loading settings the loader will look at the settings in the config\nand decide if it's using old or new settings.\nThe settings will autmatically convert between old and new settings keys, depending\non the format the settings is in.\n\n- It's not legal to mix new setting names and old setting names, that is unless\n  the setting have two alternatives (old and new).\n\n    An ImproperlyConfigured exceptions is rasised in this case, with help telling\n    user exactly how to fix the problem.\n\n- To support loading configuration from Django settings a new ``namespace``\n  argument has been added to ``Celery`` and ``config_from_object``.\n\n    This can be used from Django::\n\n        app = Celery()\n        app.config_from_object('django.conf:settings', namespace='CELERY_')\n\n        # settings.py:\n        CELERY_BROKER_URL = 'amqp://'\n        CELERY_TASK_PROTOCOL = 2\n        CELERY_TASK_ALWAYS_EAGER = True\n\n    Or other apps wanting a prefix for some reason::\n\n        app = Celery(namespace='celery_')\n        app.conf.celery_task_always_eager = True\n        app.conf.celery_task_routes = {'proj.tasks.add': 'math.yo'}\n\n- Initial configuration directly on the app object is now lazy!\n\n    You can set keys on an unfinalized app, without causing the tasks\n    or the rest of the app to be evaluated:\n\n        app = Celery()\n        app.conf.update(\n            task_default_delivery_mode=1,\n            task_default_queue='default',\n            task_default_exchange='default',\n            task_default_routing_key='default',\n        )\n        app.conf.task_always_eager = True\n        assert not app.configured  # <-- still not finalized\n\n        app.config_from_object('celeryconfig')\n        assert not app.configured  # <-- even now\n\n        app.finalize()\n        assert app.finalized       # <-- but now we are\n\n        # and the config done first remains, unlike older versions of Celery.\n        assert app.conf.task.default_queue == 'default'\n\n        app.config_from_object(object())\n        # but calling config_from_* again will reset everything.\n        assert app.conf.task_default_queue == 'celery'\n\n- ``config_from_*`` methods no longer override configuration set manually\n  before the app was finalized.\n\n    But calling again after the app is finalized, will clean out old\n    configuration.",
        "commit_url": "https://github.com/celery/celery/commit/53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "buggy_code": "default=c.CELERYBEAT_SCHEDULE_FILENAME),",
        "fixed_code": "default=c.beat_schedule_filename),",
        "patch": "@@ -84,7 +84,7 @@ def get_options(self):\n         return (\n             (Option('--detach', action='store_true'),\n              Option('-s', '--schedule',\n-                    default=c.CELERYBEAT_SCHEDULE_FILENAME),\n+                    default=c.beat_schedule_filename),\n              Option('--max-interval', type='float'),\n              Option('-S', '--scheduler', dest='scheduler_cls'),\n              Option('-l', '--loglevel', default='WARN')) +"
    },
    {
        "commit_id": "53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "commit_message": "Lowercase settings and settings cleanup (radical, but backwards compatible)\n\nAll settings are now in lowercase, and most of them have been renamed.\n\nWhen loading settings the loader will look at the settings in the config\nand decide if it's using old or new settings.\nThe settings will autmatically convert between old and new settings keys, depending\non the format the settings is in.\n\n- It's not legal to mix new setting names and old setting names, that is unless\n  the setting have two alternatives (old and new).\n\n    An ImproperlyConfigured exceptions is rasised in this case, with help telling\n    user exactly how to fix the problem.\n\n- To support loading configuration from Django settings a new ``namespace``\n  argument has been added to ``Celery`` and ``config_from_object``.\n\n    This can be used from Django::\n\n        app = Celery()\n        app.config_from_object('django.conf:settings', namespace='CELERY_')\n\n        # settings.py:\n        CELERY_BROKER_URL = 'amqp://'\n        CELERY_TASK_PROTOCOL = 2\n        CELERY_TASK_ALWAYS_EAGER = True\n\n    Or other apps wanting a prefix for some reason::\n\n        app = Celery(namespace='celery_')\n        app.conf.celery_task_always_eager = True\n        app.conf.celery_task_routes = {'proj.tasks.add': 'math.yo'}\n\n- Initial configuration directly on the app object is now lazy!\n\n    You can set keys on an unfinalized app, without causing the tasks\n    or the rest of the app to be evaluated:\n\n        app = Celery()\n        app.conf.update(\n            task_default_delivery_mode=1,\n            task_default_queue='default',\n            task_default_exchange='default',\n            task_default_routing_key='default',\n        )\n        app.conf.task_always_eager = True\n        assert not app.configured  # <-- still not finalized\n\n        app.config_from_object('celeryconfig')\n        assert not app.configured  # <-- even now\n\n        app.finalize()\n        assert app.finalized       # <-- but now we are\n\n        # and the config done first remains, unlike older versions of Celery.\n        assert app.conf.task.default_queue == 'default'\n\n        app.config_from_object(object())\n        # but calling config_from_* again will reset everything.\n        assert app.conf.task_default_queue == 'celery'\n\n- ``config_from_*`` methods no longer override configuration set manually\n  before the app was finalized.\n\n    But calling again after the app is finalized, will clean out old\n    configuration.",
        "commit_url": "https://github.com/celery/celery/commit/53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "buggy_code": "backend = args.get('backend', self.app.conf.CELERY_RESULT_BACKEND)",
        "fixed_code": "backend = args.get('backend', self.app.conf.result_backend)",
        "patch": "@@ -156,7 +156,7 @@ def maybe_abbr(l, name, max=Wmax):\n                 threads.append(reply['pool']['max-concurrency'])\n \n         wlen = len(workers)\n-        backend = args.get('backend', self.app.conf.CELERY_RESULT_BACKEND)\n+        backend = args.get('backend', self.app.conf.result_backend)\n         threads_for = {}\n         workers = maybe_abbr(workers, 'Worker')\n         if Wmax and wlen > Wmax:"
    },
    {
        "commit_id": "53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "commit_message": "Lowercase settings and settings cleanup (radical, but backwards compatible)\n\nAll settings are now in lowercase, and most of them have been renamed.\n\nWhen loading settings the loader will look at the settings in the config\nand decide if it's using old or new settings.\nThe settings will autmatically convert between old and new settings keys, depending\non the format the settings is in.\n\n- It's not legal to mix new setting names and old setting names, that is unless\n  the setting have two alternatives (old and new).\n\n    An ImproperlyConfigured exceptions is rasised in this case, with help telling\n    user exactly how to fix the problem.\n\n- To support loading configuration from Django settings a new ``namespace``\n  argument has been added to ``Celery`` and ``config_from_object``.\n\n    This can be used from Django::\n\n        app = Celery()\n        app.config_from_object('django.conf:settings', namespace='CELERY_')\n\n        # settings.py:\n        CELERY_BROKER_URL = 'amqp://'\n        CELERY_TASK_PROTOCOL = 2\n        CELERY_TASK_ALWAYS_EAGER = True\n\n    Or other apps wanting a prefix for some reason::\n\n        app = Celery(namespace='celery_')\n        app.conf.celery_task_always_eager = True\n        app.conf.celery_task_routes = {'proj.tasks.add': 'math.yo'}\n\n- Initial configuration directly on the app object is now lazy!\n\n    You can set keys on an unfinalized app, without causing the tasks\n    or the rest of the app to be evaluated:\n\n        app = Celery()\n        app.conf.update(\n            task_default_delivery_mode=1,\n            task_default_queue='default',\n            task_default_exchange='default',\n            task_default_routing_key='default',\n        )\n        app.conf.task_always_eager = True\n        assert not app.configured  # <-- still not finalized\n\n        app.config_from_object('celeryconfig')\n        assert not app.configured  # <-- even now\n\n        app.finalize()\n        assert app.finalized       # <-- but now we are\n\n        # and the config done first remains, unlike older versions of Celery.\n        assert app.conf.task.default_queue == 'default'\n\n        app.config_from_object(object())\n        # but calling config_from_* again will reset everything.\n        assert app.conf.task_default_queue == 'celery'\n\n- ``config_from_*`` methods no longer override configuration set manually\n  before the app was finalized.\n\n    But calling again after the app is finalized, will clean out old\n    configuration.",
        "commit_url": "https://github.com/celery/celery/commit/53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "buggy_code": ":setting:`CELERYD_PREFETCH_MULTIPLIER` to zero, or some value where",
        "fixed_code": ":setting:`worker_prefetch_multiplier` to zero, or some value where",
        "patch": "@@ -8,7 +8,7 @@\n .. warning::\n \n     For this to work you have to set\n-    :setting:`CELERYD_PREFETCH_MULTIPLIER` to zero, or some value where\n+    :setting:`worker_prefetch_multiplier` to zero, or some value where\n     the final multiplied value is higher than ``flush_every``.\n \n     In the future we hope to add the ability to direct batching tasks"
    },
    {
        "commit_id": "53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "commit_message": "Lowercase settings and settings cleanup (radical, but backwards compatible)\n\nAll settings are now in lowercase, and most of them have been renamed.\n\nWhen loading settings the loader will look at the settings in the config\nand decide if it's using old or new settings.\nThe settings will autmatically convert between old and new settings keys, depending\non the format the settings is in.\n\n- It's not legal to mix new setting names and old setting names, that is unless\n  the setting have two alternatives (old and new).\n\n    An ImproperlyConfigured exceptions is rasised in this case, with help telling\n    user exactly how to fix the problem.\n\n- To support loading configuration from Django settings a new ``namespace``\n  argument has been added to ``Celery`` and ``config_from_object``.\n\n    This can be used from Django::\n\n        app = Celery()\n        app.config_from_object('django.conf:settings', namespace='CELERY_')\n\n        # settings.py:\n        CELERY_BROKER_URL = 'amqp://'\n        CELERY_TASK_PROTOCOL = 2\n        CELERY_TASK_ALWAYS_EAGER = True\n\n    Or other apps wanting a prefix for some reason::\n\n        app = Celery(namespace='celery_')\n        app.conf.celery_task_always_eager = True\n        app.conf.celery_task_routes = {'proj.tasks.add': 'math.yo'}\n\n- Initial configuration directly on the app object is now lazy!\n\n    You can set keys on an unfinalized app, without causing the tasks\n    or the rest of the app to be evaluated:\n\n        app = Celery()\n        app.conf.update(\n            task_default_delivery_mode=1,\n            task_default_queue='default',\n            task_default_exchange='default',\n            task_default_routing_key='default',\n        )\n        app.conf.task_always_eager = True\n        assert not app.configured  # <-- still not finalized\n\n        app.config_from_object('celeryconfig')\n        assert not app.configured  # <-- even now\n\n        app.finalize()\n        assert app.finalized       # <-- but now we are\n\n        # and the config done first remains, unlike older versions of Celery.\n        assert app.conf.task.default_queue == 'default'\n\n        app.config_from_object(object())\n        # but calling config_from_* again will reset everything.\n        assert app.conf.task_default_queue == 'celery'\n\n- ``config_from_*`` methods no longer override configuration set manually\n  before the app was finalized.\n\n    But calling again after the app is finalized, will clean out old\n    configuration.",
        "commit_url": "https://github.com/celery/celery/commit/53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "buggy_code": "default (which is the queues in :setting:`CELERY_QUEUES`).",
        "fixed_code": "default (which is the queues in :setting:`task_queues`).",
        "patch": "@@ -141,7 +141,7 @@ def move(predicate, connection=None, exchange=None, routing_key=None,\n \n     :keyword connection: Custom connection to use.\n     :keyword source: Optional list of source queues to use instead of the\n-        default (which is the queues in :setting:`CELERY_QUEUES`).\n+        default (which is the queues in :setting:`task_queues`).\n         This list can also contain new :class:`~kombu.entity.Queue` instances.\n     :keyword exchange: Default destination exchange.\n     :keyword routing_key: Default destination routing key."
    },
    {
        "commit_id": "53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "commit_message": "Lowercase settings and settings cleanup (radical, but backwards compatible)\n\nAll settings are now in lowercase, and most of them have been renamed.\n\nWhen loading settings the loader will look at the settings in the config\nand decide if it's using old or new settings.\nThe settings will autmatically convert between old and new settings keys, depending\non the format the settings is in.\n\n- It's not legal to mix new setting names and old setting names, that is unless\n  the setting have two alternatives (old and new).\n\n    An ImproperlyConfigured exceptions is rasised in this case, with help telling\n    user exactly how to fix the problem.\n\n- To support loading configuration from Django settings a new ``namespace``\n  argument has been added to ``Celery`` and ``config_from_object``.\n\n    This can be used from Django::\n\n        app = Celery()\n        app.config_from_object('django.conf:settings', namespace='CELERY_')\n\n        # settings.py:\n        CELERY_BROKER_URL = 'amqp://'\n        CELERY_TASK_PROTOCOL = 2\n        CELERY_TASK_ALWAYS_EAGER = True\n\n    Or other apps wanting a prefix for some reason::\n\n        app = Celery(namespace='celery_')\n        app.conf.celery_task_always_eager = True\n        app.conf.celery_task_routes = {'proj.tasks.add': 'math.yo'}\n\n- Initial configuration directly on the app object is now lazy!\n\n    You can set keys on an unfinalized app, without causing the tasks\n    or the rest of the app to be evaluated:\n\n        app = Celery()\n        app.conf.update(\n            task_default_delivery_mode=1,\n            task_default_queue='default',\n            task_default_exchange='default',\n            task_default_routing_key='default',\n        )\n        app.conf.task_always_eager = True\n        assert not app.configured  # <-- still not finalized\n\n        app.config_from_object('celeryconfig')\n        assert not app.configured  # <-- even now\n\n        app.finalize()\n        assert app.finalized       # <-- but now we are\n\n        # and the config done first remains, unlike older versions of Celery.\n        assert app.conf.task.default_queue == 'default'\n\n        app.config_from_object(object())\n        # but calling config_from_* again will reset everything.\n        assert app.conf.task_default_queue == 'celery'\n\n- ``config_from_*`` methods no longer override configuration set manually\n  before the app was finalized.\n\n    But calling again after the app is finalized, will clean out old\n    configuration.",
        "commit_url": "https://github.com/celery/celery/commit/53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "buggy_code": "app.conf.BROKER_CONNECTION_MAX_RETRIES)",
        "fixed_code": "app.conf.broker_connection_max_retries)",
        "patch": "@@ -511,7 +511,7 @@ def on_connection_error(exc, interval):\n         with app.connection() as conn:\n             try:\n                 conn.ensure_connection(on_connection_error,\n-                                       app.conf.BROKER_CONNECTION_MAX_RETRIES)\n+                                       app.conf.broker_connection_max_retries)\n                 recv = app.events.Receiver(conn, handlers={'*': state.event})\n                 display.resetscreen()\n                 display.init_screen()"
    },
    {
        "commit_id": "53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "commit_message": "Lowercase settings and settings cleanup (radical, but backwards compatible)\n\nAll settings are now in lowercase, and most of them have been renamed.\n\nWhen loading settings the loader will look at the settings in the config\nand decide if it's using old or new settings.\nThe settings will autmatically convert between old and new settings keys, depending\non the format the settings is in.\n\n- It's not legal to mix new setting names and old setting names, that is unless\n  the setting have two alternatives (old and new).\n\n    An ImproperlyConfigured exceptions is rasised in this case, with help telling\n    user exactly how to fix the problem.\n\n- To support loading configuration from Django settings a new ``namespace``\n  argument has been added to ``Celery`` and ``config_from_object``.\n\n    This can be used from Django::\n\n        app = Celery()\n        app.config_from_object('django.conf:settings', namespace='CELERY_')\n\n        # settings.py:\n        CELERY_BROKER_URL = 'amqp://'\n        CELERY_TASK_PROTOCOL = 2\n        CELERY_TASK_ALWAYS_EAGER = True\n\n    Or other apps wanting a prefix for some reason::\n\n        app = Celery(namespace='celery_')\n        app.conf.celery_task_always_eager = True\n        app.conf.celery_task_routes = {'proj.tasks.add': 'math.yo'}\n\n- Initial configuration directly on the app object is now lazy!\n\n    You can set keys on an unfinalized app, without causing the tasks\n    or the rest of the app to be evaluated:\n\n        app = Celery()\n        app.conf.update(\n            task_default_delivery_mode=1,\n            task_default_queue='default',\n            task_default_exchange='default',\n            task_default_routing_key='default',\n        )\n        app.conf.task_always_eager = True\n        assert not app.configured  # <-- still not finalized\n\n        app.config_from_object('celeryconfig')\n        assert not app.configured  # <-- even now\n\n        app.finalize()\n        assert app.finalized       # <-- but now we are\n\n        # and the config done first remains, unlike older versions of Celery.\n        assert app.conf.task.default_queue == 'default'\n\n        app.config_from_object(object())\n        # but calling config_from_* again will reset everything.\n        assert app.conf.task_default_queue == 'celery'\n\n- ``config_from_*`` methods no longer override configuration set manually\n  before the app was finalized.\n\n    But calling again after the app is finalized, will clean out old\n    configuration.",
        "commit_url": "https://github.com/celery/celery/commit/53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "buggy_code": "if app.conf.CELERY_ALWAYS_EAGER:",
        "fixed_code": "if app.conf.task_always_eager:",
        "patch": "@@ -53,7 +53,7 @@ def apply_async(self, connection=None, publisher=None, taskset_id=None):\n         \"\"\"Apply TaskSet.\"\"\"\n         app = self.app\n \n-        if app.conf.CELERY_ALWAYS_EAGER:\n+        if app.conf.task_always_eager:\n             return self.apply(taskset_id=taskset_id)\n \n         with app.connection_or_acquire(connection) as conn:"
    },
    {
        "commit_id": "53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "commit_message": "Lowercase settings and settings cleanup (radical, but backwards compatible)\n\nAll settings are now in lowercase, and most of them have been renamed.\n\nWhen loading settings the loader will look at the settings in the config\nand decide if it's using old or new settings.\nThe settings will autmatically convert between old and new settings keys, depending\non the format the settings is in.\n\n- It's not legal to mix new setting names and old setting names, that is unless\n  the setting have two alternatives (old and new).\n\n    An ImproperlyConfigured exceptions is rasised in this case, with help telling\n    user exactly how to fix the problem.\n\n- To support loading configuration from Django settings a new ``namespace``\n  argument has been added to ``Celery`` and ``config_from_object``.\n\n    This can be used from Django::\n\n        app = Celery()\n        app.config_from_object('django.conf:settings', namespace='CELERY_')\n\n        # settings.py:\n        CELERY_BROKER_URL = 'amqp://'\n        CELERY_TASK_PROTOCOL = 2\n        CELERY_TASK_ALWAYS_EAGER = True\n\n    Or other apps wanting a prefix for some reason::\n\n        app = Celery(namespace='celery_')\n        app.conf.celery_task_always_eager = True\n        app.conf.celery_task_routes = {'proj.tasks.add': 'math.yo'}\n\n- Initial configuration directly on the app object is now lazy!\n\n    You can set keys on an unfinalized app, without causing the tasks\n    or the rest of the app to be evaluated:\n\n        app = Celery()\n        app.conf.update(\n            task_default_delivery_mode=1,\n            task_default_queue='default',\n            task_default_exchange='default',\n            task_default_routing_key='default',\n        )\n        app.conf.task_always_eager = True\n        assert not app.configured  # <-- still not finalized\n\n        app.config_from_object('celeryconfig')\n        assert not app.configured  # <-- even now\n\n        app.finalize()\n        assert app.finalized       # <-- but now we are\n\n        # and the config done first remains, unlike older versions of Celery.\n        assert app.conf.task.default_queue == 'default'\n\n        app.config_from_object(object())\n        # but calling config_from_* again will reset everything.\n        assert app.conf.task_default_queue == 'celery'\n\n- ``config_from_*`` methods no longer override configuration set manually\n  before the app was finalized.\n\n    But calling again after the app is finalized, will clean out old\n    configuration.",
        "commit_url": "https://github.com/celery/celery/commit/53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "buggy_code": "self.app.conf.CELERYD_HIJACK_ROOT_LOGGER = True",
        "fixed_code": "self.app.conf.worker_hijack_root_logger = True",
        "patch": "@@ -190,7 +190,7 @@ def test_setup_logging_subsystem_misc(self):\n \n     def test_setup_logging_subsystem_misc2(self):\n         with restore_logging():\n-            self.app.conf.CELERYD_HIJACK_ROOT_LOGGER = True\n+            self.app.conf.worker_hijack_root_logger = True\n             self.app.log.setup_logging_subsystem()\n \n     def test_get_default_logger(self):"
    },
    {
        "commit_id": "53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "commit_message": "Lowercase settings and settings cleanup (radical, but backwards compatible)\n\nAll settings are now in lowercase, and most of them have been renamed.\n\nWhen loading settings the loader will look at the settings in the config\nand decide if it's using old or new settings.\nThe settings will autmatically convert between old and new settings keys, depending\non the format the settings is in.\n\n- It's not legal to mix new setting names and old setting names, that is unless\n  the setting have two alternatives (old and new).\n\n    An ImproperlyConfigured exceptions is rasised in this case, with help telling\n    user exactly how to fix the problem.\n\n- To support loading configuration from Django settings a new ``namespace``\n  argument has been added to ``Celery`` and ``config_from_object``.\n\n    This can be used from Django::\n\n        app = Celery()\n        app.config_from_object('django.conf:settings', namespace='CELERY_')\n\n        # settings.py:\n        CELERY_BROKER_URL = 'amqp://'\n        CELERY_TASK_PROTOCOL = 2\n        CELERY_TASK_ALWAYS_EAGER = True\n\n    Or other apps wanting a prefix for some reason::\n\n        app = Celery(namespace='celery_')\n        app.conf.celery_task_always_eager = True\n        app.conf.celery_task_routes = {'proj.tasks.add': 'math.yo'}\n\n- Initial configuration directly on the app object is now lazy!\n\n    You can set keys on an unfinalized app, without causing the tasks\n    or the rest of the app to be evaluated:\n\n        app = Celery()\n        app.conf.update(\n            task_default_delivery_mode=1,\n            task_default_queue='default',\n            task_default_exchange='default',\n            task_default_routing_key='default',\n        )\n        app.conf.task_always_eager = True\n        assert not app.configured  # <-- still not finalized\n\n        app.config_from_object('celeryconfig')\n        assert not app.configured  # <-- even now\n\n        app.finalize()\n        assert app.finalized       # <-- but now we are\n\n        # and the config done first remains, unlike older versions of Celery.\n        assert app.conf.task.default_queue == 'default'\n\n        app.config_from_object(object())\n        # but calling config_from_* again will reset everything.\n        assert app.conf.task_default_queue == 'celery'\n\n- ``config_from_*`` methods no longer override configuration set manually\n  before the app was finalized.\n\n    But calling again after the app is finalized, will clean out old\n    configuration.",
        "commit_url": "https://github.com/celery/celery/commit/53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "buggy_code": "app.conf.CELERY_TASK_RESULT_EXPIRES = None",
        "fixed_code": "app.conf.result_expires = None",
        "patch": "@@ -375,7 +375,7 @@ def se(*args, **kwargs):\n     def test_no_expires(self):\n         b = self.create_backend(expires=None)\n         app = self.app\n-        app.conf.CELERY_TASK_RESULT_EXPIRES = None\n+        app.conf.result_expires = None\n         b = self.create_backend(expires=None)\n         with self.assertRaises(KeyError):\n             b.queue_arguments['x-expires']"
    },
    {
        "commit_id": "53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "commit_message": "Lowercase settings and settings cleanup (radical, but backwards compatible)\n\nAll settings are now in lowercase, and most of them have been renamed.\n\nWhen loading settings the loader will look at the settings in the config\nand decide if it's using old or new settings.\nThe settings will autmatically convert between old and new settings keys, depending\non the format the settings is in.\n\n- It's not legal to mix new setting names and old setting names, that is unless\n  the setting have two alternatives (old and new).\n\n    An ImproperlyConfigured exceptions is rasised in this case, with help telling\n    user exactly how to fix the problem.\n\n- To support loading configuration from Django settings a new ``namespace``\n  argument has been added to ``Celery`` and ``config_from_object``.\n\n    This can be used from Django::\n\n        app = Celery()\n        app.config_from_object('django.conf:settings', namespace='CELERY_')\n\n        # settings.py:\n        CELERY_BROKER_URL = 'amqp://'\n        CELERY_TASK_PROTOCOL = 2\n        CELERY_TASK_ALWAYS_EAGER = True\n\n    Or other apps wanting a prefix for some reason::\n\n        app = Celery(namespace='celery_')\n        app.conf.celery_task_always_eager = True\n        app.conf.celery_task_routes = {'proj.tasks.add': 'math.yo'}\n\n- Initial configuration directly on the app object is now lazy!\n\n    You can set keys on an unfinalized app, without causing the tasks\n    or the rest of the app to be evaluated:\n\n        app = Celery()\n        app.conf.update(\n            task_default_delivery_mode=1,\n            task_default_queue='default',\n            task_default_exchange='default',\n            task_default_routing_key='default',\n        )\n        app.conf.task_always_eager = True\n        assert not app.configured  # <-- still not finalized\n\n        app.config_from_object('celeryconfig')\n        assert not app.configured  # <-- even now\n\n        app.finalize()\n        assert app.finalized       # <-- but now we are\n\n        # and the config done first remains, unlike older versions of Celery.\n        assert app.conf.task.default_queue == 'default'\n\n        app.config_from_object(object())\n        # but calling config_from_* again will reset everything.\n        assert app.conf.task_default_queue == 'celery'\n\n- ``config_from_*`` methods no longer override configuration set manually\n  before the app was finalized.\n\n    But calling again after the app is finalized, will clean out old\n    configuration.",
        "commit_url": "https://github.com/celery/celery/commit/53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "buggy_code": "propagate=self.b.app.conf.CELERY_CHORD_PROPAGATES,",
        "fixed_code": "propagate=self.b.app.conf.chord_propagates,",
        "patch": "@@ -343,7 +343,7 @@ def test_chord_part_return_propagate_default(self):\n             self.assertFalse(self.b.expire.called)\n             deps.delete.assert_called_with()\n             deps.join_native.assert_called_with(\n-                propagate=self.b.app.conf.CELERY_CHORD_PROPAGATES,\n+                propagate=self.b.app.conf.chord_propagates,\n                 timeout=3.0,\n             )\n "
    },
    {
        "commit_id": "53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "commit_message": "Lowercase settings and settings cleanup (radical, but backwards compatible)\n\nAll settings are now in lowercase, and most of them have been renamed.\n\nWhen loading settings the loader will look at the settings in the config\nand decide if it's using old or new settings.\nThe settings will autmatically convert between old and new settings keys, depending\non the format the settings is in.\n\n- It's not legal to mix new setting names and old setting names, that is unless\n  the setting have two alternatives (old and new).\n\n    An ImproperlyConfigured exceptions is rasised in this case, with help telling\n    user exactly how to fix the problem.\n\n- To support loading configuration from Django settings a new ``namespace``\n  argument has been added to ``Celery`` and ``config_from_object``.\n\n    This can be used from Django::\n\n        app = Celery()\n        app.config_from_object('django.conf:settings', namespace='CELERY_')\n\n        # settings.py:\n        CELERY_BROKER_URL = 'amqp://'\n        CELERY_TASK_PROTOCOL = 2\n        CELERY_TASK_ALWAYS_EAGER = True\n\n    Or other apps wanting a prefix for some reason::\n\n        app = Celery(namespace='celery_')\n        app.conf.celery_task_always_eager = True\n        app.conf.celery_task_routes = {'proj.tasks.add': 'math.yo'}\n\n- Initial configuration directly on the app object is now lazy!\n\n    You can set keys on an unfinalized app, without causing the tasks\n    or the rest of the app to be evaluated:\n\n        app = Celery()\n        app.conf.update(\n            task_default_delivery_mode=1,\n            task_default_queue='default',\n            task_default_exchange='default',\n            task_default_routing_key='default',\n        )\n        app.conf.task_always_eager = True\n        assert not app.configured  # <-- still not finalized\n\n        app.config_from_object('celeryconfig')\n        assert not app.configured  # <-- even now\n\n        app.finalize()\n        assert app.finalized       # <-- but now we are\n\n        # and the config done first remains, unlike older versions of Celery.\n        assert app.conf.task.default_queue == 'default'\n\n        app.config_from_object(object())\n        # but calling config_from_* again will reset everything.\n        assert app.conf.task_default_queue == 'celery'\n\n- ``config_from_*`` methods no longer override configuration set manually\n  before the app was finalized.\n\n    But calling again after the app is finalized, will clean out old\n    configuration.",
        "commit_url": "https://github.com/celery/celery/commit/53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "buggy_code": "self.app.conf.CELERY_EVENT_SERIALIZER)",
        "fixed_code": "self.app.conf.event_serializer)",
        "patch": "@@ -125,7 +125,7 @@ def test_enabled_disable(self):\n             self.assertTrue(dispatcher.enabled)\n             self.assertTrue(dispatcher.producer.channel)\n             self.assertEqual(dispatcher.producer.serializer,\n-                             self.app.conf.CELERY_EVENT_SERIALIZER)\n+                             self.app.conf.event_serializer)\n \n             created_channel = dispatcher.producer.channel\n             dispatcher.disable()"
    },
    {
        "commit_id": "53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "commit_message": "Lowercase settings and settings cleanup (radical, but backwards compatible)\n\nAll settings are now in lowercase, and most of them have been renamed.\n\nWhen loading settings the loader will look at the settings in the config\nand decide if it's using old or new settings.\nThe settings will autmatically convert between old and new settings keys, depending\non the format the settings is in.\n\n- It's not legal to mix new setting names and old setting names, that is unless\n  the setting have two alternatives (old and new).\n\n    An ImproperlyConfigured exceptions is rasised in this case, with help telling\n    user exactly how to fix the problem.\n\n- To support loading configuration from Django settings a new ``namespace``\n  argument has been added to ``Celery`` and ``config_from_object``.\n\n    This can be used from Django::\n\n        app = Celery()\n        app.config_from_object('django.conf:settings', namespace='CELERY_')\n\n        # settings.py:\n        CELERY_BROKER_URL = 'amqp://'\n        CELERY_TASK_PROTOCOL = 2\n        CELERY_TASK_ALWAYS_EAGER = True\n\n    Or other apps wanting a prefix for some reason::\n\n        app = Celery(namespace='celery_')\n        app.conf.celery_task_always_eager = True\n        app.conf.celery_task_routes = {'proj.tasks.add': 'math.yo'}\n\n- Initial configuration directly on the app object is now lazy!\n\n    You can set keys on an unfinalized app, without causing the tasks\n    or the rest of the app to be evaluated:\n\n        app = Celery()\n        app.conf.update(\n            task_default_delivery_mode=1,\n            task_default_queue='default',\n            task_default_exchange='default',\n            task_default_routing_key='default',\n        )\n        app.conf.task_always_eager = True\n        assert not app.configured  # <-- still not finalized\n\n        app.config_from_object('celeryconfig')\n        assert not app.configured  # <-- even now\n\n        app.finalize()\n        assert app.finalized       # <-- but now we are\n\n        # and the config done first remains, unlike older versions of Celery.\n        assert app.conf.task.default_queue == 'default'\n\n        app.config_from_object(object())\n        # but calling config_from_* again will reset everything.\n        assert app.conf.task_default_queue == 'celery'\n\n- ``config_from_*`` methods no longer override configuration set manually\n  before the app was finalized.\n\n    But calling again after the app is finalized, will clean out old\n    configuration.",
        "commit_url": "https://github.com/celery/celery/commit/53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "buggy_code": "self.app.conf.CELERY_RESULT_SERIALIZER = 'pickle'",
        "fixed_code": "self.app.conf.result_serializer = 'pickle'",
        "patch": "@@ -210,7 +210,7 @@ def send(self, event, **fields):\n class test_Request(AppCase):\n \n     def setup(self):\n-        self.app.conf.CELERY_RESULT_SERIALIZER = 'pickle'\n+        self.app.conf.result_serializer = 'pickle'\n \n         @self.app.task(shared=False)\n         def add(x, y, **kw_):"
    },
    {
        "commit_id": "53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "commit_message": "Lowercase settings and settings cleanup (radical, but backwards compatible)\n\nAll settings are now in lowercase, and most of them have been renamed.\n\nWhen loading settings the loader will look at the settings in the config\nand decide if it's using old or new settings.\nThe settings will autmatically convert between old and new settings keys, depending\non the format the settings is in.\n\n- It's not legal to mix new setting names and old setting names, that is unless\n  the setting have two alternatives (old and new).\n\n    An ImproperlyConfigured exceptions is rasised in this case, with help telling\n    user exactly how to fix the problem.\n\n- To support loading configuration from Django settings a new ``namespace``\n  argument has been added to ``Celery`` and ``config_from_object``.\n\n    This can be used from Django::\n\n        app = Celery()\n        app.config_from_object('django.conf:settings', namespace='CELERY_')\n\n        # settings.py:\n        CELERY_BROKER_URL = 'amqp://'\n        CELERY_TASK_PROTOCOL = 2\n        CELERY_TASK_ALWAYS_EAGER = True\n\n    Or other apps wanting a prefix for some reason::\n\n        app = Celery(namespace='celery_')\n        app.conf.celery_task_always_eager = True\n        app.conf.celery_task_routes = {'proj.tasks.add': 'math.yo'}\n\n- Initial configuration directly on the app object is now lazy!\n\n    You can set keys on an unfinalized app, without causing the tasks\n    or the rest of the app to be evaluated:\n\n        app = Celery()\n        app.conf.update(\n            task_default_delivery_mode=1,\n            task_default_queue='default',\n            task_default_exchange='default',\n            task_default_routing_key='default',\n        )\n        app.conf.task_always_eager = True\n        assert not app.configured  # <-- still not finalized\n\n        app.config_from_object('celeryconfig')\n        assert not app.configured  # <-- even now\n\n        app.finalize()\n        assert app.finalized       # <-- but now we are\n\n        # and the config done first remains, unlike older versions of Celery.\n        assert app.conf.task.default_queue == 'default'\n\n        app.config_from_object(object())\n        # but calling config_from_* again will reset everything.\n        assert app.conf.task_default_queue == 'celery'\n\n- ``config_from_*`` methods no longer override configuration set manually\n  before the app was finalized.\n\n    But calling again after the app is finalized, will clean out old\n    configuration.",
        "commit_url": "https://github.com/celery/celery/commit/53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "buggy_code": "if state.app.conf.CELERYD_POOL_RESTARTS:",
        "fixed_code": "if state.app.conf.worker_pool_restarts:",
        "patch": "@@ -321,7 +321,7 @@ def pool_shrink(state, n=1, **kwargs):\n \n @Panel.register\n def pool_restart(state, modules=None, reload=False, reloader=None, **kwargs):\n-    if state.app.conf.CELERYD_POOL_RESTARTS:\n+    if state.app.conf.worker_pool_restarts:\n         state.consumer.controller.reload(modules, reload, reloader=reloader)\n         return {'ok': 'reload started'}\n     else:"
    },
    {
        "commit_id": "53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "commit_message": "Lowercase settings and settings cleanup (radical, but backwards compatible)\n\nAll settings are now in lowercase, and most of them have been renamed.\n\nWhen loading settings the loader will look at the settings in the config\nand decide if it's using old or new settings.\nThe settings will autmatically convert between old and new settings keys, depending\non the format the settings is in.\n\n- It's not legal to mix new setting names and old setting names, that is unless\n  the setting have two alternatives (old and new).\n\n    An ImproperlyConfigured exceptions is rasised in this case, with help telling\n    user exactly how to fix the problem.\n\n- To support loading configuration from Django settings a new ``namespace``\n  argument has been added to ``Celery`` and ``config_from_object``.\n\n    This can be used from Django::\n\n        app = Celery()\n        app.config_from_object('django.conf:settings', namespace='CELERY_')\n\n        # settings.py:\n        CELERY_BROKER_URL = 'amqp://'\n        CELERY_TASK_PROTOCOL = 2\n        CELERY_TASK_ALWAYS_EAGER = True\n\n    Or other apps wanting a prefix for some reason::\n\n        app = Celery(namespace='celery_')\n        app.conf.celery_task_always_eager = True\n        app.conf.celery_task_routes = {'proj.tasks.add': 'math.yo'}\n\n- Initial configuration directly on the app object is now lazy!\n\n    You can set keys on an unfinalized app, without causing the tasks\n    or the rest of the app to be evaluated:\n\n        app = Celery()\n        app.conf.update(\n            task_default_delivery_mode=1,\n            task_default_queue='default',\n            task_default_exchange='default',\n            task_default_routing_key='default',\n        )\n        app.conf.task_always_eager = True\n        assert not app.configured  # <-- still not finalized\n\n        app.config_from_object('celeryconfig')\n        assert not app.configured  # <-- even now\n\n        app.finalize()\n        assert app.finalized       # <-- but now we are\n\n        # and the config done first remains, unlike older versions of Celery.\n        assert app.conf.task.default_queue == 'default'\n\n        app.config_from_object(object())\n        # but calling config_from_* again will reset everything.\n        assert app.conf.task_default_queue == 'celery'\n\n- ``config_from_*`` methods no longer override configuration set manually\n  before the app was finalized.\n\n    But calling again after the app is finalized, will clean out old\n    configuration.",
        "commit_url": "https://github.com/celery/celery/commit/53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "buggy_code": "self._tzlocal = self.app.conf.CELERY_TIMEZONE",
        "fixed_code": "self._tzlocal = self.app.conf.timezone",
        "patch": "@@ -420,7 +420,7 @@ def __repr__(self):\n     @property\n     def tzlocal(self):\n         if self._tzlocal is None:\n-            self._tzlocal = self.app.conf.CELERY_TIMEZONE\n+            self._tzlocal = self.app.conf.timezone\n         return self._tzlocal\n \n     @property"
    },
    {
        "commit_id": "53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "commit_message": "Lowercase settings and settings cleanup (radical, but backwards compatible)\n\nAll settings are now in lowercase, and most of them have been renamed.\n\nWhen loading settings the loader will look at the settings in the config\nand decide if it's using old or new settings.\nThe settings will autmatically convert between old and new settings keys, depending\non the format the settings is in.\n\n- It's not legal to mix new setting names and old setting names, that is unless\n  the setting have two alternatives (old and new).\n\n    An ImproperlyConfigured exceptions is rasised in this case, with help telling\n    user exactly how to fix the problem.\n\n- To support loading configuration from Django settings a new ``namespace``\n  argument has been added to ``Celery`` and ``config_from_object``.\n\n    This can be used from Django::\n\n        app = Celery()\n        app.config_from_object('django.conf:settings', namespace='CELERY_')\n\n        # settings.py:\n        CELERY_BROKER_URL = 'amqp://'\n        CELERY_TASK_PROTOCOL = 2\n        CELERY_TASK_ALWAYS_EAGER = True\n\n    Or other apps wanting a prefix for some reason::\n\n        app = Celery(namespace='celery_')\n        app.conf.celery_task_always_eager = True\n        app.conf.celery_task_routes = {'proj.tasks.add': 'math.yo'}\n\n- Initial configuration directly on the app object is now lazy!\n\n    You can set keys on an unfinalized app, without causing the tasks\n    or the rest of the app to be evaluated:\n\n        app = Celery()\n        app.conf.update(\n            task_default_delivery_mode=1,\n            task_default_queue='default',\n            task_default_exchange='default',\n            task_default_routing_key='default',\n        )\n        app.conf.task_always_eager = True\n        assert not app.configured  # <-- still not finalized\n\n        app.config_from_object('celeryconfig')\n        assert not app.configured  # <-- even now\n\n        app.finalize()\n        assert app.finalized       # <-- but now we are\n\n        # and the config done first remains, unlike older versions of Celery.\n        assert app.conf.task.default_queue == 'default'\n\n        app.config_from_object(object())\n        # but calling config_from_* again will reset everything.\n        assert app.conf.task_default_queue == 'celery'\n\n- ``config_from_*`` methods no longer override configuration set manually\n  before the app was finalized.\n\n    But calling again after the app is finalized, will clean out old\n    configuration.",
        "commit_url": "https://github.com/celery/celery/commit/53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "buggy_code": "app.config_from_object('django.conf:settings')",
        "fixed_code": "app.config_from_object('django.conf:settings', namespace='CELERY_')",
        "patch": "@@ -11,7 +11,7 @@\n \n # Using a string here means the worker will not have to\n # pickle the object when using Windows.\n-app.config_from_object('django.conf:settings')\n+app.config_from_object('django.conf:settings', namespace='CELERY_')\n \n # load task modules from all registered Django app configs.\n app.autodiscover_tasks()"
    },
    {
        "commit_id": "53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "commit_message": "Lowercase settings and settings cleanup (radical, but backwards compatible)\n\nAll settings are now in lowercase, and most of them have been renamed.\n\nWhen loading settings the loader will look at the settings in the config\nand decide if it's using old or new settings.\nThe settings will autmatically convert between old and new settings keys, depending\non the format the settings is in.\n\n- It's not legal to mix new setting names and old setting names, that is unless\n  the setting have two alternatives (old and new).\n\n    An ImproperlyConfigured exceptions is rasised in this case, with help telling\n    user exactly how to fix the problem.\n\n- To support loading configuration from Django settings a new ``namespace``\n  argument has been added to ``Celery`` and ``config_from_object``.\n\n    This can be used from Django::\n\n        app = Celery()\n        app.config_from_object('django.conf:settings', namespace='CELERY_')\n\n        # settings.py:\n        CELERY_BROKER_URL = 'amqp://'\n        CELERY_TASK_PROTOCOL = 2\n        CELERY_TASK_ALWAYS_EAGER = True\n\n    Or other apps wanting a prefix for some reason::\n\n        app = Celery(namespace='celery_')\n        app.conf.celery_task_always_eager = True\n        app.conf.celery_task_routes = {'proj.tasks.add': 'math.yo'}\n\n- Initial configuration directly on the app object is now lazy!\n\n    You can set keys on an unfinalized app, without causing the tasks\n    or the rest of the app to be evaluated:\n\n        app = Celery()\n        app.conf.update(\n            task_default_delivery_mode=1,\n            task_default_queue='default',\n            task_default_exchange='default',\n            task_default_routing_key='default',\n        )\n        app.conf.task_always_eager = True\n        assert not app.configured  # <-- still not finalized\n\n        app.config_from_object('celeryconfig')\n        assert not app.configured  # <-- even now\n\n        app.finalize()\n        assert app.finalized       # <-- but now we are\n\n        # and the config done first remains, unlike older versions of Celery.\n        assert app.conf.task.default_queue == 'default'\n\n        app.config_from_object(object())\n        # but calling config_from_* again will reset everything.\n        assert app.conf.task_default_queue == 'celery'\n\n- ``config_from_*`` methods no longer override configuration set manually\n  before the app was finalized.\n\n    But calling again after the app is finalized, will clean out old\n    configuration.",
        "commit_url": "https://github.com/celery/celery/commit/53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "buggy_code": "BROKER_URL = 'amqp://guest:guest@localhost//'",
        "fixed_code": "CELERY_BROKER_URL = 'amqp://guest:guest@localhost//'",
        "patch": "@@ -6,7 +6,7 @@\n \n # Celery settings\n \n-BROKER_URL = 'amqp://guest:guest@localhost//'\n+CELERY_BROKER_URL = 'amqp://guest:guest@localhost//'\n \n #: Only add pickle to this list if your broker is secured\n #: from unwanted access (see userguide/security.html)"
    },
    {
        "commit_id": "53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "commit_message": "Lowercase settings and settings cleanup (radical, but backwards compatible)\n\nAll settings are now in lowercase, and most of them have been renamed.\n\nWhen loading settings the loader will look at the settings in the config\nand decide if it's using old or new settings.\nThe settings will autmatically convert between old and new settings keys, depending\non the format the settings is in.\n\n- It's not legal to mix new setting names and old setting names, that is unless\n  the setting have two alternatives (old and new).\n\n    An ImproperlyConfigured exceptions is rasised in this case, with help telling\n    user exactly how to fix the problem.\n\n- To support loading configuration from Django settings a new ``namespace``\n  argument has been added to ``Celery`` and ``config_from_object``.\n\n    This can be used from Django::\n\n        app = Celery()\n        app.config_from_object('django.conf:settings', namespace='CELERY_')\n\n        # settings.py:\n        CELERY_BROKER_URL = 'amqp://'\n        CELERY_TASK_PROTOCOL = 2\n        CELERY_TASK_ALWAYS_EAGER = True\n\n    Or other apps wanting a prefix for some reason::\n\n        app = Celery(namespace='celery_')\n        app.conf.celery_task_always_eager = True\n        app.conf.celery_task_routes = {'proj.tasks.add': 'math.yo'}\n\n- Initial configuration directly on the app object is now lazy!\n\n    You can set keys on an unfinalized app, without causing the tasks\n    or the rest of the app to be evaluated:\n\n        app = Celery()\n        app.conf.update(\n            task_default_delivery_mode=1,\n            task_default_queue='default',\n            task_default_exchange='default',\n            task_default_routing_key='default',\n        )\n        app.conf.task_always_eager = True\n        assert not app.configured  # <-- still not finalized\n\n        app.config_from_object('celeryconfig')\n        assert not app.configured  # <-- even now\n\n        app.finalize()\n        assert app.finalized       # <-- but now we are\n\n        # and the config done first remains, unlike older versions of Celery.\n        assert app.conf.task.default_queue == 'default'\n\n        app.config_from_object(object())\n        # but calling config_from_* again will reset everything.\n        assert app.conf.task_default_queue == 'celery'\n\n- ``config_from_*`` methods no longer override configuration set manually\n  before the app was finalized.\n\n    But calling again after the app is finalized, will clean out old\n    configuration.",
        "commit_url": "https://github.com/celery/celery/commit/53b5fdf3c504ca667ffc8d606d2c6d6fa6f21cf6",
        "buggy_code": "CELERY_TASK_RESULT_EXPIRES=3600,",
        "fixed_code": "result_expires=3600,",
        "patch": "@@ -9,7 +9,7 @@\n \n # Optional configuration, see the application user guide.\n app.conf.update(\n-    CELERY_TASK_RESULT_EXPIRES=3600,\n+    result_expires=3600,\n )\n \n if __name__ == '__main__':"
    },
    {
        "commit_id": "8fb23c6a92a2ba4d4a972d13b64fc12bf75e1924",
        "commit_message": "Attempt to fix Py3 tests",
        "commit_url": "https://github.com/celery/celery/commit/8fb23c6a92a2ba4d4a972d13b64fc12bf75e1924",
        "buggy_code": "def setup_defaults(self, concurrency=None, loglevel=None, logfile=None,",
        "fixed_code": "def setup_defaults(self, concurrency=None, loglevel='WARN', logfile=None,",
        "patch": "@@ -342,7 +342,7 @@ def __str__(self):\n     def state(self):\n         return state\n \n-    def setup_defaults(self, concurrency=None, loglevel=None, logfile=None,\n+    def setup_defaults(self, concurrency=None, loglevel='WARN', logfile=None,\n                        send_events=None, pool_cls=None, consumer_cls=None,\n                        timer_cls=None, timer_precision=None,\n                        autoscaler_cls=None, autoreloader_cls=None,"
    },
    {
        "commit_id": "cee79afbc65b080eb35ba6e7f00d5f272eed91af",
        "commit_message": "Merge pull request #2859 from paul-pearce/master\n\nFixed Control.disable_events() documentation bug",
        "commit_url": "https://github.com/celery/celery/commit/cee79afbc65b080eb35ba6e7f00d5f272eed91af",
        "buggy_code": "\"\"\"Tell all (or specific) workers to enable events.\"\"\"",
        "fixed_code": "\"\"\"Tell all (or specific) workers to disable events.\"\"\"",
        "patch": "@@ -263,7 +263,7 @@ def enable_events(self, destination=None, **kwargs):\n         return self.broadcast('enable_events', {}, destination, **kwargs)\n \n     def disable_events(self, destination=None, **kwargs):\n-        \"\"\"Tell all (or specific) workers to enable events.\"\"\"\n+        \"\"\"Tell all (or specific) workers to disable events.\"\"\"\n         return self.broadcast('disable_events', {}, destination, **kwargs)\n \n     def pool_grow(self, n=1, destination=None, **kwargs):"
    },
    {
        "commit_id": "a4bed4dd625e5ca20b7682eac4081c556978ddde",
        "commit_message": "Fixed Control.disable_events() documentation bug",
        "commit_url": "https://github.com/celery/celery/commit/a4bed4dd625e5ca20b7682eac4081c556978ddde",
        "buggy_code": "\"\"\"Tell all (or specific) workers to enable events.\"\"\"",
        "fixed_code": "\"\"\"Tell all (or specific) workers to disable events.\"\"\"",
        "patch": "@@ -263,7 +263,7 @@ def enable_events(self, destination=None, **kwargs):\n         return self.broadcast('enable_events', {}, destination, **kwargs)\n \n     def disable_events(self, destination=None, **kwargs):\n-        \"\"\"Tell all (or specific) workers to enable events.\"\"\"\n+        \"\"\"Tell all (or specific) workers to disable events.\"\"\"\n         return self.broadcast('disable_events', {}, destination, **kwargs)\n \n     def pool_grow(self, n=1, destination=None, **kwargs):"
    },
    {
        "commit_id": "8c8ee7c317021a76e9ee7a6e6aaaec8a3581c91e",
        "commit_message": "New cassandra backend, small bugs, cosmetics, flakes (Issue #2782)",
        "commit_url": "https://github.com/celery/celery/commit/8c8ee7c317021a76e9ee7a6e6aaaec8a3581c91e",
        "buggy_code": "'new_cassandra': 'celery.backends.new_cassandra:NewCassandraBackend',",
        "fixed_code": "'new_cassandra': 'celery.backends.new_cassandra:CassandraBackend',",
        "patch": "@@ -30,7 +30,7 @@\n     'db': 'celery.backends.database:DatabaseBackend',\n     'database': 'celery.backends.database:DatabaseBackend',\n     'cassandra': 'celery.backends.cassandra:CassandraBackend',\n-    'new_cassandra': 'celery.backends.new_cassandra:NewCassandraBackend',\n+    'new_cassandra': 'celery.backends.new_cassandra:CassandraBackend',\n     'couchbase': 'celery.backends.couchbase:CouchBaseBackend',\n     'couchdb': 'celery.backends.couchdb:CouchDBBackend',\n     'riak': 'celery.backends.riak:RiakBackend',"
    },
    {
        "commit_id": "e489f3cf1aacf864479e19fde46361f79c073d1c",
        "commit_message": "[CI] Attempt to fix pypy3 build",
        "commit_url": "https://github.com/celery/celery/commit/e489f3cf1aacf864479e19fde46361f79c073d1c",
        "buggy_code": "except ImportError:",
        "fixed_code": "except (ImportError, OSError):",
        "patch": "@@ -32,7 +32,7 @@ def test_run_dump(self):\n     def test_run_top(self):\n         try:\n             import curses  # noqa\n-        except ImportError:\n+        except (ImportError, OSError):\n             raise SkipTest('curses monitor requires curses')\n \n         @_old_patch('celery.events.cursesmon', 'evtop',"
    },
    {
        "commit_id": "57db7c8dba44d86664ca8e0f75dce2a5a20454ce",
        "commit_message": "Merge pull request #2802 from azalea/patch-1\n\nFix ImportError",
        "commit_url": "https://github.com/celery/celery/commit/57db7c8dba44d86664ca8e0f75dce2a5a20454ce",
        "buggy_code": "'kombu.transport.django.KombuAppConfig',",
        "fixed_code": "'kombu.transport.django',",
        "patch": "@@ -132,7 +132,7 @@\n     'django.contrib.messages',\n     'django.contrib.staticfiles',\n     'django.contrib.admin',\n-    'kombu.transport.django.KombuAppConfig',\n+    'kombu.transport.django',\n     'demoapp',\n     # Uncomment the next line to enable the admin:\n     # 'django.contrib.admin',"
    },
    {
        "commit_id": "9def9bdab1759c1bcfd800a0d5429e385a8f66c0",
        "commit_message": "Fix ImportError\n\nWith 'kombu.transport.django.KombuAppConfig' in INSTALLED_APPS,\r\nrunning any manage.py command throws:\r\n\r\nImportError: No module named KombuAppConfig\r\n\r\nIt is fixed by changing 'kombu.transport.django.KombuAppConfig' to 'kombu.transport.django'",
        "commit_url": "https://github.com/celery/celery/commit/9def9bdab1759c1bcfd800a0d5429e385a8f66c0",
        "buggy_code": "'kombu.transport.django.KombuAppConfig',",
        "fixed_code": "'kombu.transport.django',",
        "patch": "@@ -132,7 +132,7 @@\n     'django.contrib.messages',\n     'django.contrib.staticfiles',\n     'django.contrib.admin',\n-    'kombu.transport.django.KombuAppConfig',\n+    'kombu.transport.django',\n     'demoapp',\n     # Uncomment the next line to enable the admin:\n     # 'django.contrib.admin',"
    },
    {
        "commit_id": "89a121158918f4053a8d6a5f10cfbe1c4598eb9b",
        "commit_message": "overzealous code fix removed",
        "commit_url": "https://github.com/celery/celery/commit/89a121158918f4053a8d6a5f10cfbe1c4598eb9b",
        "buggy_code": "'INSERT INTO %s (task_id, status, result,'''",
        "fixed_code": "'INSERT INTO '+self.table+''' (task_id, status, result,'''",
        "patch": "@@ -105,7 +105,7 @@ def _get_connection(self, write=False):\n             # We are forced to do concatenation below, as formatting would\n             # blow up on superficial %s that will be processed by Cassandra\n             self._write_stmt = cassandra.query.SimpleStatement(\n-                'INSERT INTO %s (task_id, status, result,'''\n+                'INSERT INTO '+self.table+''' (task_id, status, result,'''\n                 ''' date_done, traceback, children) VALUES'''\n                 ' (%s, %s, %s, %s, %s, %s) '+self.cqlexpires+';')\n             self._write_stmt.consistency_level = self.write_consistency"
    },
    {
        "commit_id": "6d4bc35d0003fa41d282bb6a7eb023300df22e1f",
        "commit_message": "overzealous code fix removed",
        "commit_url": "https://github.com/celery/celery/commit/6d4bc35d0003fa41d282bb6a7eb023300df22e1f",
        "buggy_code": "'INSERT INTO %s (task_id, status, result,'''",
        "fixed_code": "'INSERT INTO '+self.table+''' (task_id, status, result,'''",
        "patch": "@@ -105,7 +105,7 @@ def _get_connection(self, write=False):\n             # We are forced to do concatenation below, as formatting would\n             # blow up on superficial %s that will be processed by Cassandra\n             self._write_stmt = cassandra.query.SimpleStatement(\n-                'INSERT INTO %s (task_id, status, result,'''\n+                'INSERT INTO '+self.table+''' (task_id, status, result,'''\n                 ''' date_done, traceback, children) VALUES'''\n                 ' (%s, %s, %s, %s, %s, %s) '+self.cqlexpires+';')\n             self._write_stmt.consistency_level = self.write_consistency"
    },
    {
        "commit_id": "c0f492205bde9fae30841239dc5dc5d6b2e2a5ce",
        "commit_message": "Fixes typo \"unbound error: results\"",
        "commit_url": "https://github.com/celery/celery/commit/c0f492205bde9fae30841239dc5dc5d6b2e2a5ce",
        "buggy_code": "tasks, result = self._frozen",
        "fixed_code": "tasks, results = self._frozen",
        "patch": "@@ -391,7 +391,7 @@ def run(self, args=(), kwargs={}, group_id=None, chord=None,\n                 if args and not self.immutable else self.args)\n \n         if self._frozen:\n-            tasks, result = self._frozen\n+            tasks, results = self._frozen\n         else:\n             tasks, results = self.prepare_steps(\n                 args, self.tasks, root_id, link_error, app,"
    },
    {
        "commit_id": "7566d2dbe7483d0dd784da95597bfc33b652ceb5",
        "commit_message": "Fixes typo in docstring for Issue #817",
        "commit_url": "https://github.com/celery/celery/commit/7566d2dbe7483d0dd784da95597bfc33b652ceb5",
        "buggy_code": "is to always use ``raise self.replace_in_chord(...)`` to convey",
        "fixed_code": "is to always use ``raise self.replace(...)`` to convey",
        "patch": "@@ -741,7 +741,7 @@ def replace(self, sig):\n         :param sig: :class:`@signature`\n \n         Note: This will raise :exc:`~@Ignore`, so the best practice\n-        is to always use ``raise self.replace_in_chord(...)`` to convey\n+        is to always use ``raise self.replace(...)`` to convey\n         to the reader that the task will not continue after being replaced.\n \n         :param: Signature of new task."
    },
    {
        "commit_id": "05f84b34b1c7dc6ec1024b12cf32e266736375bc",
        "commit_message": "Fix issue mentioned in https://github.com/celery/celery/issues/1671\n\nSee the comment from @lance-burton on June 20, 2014.\n\nA nested group in an expression such as:\nc = (group(add.s(1,1),add.s(2,2))\n     | add.s(1)\n     | add.s(1)\n     | group(mul.s(1),mul.s(2)))\nres = c.apply_async().get()\n\nCauses an \"AttributeError: 'dict' object has no attribute 'type'\".",
        "commit_url": "https://github.com/celery/celery/commit/05f84b34b1c7dc6ec1024b12cf32e266736375bc",
        "buggy_code": "tasks = regen(tasks)",
        "fixed_code": "tasks = map(signature, regen(tasks))",
        "patch": "@@ -602,7 +602,7 @@ def _maybe_group(tasks):\n     elif isinstance(tasks, Signature):\n         tasks = [tasks]\n     else:\n-        tasks = regen(tasks)\n+        tasks = map(signature, regen(tasks))\n     return tasks\n \n "
    },
    {
        "commit_id": "e6ae13bd281e9a12a02ec051733f21a7a0a0a9c1",
        "commit_message": "Fix issue mentioned in https://github.com/celery/celery/issues/1671\n\nSee the comment from @lance-burton on June 20, 2014.\n\nA nested group in an expression such as:\nc = (group(add.s(1,1),add.s(2,2))\n     | add.s(1)\n     | add.s(1)\n     | group(mul.s(1),mul.s(2)))\nres = c.apply_async().get()\n\nCauses an \"AttributeError: 'dict' object has no attribute 'type'\".",
        "commit_url": "https://github.com/celery/celery/commit/e6ae13bd281e9a12a02ec051733f21a7a0a0a9c1",
        "buggy_code": "tasks = regen(tasks)",
        "fixed_code": "tasks = map(signature, regen(tasks))",
        "patch": "@@ -602,7 +602,7 @@ def _maybe_group(tasks):\n     elif isinstance(tasks, Signature):\n         tasks = [tasks]\n     else:\n-        tasks = regen(tasks)\n+        tasks = map(signature, regen(tasks))\n     return tasks\n \n "
    },
    {
        "commit_id": "1295056a107e2b558ad6d1930d3145bee18e7b0e",
        "commit_message": "Merge pull request #2681 from TakesxiSximada/fix-docstring-typo\n\nfixes docstring typo",
        "commit_url": "https://github.com/celery/celery/commit/1295056a107e2b558ad6d1930d3145bee18e7b0e",
        "buggy_code": "\"\"\"Mark task as executed with failure. Stores the execption.\"\"\"",
        "fixed_code": "\"\"\"Mark task as executed with failure. Stores the exception.\"\"\"",
        "patch": "@@ -118,7 +118,7 @@ def mark_as_done(self, task_id, result, request=None):\n                                  status=states.SUCCESS, request=request)\n \n     def mark_as_failure(self, task_id, exc, traceback=None, request=None):\n-        \"\"\"Mark task as executed with failure. Stores the execption.\"\"\"\n+        \"\"\"Mark task as executed with failure. Stores the exception.\"\"\"\n         return self.store_result(task_id, exc, status=states.FAILURE,\n                                  traceback=traceback, request=request)\n "
    },
    {
        "commit_id": "b339b57e5c9222fefd2ebfa747b42dbb6b19cf9c",
        "commit_message": "Merge pull request #2598 from ByteInternet/fix-exception-marshalling-with-json-serializer\n\nFix Exception marshalling with JSON serializer",
        "commit_url": "https://github.com/celery/celery/commit/b339b57e5c9222fefd2ebfa747b42dbb6b19cf9c",
        "buggy_code": "results[meta['task_id']] = meta",
        "fixed_code": "results[meta['task_id']] = self.meta_from_decoded(meta)",
        "patch": "@@ -195,7 +195,7 @@ def drain_events(self, connection, consumer,\n \n         def callback(meta, message):\n             if meta['status'] in states.READY_STATES:\n-                results[meta['task_id']] = meta\n+                results[meta['task_id']] = self.meta_from_decoded(meta)\n \n         consumer.callbacks[:] = [callback]\n         time_start = now()"
    },
    {
        "commit_id": "33e72fdbc7b07fc26d13bcdc36fb6f42c8291b66",
        "commit_message": "Fix Exception marshalling with JSON serializer\n\nThe code in `drain_events` in `amqp.py` naively sets the result dict\nto a plain meta dict without transforming the dict structure back into\nan actual Exception through `exception_to_python`.\n\nWhen a task raises an exception, `AsyncResult.get` tries to raise the\nexception, which is actually still a dict and fails with:\n\n```\nTypeError: exceptions must be old-style classes or derived from\nBaseException, not dict\n```\n\nThis patch makes `drain_events` call `meta_from_decoded` which is\nresponsible for that, just like it is called in `get_many`. Then,\nraising the exception in `AsyncResult.get` works fine.\n\nTo reproduce, see the testcase in #2518. Then, apply the patch and see\nstuff start to work again.\n\ncloses #2518",
        "commit_url": "https://github.com/celery/celery/commit/33e72fdbc7b07fc26d13bcdc36fb6f42c8291b66",
        "buggy_code": "results[meta['task_id']] = meta",
        "fixed_code": "results[meta['task_id']] = self.meta_from_decoded(meta)",
        "patch": "@@ -195,7 +195,7 @@ def drain_events(self, connection, consumer,\n \n         def callback(meta, message):\n             if meta['status'] in states.READY_STATES:\n-                results[meta['task_id']] = meta\n+                results[meta['task_id']] = self.meta_from_decoded(meta)\n \n         consumer.callbacks[:] = [callback]\n         time_start = now()"
    },
    {
        "commit_id": "dad37c741dbc4374b3ce231add6448b11f5e22fa",
        "commit_message": "Process import change from billiard since 3.4 multiprocessing Fix #2530\n\n[https://github.com/celery/billiard/commit/c7eedbd0ee1498e76d4fa1affac5b\n1a275660ee7]",
        "commit_url": "https://github.com/celery/celery/commit/dad37c741dbc4374b3ce231add6448b11f5e22fa",
        "buggy_code": "from billiard.process import Process",
        "fixed_code": "from billiard.context import Process",
        "patch": "@@ -21,7 +21,7 @@\n from threading import Event, Thread\n \n from billiard import ensure_multiprocessing\n-from billiard.process import Process\n+from billiard.context import Process\n from billiard.common import reset_signals\n from kombu.utils import cached_property, reprcall\n from kombu.utils.functional import maybe_evaluate"
    },
    {
        "commit_id": "2b03a7f66fd4abe1f4df171b4283457ad3e92d44",
        "commit_message": "Merge pull request #2569 from siliconbrain/patch-1\n\nfix typo",
        "commit_url": "https://github.com/celery/celery/commit/2b03a7f66fd4abe1f4df171b4283457ad3e92d44",
        "buggy_code": "raise Exception('Your backend not suppored on_message callback')",
        "fixed_code": "raise Exception('Your backend not supported on_message callback')",
        "patch": "@@ -633,7 +633,7 @@ def join(self, timeout=None, propagate=True, interval=0.5,\n         remaining = None\n \n         if on_message is not None:\n-            raise Exception('Your backend not suppored on_message callback')\n+            raise Exception('Your backend not supported on_message callback')\n \n         results = []\n         for result in self.results:"
    },
    {
        "commit_id": "d76838ab311f6869ab76354a1127f1aa663c796f",
        "commit_message": "fix typo",
        "commit_url": "https://github.com/celery/celery/commit/d76838ab311f6869ab76354a1127f1aa663c796f",
        "buggy_code": "raise Exception('Your backend not suppored on_message callback')",
        "fixed_code": "raise Exception('Your backend not supported on_message callback')",
        "patch": "@@ -633,7 +633,7 @@ def join(self, timeout=None, propagate=True, interval=0.5,\n         remaining = None\n \n         if on_message is not None:\n-            raise Exception('Your backend not suppored on_message callback')\n+            raise Exception('Your backend not supported on_message callback')\n \n         results = []\n         for result in self.results:"
    },
    {
        "commit_id": "2522eb0a6d717b496c04f2d41bbf9c3b0200d9b6",
        "commit_message": "test fix",
        "commit_url": "https://github.com/celery/celery/commit/2522eb0a6d717b496c04f2d41bbf9c3b0200d9b6",
        "buggy_code": "b.get_many(tids, timeout=1, on_message=on_message)",
        "fixed_code": "res = list(b.get_many(tids, timeout=1, on_message=on_message))",
        "patch": "@@ -321,7 +321,7 @@ def on_message(body):\n                 on_message_results[body['task_id']] = []\n             on_message_results[body['task_id']].append( (body['status'], body['result']) )\n \n-        b.get_many(tids, timeout=1, on_message=on_message)\n+        res = list(b.get_many(tids, timeout=1, on_message=on_message))\n         self.assertEqual(sorted(on_message_results), sorted(expected_messages))\n \n     def test_get_many_raises_outer_block(self):"
    },
    {
        "commit_id": "3adcdc35eec676fb4bc5870de93f06d308b573b8",
        "commit_message": "Merge pull request #2438 from gthb/patch-3\n\nFix typo in COMPAT_MODULES",
        "commit_url": "https://github.com/celery/celery/commit/3adcdc35eec676fb4bc5870de93f06d308b573b8",
        "buggy_code": "'setup_loggig_subsystem': 'log.setup_logging_subsystem',",
        "fixed_code": "'setup_logging_subsystem': 'log.setup_logging_subsystem',",
        "patch": "@@ -77,7 +77,7 @@ def _compat_periodic_task_decorator(*args, **kwargs):\n         'log': {\n             'get_default_logger': 'log.get_default_logger',\n             'setup_logger': 'log.setup_logger',\n-            'setup_loggig_subsystem': 'log.setup_logging_subsystem',\n+            'setup_logging_subsystem': 'log.setup_logging_subsystem',\n             'redirect_stdouts_to_logger': 'log.redirect_stdouts_to_logger',\n         },\n         'messaging': {"
    },
    {
        "commit_id": "f56461b6f1164bc2caf6f7bde0126a21c5ff7d7c",
        "commit_message": "Merge pull request #2454 from lukeburden/master\n\nFixes issue #2453",
        "commit_url": "https://github.com/celery/celery/commit/f56461b6f1164bc2caf6f7bde0126a21c5ff7d7c",
        "buggy_code": "funs = [conn.close for conn in self._db.connections]",
        "fixed_code": "funs = [conn.close for conn in self._db.connections.all()]",
        "patch": "@@ -227,7 +227,7 @@ def close_database(self, **kwargs):\n \n     def _close_database(self):\n         try:\n-            funs = [conn.close for conn in self._db.connections]\n+            funs = [conn.close for conn in self._db.connections.all()]\n         except AttributeError:\n             if hasattr(self._db, 'close_old_connections'):  # django 1.6\n                 funs = [self._db.close_old_connections]"
    },
    {
        "commit_id": "3c25f3abddeab4c1efae037f164da26d5a8e6bbf",
        "commit_message": "Fixes issue #2453 where django db connections are not closed during worker initialisation.",
        "commit_url": "https://github.com/celery/celery/commit/3c25f3abddeab4c1efae037f164da26d5a8e6bbf",
        "buggy_code": "funs = [conn.close for conn in self._db.connections]",
        "fixed_code": "funs = [conn.close for conn in self._db.connections.all()]",
        "patch": "@@ -227,7 +227,7 @@ def close_database(self, **kwargs):\n \n     def _close_database(self):\n         try:\n-            funs = [conn.close for conn in self._db.connections]\n+            funs = [conn.close for conn in self._db.connections.all()]\n         except AttributeError:\n             if hasattr(self._db, 'close_old_connections'):  # django 1.6\n                 funs = [self._db.close_old_connections]"
    },
    {
        "commit_id": "4e1909e35b21b791c560602df7434c22c998e861",
        "commit_message": "Fix typo in COMPAT_MODULES\n\n(Fixing this since I happened to came across it)",
        "commit_url": "https://github.com/celery/celery/commit/4e1909e35b21b791c560602df7434c22c998e861",
        "buggy_code": "'setup_loggig_subsystem': 'log.setup_logging_subsystem',",
        "fixed_code": "'setup_logging_subsystem': 'log.setup_logging_subsystem',",
        "patch": "@@ -77,7 +77,7 @@ def _compat_periodic_task_decorator(*args, **kwargs):\n         'log': {\n             'get_default_logger': 'log.get_default_logger',\n             'setup_logger': 'log.setup_logger',\n-            'setup_loggig_subsystem': 'log.setup_logging_subsystem',\n+            'setup_logging_subsystem': 'log.setup_logging_subsystem',\n             'redirect_stdouts_to_logger': 'log.redirect_stdouts_to_logger',\n         },\n         'messaging': {"
    },
    {
        "commit_id": "65f859bab87ac9c7f7a7e39d4e4da211a091754f",
        "commit_message": "Merge pull request #2360 from tfrench/master\n\nRedis backend: max connection issue",
        "commit_url": "https://github.com/celery/celery/commit/65f859bab87ac9c7f7a7e39d4e4da211a091754f",
        "buggy_code": "'max_connections': max_connections,",
        "fixed_code": "'max_connections': self.max_connections,",
        "patch": "@@ -85,7 +85,7 @@ def _get(key):\n             'port': _get('PORT') or 6379,\n             'db': _get('DB') or 0,\n             'password': _get('PASSWORD'),\n-            'max_connections': max_connections,\n+            'max_connections': self.max_connections,\n         }\n         if url:\n             self.connparams = self._params_from_url(url, self.connparams)"
    },
    {
        "commit_id": "77d7eb06e3aea636e0f2e1388c491181b955358f",
        "commit_message": "Do not rely on billiard.util being available (Issue #2345)",
        "commit_url": "https://github.com/celery/celery/commit/77d7eb06e3aea636e0f2e1388c491181b955358f",
        "buggy_code": "from billiard import current_process",
        "fixed_code": "from billiard.process import current_process",
        "patch": "@@ -20,7 +20,7 @@\n \n from functools import partial\n \n-from billiard import current_process\n+from billiard.process import current_process\n from kombu.utils.encoding import safe_str\n from kombu.utils.url import maybe_sanitize_url\n "
    },
    {
        "commit_id": "77d7eb06e3aea636e0f2e1388c491181b955358f",
        "commit_message": "Do not rely on billiard.util being available (Issue #2345)",
        "commit_url": "https://github.com/celery/celery/commit/77d7eb06e3aea636e0f2e1388c491181b955358f",
        "buggy_code": "from billiard import current_process",
        "fixed_code": "from billiard.process import current_process",
        "patch": "@@ -43,7 +43,7 @@ def add(x, y):\n \n from pdb import Pdb\n \n-from billiard import current_process\n+from billiard.process import current_process\n \n from celery.five import range\n "
    },
    {
        "commit_id": "77d7eb06e3aea636e0f2e1388c491181b955358f",
        "commit_message": "Do not rely on billiard.util being available (Issue #2345)",
        "commit_url": "https://github.com/celery/celery/commit/77d7eb06e3aea636e0f2e1388c491181b955358f",
        "buggy_code": "from billiard import current_process",
        "fixed_code": "from billiard.process import current_process",
        "patch": "@@ -6,7 +6,7 @@\n \n from functools import wraps\n \n-from billiard import current_process\n+from billiard.process import current_process\n from kombu import Exchange, Queue\n \n from celery import platforms"
    },
    {
        "commit_id": "77d7eb06e3aea636e0f2e1388c491181b955358f",
        "commit_message": "Do not rely on billiard.util being available (Issue #2345)",
        "commit_url": "https://github.com/celery/celery/commit/77d7eb06e3aea636e0f2e1388c491181b955358f",
        "buggy_code": "from billiard import current_process",
        "fixed_code": "from billiard.process import current_process",
        "patch": "@@ -90,7 +90,7 @@ def task_ready(request):\n if C_BENCH:  # pragma: no cover\n     import atexit\n \n-    from billiard import current_process\n+    from billiard.process import current_process\n     from celery.five import monotonic\n     from celery.utils.debug import memdump, sample_mem\n "
    },
    {
        "commit_id": "50dd2abb383b615a37b37cf2826c23e853af2522",
        "commit_message": "Merge pull request #2309 from kracekumar/patch-1\n\nAdded missing back tick.",
        "commit_url": "https://github.com/celery/celery/commit/50dd2abb383b615a37b37cf2826c23e853af2522",
        "buggy_code": ":keyword producer: :class:~@kombu.Producer` instance to use.",
        "fixed_code": ":keyword producer: :class:`~@kombu.Producer` instance to use.",
        "patch": "@@ -432,7 +432,7 @@ def apply_async(self, args=None, kwargs=None, task_id=None, producer=None,\n         :keyword link_error: A single, or a list of tasks to apply\n                       if an error occurs while executing the task.\n \n-        :keyword producer: :class:~@kombu.Producer` instance to use.\n+        :keyword producer: :class:`~@kombu.Producer` instance to use.\n         :keyword add_to_parent: If set to True (default) and the task\n             is applied while executing another task, then the result\n             will be appended to the parent tasks ``request.children``"
    },
    {
        "commit_id": "78d39b61567c5d754e45456833f799e36bc5c5be",
        "commit_message": "Merge pull request #2285 from silverfix/patch-1\n\nFixed bug on 'raise exc'",
        "commit_url": "https://github.com/celery/celery/commit/78d39b61567c5d754e45456833f799e36bc5c5be",
        "buggy_code": "raise exc()",
        "fixed_code": "raise exc",
        "patch": "@@ -569,7 +569,7 @@ def retry(self, args=None, kwargs=None, exc=None, throw=True,\n                 # first try to reraise the original exception\n                 maybe_reraise()\n                 # or if not in an except block then raise the custom exc.\n-                raise exc()\n+                raise exc\n             raise self.MaxRetriesExceededError(\n                 \"Can't retry {0}[{1}] args:{2} kwargs:{3}\".format(\n                     self.name, request.id, S.args, S.kwargs))"
    },
    {
        "commit_id": "2493576c753eb493c808401dafa49e9b4af76ef9",
        "commit_message": "Fixed bug on 'raise exc'\n\nAt line 572: raise exc() has to be raise exc since exc is an instance not a class",
        "commit_url": "https://github.com/celery/celery/commit/2493576c753eb493c808401dafa49e9b4af76ef9",
        "buggy_code": "raise exc()",
        "fixed_code": "raise exc",
        "patch": "@@ -569,7 +569,7 @@ def retry(self, args=None, kwargs=None, exc=None, throw=True,\n                 # first try to reraise the original exception\n                 maybe_reraise()\n                 # or if not in an except block then raise the custom exc.\n-                raise exc()\n+                raise exc\n             raise self.MaxRetriesExceededError(\n                 \"Can't retry {0}[{1}] args:{2} kwargs:{3}\".format(\n                     self.name, request.id, S.args, S.kwargs))"
    },
    {
        "commit_id": "f7b29f637e1b83c6e756164d5396d8fdae882ab5",
        "commit_message": "Fix issue mentioned in https://github.com/celery/celery/issues/1671\n\nSee the comment from @lance-burton on June 20, 2014.\n\nA nested group in an expression such as:\nc = (group(add.s(1,1),add.s(2,2))\n     | add.s(1)\n     | add.s(1)\n     | group(mul.s(1),mul.s(2)))\nres = c.apply_async().get()\n\nCauses an \"AttributeError: 'dict' object has no attribute 'type'\".",
        "commit_url": "https://github.com/celery/celery/commit/f7b29f637e1b83c6e756164d5396d8fdae882ab5",
        "buggy_code": "tasks = regen(tasks)",
        "fixed_code": "tasks = map(signature, regen(tasks))",
        "patch": "@@ -572,7 +572,7 @@ def _maybe_group(tasks):\n     elif isinstance(tasks, Signature):\n         tasks = [tasks]\n     else:\n-        tasks = regen(tasks)\n+        tasks = map(signature, regen(tasks))\n     return tasks\n \n "
    },
    {
        "commit_id": "4eed4c2a916a3b323f82d745dfb5fde1763291a9",
        "commit_message": "Worker: Changed loglevel for unrecoverable error to critical.",
        "commit_url": "https://github.com/celery/celery/commit/4eed4c2a916a3b323f82d745dfb5fde1763291a9",
        "buggy_code": "logger.error('Unrecoverable error: %r', exc, exc_info=True)",
        "fixed_code": "logger.critical('Unrecoverable error: %r', exc, exc_info=True)",
        "patch": "@@ -209,7 +209,7 @@ def start(self):\n         except WorkerTerminate:\n             self.terminate()\n         except Exception as exc:\n-            logger.error('Unrecoverable error: %r', exc, exc_info=True)\n+            logger.critical('Unrecoverable error: %r', exc, exc_info=True)\n             self.stop(exitcode=EX_FAILURE)\n         except SystemExit as exc:\n             self.stop(exitcode=exc.code)"
    },
    {
        "commit_id": "d6ae1a2be401a3bfd53cd1e68ee0a1226f8848e3",
        "commit_message": "Fix test for working_directory",
        "commit_url": "https://github.com/celery/celery/commit/d6ae1a2be401a3bfd53cd1e68ee0a1226f8848e3",
        "buggy_code": "working_directory='/',",
        "fixed_code": "working_directory=None,",
        "patch": "@@ -85,7 +85,7 @@ def test_execute_from_commandline(self, detach, exit):\n         detach.assert_called_with(\n             path=x.execv_path, uid=None, gid=None,\n             umask=0, fake=False, logfile='/var/log', pidfile='celeryd.pid',\n-            working_directory='/',\n+            working_directory=None,\n             argv=x.execv_argv + [\n                 '-c', '1', '-lDEBUG',\n                 '--logfile=/var/log', '--pidfile=celeryd.pid',"
    },
    {
        "commit_id": "06bb335af95ecf13172fa12b252659c5207af44d",
        "commit_message": "Merge pull request #2007 from malinoff/fix-worker-argv-run\n\nFixed wrong arguments passed to maybe_detach",
        "commit_url": "https://github.com/celery/celery/commit/06bb335af95ecf13172fa12b252659c5207af44d",
        "buggy_code": "self.maybe_detach([command] + sys.argv[1:])",
        "fixed_code": "self.maybe_detach([command] + argv)",
        "patch": "@@ -175,7 +175,7 @@ def run_from_argv(self, prog_name, argv=None, command=None):\n         # parse options before detaching so errors can be handled.\n         options, args = self.prepare_args(\n             *self.parse_options(prog_name, argv, command))\n-        self.maybe_detach([command] + sys.argv[1:])\n+        self.maybe_detach([command] + argv)\n         return self(*args, **options)\n \n     def maybe_detach(self, argv, dopts=['-D', '--detach']):"
    },
    {
        "commit_id": "90ce8a4d4da75a2c1bfbd0f1d83f91071202e0f6",
        "commit_message": "Fix value assertion - should be 2 (1-3+2*2=2)",
        "commit_url": "https://github.com/celery/celery/commit/90ce8a4d4da75a2c1bfbd0f1d83f91071202e0f6",
        "buggy_code": "self.assertEqual(x.value, 3)",
        "fixed_code": "self.assertEqual(x.value, 2)",
        "patch": "@@ -83,7 +83,7 @@ def test_grow_shrink(self):\n         x.grow(2)\n         cb2.assert_called_with(2)\n         cb3.assert_called_with(3)\n-        self.assertEqual(x.value, 3)\n+        self.assertEqual(x.value, 2)\n         self.assertEqual(x.initial_value, 3)\n \n         self.assertFalse(x._waiting)"
    },
    {
        "commit_id": "30d1b2568d1b29dcb292adbef0deab8c1ca1ddf4",
        "commit_message": "[Py3] Fixes internal error reporting on Python 3",
        "commit_url": "https://github.com/celery/celery/commit/30d1b2568d1b29dcb292adbef0deab8c1ca1ddf4",
        "buggy_code": "_value = task.backend.prepare_exception(exc)",
        "fixed_code": "_value = task.backend.prepare_exception(exc, 'pickle')",
        "patch": "@@ -341,7 +341,7 @@ def eager_trace_task(task, uuid, args, kwargs, request=None, **opts):\n def report_internal_error(task, exc):\n     _type, _value, _tb = sys.exc_info()\n     try:\n-        _value = task.backend.prepare_exception(exc)\n+        _value = task.backend.prepare_exception(exc, 'pickle')\n         exc_info = ExceptionInfo((_type, _value, _tb), internal=True)\n         warn(RuntimeWarning(\n             'Exception raised outside body: {0!r}:\\n{1}'.format("
    },
    {
        "commit_id": "3eafba5a4903969372b2cedfa3e361eddfa19b8f",
        "commit_message": "Ability to use one log file per child process using format keys %i/%I\n\nStarting from 3.2 there will be one log file per process, but that would be\nuseful even in this verison and is very hard to accomplish by configuration,\nso this patch introduces a new format specifier for the logfile name.\n\nNote that the numbers will stay within the process limit even if processes exit or\nif autoscale/maxtasksperchild/time limits are used.  I.e. the number is the\n*process index* not the process count or pid.\n\nThe new format specifiers are:\n\n* ``%i`` -  Pool process index or 0 if MainProcess.\n\n    With ``-n worker1@example.com -c2 -f %n-%i.log`` this will result in\n    three logfiles:\n\n        - ``worker1-0.log`` (main process)\n        - ``worker1-1.log`` (pool process 1)\n        - ``worker1-2.log`` (pool process 2)\n\n* ``%I`` -  Pool process index with separator.\n\n    With ``-n worker1@example.com -c2 -f %n%i.log` this will result in\n    three logfiles:\n\n        - ``worker1.log`` (main process)\n        - ``worker1-1.log`` (pool process 1)\n        - ``worker1-2.log`` (pool process 2)",
        "commit_url": "https://github.com/celery/celery/commit/3eafba5a4903969372b2cedfa3e361eddfa19b8f",
        "buggy_code": "redirect_stdouts=False, colorize=colorize,",
        "fixed_code": "redirect_stdouts=False, colorize=colorize, hostname=self.hostname,",
        "patch": "@@ -181,7 +181,7 @@ def setup_logging(self, colorize=None):\n             colorize = not self.no_color\n         return self.app.log.setup(\n             self.loglevel, self.logfile,\n-            redirect_stdouts=False, colorize=colorize,\n+            redirect_stdouts=False, colorize=colorize, hostname=self.hostname,\n         )\n \n     def purge_messages(self):"
    },
    {
        "commit_id": "c832d322356e505d76548b55dfa707ef91435a24",
        "commit_message": "Merge pull request #1902 from malinoff/patch-1\n\n\"Falsy\" value is always substituted",
        "commit_url": "https://github.com/celery/celery/commit/c832d322356e505d76548b55dfa707ef91435a24",
        "buggy_code": "raise ImproperlyConfigured(ERR_ENVVAR_NOT_SET.format(module_name))",
        "fixed_code": "raise ImproperlyConfigured(ERR_ENVVAR_NOT_SET.format(variable_name))",
        "patch": "@@ -273,7 +273,7 @@ def config_from_envvar(self, variable_name, silent=False, force=False):\n         if not module_name:\n             if silent:\n                 return False\n-            raise ImproperlyConfigured(ERR_ENVVAR_NOT_SET.format(module_name))\n+            raise ImproperlyConfigured(ERR_ENVVAR_NOT_SET.format(variable_name))\n         return self.config_from_object(module_name, silent=silent, force=force)\n \n     def config_from_cmdline(self, argv, namespace='celery'):"
    },
    {
        "commit_id": "32331cf1590221cc7e2e3ef7c37e0588033f67a3",
        "commit_message": "Merge pull request #1832 from kaizoku/comment_typo\n\nfix comment typo",
        "commit_url": "https://github.com/celery/celery/commit/32331cf1590221cc7e2e3ef7c37e0588033f67a3",
        "buggy_code": "`{receriverkey (id): weakref(receiver)}` mappings.",
        "fixed_code": "`{receiverkey (id): weakref(receiver)}` mappings.",
        "patch": "@@ -23,7 +23,7 @@ class Signal(object):  # pragma: no cover\n \n     .. attribute:: receivers\n         Internal attribute, holds a dictionary of\n-        `{receriverkey (id): weakref(receiver)}` mappings.\n+        `{receiverkey (id): weakref(receiver)}` mappings.\n \n     \"\"\"\n "
    },
    {
        "commit_id": "a0057bed6819c979a2538f75bad53f25702acec1",
        "commit_message": "Makes inspect.getargs(@task(x)) work. Issue #1833",
        "commit_url": "https://github.com/celery/celery/commit/a0057bed6819c979a2538f75bad53f25702acec1",
        "buggy_code": "but the list might become to big.",
        "fixed_code": "but the list might become too big.",
        "patch": "@@ -555,7 +555,7 @@ class LimitedSet(object):\n     \"\"\"Kind-of Set with limitations.\n \n     Good for when you need to test for membership (`a in set`),\n-    but the list might become to big.\n+    but the list might become too big.\n \n     :keyword maxlen: Maximum number of members before we start\n                      evicting expired members."
    },
    {
        "commit_id": "59e44ae6300e5b39b3306bc2cdc76a0b85b3d418",
        "commit_message": "Merge pull request #1831 from eyvoro/patch-1\n\nFixed basic.publish command in celery amqp program",
        "commit_url": "https://github.com/celery/celery/commit/59e44ae6300e5b39b3306bc2cdc76a0b85b3d418",
        "buggy_code": "'basic.publish': Spec(('msg', Message),",
        "fixed_code": "'basic.publish': Spec(('msg', str),",
        "patch": "@@ -175,7 +175,7 @@ class AMQShell(cmd.Cmd):\n         'basic.get': Spec(('queue', str),\n                           ('no_ack', bool, 'off'),\n                           returns=dump_message),\n-        'basic.publish': Spec(('msg', Message),\n+        'basic.publish': Spec(('msg', str),\n                               ('exchange', str),\n                               ('routing_key', str),\n                               ('mandatory', bool, 'no'),"
    },
    {
        "commit_id": "9ebb7ac0e1b3cc3d1c5a1c67683cce57cc780543",
        "commit_message": "fix comment typo",
        "commit_url": "https://github.com/celery/celery/commit/9ebb7ac0e1b3cc3d1c5a1c67683cce57cc780543",
        "buggy_code": "`{receriverkey (id): weakref(receiver)}` mappings.",
        "fixed_code": "`{receiverkey (id): weakref(receiver)}` mappings.",
        "patch": "@@ -23,7 +23,7 @@ class Signal(object):  # pragma: no cover\n \n     .. attribute:: receivers\n         Internal attribute, holds a dictionary of\n-        `{receriverkey (id): weakref(receiver)}` mappings.\n+        `{receiverkey (id): weakref(receiver)}` mappings.\n \n     \"\"\"\n "
    },
    {
        "commit_id": "b6e3ca1568b7b9b35b950abe7062144c99d9050f",
        "commit_message": "fix: chains ignore options when apply_async()",
        "commit_url": "https://github.com/celery/celery/commit/b6e3ca1568b7b9b35b950abe7062144c99d9050f",
        "buggy_code": "tasks[0].apply_async()",
        "fixed_code": "tasks[0].apply_async(**options)",
        "patch": "@@ -301,7 +301,7 @@ def apply_async(self, args=(), kwargs={}, group_id=None, chord=None,\n             if link_error:\n                 for task in tasks:\n                     task.set(link_error=link_error)\n-            tasks[0].apply_async()\n+            tasks[0].apply_async(**options)\n             return result\n \n         def apply(self, args=(), kwargs={}, signature=maybe_signature,"
    },
    {
        "commit_id": "2028b696c50bf632b5e7a5f2b64384bb757c0633",
        "commit_message": "Merge pull request #1759 from skovorodkin/master\n\nFix typo in docstring of utils.deprecated decorator",
        "commit_url": "https://github.com/celery/celery/commit/2028b696c50bf632b5e7a5f2b64384bb757c0633",
        "buggy_code": ":keyword removed:  Future version when this feature will be removed.",
        "fixed_code": ":keyword removal:  Future version when this feature will be removed.",
        "patch": "@@ -96,7 +96,7 @@ def deprecated(deprecation=None, removal=None,\n     :keyword deprecation: Version that marks first deprecation, if this\n       argument is not set a ``PendingDeprecationWarning`` will be emitted\n       instead.\n-    :keyword removed:  Future version when this feature will be removed.\n+    :keyword removal:  Future version when this feature will be removed.\n     :keyword alternative:  Instructions for an alternative solution (if any).\n     :keyword description: Description of what is being deprecated.\n "
    },
    {
        "commit_id": "1faa3a893c8a444995d7ee36f6c478f00cb867ac",
        "commit_message": "Fix typo in docstring of utils.deprecated decorator",
        "commit_url": "https://github.com/celery/celery/commit/1faa3a893c8a444995d7ee36f6c478f00cb867ac",
        "buggy_code": ":keyword removed:  Future version when this feature will be removed.",
        "fixed_code": ":keyword removal:  Future version when this feature will be removed.",
        "patch": "@@ -96,7 +96,7 @@ def deprecated(deprecation=None, removal=None,\n     :keyword deprecation: Version that marks first deprecation, if this\n       argument is not set a ``PendingDeprecationWarning`` will be emitted\n       instead.\n-    :keyword removed:  Future version when this feature will be removed.\n+    :keyword removal:  Future version when this feature will be removed.\n     :keyword alternative:  Instructions for an alternative solution (if any).\n     :keyword description: Description of what is being deprecated.\n "
    },
    {
        "commit_id": "3268526a5edcfd21707ee52ca05a8c1fd41177fd",
        "commit_message": "Fixes bug in utcoffset (drift warning).  Closes #1743",
        "commit_url": "https://github.com/celery/celery/commit/3268526a5edcfd21707ee52ca05a8c1fd41177fd",
        "buggy_code": "return (__timezone__ + __altzone__) // 3600",
        "fixed_code": "return __altzone__ // 3600",
        "patch": "@@ -335,7 +335,7 @@ def _fields(self, **extra):\n \n def utcoffset():\n     if _time.daylight:\n-        return (__timezone__ + __altzone__) // 3600\n+        return __altzone__ // 3600\n     return __timezone__ // 3600\n \n "
    },
    {
        "commit_id": "d82c304c7ac54e922d63169ac85f3c4b73f4ce9c",
        "commit_message": "Merge pull request #1719 from ionelmc/patch-1\n\nFix _set_task_join_will_block to actually use argument.",
        "commit_url": "https://github.com/celery/celery/commit/d82c304c7ac54e922d63169ac85f3c4b73f4ce9c",
        "buggy_code": "_task_join_will_block = True",
        "fixed_code": "_task_join_will_block = blocks",
        "patch": "@@ -58,7 +58,7 @@ def __iter__(self):\n \n def _set_task_join_will_block(blocks):\n     global _task_join_will_block\n-    _task_join_will_block = True\n+    _task_join_will_block = blocks\n \n \n def task_join_will_block():"
    },
    {
        "commit_id": "99709a9714e1a646138c73aaac643e7818c0318a",
        "commit_message": "Fix _set_task_join_will_block to actually use argument.",
        "commit_url": "https://github.com/celery/celery/commit/99709a9714e1a646138c73aaac643e7818c0318a",
        "buggy_code": "_task_join_will_block = True",
        "fixed_code": "_task_join_will_block = blocks",
        "patch": "@@ -58,7 +58,7 @@ def __iter__(self):\n \n def _set_task_join_will_block(blocks):\n     global _task_join_will_block\n-    _task_join_will_block = True\n+    _task_join_will_block = blocks\n \n \n def task_join_will_block():"
    },
    {
        "commit_id": "36393ade1f76d80be0509aa92c0728024f5c1e13",
        "commit_message": "Merge pull request #1654 from nadad/master\n\nFixed a little syntax error in string formatting in beat.py",
        "commit_url": "https://github.com/celery/celery/commit/36393ade1f76d80be0509aa92c0728024f5c1e13",
        "buggy_code": "entry, exc)), sys.exc_info()[2])",
        "fixed_code": "entry, exc=exc)), sys.exc_info()[2])",
        "patch": "@@ -244,7 +244,7 @@ def apply_async(self, entry, publisher=None, **kwargs):\n         except Exception as exc:\n             reraise(SchedulingError, SchedulingError(\n                 \"Couldn't apply scheduled task {0.name}: {exc}\".format(\n-                    entry, exc)), sys.exc_info()[2])\n+                    entry, exc=exc)), sys.exc_info()[2])\n         finally:\n             if self.should_sync():\n                 self._do_sync()"
    },
    {
        "commit_id": "b27b022c99c390ded4d0d7bbf12b64ad6c1a9423",
        "commit_message": "Fixed a little syntax error in string formatting in beat.py",
        "commit_url": "https://github.com/celery/celery/commit/b27b022c99c390ded4d0d7bbf12b64ad6c1a9423",
        "buggy_code": "entry, exc)), sys.exc_info()[2])",
        "fixed_code": "entry, exc=exc)), sys.exc_info()[2])",
        "patch": "@@ -244,7 +244,7 @@ def apply_async(self, entry, publisher=None, **kwargs):\n         except Exception as exc:\n             reraise(SchedulingError, SchedulingError(\n                 \"Couldn't apply scheduled task {0.name}: {exc}\".format(\n-                    entry, exc)), sys.exc_info()[2])\n+                    entry, exc=exc)), sys.exc_info()[2])\n         finally:\n             if self.should_sync():\n                 self._do_sync()"
    },
    {
        "commit_id": "9c3fe17e7faa5389a01992468877490fa23c8d3c",
        "commit_message": "Fixes Unicode error in celery worker.  Closes celery/kombu#274",
        "commit_url": "https://github.com/celery/celery/commit/9c3fe17e7faa5389a01992468877490fa23c8d3c",
        "buggy_code": "from __future__ import absolute_import",
        "fixed_code": "from __future__ import absolute_import, unicode_literals",
        "patch": "@@ -10,7 +10,7 @@\n     and so on.\n \n \"\"\"\n-from __future__ import absolute_import\n+from __future__ import absolute_import, unicode_literals\n \n import socket\n import sys"
    },
    {
        "commit_id": "9c3fe17e7faa5389a01992468877490fa23c8d3c",
        "commit_message": "Fixes Unicode error in celery worker.  Closes celery/kombu#274",
        "commit_url": "https://github.com/celery/celery/commit/9c3fe17e7faa5389a01992468877490fa23c8d3c",
        "buggy_code": "from __future__ import absolute_import, print_function",
        "fixed_code": "from __future__ import absolute_import, print_function, unicode_literals",
        "patch": "@@ -5,7 +5,7 @@\n .. program:: celery amqp\n \n \"\"\"\n-from __future__ import absolute_import, print_function\n+from __future__ import absolute_import, print_function, unicode_literals\n \n import cmd\n import sys"
    },
    {
        "commit_id": "9c3fe17e7faa5389a01992468877490fa23c8d3c",
        "commit_message": "Fixes Unicode error in celery worker.  Closes celery/kombu#274",
        "commit_url": "https://github.com/celery/celery/commit/9c3fe17e7faa5389a01992468877490fa23c8d3c",
        "buggy_code": "from __future__ import absolute_import, print_function",
        "fixed_code": "from __future__ import absolute_import, print_function, unicode_literals",
        "patch": "@@ -63,7 +63,7 @@\n     Optional directory to change to after detaching.\n \n \"\"\"\n-from __future__ import absolute_import, print_function\n+from __future__ import absolute_import, print_function, unicode_literals\n \n import os\n import re"
    },
    {
        "commit_id": "9c3fe17e7faa5389a01992468877490fa23c8d3c",
        "commit_message": "Fixes Unicode error in celery worker.  Closes celery/kombu#274",
        "commit_url": "https://github.com/celery/celery/commit/9c3fe17e7faa5389a01992468877490fa23c8d3c",
        "buggy_code": "from __future__ import absolute_import",
        "fixed_code": "from __future__ import absolute_import, unicode_literals",
        "patch": "@@ -35,7 +35,7 @@\n     `ERROR`, `CRITICAL`, or `FATAL`.  Default is INFO.\n \n \"\"\"\n-from __future__ import absolute_import\n+from __future__ import absolute_import, unicode_literals\n \n import sys\n "
    },
    {
        "commit_id": "9c3fe17e7faa5389a01992468877490fa23c8d3c",
        "commit_message": "Fixes Unicode error in celery worker.  Closes celery/kombu#274",
        "commit_url": "https://github.com/celery/celery/commit/9c3fe17e7faa5389a01992468877490fa23c8d3c",
        "buggy_code": "from __future__ import absolute_import, print_function",
        "fixed_code": "from __future__ import absolute_import, print_function, unicode_literals",
        "patch": "@@ -91,7 +91,7 @@\n     celery worker -n xuzzy@myhost -c 3\n \n \"\"\"\n-from __future__ import absolute_import, print_function\n+from __future__ import absolute_import, print_function, unicode_literals\n \n import errno\n import os"
    },
    {
        "commit_id": "9c3fe17e7faa5389a01992468877490fa23c8d3c",
        "commit_message": "Fixes Unicode error in celery worker.  Closes celery/kombu#274",
        "commit_url": "https://github.com/celery/celery/commit/9c3fe17e7faa5389a01992468877490fa23c8d3c",
        "buggy_code": "from __future__ import absolute_import",
        "fixed_code": "from __future__ import absolute_import, unicode_literals",
        "patch": "@@ -130,7 +130,7 @@\n     Don't do execv after multiprocessing child fork.\n \n \"\"\"\n-from __future__ import absolute_import\n+from __future__ import absolute_import, unicode_literals\n \n import sys\n "
    },
    {
        "commit_id": "003d94e337666e078c442b8e80fd994af5d6a135",
        "commit_message": "Temporary until 3.1.4 (Issue #1647)",
        "commit_url": "https://github.com/celery/celery/commit/003d94e337666e078c442b8e80fd994af5d6a135",
        "buggy_code": "from .celery import app as celery_app",
        "fixed_code": "from .celery import app",
        "patch": "@@ -2,4 +2,4 @@\n \n # This will make sure the app is always imported when\n # Django starts so that shared_task will use this app.\n-from .celery import app as celery_app\n+from .celery import app"
    },
    {
        "commit_id": "74663dad463d1a196ac45b7cb9ef6bf90f36b92d",
        "commit_message": "Hold on a bit with E_WOULDBLOCK error",
        "commit_url": "https://github.com/celery/celery/commit/74663dad463d1a196ac45b7cb9ef6bf90f36b92d",
        "buggy_code": "raise Exception(E_WOULDBLOCK)",
        "fixed_code": "pass   # TODO future version: raise",
        "patch": "@@ -36,7 +36,7 @@\n \n def assert_will_not_block():\n     if task_join_will_block():\n-        raise Exception(E_WOULDBLOCK)\n+        pass   # TODO future version: raise\n \n \n class ResultBase(object):"
    },
    {
        "commit_id": "0822761ec2d34fd828abb248c552f16fd8a14c7c",
        "commit_message": "Fix compat with no billiard C extension",
        "commit_url": "https://github.com/celery/celery/commit/0822761ec2d34fd828abb248c552f16fd8a14c7c",
        "buggy_code": "proc.inq._writer.setblocking(1)",
        "fixed_code": "setblocking(proc.inq._writer, 1)",
        "patch": "@@ -973,7 +973,7 @@ def _process_cleanup_queues(self, proc):\n     def _stop_task_handler(task_handler):\n         \"\"\"Called at shutdown to tell processes that we are shutting down.\"\"\"\n         for proc in task_handler.pool:\n-            proc.inq._writer.setblocking(1)\n+            setblocking(proc.inq._writer, 1)\n             try:\n                 proc.inq.put(None)\n             except OSError as exc:"
    },
    {
        "commit_id": "00c85dda699a1ec9a3b99d142a7b7a43e316b8e3",
        "commit_message": "Merge pull request #1613 from twright/patch-1\n\nFix typo in header comment of celery.canvas.",
        "commit_url": "https://github.com/celery/celery/commit/00c85dda699a1ec9a3b99d142a7b7a43e316b8e3",
        "buggy_code": "You should not import these from :mod:`celery` and not this module.",
        "fixed_code": "You should import these from :mod:`celery` and not this module.",
        "patch": "@@ -6,7 +6,7 @@\n     Composing task workflows.\n \n     Documentation for some of these types are in :mod:`celery`.\n-    You should not import these from :mod:`celery` and not this module.\n+    You should import these from :mod:`celery` and not this module.\n \n \n \"\"\""
    },
    {
        "commit_id": "7ec099efafb5380cb5ecdbcfafc01b6273191eaa",
        "commit_message": "Fix typo in header comment of celery.canvas.\n\nshould is currently used instead of should not",
        "commit_url": "https://github.com/celery/celery/commit/7ec099efafb5380cb5ecdbcfafc01b6273191eaa",
        "buggy_code": "You should not import these from :mod:`celery` and not this module.",
        "fixed_code": "You should import these from :mod:`celery` and not this module.",
        "patch": "@@ -6,7 +6,7 @@\n     Composing task workflows.\n \n     Documentation for some of these types are in :mod:`celery`.\n-    You should not import these from :mod:`celery` and not this module.\n+    You should import these from :mod:`celery` and not this module.\n \n \n \"\"\""
    },
    {
        "commit_id": "ce9436eedd4a91430568d9f3afc16700967aca8c",
        "commit_message": "Fixes bug with revoke list only terminating one task.  Closes #1592",
        "commit_url": "https://github.com/celery/celery/commit/ce9436eedd4a91430568d9f3afc16700967aca8c",
        "buggy_code": "if isinstance(other, self.__class__):",
        "fixed_code": "if isinstance(other, LimitedSet):",
        "patch": "@@ -619,7 +619,7 @@ def purge(self, limit=None, offset=0, now=time.time):\n             i += 1\n \n     def update(self, other, heappush=heappush):\n-        if isinstance(other, self.__class__):\n+        if isinstance(other, LimitedSet):\n             self._data.update(other._data)\n             self._heap.extend(other._heap)\n             heapify(self._heap)"
    },
    {
        "commit_id": "1ac10f3b8f2bc0a21b7e418ee6c967df614bd106",
        "commit_message": "Fixed error in protocol handling for the riak backend",
        "commit_url": "https://github.com/celery/celery/commit/1ac10f3b8f2bc0a21b7e418ee6c967df614bd106",
        "buggy_code": "self.protocol = uprot or config.get('protocol', self.protocol)",
        "fixed_code": "self.protocol = protocol or config.get('protocol', self.protocol)",
        "patch": "@@ -91,7 +91,7 @@ def __init__(self, host=None, port=None, bucket_name=None, protocol=None,\n         self.host = uhost or config.get('host', self.host)\n         self.port = int(uport or config.get('port', self.port))\n         self.bucket_name = ubucket or config.get('bucket', self.bucket_name)\n-        self.protocol = uprot or config.get('protocol', self.protocol)\n+        self.protocol = protocol or config.get('protocol', self.protocol)\n \n         # riak bucket must be ascii letters or numbers only\n         if not Validators.validate_riak_bucket_name(self.bucket_name):"
    },
    {
        "commit_id": "aecdf13082a05053f7bda6329c802e476fa7aa6e",
        "commit_message": "Fixes bug with solo/threads pool.  Closes #1548",
        "commit_url": "https://github.com/celery/celery/commit/aecdf13082a05053f7bda6329c802e476fa7aa6e",
        "buggy_code": "cache = pool._pool._cache",
        "fixed_code": "cache = getattr(pool._pool, '_cache', None)",
        "patch": "@@ -107,7 +107,7 @@ def on_poll_init(self, pool, w, hub):\n         add_reader = hub.add_reader\n         remove = hub.remove\n         now = time.time\n-        cache = pool._pool._cache\n+        cache = getattr(pool._pool, '_cache', None)\n \n         # did_start_ok will verify that pool processes were able to start,\n         # but this will only work the first time we start, as"
    },
    {
        "commit_id": "3a37cc7eb0660092bd2188d81d961bdb4d41e4d1",
        "commit_message": "Fixes syntax error in httpexample's manage.py",
        "commit_url": "https://github.com/celery/celery/commit/3a37cc7eb0660092bd2188d81d961bdb4d41e4d1",
        "buggy_code": "\"containing {0!r}.\".format(__file__)",
        "fixed_code": "\"containing {0!r}.\".format(__file__))",
        "patch": "@@ -6,7 +6,7 @@\n     import sys\n     sys.stderr.write(\n         \"Error: Can't find the file 'settings.py' in the directory \"\n-        \"containing {0!r}.\".format(__file__)\n+        \"containing {0!r}.\".format(__file__))\n     sys.exit(1)\n \n if __name__ == '__main__':"
    },
    {
        "commit_id": "46e60700d4829848e8b57cfb20c03f2ee5489c21",
        "commit_message": "result: make base backend and iter_native interval default value agree\n\nThe base backend has a default of 0.5, when we passed None in\nthat caused it to ignore the default (since we passed a value)\nand raised an error when calling time.sleep.",
        "commit_url": "https://github.com/celery/celery/commit/46e60700d4829848e8b57cfb20c03f2ee5489c21",
        "buggy_code": "def iter_native(self, timeout=None, interval=None):",
        "fixed_code": "def iter_native(self, timeout=None, interval=0.5):",
        "patch": "@@ -512,7 +512,7 @@ def join(self, timeout=None, propagate=True, interval=0.5):\n                                       interval=interval))\n         return results\n \n-    def iter_native(self, timeout=None, interval=None):\n+    def iter_native(self, timeout=None, interval=0.5):\n         \"\"\"Backend optimized version of :meth:`iterate`.\n \n         .. versionadded:: 2.2"
    },
    {
        "commit_id": "3681099ec9d7a48820a62ce125d19a8ef345b891",
        "commit_message": "Fixes type error",
        "commit_url": "https://github.com/celery/celery/commit/3681099ec9d7a48820a62ce125d19a8ef345b891",
        "buggy_code": "tablenames = conf.CELERY_RESULT_DB_TABLENAMES",
        "fixed_code": "tablenames = conf.CELERY_RESULT_DB_TABLENAMES or {}",
        "patch": "@@ -70,7 +70,7 @@ def __init__(self, dburi=None, expires=None,\n             conf.CELERY_RESULT_DB_SHORT_LIVED_SESSIONS,\n         )\n \n-        tablenames = conf.CELERY_RESULT_DB_TABLENAMES\n+        tablenames = conf.CELERY_RESULT_DB_TABLENAMES or {}\n         Task.__table__.name = tablenames.get('task', 'celery_taskmeta')\n         TaskSet.__table__.name = tablenames.get('group', 'celery_tasksetmeta')\n "
    },
    {
        "commit_id": "81fb7f46ae05499fcc958a6449fdb9247abba673",
        "commit_message": "Fix django fixup for Django < 1.6",
        "commit_url": "https://github.com/celery/celery/commit/81fb7f46ae05499fcc958a6449fdb9247abba673",
        "buggy_code": "except ImportError:",
        "fixed_code": "except (ImportError, AttributeError):",
        "patch": "@@ -89,7 +89,7 @@ def __init__(self, app):\n             self._close_old_connections = symbol_by_name(\n                 'django.db:close_old_connections',\n             )\n-        except ImportError:\n+        except (ImportError, AttributeError):\n             self._close_old_connections = None\n         self.database_errors = (\n             (DatabaseError, ) +"
    },
    {
        "commit_id": "8e4d53e5ac31e6c5bcb91fc02fb7ddfa620b5456",
        "commit_message": "Always use mediator, emergency deadlock fix until 3.1",
        "commit_url": "https://github.com/celery/celery/commit/8e4d53e5ac31e6c5bcb91fc02fb7ddfa620b5456",
        "buggy_code": "return w.start_mediator and not w.use_eventloop",
        "fixed_code": "return w.start_mediator",
        "patch": "@@ -36,7 +36,7 @@ def __init__(self, w, **kwargs):\n         w.mediator = None\n \n     def include_if(self, w):\n-        return w.start_mediator and not w.use_eventloop\n+        return w.start_mediator\n \n     def create(self, w):\n         m = w.mediator = self.instantiate(w.mediator_cls, w.ready_queue,"
    },
    {
        "commit_id": "8e4eaef0c6c8f98addeb4bb0afa1b955736e65f3",
        "commit_message": "Fixes divzero error",
        "commit_url": "https://github.com/celery/celery/commit/8e4eaef0c6c8f98addeb4bb0afa1b955736e65f3",
        "buggy_code": "'avg': per(total / len(self.write_stats), total),",
        "fixed_code": "'avg': per(total / len(self.write_stats) if total else 0, total),",
        "patch": "@@ -516,7 +516,7 @@ def per(v, total):\n \n         return {\n             'total': total,\n-            'avg': per(total / len(self.write_stats), total),\n+            'avg': per(total / len(self.write_stats) if total else 0, total),\n             'all': ', '.join(per(v, total) for v in vals)\n         }\n "
    },
    {
        "commit_id": "8492b5c09d7434b3920ff6b2a4390576d9c5396d",
        "commit_message": "Fixed problem #1373 a unicode decode error caused by utf-8 characters in the platform",
        "commit_url": "https://github.com/celery/celery/commit/8492b5c09d7434b3920ff6b2a4390576d9c5396d",
        "buggy_code": "'platform': _platform.platform(),",
        "fixed_code": "'platform': safe_str(_platform.platform()),",
        "patch": "@@ -251,7 +251,7 @@ def startup_info(self):\n             'version': VERSION_BANNER,\n             'conninfo': self.app.connection().as_uri(),\n             'concurrency': concurrency,\n-            'platform': _platform.platform(),\n+            'platform': safe_str(_platform.platform()),\n             'events': events,\n             'queues': app.amqp.queues.format(indent=0, indent_first=False),\n         }).splitlines()"
    },
    {
        "commit_id": "b87038e8a43e0bb00bbc373154cb2ed8a3abc201",
        "commit_message": "Fixed problem #1373 a unicode decode error caused by utf-8 characters in the platform",
        "commit_url": "https://github.com/celery/celery/commit/b87038e8a43e0bb00bbc373154cb2ed8a3abc201",
        "buggy_code": "platform=_platform.platform(),",
        "fixed_code": "platform=safe_str(_platform.platform()),",
        "patch": "@@ -203,7 +203,7 @@ def startup_info(self):\n             version=VERSION_BANNER,\n             conninfo=self.app.connection().as_uri(),\n             concurrency=concurrency,\n-            platform=_platform.platform(),\n+            platform=safe_str(_platform.platform()),\n             events=events,\n             queues=app.amqp.queues.format(indent=0, indent_first=False),\n         ).splitlines()"
    },
    {
        "commit_id": "1b30d45b3fb0a4e916911446fa90126c3a479b93",
        "commit_message": "Fix for broken build 721 due to safe parameter",
        "commit_url": "https://github.com/celery/celery/commit/1b30d45b3fb0a4e916911446fa90126c3a479b93",
        "buggy_code": "{'_id': sentinel.task_id}, safe=True)",
        "fixed_code": "{'_id': sentinel.task_id})",
        "patch": "@@ -289,7 +289,7 @@ def test_forget(self, mock_get_database):\n         mock_database.__getitem__.assert_called_once_with(\n             MONGODB_COLLECTION)\n         mock_collection.remove.assert_called_once_with(\n-            {'_id': sentinel.task_id}, safe=True)\n+            {'_id': sentinel.task_id})\n \n     @patch('celery.backends.mongodb.MongoBackend._get_database')\n     def test_cleanup(self, mock_get_database):"
    },
    {
        "commit_id": "2845ef67bd54e9108996706be7cbd93e79113d3d",
        "commit_message": "Fix for broken build 721 due to safe parameter",
        "commit_url": "https://github.com/celery/celery/commit/2845ef67bd54e9108996706be7cbd93e79113d3d",
        "buggy_code": "{'_id': sentinel.task_id}, safe=True)",
        "fixed_code": "{'_id': sentinel.task_id})",
        "patch": "@@ -287,7 +287,7 @@ def test_forget(self, mock_get_database):\n         mock_database.__getitem__.assert_called_once_with(\n             MONGODB_COLLECTION)\n         mock_collection.remove.assert_called_once_with(\n-            {'_id': sentinel.task_id}, safe=True)\n+            {'_id': sentinel.task_id})\n \n     @patch('celery.backends.mongodb.MongoBackend._get_database')\n     def test_cleanup(self, mock_get_database):"
    },
    {
        "commit_id": "0fc497b65827facec5e9677f2bafa2c578921afa",
        "commit_message": "Decode message error log now includes traceback",
        "commit_url": "https://github.com/celery/celery/commit/0fc497b65827facec5e9677f2bafa2c578921afa",
        "buggy_code": "dump_body(message, message.body))",
        "fixed_code": "dump_body(message, message.body), exc_info=1)",
        "patch": "@@ -668,7 +668,7 @@ def on_decode_error(self, message, exc):\n         \"\"\"\n         crit(\"Can't decode message body: %r (type:%r encoding:%r raw:%r')\",\n              exc, message.content_type, message.content_encoding,\n-             dump_body(message, message.body))\n+             dump_body(message, message.body), exc_info=1)\n         message.ack()\n \n     def reset_pidbox_node(self):"
    },
    {
        "commit_id": "30e821b1bd8cab9ddfae456c1d8acdd64c32ecf7",
        "commit_message": "Fixes syntax error",
        "commit_url": "https://github.com/celery/celery/commit/30e821b1bd8cab9ddfae456c1d8acdd64c32ecf7",
        "buggy_code": "registry.disable(name)whitelist)",
        "fixed_code": "registry.disable(name)",
        "patch": "@@ -36,7 +36,7 @@\n \n def disable_untrusted_serializers(whitelist=None):\n     for name in set(registry._decoders) - set(whitelist or []):\n-        registry.disable(name)whitelist)\n+        registry.disable(name)\n \n \n def setup_security(allowed_serializers=None, key=None, cert=None, store=None,"
    },
    {
        "commit_id": "fd89eb8d0ac1a6a4085edc9d7f2274daf607ba92",
        "commit_message": "Fix pickling error with AsyncResult",
        "commit_url": "https://github.com/celery/celery/commit/fd89eb8d0ac1a6a4085edc9d7f2274daf607ba92",
        "buggy_code": "return self.id, self.backend, self.task_name, self.parent",
        "fixed_code": "return self.id, self.backend, self.task_name, self.app, self.parent",
        "patch": "@@ -210,7 +210,7 @@ def __reduce__(self):\n         return self.__class__, self.__reduce_args__()\n \n     def __reduce_args__(self):\n-        return self.id, self.backend, self.task_name, self.parent\n+        return self.id, self.backend, self.task_name, self.app, self.parent\n \n     @cached_property\n     def graph(self):"
    },
    {
        "commit_id": "f4f53540d0e2326a223d73b091c820d83a9cef63",
        "commit_message": "Merge pull request #1236 from dash1291/master\n\nFix syntax error in `celery_http_gateway` example app.",
        "commit_url": "https://github.com/celery/celery/commit/f4f53540d0e2326a223d73b091c820d83a9cef63",
        "buggy_code": "\"containing {0!r}.\".format(__file__)",
        "fixed_code": "\"containing {0!r}.\".format(__file__))",
        "patch": "@@ -6,7 +6,7 @@\n     import sys\n     sys.stderr.write(\n         \"Error: Can't find the file 'settings.py' in the directory \"\n-        \"containing {0!r}.\".format(__file__)\n+        \"containing {0!r}.\".format(__file__))\n     sys.exit(1)\n \n if __name__ == '__main__':"
    },
    {
        "commit_id": "6fc67563b5ed8d55a8d2778f584bb78e4a8c8773",
        "commit_message": "Fix syntax error",
        "commit_url": "https://github.com/celery/celery/commit/6fc67563b5ed8d55a8d2778f584bb78e4a8c8773",
        "buggy_code": "\"containing {0!r}.\".format(__file__)",
        "fixed_code": "\"containing {0!r}.\".format(__file__))",
        "patch": "@@ -6,7 +6,7 @@\n     import sys\n     sys.stderr.write(\n         \"Error: Can't find the file 'settings.py' in the directory \"\n-        \"containing {0!r}.\".format(__file__)\n+        \"containing {0!r}.\".format(__file__))\n     sys.exit(1)\n \n if __name__ == '__main__':"
    },
    {
        "commit_id": "d7ea6c4b382e2790754b67c70612e6fdbe389695",
        "commit_message": "Fixes syntax error in example",
        "commit_url": "https://github.com/celery/celery/commit/d7ea6c4b382e2790754b67c70612e6fdbe389695",
        "buggy_code": "print('GET {0!r}'.format(url)",
        "fixed_code": "print('GET {0!r}'.format(url))",
        "patch": "@@ -30,7 +30,7 @@ def add(x, y):\n \n @task()\n def make_request(id, url):\n-    print('GET {0!r}'.format(url)\n+    print('GET {0!r}'.format(url))\n     return url\n \n "
    },
    {
        "commit_id": "d2f5a9a1e2e0ce61ffb9d7f5742fe1d541d40aeb",
        "commit_message": "Fixes fallback chord result passing bug.  Closes #1216",
        "commit_url": "https://github.com/celery/celery/commit/d2f5a9a1e2e0ce61ffb9d7f5742fe1d541d40aeb",
        "buggy_code": "kwargs['result'] = [r.id for r in result]",
        "fixed_code": "kwargs['result'] = [r.serializable() for r in result]",
        "patch": "@@ -280,7 +280,7 @@ def on_chord_part_return(self, task, propagate=False):\n \n     def fallback_chord_unlock(self, group_id, body, result=None,\n                               countdown=1, **kwargs):\n-        kwargs['result'] = [r.id for r in result]\n+        kwargs['result'] = [r.serializable() for r in result]\n         self.app.tasks['celery.chord_unlock'].apply_async(\n             (group_id, body, ), kwargs, countdown=countdown,\n         )"
    },
    {
        "commit_id": "e5caf9cc19bbc5d55a273d2ba6afb8b850380774",
        "commit_message": "Configure multiprocessing with loglevel ERROR by default (if MP_LOG envvar not set)",
        "commit_url": "https://github.com/celery/celery/commit/e5caf9cc19bbc5d55a273d2ba6afb8b850380774",
        "buggy_code": "return mputil.get_logger() if mputil and MP_LOG else None",
        "fixed_code": "return mputil.get_logger() if mputil else None",
        "patch": "@@ -212,7 +212,7 @@ def makeRecord(self, *args, **kwds):\n \n \n def get_multiprocessing_logger():\n-    return mputil.get_logger() if mputil and MP_LOG else None\n+    return mputil.get_logger() if mputil else None\n \n \n def reset_multiprocessing_logger():"
    },
    {
        "commit_id": "8f4e26359f1a9b350b5c7567c5897acc297881f0",
        "commit_message": "Merge pull request #1138 from rslinckx/patch-1\n\nUse the now() from the underlying schedule in ScheduleEntry",
        "commit_url": "https://github.com/celery/celery/commit/8f4e26359f1a9b350b5c7567c5897acc297881f0",
        "buggy_code": "return current_app.now()",
        "fixed_code": "return self.schedule.now() if self.schedule else current_app.now()",
        "patch": "@@ -91,7 +91,7 @@ def __init__(self, name=None, task=None, last_run_at=None,\n         self.total_run_count = total_run_count or 0\n \n     def _default_now(self):\n-        return current_app.now()\n+        return self.schedule.now() if self.schedule else current_app.now()\n \n     def _next_instance(self, last_run_at=None):\n         \"\"\"Returns a new instance of the same class, but with"
    },
    {
        "commit_id": "b871634c14c277f1c7b598e718db5945aaa161d8",
        "commit_message": "Fix typo in app/amqp.py",
        "commit_url": "https://github.com/celery/celery/commit/b871634c14c277f1c7b598e718db5945aaa161d8",
        "buggy_code": "'timeouts': timeouts or (timeout, soft_timeout)}",
        "fixed_code": "'timeouts': timeouts or (timeout, soft_timeout),",
        "patch": "@@ -227,7 +227,7 @@ def publish_task(self, task_name, task_args=None, task_kwargs=None,\n             'callbacks': callbacks,\n             'errbacks': errbacks,\n             'reply_to': reply_to,\n-            'timeouts': timeouts or (timeout, soft_timeout)}\n+            'timeouts': timeouts or (timeout, soft_timeout),\n             'taskset': group_id or taskset_id,\n             'chord': chord,\n         }"
    },
    {
        "commit_id": "72f488698fb5caa7ae0e734f873dde89e3ddd7e9",
        "commit_message": "Fixes syntax error",
        "commit_url": "https://github.com/celery/celery/commit/72f488698fb5caa7ae0e734f873dde89e3ddd7e9",
        "buggy_code": "priority=priority, declare=declare)",
        "fixed_code": "priority=priority, declare=declare,",
        "patch": "@@ -233,7 +233,7 @@ def publish_task(self, task_name, task_args=None, task_kwargs=None,\n              serializer=serializer or self.serializer,\n              compression=compression or self.compression,\n              retry=retry, retry_policy=_rp, delivery_mode=delivery_mode,\n-             priority=priority, declare=declare)\n+             priority=priority, declare=declare,\n              **kwargs)\n \n         signals.task_sent.send(sender=task_name, **body)"
    },
    {
        "commit_id": "783c280d8216139ffee9659cae9c782ec1a3b091",
        "commit_message": "Fixed a trivial bug that prevented backends.base.get_many from hitting timeout.",
        "commit_url": "https://github.com/celery/celery/commit/783c280d8216139ffee9659cae9c782ec1a3b091",
        "buggy_code": "iterations += 0",
        "fixed_code": "iterations += 1",
        "patch": "@@ -416,7 +416,7 @@ def get_many(self, task_ids, timeout=None, interval=0.5):\n             if timeout and iterations * interval >= timeout:\n                 raise TimeoutError('Operation timed out (%s)' % (timeout, ))\n             time.sleep(interval)  # don't busy loop.\n-            iterations += 0\n+            iterations += 1\n \n     def _forget(self, task_id):\n         self.delete(self.get_key_for_task(task_id))"
    },
    {
        "commit_id": "8d04d381d75f8ab173f08d56384a1d53290b57ed",
        "commit_message": "Merge pull request #1043 from lrem/master\n\n Fixed a trivial bug that prevented backends.base.get_many from hitting timeout.",
        "commit_url": "https://github.com/celery/celery/commit/8d04d381d75f8ab173f08d56384a1d53290b57ed",
        "buggy_code": "iterations += 0",
        "fixed_code": "iterations += 1",
        "patch": "@@ -360,7 +360,7 @@ def get_many(self, task_ids, timeout=None, interval=0.5):\n             if timeout and iterations * interval >= timeout:\n                 raise TimeoutError('Operation timed out ({0})'.format(timeout))\n             time.sleep(interval)  # don't busy loop.\n-            iterations += 0\n+            iterations += 1\n \n     def _forget(self, task_id):\n         self.delete(self.get_key_for_task(task_id))"
    },
    {
        "commit_id": "7097db7d455da548ebf57193914a1f0bfecc9a4a",
        "commit_message": "Fixed a trivial bug that prevented backends.base.get_many from hitting timeout.",
        "commit_url": "https://github.com/celery/celery/commit/7097db7d455da548ebf57193914a1f0bfecc9a4a",
        "buggy_code": "iterations += 0",
        "fixed_code": "iterations += 1",
        "patch": "@@ -357,7 +357,7 @@ def get_many(self, task_ids, timeout=None, interval=0.5):\n             if timeout and iterations * interval >= timeout:\n                 raise TimeoutError('Operation timed out ({0})'.format(timeout))\n             time.sleep(interval)  # don't busy loop.\n-            iterations += 0\n+            iterations += 1\n \n     def _forget(self, task_id):\n         self.delete(self.get_key_for_task(task_id))"
    },
    {
        "commit_id": "1c5efa6bdedafa2de6770436c1e7acf4ef81aebf",
        "commit_message": "Fixes strange Python3.2 bug.  Closes #1034",
        "commit_url": "https://github.com/celery/celery/commit/1c5efa6bdedafa2de6770436c1e7acf4ef81aebf",
        "buggy_code": "from kombu import Exchange, Queue",
        "fixed_code": "from kombu.entity import Exchange, Queue",
        "patch": "@@ -19,7 +19,7 @@\n from inspect import getargspec\n from pprint import pprint\n \n-from kombu import Exchange, Queue\n+from kombu.entity import Exchange, Queue\n \n from celery.exceptions import CPendingDeprecationWarning, CDeprecationWarning\n from .compat import StringIO"
    },
    {
        "commit_id": "f5bcca4fd4cedc3c8c65a3ddadc5d93da6363374",
        "commit_message": "Fix flakes from master",
        "commit_url": "https://github.com/celery/celery/commit/f5bcca4fd4cedc3c8c65a3ddadc5d93da6363374",
        "buggy_code": "from .utils.imports import instantiate, qualname, symbol_by_name",
        "fixed_code": "from .utils.imports import instantiate, qualname",
        "patch": "@@ -16,7 +16,7 @@\n from kombu.utils import symbol_by_name\n \n from .datastructures import DependencyGraph\n-from .utils.imports import instantiate, qualname, symbol_by_name\n+from .utils.imports import instantiate, qualname\n from .utils.log import get_logger\n from .utils.threads import default_socket_timeout\n "
    },
    {
        "commit_id": "f5bcca4fd4cedc3c8c65a3ddadc5d93da6363374",
        "commit_message": "Fix flakes from master",
        "commit_url": "https://github.com/celery/celery/commit/f5bcca4fd4cedc3c8c65a3ddadc5d93da6363374",
        "buggy_code": "def test_pool_restart_relaod_modules(self):",
        "fixed_code": "def test_pool_restart_reload_modules(self):",
        "patch": "@@ -439,7 +439,7 @@ def test_pool_restart_import_modules(self):\n         self.assertEqual([(('foo',), {}), (('bar',), {})],\n                           _import.call_args_list)\n \n-    def test_pool_restart_relaod_modules(self):\n+    def test_pool_restart_reload_modules(self):\n         consumer = Consumer()\n         consumer.controller = _WC(app=current_app)\n         consumer.controller.pool.restart = Mock()"
    },
    {
        "commit_id": "e84ab03426cd8a713ec8d2eea174105d50c326b5",
        "commit_message": "Fix flakes from master",
        "commit_url": "https://github.com/celery/celery/commit/e84ab03426cd8a713ec8d2eea174105d50c326b5",
        "buggy_code": "from .utils.imports import instantiate, qualname, symbol_by_name",
        "fixed_code": "from .utils.imports import instantiate, qualname",
        "patch": "@@ -16,7 +16,7 @@\n from kombu.utils import symbol_by_name\n \n from .datastructures import DependencyGraph\n-from .utils.imports import instantiate, qualname, symbol_by_name\n+from .utils.imports import instantiate, qualname\n from .utils.log import get_logger\n from .utils.threads import default_socket_timeout\n "
    },
    {
        "commit_id": "5f2bd2ef6c7e62516da0f9388ff57e8494e4f4b5",
        "commit_message": "Revert discussed change (Issue #969)",
        "commit_url": "https://github.com/celery/celery/commit/5f2bd2ef6c7e62516da0f9388ff57e8494e4f4b5",
        "buggy_code": "for request in state.reserved_requests:",
        "fixed_code": "for request in state.active_requests:",
        "patch": "@@ -40,7 +40,7 @@ def revoke(panel, task_id, terminate=False, signal=None, **kwargs):\n     action = 'revoked'\n     if terminate:\n         signum = _signals.signum(signal or 'TERM')\n-        for request in state.reserved_requests:\n+        for request in state.active_requests:\n             if request.id == task_id:\n                 action = 'terminated (%s)' % (signum, )\n                 request.terminate(panel.consumer.pool, signal=signum)"
    },
    {
        "commit_id": "a20ff8a98e0673fa404425a6e3fe8b7837eb66b0",
        "commit_message": "Fixes more eventlet/gevent/threads early patch problems, and also moves importlib+ordereddict (<Py2.7) and simplejson (Py<2.6) dependencies to Kombu",
        "commit_url": "https://github.com/celery/celery/commit/a20ff8a98e0673fa404425a6e3fe8b7837eb66b0",
        "buggy_code": "from celery.utils import cached_property, uuid",
        "fixed_code": "from kombu.utils import cached_property, uuid",
        "patch": "@@ -14,10 +14,10 @@\n from kombu import Connection, Consumer, Exchange, Producer, Queue\n from kombu.common import entry_to_queue\n from kombu.pools import ProducerPool\n+from kombu.utils import cached_property, uuid\n from kombu.utils.encoding import safe_repr\n \n from celery import signals\n-from celery.utils import cached_property, uuid\n from celery.utils.text import indent as textindent\n \n from . import app_or_default"
    },
    {
        "commit_id": "a20ff8a98e0673fa404425a6e3fe8b7837eb66b0",
        "commit_message": "Fixes more eventlet/gevent/threads early patch problems, and also moves importlib+ordereddict (<Py2.7) and simplejson (Py<2.6) dependencies to Kombu",
        "commit_url": "https://github.com/celery/celery/commit/a20ff8a98e0673fa404425a6e3fe8b7837eb66b0",
        "buggy_code": "from celery.utils import cached_property",
        "fixed_code": "from kombu.utils import cached_property",
        "patch": "@@ -8,10 +8,10 @@\n \"\"\"\n from __future__ import absolute_import\n \n+from kombu.utils import cached_property\n from kombu.utils.url import _parse_url\n \n from celery.exceptions import ImproperlyConfigured\n-from celery.utils import cached_property\n \n from .base import KeyValueStoreBackend\n "
    },
    {
        "commit_id": "a20ff8a98e0673fa404425a6e3fe8b7837eb66b0",
        "commit_message": "Fixes more eventlet/gevent/threads early patch problems, and also moves importlib+ordereddict (<Py2.7) and simplejson (Py<2.6) dependencies to Kombu",
        "commit_url": "https://github.com/celery/celery/commit/a20ff8a98e0673fa404425a6e3fe8b7837eb66b0",
        "buggy_code": "from celery.utils import cached_property",
        "fixed_code": "from kombu.utils import cached_property",
        "patch": "@@ -15,11 +15,11 @@\n \n from datetime import datetime\n \n+from kombu.utils import cached_property\n from kombu.utils.encoding import safe_str\n \n from celery.datastructures import DictAttribute\n from celery.exceptions import ImproperlyConfigured\n-from celery.utils import cached_property\n from celery.utils.imports import import_from_cwd, symbol_by_name\n from celery.utils.functional import maybe_list\n "
    },
    {
        "commit_id": "9d488dc6dcbd29f348de363824cd9aff505d66bf",
        "commit_message": "Fixes another PyPI test bug",
        "commit_url": "https://github.com/celery/celery/commit/9d488dc6dcbd29f348de363824cd9aff505d66bf",
        "buggy_code": "self.eventlet = __import__('gevent')",
        "fixed_code": "self.gevent = __import__('gevent')",
        "patch": "@@ -28,7 +28,7 @@ class GeventCase(Case):\n     @skip_if_pypy\n     def setUp(self):\n         try:\n-            self.eventlet = __import__('gevent')\n+            self.gevent = __import__('gevent')\n         except ImportError:\n             raise SkipTest(\n                 'gevent not installed, skipping related tests.')"
    },
    {
        "commit_id": "4b33bc132a2b8fb1c904dd1a8817e43b41d18b72",
        "commit_message": "Fixes another PyPI test bug",
        "commit_url": "https://github.com/celery/celery/commit/4b33bc132a2b8fb1c904dd1a8817e43b41d18b72",
        "buggy_code": "self.eventlet = __import__('gevent')",
        "fixed_code": "self.gevent = __import__('gevent')",
        "patch": "@@ -27,7 +27,7 @@ class GeventCase(Case):\n     @skip_if_pypy\n     def setUp(self):\n         try:\n-            self.eventlet = __import__('gevent')\n+            self.gevent = __import__('gevent')\n         except ImportError:\n             raise SkipTest(\n                 'gevent not installed, skipping related tests.')"
    },
    {
        "commit_id": "9792d32034549a68f41502482f2552ab5d766f5c",
        "commit_message": "Fix actor_reset",
        "commit_url": "https://github.com/celery/celery/commit/9792d32034549a68f41502482f2552ab5d766f5c",
        "buggy_code": "for actor, consumer in self.actor_registry:",
        "fixed_code": "for _, consumer in self.actor_registry.items():",
        "patch": "@@ -543,7 +543,7 @@ def stop_all_actors(self):\n         self.actor_registry.clear()\n     \n     def reset_actor_nodes(self):\n-        for actor, consumer in self.actor_registry:\n+        for _, consumer in self.actor_registry.items():\n             self.maybe_conn_error(consumer.cancel)\n             consumer.consume()\n     "
    },
    {
        "commit_id": "9792d32034549a68f41502482f2552ab5d766f5c",
        "commit_message": "Fix actor_reset",
        "commit_url": "https://github.com/celery/celery/commit/9792d32034549a68f41502482f2552ab5d766f5c",
        "buggy_code": "return {'ok':'ihu-pong'}",
        "fixed_code": "return {'ok':'pong'}",
        "patch": "@@ -213,7 +213,7 @@ def _extract_info(task):\n \n @Panel.register\n def ping(panel, **kwargs):\n-    return {'ok':'ihu-pong'}\n+    return {'ok':'pong'}\n \n \n @Panel.register"
    },
    {
        "commit_id": "19dc001aa860a1a8f1bcb81fc7f233be80758e63",
        "commit_message": "Fixes syntax error",
        "commit_url": "https://github.com/celery/celery/commit/19dc001aa860a1a8f1bcb81fc7f233be80758e63",
        "buggy_code": "events = poll(poll_timeout):",
        "fixed_code": "events = poll(poll_timeout)",
        "patch": "@@ -441,7 +441,7 @@ def on_task_received(body, message):\n                     connection.more_to_read = True\n                     while connection.more_to_read:\n                         try:\n-                            events = poll(poll_timeout):\n+                            events = poll(poll_timeout)\n                         except ValueError:  # Issue 882\n                             return\n                         for fileno, event in events or ():"
    },
    {
        "commit_id": "3ade3cb57ecfc58067f0f38132220313690090a6",
        "commit_message": "Fix SyntaxError in test_leak.py",
        "commit_url": "https://github.com/celery/celery/commit/3ade3cb57ecfc58067f0f38132220313690090a6",
        "buggy_code": "raise SkipTest('Can't execute command: %r: %r' % (cmd, exc))",
        "fixed_code": "raise SkipTest(\"Can't execute command: %r: %r\" % (cmd, exc))",
        "patch": "@@ -40,7 +40,7 @@ def get_rsize(self, cmd=GET_RSIZE):\n                         shlex.split(cmd % {'pid': os.getpid()}),\n                             stdout=subprocess.PIPE).communicate()[0].strip())\n         except OSError, exc:\n-            raise SkipTest('Can't execute command: %r: %r' % (cmd, exc))\n+            raise SkipTest(\"Can't execute command: %r: %r\" % (cmd, exc))\n \n     def sample_allocated(self, fun, *args, **kwargs):\n         before = self.get_rsize()"
    },
    {
        "commit_id": "f2856773fd526d239dc7fb510b8ccba471a22cb8",
        "commit_message": "Fix exc_type in handle_failure",
        "commit_url": "https://github.com/celery/celery/commit/f2856773fd526d239dc7fb510b8ccba471a22cb8",
        "buggy_code": "_, type_, tb = sys.exc_info()",
        "fixed_code": "type_, _, tb = sys.exc_info()",
        "patch": "@@ -110,7 +110,7 @@ def handle_retry(self, task, store_errors=True):\n     def handle_failure(self, task, store_errors=True):\n         \"\"\"Handle exception.\"\"\"\n         req = task.request\n-        _, type_, tb = sys.exc_info()\n+        type_, _, tb = sys.exc_info()\n         try:\n             exc = self.retval\n             einfo = ExceptionInfo((type_, get_pickleable_exception(exc), tb))"
    },
    {
        "commit_id": "de6d870cdce0bc4676d444a5458ed652713dce6b",
        "commit_message": "Fix 2to3 race which prevents installation on Py3k\n\nsetup.py correctly identifies that it needs to run 2to3 but, before it does so,\nattempts to import celery.app which results in an AttributeError due to celery's\nusage of iteritems().\n\n\tDownloading/unpacking Celery\n\t  Running setup.py egg_info for package Celery\n\t\tTraceback (most recent call last):\n\t\t  File \"<string>\", line 14, in <module>\n\t\t  File \"/Users/jed/[snip]/build/Celery/setup.py\", line 16, in <module>\n\t\t\timport celery.app\n\t\t  File \"celery/__init__.py\", line 38, in <module>\n\t\t\tVERSION=VERSION, SERIES=SERIES, VERSION_BANNER=VERSION_BANNER,\n\t\t  File \"celery/__compat__.py\", line 164, in recreate_module\n\t\t\torigins = get_origins(by_module)\n\t\t  File \"celery/__compat__.py\", line 196, in get_origins\n\t\t\tfor module, items in defs.iteritems():\n\t\tAttributeError: 'dict' object has no attribute 'iteritems'\n\nThis is a temporary emergency fix which allows Celery to install successfully on\nPythons where 2to3 is required but better handling of this should be examined.",
        "commit_url": "https://github.com/celery/celery/commit/de6d870cdce0bc4676d444a5458ed652713dce6b",
        "buggy_code": "except ImportError:",
        "fixed_code": "except:",
        "patch": "@@ -29,7 +29,7 @@\n         print('Upgrade: no old version found.')\n     finally:\n         sys.path[:] = orig_path\n-except ImportError:\n+except:\n     pass\n \n "
    },
    {
        "commit_id": "699f3a6d719575dc58e6486b88bedfb382233ca9",
        "commit_message": "Fixes bug in bin.base",
        "commit_url": "https://github.com/celery/celery/commit/699f3a6d719575dc58e6486b88bedfb382233ca9",
        "buggy_code": "name, val = arg.split('=', 1)",
        "fixed_code": "name, _, val = arg.partition('=')",
        "patch": "@@ -176,7 +176,7 @@ def _find_option_with_arg(self, argv, short_opts=None, long_opts=None):\n         for i, arg in enumerate(argv):\n             if arg.startswith('-'):\n                 if long_opts and arg.startswith('--'):\n-                    name, val = arg.split('=', 1)\n+                    name, _, val = arg.partition('=')\n                     if name in long_opts:\n                         return val\n                 if short_opts and arg in short_opts:"
    },
    {
        "commit_id": "6b9d03b4d23dad1c0ce577334728b45f37f34530",
        "commit_message": "Fix 2to3 race which prevents installation on Py3k\n\nsetup.py correctly identifies that it needs to run 2to3 but, before it does so,\nattempts to import celery.app which results in an AttributeError due to celery's\nusage of iteritems().\n\n\tDownloading/unpacking Celery\n\t  Running setup.py egg_info for package Celery\n\t\tTraceback (most recent call last):\n\t\t  File \"<string>\", line 14, in <module>\n\t\t  File \"/Users/jed/[snip]/build/Celery/setup.py\", line 16, in <module>\n\t\t\timport celery.app\n\t\t  File \"celery/__init__.py\", line 38, in <module>\n\t\t\tVERSION=VERSION, SERIES=SERIES, VERSION_BANNER=VERSION_BANNER,\n\t\t  File \"celery/__compat__.py\", line 164, in recreate_module\n\t\t\torigins = get_origins(by_module)\n\t\t  File \"celery/__compat__.py\", line 196, in get_origins\n\t\t\tfor module, items in defs.iteritems():\n\t\tAttributeError: 'dict' object has no attribute 'iteritems'\n\nThis is a temporary emergency fix which allows Celery to install successfully on\nPythons where 2to3 is required but better handling of this should be examined.",
        "commit_url": "https://github.com/celery/celery/commit/6b9d03b4d23dad1c0ce577334728b45f37f34530",
        "buggy_code": "except ImportError:",
        "fixed_code": "except:",
        "patch": "@@ -29,7 +29,7 @@\n         print('Upgrade: no old version found.')\n     finally:\n         sys.path[:] = orig_path\n-except ImportError:\n+except:\n     pass\n \n "
    },
    {
        "commit_id": "0cf864fab74be52e0fde547bebc38ef5d3a7f88b",
        "commit_message": "Merge branch 'jbiel/patch-1'",
        "commit_url": "https://github.com/celery/celery/commit/0cf864fab74be52e0fde547bebc38ef5d3a7f88b",
        "buggy_code": "return '.'.join([obj.__module__, obj.__name__])",
        "fixed_code": "return '.'.join([str(obj.__module__), str(obj.__name__)])",
        "patch": "@@ -34,7 +34,7 @@ def qualname(obj):  # noqa\n         if not hasattr(obj, '__name__') and hasattr(obj, '__class__'):\n             return qualname(obj.__class__)\n \n-        return '.'.join([obj.__module__, obj.__name__])\n+        return '.'.join([str(obj.__module__), str(obj.__name__)])\n \n \n def symbol_by_name(name, aliases={}, imp=None, package=None,"
    },
    {
        "commit_id": "777db9daf11640b8121f36e09cdd02642203a27d",
        "commit_message": "Update imports.py to work properly with celery_http_gateway.\r\n\r\nWithout this fix in place the following error was emitted\r\nwhen trying to query a task status via the celery_http_gateway:\r\n\"sequence item 0: expected string, module found\"\r\nTraceback: http://pastie.org/4188542",
        "commit_url": "https://github.com/celery/celery/commit/777db9daf11640b8121f36e09cdd02642203a27d",
        "buggy_code": "return '.'.join([obj.__module__, obj.__name__])",
        "fixed_code": "return '.'.join([str(obj.__module__), str(obj.__name__)])",
        "patch": "@@ -34,7 +34,7 @@ def qualname(obj):  # noqa\n         if not hasattr(obj, '__name__') and hasattr(obj, '__class__'):\n             return qualname(obj.__class__)\n \n-        return '.'.join([obj.__module__, obj.__name__])\n+        return '.'.join([str(obj.__module__), str(obj.__name__)])\n \n \n def symbol_by_name(name, aliases={}, imp=None, package=None,"
    },
    {
        "commit_id": "8861c3c04d6c9ae26f7fc1ebcd7102a4eedd7985",
        "commit_message": "Fix bench_worker CELERYD_PREFETCH_MULTIPLIER",
        "commit_url": "https://github.com/celery/celery/commit/8861c3c04d6c9ae26f7fc1ebcd7102a4eedd7985",
        "buggy_code": "CELERY_PREFETCH_MULTIPLIER=0,",
        "fixed_code": "CELERYD_PREFETCH_MULTIPLIER=0,",
        "patch": "@@ -23,7 +23,7 @@\n celery.conf.update(BROKER_TRANSPORT=BROKER_TRANSPORT,\n                    BROKER_POOL_LIMIT=10,\n                    CELERYD_POOL='solo',\n-                   CELERY_PREFETCH_MULTIPLIER=0,\n+                   CELERYD_PREFETCH_MULTIPLIER=0,\n                    CELERY_DISABLE_RATE_LIMITS=True,\n                    CELERY_DEFAULT_DELIVERY_MODE=1,\n                    CELERY_QUEUES = {"
    },
    {
        "commit_id": "29cfdd7f6b3c10f92fa3ef8e26d193dac62f5103",
        "commit_message": "fix typo in Chord return",
        "commit_url": "https://github.com/celery/celery/commit/29cfdd7f6b3c10f92fa3ef8e26d193dac62f5103",
        "buggy_code": "if val >= deps.total:",
        "fixed_code": "if val >= len(deps):",
        "patch": "@@ -469,7 +469,7 @@ def on_chord_part_return(self, task, propagate=False):\n         key = self.get_key_for_chord(gid)\n         deps = GroupResult.restore(gid, backend=task.backend)\n         val = self.incr(key)\n-        if val >= deps.total:\n+        if val >= len(deps):\n             subtask(task.request.chord).delay(deps.join(propagate=propagate))\n             deps.delete()\n             self.client.delete(key)"
    },
    {
        "commit_id": "f5c1364c8cff38e18e3a10e431215af31b1d03ff",
        "commit_message": "Fixes bug that causes priority to not be set for messages.\n\nCloses #708",
        "commit_url": "https://github.com/celery/celery/commit/f5c1364c8cff38e18e3a10e431215af31b1d03ff",
        "buggy_code": "retry=retry, retry_policy=_rp, delivery_mode=delivery_mode,",
        "fixed_code": "retry=retry, retry_policy=_rp, delivery_mode=delivery_mode, priority=priority,",
        "patch": "@@ -190,7 +190,7 @@ def delay_task(self, task_name, task_args=None, task_kwargs=None,\n              immediate=immediate, routing_key=routing_key,\n              serializer=serializer or self.serializer,\n              compression=compression or self.compression,\n-             retry=retry, retry_policy=_rp, delivery_mode=delivery_mode,\n+             retry=retry, retry_policy=_rp, delivery_mode=delivery_mode, priority=priority,\n              declare=[self.queues[queue]] if queue else [],\n              **kwargs)\n "
    },
    {
        "commit_id": "0e45b1a92aecef8ea3dbeb07130e65b845dcaf00",
        "commit_message": "Merge pull request #710 from steeve/patch-6\n\nNo longer ignore Chord result.",
        "commit_url": "https://github.com/celery/celery/commit/0e45b1a92aecef8ea3dbeb07130e65b845dcaf00",
        "buggy_code": "ignore_result = True",
        "fixed_code": "ignore_result = False",
        "patch": "@@ -213,7 +213,7 @@ class Chord(app.Task):\n         app = _app\n         name = \"celery.chord\"\n         accept_magic_kwargs = False\n-        ignore_result = True\n+        ignore_result = False\n \n         def run(self, header, body, interval=1, max_retries=None,\n                 propagate=False, eager=False, **kwargs):"
    },
    {
        "commit_id": "2ecda699a6e4ce1b1d507c2b69c1cbc6482f67c5",
        "commit_message": "Merge branch 'mthurman/patch-2'",
        "commit_url": "https://github.com/celery/celery/commit/2ecda699a6e4ce1b1d507c2b69c1cbc6482f67c5",
        "buggy_code": "\"exc\": safe_repr(exc_info.exception.exc)}, exc_info=exc_info)",
        "fixed_code": "\"exc\": safe_repr(exc_info.exception.exc)}, exc_info=exc_info.exc_info)",
        "patch": "@@ -355,7 +355,7 @@ def on_retry(self, exc_info):\n         if _does_info:\n             info(self.retry_msg.strip(), {\n                 \"id\": self.id, \"name\": self.name,\n-                \"exc\": safe_repr(exc_info.exception.exc)}, exc_info=exc_info)\n+                \"exc\": safe_repr(exc_info.exception.exc)}, exc_info=exc_info.exc_info)\n \n     def on_failure(self, exc_info):\n         \"\"\"Handler called if the task raised an exception.\"\"\""
    },
    {
        "commit_id": "7c0befe58a7b9552f46018fa3c84bdc3f629a166",
        "commit_message": "Beat: Fixes bug when entry.args is None.  Closes #657",
        "commit_url": "https://github.com/celery/celery/commit/7c0befe58a7b9552f46018fa3c84bdc3f629a166",
        "buggy_code": "reprcall(self.task, self.args, self.kwargs),",
        "fixed_code": "reprcall(self.task, self.args or (), self.kwargs or {}),",
        "patch": "@@ -119,7 +119,7 @@ def __iter__(self):\n \n     def __repr__(self):\n         return (\"<Entry: %s %s {%s}\" % (self.name,\n-                    reprcall(self.task, self.args, self.kwargs),\n+                    reprcall(self.task, self.args or (), self.kwargs or {}),\n                     self.schedule))\n \n "
    },
    {
        "commit_id": "041cb3c20da9bf774c9295e088cbe78d164b89b4",
        "commit_message": "Tasks can now have callbacks and errbacks, and dependencies are recorded\n\n- The task message format have been updated with two new extension keys\n\n    Both keys can be empty/undefined or a list of subtasks.\n\n    - ``callbacks``\n\n        Applied if the task exits successfully, with the result\n        of the task as an argument.\n\n    - ``errbacks``\n\n        Applied if an error occurred while executing the task,\n        with the uuid of the task as an argument.  Since it may not be possible\n        to serialize the exception instance, it passes the uuid of the task\n        instead.  The uuid can then be used to retrieve the exception and\n        traceback of the task from the result backend.\n\n- ``link`` and ``link_error`` keyword arguments has been added\n  to ``apply_async``.\n\n    The value passed can be either a subtask or a list of\n    subtasks:\n\n    .. code-block:: python\n\n        add.apply_async((2, 2), link=mul.subtask())\n        add.apply_async((2, 2), link=[mul.subtask(), echo.subtask()])\n\n    Example error callback:\n\n    .. code-block:: python\n\n        @task\n        def error_handler(uuid):\n            result = AsyncResult(uuid)\n            exc = result.get(propagate=False)\n            print(\"Task %r raised exception: %r\\n%r\" % (\n                exc, result.traceback))\n\n        >>> add.apply_async((2, 2), link_error=error_handler)\n\n- We now track what subtasks a task sends, and some result backends\n  supports retrieving this information.\n\n    - task.request.children\n\n        Contains the result instances of the subtasks\n        the currently executing task has applied.\n\n    - AsyncResult.children\n\n        Returns the tasks dependencies, as a list of\n        ``AsyncResult``/``ResultSet`` instances.\n\n    - AsyncResult.iterdeps\n\n        Recursively iterates over the tasks dependencies,\n        yielding `(parent, node)` tuples.\n\n        Raises IncompleteStream if any of the dependencies\n        has not returned yet.\n\n    - AsyncResult.graph\n\n        A ``DependencyGraph`` of the tasks dependencies.\n        This can also be used to convert to dot format:\n\n        .. code-block:: python\n\n            with open(\"graph.dot\") as fh:\n                result.graph.to_dot(fh)\n\n        which can than be used to produce an image::\n\n            $ dot -Tpng graph.dot -o graph.png",
        "commit_url": "https://github.com/celery/celery/commit/041cb3c20da9bf774c9295e088cbe78d164b89b4",
        "buggy_code": "+ \"Redis result store backend.\")",
        "fixed_code": "+ \"the Redis result store backend.\")",
        "patch": "@@ -44,7 +44,7 @@ def __init__(self, host=None, port=None, db=None, password=None,\n         if self.redis is None:\n             raise ImproperlyConfigured(\n                     \"You need to install the redis library in order to use \"\n-                  + \"Redis result store backend.\")\n+                  + \"the Redis result store backend.\")\n \n         # For compatibility with the old REDIS_* configuration keys.\n         def _get(key):"
    },
    {
        "commit_id": "980df77feb51e2a64c5ab174f4b8efc7b26495ea",
        "commit_message": "Removes expected error output from tests",
        "commit_url": "https://github.com/celery/celery/commit/980df77feb51e2a64c5ab174f4b8efc7b26495ea",
        "buggy_code": "None, sys.__stderr__)",
        "fixed_code": "None, sys.stderr)",
        "patch": "@@ -42,7 +42,7 @@ def body(self):\n     def on_crash(self, exc_info, msg, *fmt, **kwargs):\n         sys.stderr.write((msg + \"\\n\") % fmt)\n         traceback.print_exception(exc_info[0], exc_info[1], exc_info[2],\n-                                  None, sys.__stderr__)\n+                                  None, sys.stderr)\n \n     def run(self):\n         shutdown = self._is_shutdown"
    },
    {
        "commit_id": "980df77feb51e2a64c5ab174f4b8efc7b26495ea",
        "commit_message": "Removes expected error output from tests",
        "commit_url": "https://github.com/celery/celery/commit/980df77feb51e2a64c5ab174f4b8efc7b26495ea",
        "buggy_code": "None, sys.__stderr__)",
        "fixed_code": "None, sys.stderr)",
        "patch": "@@ -197,7 +197,7 @@ def apply_entry(self, entry):\n                     traceback.print_exception(exc_info[0],\n                                               exc_info[1],\n                                               exc_info[2],\n-                                              None, sys.__stderr__)\n+                                              None, sys.stderr)\n             finally:\n                 del(exc_info)\n "
    },
    {
        "commit_id": "bf41260bceee7ea6a638b648ec05506fc39ebf80",
        "commit_message": "Fix merge",
        "commit_url": "https://github.com/celery/celery/commit/bf41260bceee7ea6a638b648ec05506fc39ebf80",
        "buggy_code": "w.ready_queue = TaskBucket(task_registry=self.app.tasks)",
        "fixed_code": "w.ready_queue = TaskBucket(task_registry=w.app.tasks)",
        "patch": "@@ -130,7 +130,7 @@ def create(self, w):\n                 # just send task directly to pool, skip the mediator.\n                 w.ready_queue.put = w.process_task\n         else:\n-            w.ready_queue = TaskBucket(task_registry=self.app.tasks)\n+            w.ready_queue = TaskBucket(task_registry=w.app.tasks)\n \n \n class Timers(abstract.Component):"
    },
    {
        "commit_id": "bf41260bceee7ea6a638b648ec05506fc39ebf80",
        "commit_message": "Fix merge",
        "commit_url": "https://github.com/celery/celery/commit/bf41260bceee7ea6a638b648ec05506fc39ebf80",
        "buggy_code": "sh(\"python contrib/release/flakeplus.py celery\",",
        "fixed_code": "sh(\"flakeplus celery\",",
        "patch": "@@ -97,7 +97,7 @@ def flake8(options):\n ])\n def flakeplus(options):\n     noerror = getattr(options, \"noerror\", False)\n-    sh(\"python contrib/release/flakeplus.py celery\",\n+    sh(\"flakeplus celery\",\n        ignore_error=noerror)\n \n "
    },
    {
        "commit_id": "c2dbd1a9adaf08bf8c2527a7ca7b7ce35e218c1b",
        "commit_message": "Merge branch 'dcramer/fix-test-reqs'",
        "commit_url": "https://github.com/celery/celery/commit/c2dbd1a9adaf08bf8c2527a7ca7b7ce35e218c1b",
        "buggy_code": "tests_require = [\"nose\", \"nose-cover3\", \"sqlalchemy\", \"mock\"]",
        "fixed_code": "tests_require = [\"nose\", \"nose-cover3\", \"sqlalchemy\", \"mock\", \"cl\"]",
        "patch": "@@ -136,7 +136,7 @@ def run(self, *args, **kwargs):\n \n # -*- Tests Requires -*-\n \n-tests_require = [\"nose\", \"nose-cover3\", \"sqlalchemy\", \"mock\"]\n+tests_require = [\"nose\", \"nose-cover3\", \"sqlalchemy\", \"mock\", \"cl\"]\n if sys.version_info < (2, 7):\n     tests_require.append(\"unittest2\")\n elif sys.version_info <= (2, 5):"
    },
    {
        "commit_id": "87350d7c6b7bc5c769222d1dd1864954b858ea45",
        "commit_message": "Merge branch 'martinmelin/fix-package-in-celery-bin'",
        "commit_url": "https://github.com/celery/celery/commit/87350d7c6b7bc5c769222d1dd1864954b858ea45",
        "buggy_code": "if \"__main__\" and __package__ is None:",
        "fixed_code": "if __name__ == \"__main__\" and __package__ is None:",
        "patch": "@@ -73,7 +73,7 @@\n \"\"\"\n from __future__ import absolute_import\n \n-if \"__main__\" and __package__ is None:\n+if __name__ == \"__main__\" and __package__ is None:\n     __package__ = \"celery.bin.celeryd\"\n \n import sys"
    },
    {
        "commit_id": "9cd8db16d0a2d835aecf6bcea9c6cc3393604422",
        "commit_message": "Force execv patch broke -B option.  Closes #608",
        "commit_url": "https://github.com/celery/celery/commit/9cd8db16d0a2d835aecf6bcea9c6cc3393604422",
        "buggy_code": "self.force_execv = process_obj.force_execv",
        "fixed_code": "self.force_execv = getattr(process_obj, \"force_execv\", False)",
        "patch": "@@ -56,7 +56,7 @@ class Popen(_forking.Popen):  # noqa\n         returncode = None\n \n         def __init__(self, process_obj):\n-            self.force_execv = process_obj.force_execv\n+            self.force_execv = getattr(process_obj, \"force_execv\", False)\n \n             if self.force_execv:\n                 sys.stdout.flush()"
    },
    {
        "commit_id": "ee53d1ba4bcac77414e0172b95e80b0fcca69f13",
        "commit_message": "Merge branch 'jterrace/pycassa-1.4-fix'",
        "commit_url": "https://github.com/celery/celery/commit/ee53d1ba4bcac77414e0172b95e80b0fcca69f13",
        "buggy_code": "conn = pycassa.ConnectionPool(self.keyspace, servers=self.servers,",
        "fixed_code": "conn = pycassa.ConnectionPool(self.keyspace, server_list=self.servers,",
        "patch": "@@ -106,7 +106,7 @@ def _retry_on_error(self, fun, *args, **kwargs):\n \n     def _get_column_family(self):\n         if self._column_family is None:\n-            conn = pycassa.ConnectionPool(self.keyspace, servers=self.servers,\n+            conn = pycassa.ConnectionPool(self.keyspace, server_list=self.servers,\n                                    **self.cassandra_options)\n             self._column_family = \\\n               pycassa.ColumnFamily(conn, self.column_family,"
    },
    {
        "commit_id": "d0417d7b98669612468f2ac08845e43ddf1699fe",
        "commit_message": "Fix Cassandra backend to use pycassa.ConnectionPool since pycassa.connect is deprecated in pycassa 1.4",
        "commit_url": "https://github.com/celery/celery/commit/d0417d7b98669612468f2ac08845e43ddf1699fe",
        "buggy_code": "conn = pycassa.connect(self.keyspace, servers=self.servers,",
        "fixed_code": "conn = pycassa.ConnectionPool(self.keyspace, servers=self.servers,",
        "patch": "@@ -106,7 +106,7 @@ def _retry_on_error(self, fun, *args, **kwargs):\n \n     def _get_column_family(self):\n         if self._column_family is None:\n-            conn = pycassa.connect(self.keyspace, servers=self.servers,\n+            conn = pycassa.ConnectionPool(self.keyspace, servers=self.servers,\n                                    **self.cassandra_options)\n             self._column_family = \\\n               pycassa.ColumnFamily(conn, self.column_family,"
    },
    {
        "commit_id": "fc0bf576035fe4ff908bcfdb20d68465d2d63328",
        "commit_message": "Now forks with execv to protect against deadlocks.  Using modified patch originating from http://bugs.python.org/issue8713",
        "commit_url": "https://github.com/celery/celery/commit/fc0bf576035fe4ff908bcfdb20d68465d2d63328",
        "buggy_code": "from multiprocessing import freeze_support",
        "fixed_code": "from celery.concurrency.processes.forking import freeze_support",
        "patch": "@@ -76,7 +76,7 @@\n import sys\n \n try:\n-    from multiprocessing import freeze_support\n+    from celery.concurrency.processes.forking import freeze_support\n except ImportError:  # pragma: no cover\n     freeze_support = lambda: True  # noqa\n "
    },
    {
        "commit_id": "8462914b8e0b0675b471c79b1190bcd7d8f78151",
        "commit_message": "Fix a few failing unit tests\n\n* pyparsing is no longer used- we have our own ParseException class\n* StringIO has been subclassed by WhateverIO, causing a broken import\n* We should use datetime.utcnow() rather than datetime.now() calls in\n  tests now that the UTC branch has been merged, this caused two failing\n  tests (at least in my timezone)",
        "commit_url": "https://github.com/celery/celery/commit/8462914b8e0b0675b471c79b1190bcd7d8f78151",
        "buggy_code": "\"\"\"Override `sys.stdout` and `sys.stderr` with `StringIO`.\"\"\"",
        "fixed_code": "\"\"\"Override `sys.stdout` and `sys.stderr` with `WhateverIO`.\"\"\"",
        "patch": "@@ -254,7 +254,7 @@ def myimp(name, *args, **kwargs):\n \n @contextmanager\n def override_stdouts():\n-    \"\"\"Override `sys.stdout` and `sys.stderr` with `StringIO`.\"\"\"\n+    \"\"\"Override `sys.stdout` and `sys.stderr` with `WhateverIO`.\"\"\"\n     prev_out, prev_err = sys.stdout, sys.stderr\n     mystdout, mystderr = WhateverIO(), WhateverIO()\n     sys.stdout = sys.__stdout__ = mystdout"
    },
    {
        "commit_id": "f36fb92b8fca2395521637afaa40f2959cd3bd18",
        "commit_message": "Add a test for and fix behavior with bogus arguments\n\nWe should have been using %s, not %r here.",
        "commit_url": "https://github.com/celery/celery/commit/f36fb92b8fca2395521637afaa40f2959cd3bd18",
        "buggy_code": "\"\\nUnrecognized command line arguments: %r\\n\" % (",
        "fixed_code": "\"\\nUnrecognized command line arguments: %s\\n\" % (",
        "patch": "@@ -108,7 +108,7 @@ def handle_argv(self, prog_name, argv):\n         options, args = self.parse_options(prog_name, argv)\n         if not self.supports_args and args:\n             sys.stderr.write(\n-                \"\\nUnrecognized command line arguments: %r\\n\" % (\n+                \"\\nUnrecognized command line arguments: %s\\n\" % (\n                     \", \".join(args), ))\n             sys.stderr.write(\"\\nTry --help?\\n\")\n             sys.exit(1)"
    },
    {
        "commit_id": "e43502b7708e2295d67231f394ae6a82b63010a9",
        "commit_message": "Merge pull request #494 from jonashaag/patch-1\n\nMention 'solo' and 'threads' pool implementations in celeryd CLI docs",
        "commit_url": "https://github.com/celery/celery/commit/e43502b7708e2295d67231f394ae6a82b63010a9",
        "buggy_code": "\"processes (default), eventlet or gevent.\"),",
        "fixed_code": "\"processes (default), eventlet, gevent, solo or threads.\"),",
        "patch": "@@ -108,7 +108,7 @@ def get_options(self):\n                 default=conf.CELERYD_POOL,\n                 action=\"store\", dest=\"pool\", type=\"str\",\n                 help=\"Pool implementation: \"\n-                     \"processes (default), eventlet or gevent.\"),\n+                     \"processes (default), eventlet, gevent, solo or threads.\"),\n             Option('--purge', '--discard', default=False,\n                 action=\"store_true\", dest=\"discard\",\n                 help=\"Discard all waiting tasks before the server is\""
    },
    {
        "commit_id": "2700e0f1a4bcc367e1010139dc3169bddfc430c3",
        "commit_message": "Infinite recursion error.",
        "commit_url": "https://github.com/celery/celery/commit/2700e0f1a4bcc367e1010139dc3169bddfc430c3",
        "buggy_code": "self.pop(key, *args)",
        "fixed_code": "super(LocalCache, self).pop(key, *args)",
        "patch": "@@ -311,7 +311,7 @@ def __setitem__(self, key, value):\n \n     def pop(self, key, *args):\n         with self.lock:\n-            self.pop(key, *args)\n+            super(LocalCache, self).pop(key, *args)\n \n \n class TokenBucket(object):"
    },
    {
        "commit_id": "1eb43e884e674d741eaa5508d8a510a4e121e19f",
        "commit_message": "Merge pull request #412 from drx/patch-1\n\nTypo correction (cahe -> cache).",
        "commit_url": "https://github.com/celery/celery/commit/1eb43e884e674d741eaa5508d8a510a4e121e19f",
        "buggy_code": "def test_get_backend_cahe(self):",
        "fixed_code": "def test_get_backend_cache(self):",
        "patch": "@@ -14,7 +14,7 @@ def test_get_backend_aliases(self):\n             self.assertIsInstance(backends.get_backend_cls(expect_name)(),\n                                   expect_cls)\n \n-    def test_get_backend_cahe(self):\n+    def test_get_backend_cache(self):\n         backends._backend_cache = {}\n         backends.get_backend_cls(\"amqp\")\n         self.assertIn(\"amqp\", backends._backend_cache)"
    },
    {
        "commit_id": "990c892426689163d3c4bb84aa24d5f9da78d262",
        "commit_message": "fix --gid option of celery_multi",
        "commit_url": "https://github.com/celery/celery/commit/990c892426689163d3c4bb84aa24d5f9da78d262",
        "buggy_code": "os.setegid",
        "fixed_code": "os.setegid(gid)",
        "patch": "@@ -224,7 +224,7 @@ def setegid(gid):\n     \"\"\"Set effective group id.\"\"\"\n     gid = parse_gid(gid)\n     if gid != os.getgid():\n-        os.setegid\n+        os.setegid(gid)\n \n \n def seteuid(uid):"
    },
    {
        "commit_id": "4ba2b68e9ee6530c8052f6fa00352da2fa41105f",
        "commit_message": "Fixes bug in celery.utils.find_module",
        "commit_url": "https://github.com/celery/celery/commit/4ba2b68e9ee6530c8052f6fa00352da2fa41105f",
        "buggy_code": "def import_from_cwd(self, name):",
        "fixed_code": "def find_module(self, name):",
        "patch": "@@ -201,7 +201,7 @@ def test_unconfigured_settings(self):\n \n         class _Loader(default.Loader):\n \n-            def import_from_cwd(self, name):\n+            def find_module(self, name):\n                 raise ImportError(name)\n \n         with catch_warnings(record=True) as log:"
    },
    {
        "commit_id": "3bb7227c542101a5976598c9c80cb240534d5535",
        "commit_message": "Fixing a bug.",
        "commit_url": "https://github.com/celery/celery/commit/3bb7227c542101a5976598c9c80cb240534d5535",
        "buggy_code": "\"BACKEND_EXTRA_ARGS\": Option({}, type=\"dict\")",
        "fixed_code": "\"TRANSPORT_OPTIONS\": Option({}, type=\"dict\")",
        "patch": "@@ -52,7 +52,7 @@ def to_python(self, value):\n         \"CONNECTION_MAX_RETRIES\": Option(100, type=\"int\"),\n         \"INSIST\": Option(False, type=\"bool\"),\n         \"USE_SSL\": Option(False, type=\"bool\"),\n-        \"BACKEND_EXTRA_ARGS\": Option({}, type=\"dict\")\n+        \"TRANSPORT_OPTIONS\": Option({}, type=\"dict\")\n     },\n     \"CELERY\": {\n         \"ACKS_LATE\": Option(False, type=\"bool\"),"
    },
    {
        "commit_id": "3cbd7cedc8d5907e77c8ef9dc829ba8456f081a2",
        "commit_message": "Fixes issues related to producer queue declarations.\n\nThis patch changes producer queue declaration behavior to the following:\n\n    * Queues are only declared when needed.\n\n        Previously configured queues were only declared once: when\n        the first message was sent.\n\n    * Automatically configured queues are now declared in the same manner.\n\n        These are queues created because of CREATE_MISSING_QUEUES.\n        Kombu virtual transports requires the producer to declare all\n        queues, as the routing table is kept in producer memory.\n        For AMQP this means we won't lose messages if there are no one\n        consuming from this queue.",
        "commit_url": "https://github.com/celery/celery/commit/3cbd7cedc8d5907e77c8ef9dc829ba8456f081a2",
        "buggy_code": "self.assertNotIn(\"queue\", route)",
        "fixed_code": "self.assertIn(\"queue\", route)",
        "patch": "@@ -93,7 +93,7 @@ def test_expands_queue_in_options(self):\n                                        \"routing_key\": \"testq\",\n                                        \"immediate\": False},\n                                        route)\n-        self.assertNotIn(\"queue\", route)\n+        self.assertIn(\"queue\", route)\n \n     @with_queues(foo=a_queue, bar=b_queue)\n     def test_expand_destaintion_string(self):"
    },
    {
        "commit_id": "f0d761bce7ee049fa32aac4d56a79eb999aaa6f9",
        "commit_message": "Worker pid is now sent with the task-accepted event.\n\nIn addition time_start (used e.g. to calculate the total execution time)\nis now taken from what the worker reports, meaning more accuracy\nand saving us a call to time.time() (yay ;)\n\nCloses #277.  Should probably open up a new issue to display this\ninfo in monitors (celeryev/djcelerymon)",
        "commit_url": "https://github.com/celery/celery/commit/f0d761bce7ee049fa32aac4d56a79eb999aaa6f9",
        "buggy_code": "self._accept_callback()",
        "fixed_code": "self._accept_callback(pid, time_accepted)",
        "patch": "@@ -863,7 +863,7 @@ def _ack(self, i, time_accepted, pid):\n         self._time_accepted = time_accepted\n         self._worker_pid = pid\n         if self._accept_callback:\n-            self._accept_callback()\n+            self._accept_callback(pid, time_accepted)\n         if self._ready:\n             self._cache.pop(self._job, None)\n "
    },
    {
        "commit_id": "f4aefcdd0df8118781057621072c24e6cf1bc820",
        "commit_message": "Removed `celery.task.RemoteExecuteTask` and accompanying functions: `dmap`, `dmap_async`, and `execute_remote`.\n\nExecuting arbitrary code using pickle is a potential security issue if\nsomeone gains unrestricted access to the message broker.\n\nIf you really need this functionality, then you can simply add this\nmanually.",
        "commit_url": "https://github.com/celery/celery/commit/f4aefcdd0df8118781057621072c24e6cf1bc820",
        "buggy_code": "from celery.serialization import pickle",
        "fixed_code": "from celery.utils.serialization import pickle",
        "patch": "@@ -15,7 +15,7 @@\n \n from celery.backends.base import BaseDictBackend\n from celery.exceptions import ImproperlyConfigured\n-from celery.serialization import pickle\n+from celery.utils.serialization import pickle\n from celery import states\n \n "
    },
    {
        "commit_id": "f4aefcdd0df8118781057621072c24e6cf1bc820",
        "commit_message": "Removed `celery.task.RemoteExecuteTask` and accompanying functions: `dmap`, `dmap_async`, and `execute_remote`.\n\nExecuting arbitrary code using pickle is a potential security issue if\nsomeone gains unrestricted access to the message broker.\n\nIf you really need this functionality, then you can simply add this\nmanually.",
        "commit_url": "https://github.com/celery/celery/commit/f4aefcdd0df8118781057621072c24e6cf1bc820",
        "buggy_code": "from celery.serialization import pickle",
        "fixed_code": "from celery.utils.serialization import pickle",
        "patch": "@@ -9,7 +9,7 @@\n from celery import states\n from celery.backends.base import BaseDictBackend\n from celery.exceptions import ImproperlyConfigured\n-from celery.serialization import pickle\n+from celery.utils.serialization import pickle\n \n \n class Bunch:"
    },
    {
        "commit_id": "f4aefcdd0df8118781057621072c24e6cf1bc820",
        "commit_message": "Removed `celery.task.RemoteExecuteTask` and accompanying functions: `dmap`, `dmap_async`, and `execute_remote`.\n\nExecuting arbitrary code using pickle is a potential security issue if\nsomeone gains unrestricted access to the message broker.\n\nIf you really need this functionality, then you can simply add this\nmanually.",
        "commit_url": "https://github.com/celery/celery/commit/f4aefcdd0df8118781057621072c24e6cf1bc820",
        "buggy_code": "from celery.serialization import pickle",
        "fixed_code": "from celery.utils.serialization import pickle",
        "patch": "@@ -1,6 +1,6 @@\n from celery.tests.utils import unittest\n \n-from celery.serialization import pickle\n+from celery.utils.serialization import pickle\n \n \n class RegularException(Exception):"
    },
    {
        "commit_id": "f4aefcdd0df8118781057621072c24e6cf1bc820",
        "commit_message": "Removed `celery.task.RemoteExecuteTask` and accompanying functions: `dmap`, `dmap_async`, and `execute_remote`.\n\nExecuting arbitrary code using pickle is a potential security issue if\nsomeone gains unrestricted access to the message broker.\n\nIf you really need this functionality, then you can simply add this\nmanually.",
        "commit_url": "https://github.com/celery/celery/commit/f4aefcdd0df8118781057621072c24e6cf1bc820",
        "buggy_code": "from celery.serialization import pickle",
        "fixed_code": "from celery.utils.serialization import pickle",
        "patch": "@@ -12,13 +12,13 @@\n from celery.concurrency.base import BasePool\n from celery.decorators import task as task_dec\n from celery.decorators import periodic_task as periodic_task_dec\n-from celery.serialization import pickle\n from celery.utils import gen_unique_id\n from celery.worker import WorkController\n from celery.worker.buckets import FastQueue\n from celery.worker.job import TaskRequest\n from celery.worker.consumer import Consumer as MainConsumer\n from celery.worker.consumer import QoS, RUN\n+from celery.utils.serialization import pickle\n \n from celery.tests.compat import catch_warnings\n from celery.tests.utils import execute_context"
    },
    {
        "commit_id": "5fee1548ddd4d6dd2b972f214619dd4174785e55",
        "commit_message": "Fix the ncurses application layout so that it scales task and worker columns for larger displays in celeryev",
        "commit_url": "https://github.com/celery/celery/commit/5fee1548ddd4d6dd2b972f214619dd4174785e55",
        "buggy_code": "module = abbr(module, max - len(cls), False)",
        "fixed_code": "module = abbr(module, max - len(cls) - 3, False)",
        "patch": "@@ -306,7 +306,7 @@ def abbrtask(S, max):\n         return \"???\"\n     if len(S) > max:\n         module, _, cls = rpartition(S, \".\")\n-        module = abbr(module, max - len(cls), False)\n+        module = abbr(module, max - len(cls) - 3, False)\n         return module + \"[.]\" + cls\n     return S\n "
    },
    {
        "commit_id": "6d255867ae20b675314c51bcd6fcd759dd8b2ca1",
        "commit_message": "Yes! Yes! Got eventlet support working (but some small bugs to fix still)",
        "commit_url": "https://github.com/celery/celery/commit/6d255867ae20b675314c51bcd6fcd759dd8b2ca1",
        "buggy_code": "runtime = time.time() - self.time_start",
        "fixed_code": "runtime = self.time_start and (time.time() - self.time_start) or 0",
        "patch": "@@ -430,7 +430,7 @@ def on_success(self, ret_value):\n         if self.task.acks_late:\n             self.acknowledge()\n \n-        runtime = time.time() - self.time_start\n+        runtime = self.time_start and (time.time() - self.time_start) or 0\n         self.send_event(\"task-succeeded\", uuid=self.task_id,\n                         result=repr(ret_value), runtime=runtime)\n "
    },
    {
        "commit_id": "2c462cf537cc0ffd88deae681d2e2c70ab055cf4",
        "commit_message": "Error email body now uses repr(exc) instead of str(exc).\n\nAs the latter could result in unicode decode errors.\n\nCloses #245.",
        "commit_url": "https://github.com/celery/celery/commit/2c462cf537cc0ffd88deae681d2e2c70ab055cf4",
        "buggy_code": "Task %%(name)s with id %%(id)s raised exception:\\n%%(exc)s",
        "fixed_code": "Task %%(name)s with id %%(id)s raised exception:\\n%%(exc)r",
        "patch": "@@ -26,7 +26,7 @@\n \n #: format string for the body of an error e-mail.\n TASK_ERROR_EMAIL_BODY = \"\"\"\n-Task %%(name)s with id %%(id)s raised exception:\\n%%(exc)s\n+Task %%(name)s with id %%(id)s raised exception:\\n%%(exc)r\n \n \n Task was called with args: %%(args)s kwargs: %%(kwargs)s."
    },
    {
        "commit_id": "37c683ffc98ac5778ee49bd8f695d8bcdb4412be",
        "commit_message": "Added a 2 second timeout for sending error e-mails.  Closes #222",
        "commit_url": "https://github.com/celery/celery/commit/37c683ffc98ac5778ee49bd8f695d8bcdb4412be",
        "buggy_code": "\"runtime\": 0.1376}",
        "fixed_code": "\"runtime\": 0.3641}",
        "patch": "@@ -323,7 +323,7 @@ def test_task_wrapper_mail_attrs(self):\n         x = tw.success_msg % {\"name\": tw.task_name,\n                               \"id\": tw.task_id,\n                               \"return_value\": 10,\n-                              \"runtime\": 0.1376}\n+                              \"runtime\": 0.3641}\n         self.assertTrue(x)\n         x = tw.error_msg % {\"name\": tw.task_name,\n                            \"id\": tw.task_id,"
    },
    {
        "commit_id": "895ad0b0d5bc1c6b3d1f048a7eb5b2763fc22e8a",
        "commit_message": "Fixed syntax error",
        "commit_url": "https://github.com/celery/celery/commit/895ad0b0d5bc1c6b3d1f048a7eb5b2763fc22e8a",
        "buggy_code": "return dict((name, options.get(name) for name in keep))",
        "fixed_code": "return dict((name, options.get(name)) for name in keep)",
        "patch": "@@ -38,7 +38,7 @@\n \n \n def extract_msg_options(options, keep=MSG_OPTIONS):\n-    return dict((name, options.get(name) for name in keep))\n+    return dict((name, options.get(name)) for name in keep)\n \n \n class Queues(UserDict):"
    },
    {
        "commit_id": "b34074a5840086dd2a1e04e241fd9b6fabc0a570",
        "commit_message": "Fix for a race condition where Timer.enter is called twice before the thread actually runs.",
        "commit_url": "https://github.com/celery/celery/commit/b34074a5840086dd2a1e04e241fd9b6fabc0a570",
        "buggy_code": "if not self.running:",
        "fixed_code": "if not self.running and not self.is_alive():",
        "patch": "@@ -180,7 +180,7 @@ def stop(self):\n             self.running = False\n \n     def enter(self, entry, eta, priority=None):\n-        if not self.running:\n+        if not self.running and not self.is_alive():\n             self.start()\n         return self.schedule.enter(entry, eta, priority)\n "
    },
    {
        "commit_id": "54e755d0fe9c0c06cfd5e18b52d73145268a272f",
        "commit_message": "Fixed syntax error in setup.py",
        "commit_url": "https://github.com/celery/celery/commit/54e755d0fe9c0c06cfd5e18b52d73145268a272f",
        "buggy_code": "\"kombu",
        "fixed_code": "\"kombu\",",
        "patch": "@@ -129,7 +129,7 @@ def run(self, *args, **kwargs):\n install_requires.extend([\n     \"python-dateutil\",\n     \"anyjson\",\n-    \"kombu\n+    \"kombu\",\n     \"pyparsing\",\n ])\n "
    },
    {
        "commit_id": "14807e6941c97e0ef20963fbf4e8303a9b65b4a4",
        "commit_message": "Messed up fix for #182",
        "commit_url": "https://github.com/celery/celery/commit/14807e6941c97e0ef20963fbf4e8303a9b65b4a4",
        "buggy_code": "kwargs=dict(kwargs, **extra) or {},",
        "fixed_code": "kwargs=dict(kwargs or {}, **extra),",
        "patch": "@@ -71,7 +71,7 @@ def __init__(self, task=None, args=None, kwargs=None, options=None,\n             task_name = task\n \n         init(task=task_name, args=tuple(args or ()),\n-                             kwargs=dict(kwargs, **extra) or {},\n+                             kwargs=dict(kwargs or {}, **extra),\n                              options=options or {})\n \n     def delay(self, *argmerge, **kwmerge):"
    },
    {
        "commit_id": "9710a2669901566788210a296757cd4b463165e4",
        "commit_message": "term.colored: Fix parameter list to work for Python <= 2.5",
        "commit_url": "https://github.com/celery/celery/commit/9710a2669901566788210a296757cd4b463165e4",
        "buggy_code": "return self.__class__(*s, enabled=self.enabled, op=op)",
        "fixed_code": "return self.__class__(enabled=self.enabled, op=op, *s)",
        "patch": "@@ -55,7 +55,7 @@ def __str__(self):\n         return prefix + reduce(self._add, self.s) + suffix\n \n     def node(self, s, op):\n-        return self.__class__(*s, enabled=self.enabled, op=op)\n+        return self.__class__(enabled=self.enabled, op=op, *s)\n \n     def black(self, *s):\n         return self.node(s, fg(30 + BLACK))"
    },
    {
        "commit_id": "4686af8d3490b76b6af7def843f18664d82ab6f8",
        "commit_message": "Fix default_retry_delay docstring to match reality",
        "commit_url": "https://github.com/celery/celery/commit/4686af8d3490b76b6af7def843f18664d82ab6f8",
        "buggy_code": "executed. Default is a 1 minute delay.",
        "fixed_code": "executed. Default is a 3 minute delay.",
        "patch": "@@ -132,7 +132,7 @@ class Task(object):\n     .. attribute:: default_retry_delay\n \n         Default time in seconds before a retry of the task should be\n-        executed. Default is a 1 minute delay.\n+        executed. Default is a 3 minute delay.\n \n     .. attribute:: rate_limit\n "
    },
    {
        "commit_id": "280cbb4839007acb11a3930271dd7da7d2510003",
        "commit_message": "Fix incorrect config key in documentation",
        "commit_url": "https://github.com/celery/celery/commit/280cbb4839007acb11a3930271dd7da7d2510003",
        "buggy_code": "``settings.SEND_CELERY_ERROR_EMAILS`` is on.)",
        "fixed_code": "``settings.CELERY_SEND_TASK_ERROR_EMAILS`` is on.)",
        "patch": "@@ -147,7 +147,7 @@ class Task(object):\n     .. attribute:: disable_error_emails\n \n         Disable all error e-mails for this task (only applicable if\n-        ``settings.SEND_CELERY_ERROR_EMAILS`` is on.)\n+        ``settings.CELERY_SEND_TASK_ERROR_EMAILS`` is on.)\n \n     .. attribute:: serializer\n "
    },
    {
        "commit_id": "acfb51c045a9a9f6b6c98ff9822bc22660668c86",
        "commit_message": "API reference: Fix :returns: / :rtype: so they work with Sphinx 1.0b2",
        "commit_url": "https://github.com/celery/celery/commit/acfb51c045a9a9f6b6c98ff9822bc22660668c86",
        "buggy_code": ":rtype: :exc:`Exception`",
        "fixed_code": ":rtype :exc:`Exception`:",
        "patch": "@@ -57,7 +57,7 @@ def find_nearest_pickleable_exception(exc):\n     :returns: the nearest exception if it's not :exc:`Exception` or below,\n         if it is it returns ``None``.\n \n-    :rtype: :exc:`Exception`\n+    :rtype :exc:`Exception`:\n \n     \"\"\"\n     cls = exc.__class__"
    },
    {
        "commit_id": "4e57d705e9c9d2788abdc7e3f77267b301377fca",
        "commit_message": "Billiard moved back to celery repo, as Debian doesn't approve much of it.\n\nSee http://bugs.debian.org/cgi-bin/bugreport.cgi?bug=571656",
        "commit_url": "https://github.com/celery/celery/commit/4e57d705e9c9d2788abdc7e3f77267b301377fca",
        "buggy_code": "from billiard.serialization import pickle",
        "fixed_code": "from celery.serialization import pickle",
        "patch": "@@ -1,7 +1,6 @@\n \"\"\"MongoDB backend for celery.\"\"\"\n from datetime import datetime\n \n-from billiard.serialization import pickle\n try:\n     import pymongo\n except ImportError:\n@@ -12,6 +11,7 @@\n from celery.loaders import load_settings\n from celery.backends.base import BaseDictBackend\n from celery.exceptions import ImproperlyConfigured\n+from celery.serialization import pickle\n \n \n class Bunch:"
    },
    {
        "commit_id": "4e57d705e9c9d2788abdc7e3f77267b301377fca",
        "commit_message": "Billiard moved back to celery repo, as Debian doesn't approve much of it.\n\nSee http://bugs.debian.org/cgi-bin/bugreport.cgi?bug=571656",
        "commit_url": "https://github.com/celery/celery/commit/4e57d705e9c9d2788abdc7e3f77267b301377fca",
        "buggy_code": "from billiard.utils.functional import curry",
        "fixed_code": "from celery.utils.functional import curry",
        "patch": "@@ -1,9 +1,9 @@\n \n import threading\n-from billiard.utils.functional import curry\n from threadpool import ThreadPool, WorkRequest\n \n from celery import log\n+from celery.utils.functional import curry\n from celery.datastructures import ExceptionInfo\n \n "
    },
    {
        "commit_id": "4e57d705e9c9d2788abdc7e3f77267b301377fca",
        "commit_message": "Billiard moved back to celery repo, as Debian doesn't approve much of it.\n\nSee http://bugs.debian.org/cgi-bin/bugreport.cgi?bug=571656",
        "commit_url": "https://github.com/celery/celery/commit/4e57d705e9c9d2788abdc7e3f77267b301377fca",
        "buggy_code": "from billiard.utils.functional import wraps",
        "fixed_code": "from celery.utils.functional import wraps",
        "patch": "@@ -9,11 +9,11 @@\n \n from carrot.connection import DjangoBrokerConnection\n from carrot.messaging import Publisher, Consumer, ConsumerSet as _ConsumerSet\n-from billiard.utils.functional import wraps\n \n from celery import conf\n from celery import signals\n from celery.utils import gen_unique_id, mitemgetter, noop\n+from celery.utils.functional import wraps\n from celery.routes import lookup_route, expand_destination\n from celery.loaders import load_settings\n "
    },
    {
        "commit_id": "4e57d705e9c9d2788abdc7e3f77267b301377fca",
        "commit_message": "Billiard moved back to celery repo, as Debian doesn't approve much of it.\n\nSee http://bugs.debian.org/cgi-bin/bugreport.cgi?bug=571656",
        "commit_url": "https://github.com/celery/celery/commit/4e57d705e9c9d2788abdc7e3f77267b301377fca",
        "buggy_code": "from billiard.utils.functional import curry",
        "fixed_code": "from celery.utils.functional import curry",
        "patch": "@@ -6,11 +6,11 @@\n import unittest2 as unittest\n from itertools import chain, izip\n \n-from billiard.utils.functional import curry\n \n from celery.task.base import Task\n from celery.utils import timeutils\n from celery.utils import gen_unique_id\n+from celery.utils.functional import curry\n from celery.worker import buckets\n from celery.registry import TaskRegistry\n "
    },
    {
        "commit_id": "4e57d705e9c9d2788abdc7e3f77267b301377fca",
        "commit_message": "Billiard moved back to celery repo, as Debian doesn't approve much of it.\n\nSee http://bugs.debian.org/cgi-bin/bugreport.cgi?bug=571656",
        "commit_url": "https://github.com/celery/celery/commit/4e57d705e9c9d2788abdc7e3f77267b301377fca",
        "buggy_code": "from billiard.serialization import pickle",
        "fixed_code": "from celery.serialization import pickle",
        "patch": "@@ -1,6 +1,6 @@\n import unittest2 as unittest\n \n-from billiard.serialization import pickle\n+from celery.serialization import pickle\n \n \n class RegularException(Exception):"
    },
    {
        "commit_id": "4e57d705e9c9d2788abdc7e3f77267b301377fca",
        "commit_message": "Billiard moved back to celery repo, as Debian doesn't approve much of it.\n\nSee http://bugs.debian.org/cgi-bin/bugreport.cgi?bug=571656",
        "commit_url": "https://github.com/celery/celery/commit/4e57d705e9c9d2788abdc7e3f77267b301377fca",
        "buggy_code": "from billiard.utils.functional import wraps",
        "fixed_code": "from celery.utils.functional import wraps",
        "patch": "@@ -1,10 +1,10 @@\n import unittest2 as unittest\n \n-from billiard.utils.functional import wraps\n \n from celery import conf\n from celery import routes\n from celery.utils import gen_unique_id\n+from celery.utils.functional import wraps\n from celery.exceptions import RouteNotFound\n \n "
    },
    {
        "commit_id": "4e57d705e9c9d2788abdc7e3f77267b301377fca",
        "commit_message": "Billiard moved back to celery repo, as Debian doesn't approve much of it.\n\nSee http://bugs.debian.org/cgi-bin/bugreport.cgi?bug=571656",
        "commit_url": "https://github.com/celery/celery/commit/4e57d705e9c9d2788abdc7e3f77267b301377fca",
        "buggy_code": "from billiard.utils.functional import wraps",
        "fixed_code": "from celery.utils.functional import wraps",
        "patch": "@@ -4,14 +4,14 @@\n \n from pyparsing import ParseException\n \n-from billiard.utils.functional import wraps\n \n from celery import conf\n from celery import task\n from celery import messaging\n from celery.task.schedules import crontab, crontab_parser\n from celery.utils import timeutils\n from celery.utils import gen_unique_id\n+from celery.utils.functional import wraps\n from celery.result import EagerResult\n from celery.execute import send_task\n from celery.backends import default_backend"
    },
    {
        "commit_id": "4e57d705e9c9d2788abdc7e3f77267b301377fca",
        "commit_message": "Billiard moved back to celery repo, as Debian doesn't approve much of it.\n\nSee http://bugs.debian.org/cgi-bin/bugreport.cgi?bug=571656",
        "commit_url": "https://github.com/celery/celery/commit/4e57d705e9c9d2788abdc7e3f77267b301377fca",
        "buggy_code": "from billiard.utils.functional import wraps",
        "fixed_code": "from celery.utils.functional import wraps",
        "patch": "@@ -13,10 +13,10 @@\n except ImportError:\n     from StringIO import StringIO\n \n-from billiard.utils.functional import wraps\n from anyjson import serialize\n \n from celery.task import http\n+from celery.utils.functional import wraps\n \n from celery.tests.utils import eager_tasks, execute_context\n "
    },
    {
        "commit_id": "4e57d705e9c9d2788abdc7e3f77267b301377fca",
        "commit_message": "Billiard moved back to celery repo, as Debian doesn't approve much of it.\n\nSee http://bugs.debian.org/cgi-bin/bugreport.cgi?bug=571656",
        "commit_url": "https://github.com/celery/celery/commit/4e57d705e9c9d2788abdc7e3f77267b301377fca",
        "buggy_code": "from billiard.serialization import pickle",
        "fixed_code": "from celery.serialization import pickle",
        "patch": "@@ -5,7 +5,6 @@\n \n from carrot.connection import BrokerConnection\n from carrot.backends.base import BaseMessage\n-from billiard.serialization import pickle\n \n from celery import conf\n from celery.utils import gen_unique_id\n@@ -16,6 +15,7 @@\n from celery.worker.scheduler import Scheduler\n from celery.decorators import task as task_dec\n from celery.decorators import periodic_task as periodic_task_dec\n+from celery.serialization import pickle\n \n from celery.tests.utils import execute_context\n from celery.tests.compat import catch_warnings"
    },
    {
        "commit_id": "4e57d705e9c9d2788abdc7e3f77267b301377fca",
        "commit_message": "Billiard moved back to celery repo, as Debian doesn't approve much of it.\n\nSee http://bugs.debian.org/cgi-bin/bugreport.cgi?bug=571656",
        "commit_url": "https://github.com/celery/celery/commit/4e57d705e9c9d2788abdc7e3f77267b301377fca",
        "buggy_code": "from billiard.utils.functional import curry",
        "fixed_code": "from celery.utils.functional import curry",
        "patch": "@@ -16,10 +16,10 @@\n from itertools import islice\n \n from carrot.utils import rpartition\n-from billiard.utils.functional import curry\n \n from celery.utils.compat import all, any, defaultdict\n from celery.utils.timeutils import timedelta_seconds # was here before\n+from celery.utils.functional import curry\n \n \n def noop(*args, **kwargs):"
    },
    {
        "commit_id": "895af00b1fe5eb66c944cb67f6b55c40909f3fe9",
        "commit_message": "Fix: docbugs.",
        "commit_url": "https://github.com/celery/celery/commit/895af00b1fe5eb66c944cb67f6b55c40909f3fe9",
        "buggy_code": "numbers represent the units of time that the crontab needs to run on.",
        "fixed_code": "numbers represent the units of time that the crontab needs to run on::",
        "patch": "@@ -33,7 +33,7 @@ def is_due(self, last_run_at):\n class crontab_parser(object):\n     \"\"\"Parser for crontab expressions. Any expression of the form 'groups' (see\n     BNF grammar below) is accepted and expanded to a set of numbers.  These\n-    numbers represent the units of time that the crontab needs to run on.\n+    numbers represent the units of time that the crontab needs to run on::\n \n         digit   :: '0'..'9'\n         dow     :: 'a'..'z'"
    },
    {
        "commit_id": "abbc12e04dd30bc903123657f458819f49e762f3",
        "commit_message": "Fix for isoweekday()'s return value.\n\nIts return values are in the range 1..7 (instead of the expected range 0..6).\nThis is backed up by three extra unit tests.",
        "commit_url": "https://github.com/celery/celery/commit/abbc12e04dd30bc903123657f458819f49e762f3",
        "buggy_code": "due = now.isoweekday() in self.day_of_week and \\",
        "fixed_code": "due = now.isoweekday() % 7 in self.day_of_week and \\",
        "patch": "@@ -217,7 +217,7 @@ def is_due(self, last_run_at):\n         last = now - last_run_at\n         due, when = False, 1\n         if last.days > 0 or last.seconds > 60:\n-            due = now.isoweekday() in self.day_of_week and \\\n+            due = now.isoweekday() % 7 in self.day_of_week and \\\n                   now.hour in self.hour and \\\n                   now.minute in self.minute\n         return due, when"
    },
    {
        "commit_id": "3ef777fb66047cd599cd9817158c05cfd7a9d12c",
        "commit_message": "celery.execute.apply: Should return exception, not ExceptionInfo on error.\nCloses #111. Thanks to jonozzz",
        "commit_url": "https://github.com/celery/celery/commit/3ef777fb66047cd599cd9817158c05cfd7a9d12c",
        "buggy_code": "raise self.result.exception",
        "fixed_code": "raise self.result",
        "patch": "@@ -371,7 +371,7 @@ def wait(self, timeout=None):\n         if self.status == states.SUCCESS:\n             return self.result\n         elif self.status == states.FAILURE:\n-            raise self.result.exception\n+            raise self.result\n \n     def revoke(self):\n         pass"
    },
    {
        "commit_id": "b2ad4207144a3d114fc17e37c24fec7bc66816e2",
        "commit_message": "models: result field should not ever be NULL.\n\nNeed to fix the underlying issue here.",
        "commit_url": "https://github.com/celery/celery/commit/b2ad4207144a3d114fc17e37c24fec7bc66816e2",
        "buggy_code": "result = PickledObjectField(null=True)",
        "fixed_code": "result = PickledObjectField(null=False)",
        "patch": "@@ -16,7 +16,7 @@ class TaskMeta(models.Model):\n     task_id = models.CharField(_(u\"task id\"), max_length=255, unique=True)\n     status = models.CharField(_(u\"task status\"), max_length=50,\n             default=states.PENDING, choices=TASK_STATUSES_CHOICES)\n-    result = PickledObjectField(null=True)\n+    result = PickledObjectField(null=False)\n     date_done = models.DateTimeField(_(u\"done at\"), auto_now=True)\n     traceback = models.TextField(_(u\"traceback\"), blank=True, null=True)\n "
    },
    {
        "commit_id": "540088ec7b21eb0f2a47c7e0b9efb26eafdd137f",
        "commit_message": "pavement: Fix the ghdocs task (quoted shell glob pattern by mistake)",
        "commit_url": "https://github.com/celery/celery/commit/540088ec7b21eb0f2a47c7e0b9efb26eafdd137f",
        "buggy_code": "cp -r '%s/*' .    && \\",
        "fixed_code": "cp -r %s/* .    && \\",
        "patch": "@@ -30,7 +30,7 @@ def ghdocs(options):\n     builtdocs = sphinx_builddir(options)\n     sh(\"sphinx-to-github\", cwd=builtdocs)\n     sh(\"git checkout gh-pages && \\\n-            cp -r '%s/*' .    && \\\n+            cp -r %s/* .    && \\\n             git commit . -m 'Rendered documentation for Github Pages.' && \\\n             git push origin gh-pages && \\\n             git checkout master\" % builtdocs)"
    },
    {
        "commit_id": "bf8defa2d679d68720ea1668c2841d60fb085d7b",
        "commit_message": "management.commands.camqadm: Fix typo camqpadm -> camqadm. Thanks to jpwatts.  Closes #83",
        "commit_url": "https://github.com/celery/celery/commit/bf8defa2d679d68720ea1668c2841d60fb085d7b",
        "buggy_code": "from celery.bin.camqpadm import camqadm, OPTION_LIST",
        "fixed_code": "from celery.bin.camqadm import camqadm, OPTION_LIST",
        "patch": "@@ -5,7 +5,7 @@\n \"\"\"\n from django.core.management.base import BaseCommand\n \n-from celery.bin.camqpadm import camqadm, OPTION_LIST\n+from celery.bin.camqadm import camqadm, OPTION_LIST\n \n \n class Command(BaseCommand):"
    },
    {
        "commit_id": "234175d38e08361e3daca9e11639457a8357a873",
        "commit_message": "celery.task.http: Fixed rst bug in docstring",
        "commit_url": "https://github.com/celery/celery/commit/234175d38e08361e3daca9e11639457a8357a873",
        "buggy_code": "and``POST``.",
        "fixed_code": "and ``POST``.",
        "patch": "@@ -89,7 +89,7 @@ class HttpDispatch(object):\n \n     :param url: The URL to request.\n     :param method: HTTP method used. Currently supported methods are ``GET``\n-        and``POST``.\n+        and ``POST``.\n     :param task_kwargs: Task keyword arguments.\n     :param logger: Logger used for user/system feedback.\n "
    },
    {
        "commit_id": "1cd610b7591b69c9d5c03b008043bcdc2ca5f385",
        "commit_message": "TaskSet: Fixed a bug with using tuples in the argument list. Thanks to Harel Malka.",
        "commit_url": "https://github.com/celery/celery/commit/1cd610b7591b69c9d5c03b008043bcdc2ca5f385",
        "buggy_code": "return container[:size] + [default] * (size - len(container))",
        "fixed_code": "return list(container)[:size] + [default] * (size - len(container))",
        "patch": "@@ -76,7 +76,7 @@ def padlist(container, size, default=None):\n         (\"George\", \"Constanza\", \"NYC\", \"Earth\")\n \n     \"\"\"\n-    return container[:size] + [default] * (size - len(container))\n+    return list(container)[:size] + [default] * (size - len(container))\n \n \n def mitemgetter(*items):"
    },
    {
        "commit_id": "7dd57018fb8ccaf5ab874f0f562d702bd98ed912",
        "commit_message": "Fixed loader bug in celerybeat standalone.",
        "commit_url": "https://github.com/celery/celery/commit/7dd57018fb8ccaf5ab874f0f562d702bd98ed912",
        "buggy_code": "current_loader.on_worker_init()",
        "fixed_code": "current_loader().on_worker_init()",
        "patch": "@@ -68,7 +68,7 @@ def run_clockservice(loglevel=conf.CELERYBEAT_LOG_LEVEL,\n     # Run the worker init handler.\n     # (Usually imports task modules and such.)\n     from celery.loaders import current_loader\n-    current_loader.on_worker_init()\n+    current_loader().on_worker_init()\n \n \n     # Dump configuration to screen so we have some basic information"
    },
    {
        "commit_id": "911e9d58a878695f4f6be92c2e8f87a0d32944bf",
        "commit_message": "Don't return exception from handle_retry, so error mails for retried tasks isn't sent. Thanks Mat Clayton.",
        "commit_url": "https://github.com/celery/celery/commit/911e9d58a878695f4f6be92c2e8f87a0d32944bf",
        "buggy_code": "return self.super.handle_retry(exc, type_, tb, strtb)",
        "fixed_code": "self.super.handle_retry(exc, type_, tb, strtb)",
        "patch": "@@ -106,7 +106,7 @@ def handle_retry(self, exc, type_, tb, strtb):\n         message, orig_exc = exc.args\n         if self._store_errors:\n             self.task.backend.mark_as_retry(self.task_id, orig_exc, strtb)\n-        return self.super.handle_retry(exc, type_, tb, strtb)\n+        self.super.handle_retry(exc, type_, tb, strtb)\n \n     def handle_failure(self, exc, type_, tb, strtb):\n         \"\"\"Handle exception.\"\"\""
    },
    {
        "commit_id": "172d84bed14659d7146ba13cf4ca03eba460cdaa",
        "commit_message": "Fixed syntax error in celerybeat introduced in previous commit.",
        "commit_url": "https://github.com/celery/celery/commit/172d84bed14659d7146ba13cf4ca03eba460cdaa",
        "buggy_code": "optparse.make_option('-f', '--logfile', default=EAT_LOG_FILE,",
        "fixed_code": "optparse.make_option('-f', '--logfile', default=conf.CELERYBEAT_LOG_FILE,",
        "patch": "@@ -44,7 +44,7 @@\n             help=\"Path to the schedule database. The extension \\\n                     '.db' will be appended to the filename. Default: %s\" % (\n                     conf.CELERYBEAT_SCHEDULE_FILENAME)),\n-    optparse.make_option('-f', '--logfile', default=EAT_LOG_FILE,\n+    optparse.make_option('-f', '--logfile', default=conf.CELERYBEAT_LOG_FILE,\n             action=\"store\", dest=\"logfile\",\n             help=\"Path to log file.\"),\n     optparse.make_option('-l', '--loglevel',"
    },
    {
        "commit_id": "f31e4889c0a9c3833d885b82252b5a93a5dbdf4d",
        "commit_message": "Loglevel for stderr/stderr set from INFO to ERROR",
        "commit_url": "https://github.com/celery/celery/commit/f31e4889c0a9c3833d885b82252b5a93a5dbdf4d",
        "buggy_code": "loglevel = logging.INFO",
        "fixed_code": "loglevel = logging.ERROR",
        "patch": "@@ -95,7 +95,7 @@ class LoggingProxy(object):\n     mode = \"w\"\n     name = None\n     closed = False\n-    loglevel = logging.INFO\n+    loglevel = logging.ERROR\n \n     def __init__(self, logger, loglevel=None):\n         self.logger = logger"
    },
    {
        "commit_id": "f622c749143c49232f3beca84607e956cfa10091",
        "commit_message": "Fixed bug in beat service.",
        "commit_url": "https://github.com/celery/celery/commit/f622c749143c49232f3beca84607e956cfa10091",
        "buggy_code": "open_schedule = shelve.open",
        "fixed_code": "open_schedule = lambda self, filename: shelve.open(filename)",
        "patch": "@@ -152,7 +152,7 @@ def schedule(self):\n class ClockService(object):\n     scheduler_cls = Scheduler\n     registry = _registry.tasks\n-    open_schedule = shelve.open\n+    open_schedule = lambda self, filename: shelve.open(filename)\n \n     def __init__(self, logger=None, is_detached=False,\n             max_interval=conf.CELERYBEAT_MAX_LOOP_INTERVAL,"
    },
    {
        "commit_id": "82bb0b58eeeb8bf9cac877c64bc3deb5a780cfb6",
        "commit_message": "Rename celery.patch -> celery.utils.patch",
        "commit_url": "https://github.com/celery/celery/commit/82bb0b58eeeb8bf9cac877c64bc3deb5a780cfb6",
        "buggy_code": "\"celery.patch\",",
        "fixed_code": "\"celery.utils.patch\",",
        "patch": "@@ -24,7 +24,7 @@\n                             \"celery.management.*\",\n                             \"celery.contrib.*\",\n                             \"celery.bin.*\",\n-                            \"celery.patch\",\n+                            \"celery.utils.patch\",\n                             \"celery.urls\",\n                             \"celery.views\",\n                             \"celery.task.strategy\")"
    },
    {
        "commit_id": "15ebb814dabefa7ba3e4c5e7287f353e729a9c84",
        "commit_message": "Fix typo os.unlink(filename) -> os.unlink(path). Thanks dmishe. Closes #55",
        "commit_url": "https://github.com/celery/celery/commit/15ebb814dabefa7ba3e4c5e7287f353e729a9c84",
        "buggy_code": "os.unlink(filename)",
        "fixed_code": "os.unlink(path)",
        "patch": "@@ -26,7 +26,7 @@ def maybe_remove_file(path, ignore_perm_denied=False):\n \n     \"\"\"\n     try:\n-        os.unlink(filename)\n+        os.unlink(path)\n     except OSError, exc:\n         if exc.errno == errno.ENOENT:\n             return"
    },
    {
        "commit_id": "d58005cfd4e8bb945043ad8f8e45b120e0aa67d1",
        "commit_message": "Fix a bug in the estimate remaining time part.",
        "commit_url": "https://github.com/celery/celery/commit/d58005cfd4e8bb945043ad8f8e45b120e0aa67d1",
        "buggy_code": "if not rem.days:",
        "fixed_code": "if rem.days == -1:",
        "patch": "@@ -587,7 +587,7 @@ def __init__(self):\n \n     def remaining_estimate(self, last_run_at):\n         rem = (last_run_at + self.run_every) - datetime.now()\n-        if not rem.days:\n+        if rem.days == -1:\n             return 0\n         return rem.seconds + (rem.microseconds / 10e5)\n "
    },
    {
        "commit_id": "d58005cfd4e8bb945043ad8f8e45b120e0aa67d1",
        "commit_message": "Fix a bug in the estimate remaining time part.",
        "commit_url": "https://github.com/celery/celery/commit/d58005cfd4e8bb945043ad8f8e45b120e0aa67d1",
        "buggy_code": "run_every = timedelta(days=1)",
        "fixed_code": "run_every = timedelta(minutes=1)",
        "patch": "@@ -13,7 +13,7 @@ class DeleteExpiredTaskMetaTask(PeriodicTask):\n \n     \"\"\"\n     name = \"celery.delete_expired_task_meta\"\n-    run_every = timedelta(days=1)\n+    run_every = timedelta(minutes=1)\n \n     def run(self, **kwargs):\n         \"\"\"The method run by ``celeryd``.\"\"\""
    },
    {
        "commit_id": "19a2a5a527f592b4c4eef6bfb923f20f23cb2f71",
        "commit_message": "Fix a test using the deprecated carrot Consumer.decoder",
        "commit_url": "https://github.com/celery/celery/commit/19a2a5a527f592b4c4eef6bfb923f20f23cb2f71",
        "buggy_code": "m = consumer.decoder(consumer.fetch().body)",
        "fixed_code": "m = consumer.fetch().payload",
        "patch": "@@ -279,7 +279,7 @@ def test_counter_taskset(self):\n         subtasks = taskset_res.subtasks\n         taskset_id = taskset_res.taskset_id\n         for subtask in subtasks:\n-            m = consumer.decoder(consumer.fetch().body)\n+            m = consumer.fetch().payload\n             self.assertEquals(m.get(\"taskset\"), taskset_id)\n             self.assertEquals(m.get(\"task\"), IncrementCounterTask.name)\n             self.assertEquals(m.get(\"id\"), subtask.task_id)"
    },
    {
        "commit_id": "be4253b64d1695c1ef22e7e2b9cd275280e52b98",
        "commit_message": "fix typo platform.reset_signal -> reset_signal",
        "commit_url": "https://github.com/celery/celery/commit/be4253b64d1695c1ef22e7e2b9cd275280e52b98",
        "buggy_code": "platform.reset_signal(\"SIGCLD\")",
        "fixed_code": "reset_signal(\"SIGCLD\")",
        "patch": "@@ -56,7 +56,7 @@ def create_daemon_context(logfile=None, pidfile=None, **options):\n     # set SIGCLD back to the default SIG_DFL (before python-daemon overrode\n     # it) lets the parent wait() for the terminated child process and stops\n     # the 'OSError: [Errno 10] No child processes' problem.\n-    platform.reset_signal(\"SIGCLD\")\n+    reset_signal(\"SIGCLD\")\n \n     # Since without stderr any errors will be silently suppressed,\n     # we need to know that we have access to the logfile"
    },
    {
        "commit_id": "188dbabf5956575ce9b63c60da69b45cc1e66922",
        "commit_message": "Fix typo",
        "commit_url": "https://github.com/celery/celery/commit/188dbabf5956575ce9b63c60da69b45cc1e66922",
        "buggy_code": "\"\"\"Functional utilities for Python 2.4 compatability.\"\"\"",
        "fixed_code": "\"\"\"Functional utilities for Python 2.4 compatibility.\"\"\"",
        "patch": "@@ -1,4 +1,4 @@\n-\"\"\"Functional utilities for Python 2.4 compatability.\"\"\"\n+\"\"\"Functional utilities for Python 2.4 compatibility.\"\"\"\n \n \n def _compat_curry(fun, *args, **kwargs):"
    },
    {
        "commit_id": "f77d761007a6a35526bf2e4ebf79617f6832d465",
        "commit_message": "Fix syntax error in celery.platform (thanks Didier Deshommes)",
        "commit_url": "https://github.com/celery/celery/commit/f77d761007a6a35526bf2e4ebf79617f6832d465",
        "buggy_code": "if not hasattr(signal, signal):",
        "fixed_code": "if not hasattr(signal, signal_name):",
        "patch": "@@ -85,7 +85,7 @@ def reset_signal(signal_name):\n \n def install_signal_handler(signal_name, handler):\n     \"\"\"Install a SIGHUP handler.\"\"\"\n-    if not hasattr(signal, signal):\n+    if not hasattr(signal, signal_name):\n         return # Platform doesn't support signal.\n \n     signum = getattr(signal, signal_name)"
    },
    {
        "commit_id": "137f6d7fbcbf375e11cc271adec95384f8efc287",
        "commit_message": "Fixed typo bug with uuid generation.",
        "commit_url": "https://github.com/celery/celery/commit/137f6d7fbcbf375e11cc271adec95384f8efc287",
        "buggy_code": "return str(uuid.uuid4())",
        "fixed_code": "return str(uuid4())",
        "patch": "@@ -50,7 +50,7 @@ def gen_unique_id():\n         buffer = ctypes.create_string_buffer(16)\n         _uuid_generate_random(buffer)\n         return str(UUID(bytes=buffer.raw))\n-    return str(uuid.uuid4())\n+    return str(uuid4())\n \n \n def mitemgetter(*keys):"
    },
    {
        "commit_id": "21e5ca23d53c6373be035b4ca285842aa1fe8d8d",
        "commit_message": "Fix running tests without the pytyrant library installed",
        "commit_url": "https://github.com/celery/celery/commit/21e5ca23d53c6373be035b4ca285842aa1fe8d8d",
        "buggy_code": "pytrant = None",
        "fixed_code": "pytyrant = None",
        "patch": "@@ -6,7 +6,7 @@\n try:\n     import pytyrant\n except ImportError:\n-    pytrant = None\n+    pytyrant = None\n \n \n class Backend(KeyValueStoreBackend):"
    },
    {
        "commit_id": "9212395bba8d180e471dc082a139f05b58316c2d",
        "commit_message": "Fix docstring references to celery.task.base.RetryTaskError -> celery.exceptions.RetryTaskError",
        "commit_url": "https://github.com/celery/celery/commit/9212395bba8d180e471dc082a139f05b58316c2d",
        "buggy_code": "If the call raises :exc:`celery.task.base.RetryTaskError`, it extracts",
        "fixed_code": "If the call raises :exc:`celery.exceptions.RetryTaskError`, it extracts",
        "patch": "@@ -180,7 +180,7 @@ class ExecuteWrapper(object):\n     If the call was successful, it saves the result to the task result\n     backend, and sets the task status to ``\"DONE\"``.\n \n-    If the call raises :exc:`celery.task.base.RetryTaskError`, it extracts\n+    If the call raises :exc:`celery.exceptions.RetryTaskError`, it extracts\n     the original exception, uses that as the result and sets the task status\n     to ``\"RETRY\"``.\n "
    },
    {
        "commit_id": "29b8547a90057935550e3724db76cc6ddb942b54",
        "commit_message": "Fix typo \".. import map\" -> \".. import dmap\" Thanks mikedizon",
        "commit_url": "https://github.com/celery/celery/commit/29b8547a90057935550e3724db76cc6ddb942b54",
        "buggy_code": ">>> from celery.task import map",
        "fixed_code": ">>> from celery.task import dmap",
        "patch": "@@ -48,7 +48,7 @@ def dmap(func, args, timeout=None):\n \n     Example\n \n-        >>> from celery.task import map\n+        >>> from celery.task import dmap\n         >>> import operator\n         >>> dmap(operator.add, [[2, 2], [4, 4], [8, 8]])\n         [4, 8, 16]"
    },
    {
        "commit_id": "af7bea2cc51599585d24ce6a80b894697ca7f684",
        "commit_message": "Fix docstring typo carrot.utils.retry_over_time -> celery.utils.retry_over_time",
        "commit_url": "https://github.com/celery/celery/commit/af7bea2cc51599585d24ce6a80b894697ca7f684",
        "buggy_code": "See :func:`carrot.utils.retry_over_time`.",
        "fixed_code": "See :func:`celery.utils.retry_over_time`.",
        "patch": "@@ -136,7 +136,7 @@ def reset_connection(self):\n     def _open_connection(self):\n         \"\"\"Retries connecting to the AMQP broker over time.\n \n-        See :func:`carrot.utils.retry_over_time`.\n+        See :func:`celery.utils.retry_over_time`.\n \n         \"\"\"\n "
    },
    {
        "commit_id": "999f68fcafad7ad040ac999109f9211d7ced6b63",
        "commit_message": "Fix typo _add_worker -> add_worker",
        "commit_url": "https://github.com/celery/celery/commit/999f68fcafad7ad040ac999109f9211d7ced6b63",
        "buggy_code": "map(self._add_worker, range(size))",
        "fixed_code": "map(self.add_worker, range(size))",
        "patch": "@@ -62,7 +62,7 @@ def add_worker(self):\n \n     def grow(self, size=1):\n         \"\"\"Add ``size`` new workers to the pool.\"\"\"\n-        map(self._add_worker, range(size))\n+        map(self.add_worker, range(size))\n \n     def is_dead(self, process):\n         # First try to see if the process is actually running,"
    },
    {
        "commit_id": "659bdb2c254541268fda1cf965d147f76351f373",
        "commit_message": "Logmessage \"Unknown task ignored...\" now has loglevel ERROR",
        "commit_url": "https://github.com/celery/celery/commit/659bdb2c254541268fda1cf965d147f76351f373",
        "buggy_code": "self.logger.info(\"Unknown task ignored: %s\" % (exc))",
        "fixed_code": "self.logger.error(\"Unknown task ignored: %s\" % (exc))",
        "patch": "@@ -75,7 +75,7 @@ def receive_message(self, message_data, message):\n             task = TaskWrapper.from_message(message, message_data,\n                                             logger=self.logger)\n         except NotRegistered, exc:\n-            self.logger.info(\"Unknown task ignored: %s\" % (exc))\n+            self.logger.error(\"Unknown task ignored: %s\" % (exc))\n             return\n \n         eta = message_data.get(\"eta\")"
    },
    {
        "commit_id": "3b0e993410a6d722c310e95a1014bc5356dc1779",
        "commit_message": "Fixed a bug with parsing the message options (mandatory, routing_key,\nimmediate, priority)",
        "commit_url": "https://github.com/celery/celery/commit/3b0e993410a6d722c310e95a1014bc5356dc1779",
        "buggy_code": "get_msg_options = mitemgetter(MSG_OPTIONS)",
        "fixed_code": "get_msg_options = mitemgetter(*MSG_OPTIONS)",
        "patch": "@@ -13,7 +13,7 @@\n MSG_OPTIONS = (\"mandatory\", \"priority\",\n                \"immediate\", \"routing_key\")\n \n-get_msg_options = mitemgetter(MSG_OPTIONS)\n+get_msg_options = mitemgetter(*MSG_OPTIONS)\n \n extract_msg_options = lambda d: dict(zip(MSG_OPTIONS, get_msg_options(d)))\n "
    },
    {
        "commit_id": "0350e464c74395127d3ae0f2f6f43a886c9369e4",
        "commit_message": "Convert unicode string to str to fix cache test",
        "commit_url": "https://github.com/celery/celery/commit/0350e464c74395127d3ae0f2f6f43a886c9369e4",
        "buggy_code": "meta = pickle.loads(meta)",
        "fixed_code": "meta = pickle.loads(str(meta)) # Not complete sure if this is correct, but tests pass -vbabiy",
        "patch": "@@ -249,7 +249,7 @@ def _get_task_meta_for(self, task_id):\n         meta = self.get(self.get_cache_key_for_task(task_id))\n         if not meta:\n             return {\"status\": \"PENDING\", \"result\": None}\n-        meta = pickle.loads(meta)\n+        meta = pickle.loads(str(meta)) # Not complete sure if this is correct, but tests pass -vbabiy\n         if meta.get(\"status\") == \"DONE\":\n             self._cache[task_id] = meta\n         return meta"
    },
    {
        "commit_id": "96974bb9b8aaf7e958c4ba1282088519cd77c7c9",
        "commit_message": "Fix syntax error in celery.views",
        "commit_url": "https://github.com/celery/celery/commit/96974bb9b8aaf7e958c4ba1282088519cd77c7c9",
        "buggy_code": "return JSON_dump({\"ok\": \"true\", \"task_id\": result.task_id",
        "fixed_code": "return JSON_dump({\"ok\": \"true\", \"task_id\": result.task_id})",
        "patch": "@@ -24,7 +24,7 @@ def apply(request, task_name, *args):\n         \n     task = tasks[task_name]\n     result = apply_async(task, args=args, kwargs=kwargs)\n-    return JSON_dump({\"ok\": \"true\", \"task_id\": result.task_id\n+    return JSON_dump({\"ok\": \"true\", \"task_id\": result.task_id})\n \n \n def is_task_done(request, task_id):"
    },
    {
        "commit_id": "0d1f174559a461b42e145d3df12e39361d5af0eb",
        "commit_message": "Fix typo import -> as",
        "commit_url": "https://github.com/celery/celery/commit/0d1f174559a461b42e145d3df12e39361d5af0eb",
        "buggy_code": "from functools import partial import curry",
        "fixed_code": "from functools import partial as curry",
        "patch": "@@ -12,7 +12,7 @@\n from datetime import timedelta\n from celery.backends import default_backend\n from celery.result import AsyncResult, TaskSetResult\n-from functools import partial import curry\n+from functools import partial as curry\n import uuid\n import pickle\n "
    },
    {
        "commit_id": "8b04474d9cf6f8722d8bfce00b01c23ea649556e",
        "commit_message": "Documentation: Fix rSt errors",
        "commit_url": "https://github.com/celery/celery/commit/8b04474d9cf6f8722d8bfce00b01c23ea649556e",
        "buggy_code": ":method:`collect` was executed.\"\"\"",
        "fixed_code": ":meth:`collect` was executed.\"\"\"",
        "patch": "@@ -163,7 +163,7 @@ def __init__(self):\n \n     def collect(self):\n         \"\"\"Collect any new statistics available since the last time\n-        :method:`collect` was executed.\"\"\"\n+        :meth:`collect` was executed.\"\"\"\n         connection = DjangoAMQPConnection()\n         consumer = StatsConsumer(connection=connection)\n         it = consumer.iterqueue(infinite=False)"
    },
    {
        "commit_id": "11150f6c5ba77adbfa39af3f1c0650dc00b05659",
        "commit_message": "Fix a regression, context is not defined unless detach is true.",
        "commit_url": "https://github.com/celery/celery/commit/11150f6c5ba77adbfa39af3f1c0650dc00b05659",
        "buggy_code": "if context:",
        "fixed_code": "if daemon:",
        "patch": "@@ -226,7 +226,7 @@ def run_worker(concurrency=DAEMON_CONCURRENCY, detach=False,\n         emergency_error(logfile, \"celeryd raised exception %s: %s\\n%s\" % (\n                             e.__class__, e, traceback.format_exc()))\n     except:\n-        if context:\n+        if daemon:\n             context.close()\n         raise\n "
    },
    {
        "commit_id": "2c28350d949c1964940546bcbdaacec049adeaed",
        "commit_message": "fix typo discard_count -> discarded_count",
        "commit_url": "https://github.com/celery/celery/commit/2c28350d949c1964940546bcbdaacec049adeaed",
        "buggy_code": "what = discard_count > 1 and \"messages\" or \"message\"",
        "fixed_code": "what = discarded_count > 1 and \"messages\" or \"message\"",
        "patch": "@@ -184,7 +184,7 @@ def say(msg):\n \n     if discard:\n         discarded_count = discard_all()\n-        what = discard_count > 1 and \"messages\" or \"message\"\n+        what = discarded_count > 1 and \"messages\" or \"message\"\n         say(\"discard: Erased %d %s from the queue.\\n\" % (\n                 discarded_count, what))\n "
    },
    {
        "commit_id": "73913ad581c871e6d40a16ae49f7fb951545a6ae",
        "commit_message": "Fix typo scheme -> cache_scheme",
        "commit_url": "https://github.com/celery/celery/commit/73913ad581c871e6d40a16ae49f7fb951545a6ae",
        "buggy_code": "if \"memcached\" in scheme:",
        "fixed_code": "if \"memcached\" in cache_scheme:",
        "patch": "@@ -84,7 +84,7 @@ def jail(task_id, func, args, kwargs):\n     else:\n         # Django <= 1.0.2\n         cache_scheme = cache_backend.split(\":\", 1)[0]\n-    if \"memcached\" in scheme:\n+    if \"memcached\" in cache_scheme:\n         cache.cache.close()\n \n     # Backend process cleanup"
    },
    {
        "commit_id": "9fe786b9c2b297538bcf3c232eb40af9244bc10e",
        "commit_message": "Fix bug in TaskPool : there was no logger attribute",
        "commit_url": "https://github.com/celery/celery/commit/9fe786b9c2b297538bcf3c232eb40af9244bc10e",
        "buggy_code": "self.pool = TaskPool(self.concurrency)",
        "fixed_code": "self.pool = TaskPool(self.concurrency, logger=self.logger)",
        "patch": "@@ -267,7 +267,7 @@ def __init__(self, concurrency=None, logfile=None, loglevel=None,\n         self.queue_wakeup_after = queue_wakeup_after or \\\n                                     self.queue_wakeup_after\n         self.logger = setup_logger(loglevel, logfile)\n-        self.pool = TaskPool(self.concurrency)\n+        self.pool = TaskPool(self.concurrency, logger=self.logger)\n         self.task_consumer = None\n         self.is_detached = is_detached\n         self.reset_connection()"
    },
    {
        "commit_id": "bd3149fe4837034116287a0b2e27627b72be4f73",
        "commit_message": "Fix occurences of \"e.g\"/\"i.e\" -> \"e.g.\"/\"i.e.\"",
        "commit_url": "https://github.com/celery/celery/commit/bd3149fe4837034116287a0b2e27627b72be4f73",
        "buggy_code": "route e.g some tasks to one server, and others to the rest.",
        "fixed_code": "route e.g. some tasks to one server, and others to the rest.",
        "patch": "@@ -117,7 +117,7 @@\n \n The type of exchange. If the exchange type is ``direct``, all messages\n receives all tasks. However, if the exchange type is ``topic``, you can\n-route e.g some tasks to one server, and others to the rest.\n+route e.g. some tasks to one server, and others to the rest.\n See `Exchange types and the effect of bindings`_.\n \n .. _`Exchange types and the effect of bindings:"
    },
    {
        "commit_id": "62229191be6c345c8c5c67596340f9c3434ffe54",
        "commit_message": "Fix stupid mistakes",
        "commit_url": "https://github.com/celery/celery/commit/62229191be6c345c8c5c67596340f9c3434ffe54",
        "buggy_code": "VERSION = (0, 2, 9)",
        "fixed_code": "VERSION = (0, 2, 14)",
        "patch": "@@ -1,5 +1,5 @@\n \"\"\"Distributed Task Queue for Django\"\"\"\n-VERSION = (0, 2, 9)\n+VERSION = (0, 2, 14)\n __version__ = \".\".join(map(str, VERSION))\n __author__ = \"Ask Solem\"\n __contact__ = \"askh@opera.com\""
    },
    {
        "commit_id": "72ff807a4c9116f095fe5048173b4b4f0022c736",
        "commit_message": "Fix syntax errors",
        "commit_url": "https://github.com/celery/celery/commit/72ff807a4c9116f095fe5048173b4b4f0022c736",
        "buggy_code": "VERSION = (0, 2, 4)",
        "fixed_code": "VERSION = (0, 2, 9)",
        "patch": "@@ -1,5 +1,5 @@\n \"\"\"Distributed Task Queue for Django\"\"\"\n-VERSION = (0, 2, 4)\n+VERSION = (0, 2, 9)\n __version__ = \".\".join(map(str, VERSION))\n __author__ = \"Ask Solem\"\n __contact__ = \"askh@opera.com\""
    },
    {
        "commit_id": "27268af673b06c4dfa2d4fbf02a62e17d560a13e",
        "commit_message": "Fix tyrant and reset to using multiprocessing.Pool but using a new algorithm",
        "commit_url": "https://github.com/celery/celery/commit/27268af673b06c4dfa2d4fbf02a62e17d560a13e",
        "buggy_code": "VERSION = (0, 2, 1)",
        "fixed_code": "VERSION = (0, 2, 2)",
        "patch": "@@ -1,5 +1,5 @@\n \"\"\"Distributed Task Queue for Django\"\"\"\n-VERSION = (0, 2, 1)\n+VERSION = (0, 2, 2)\n __version__ = \".\".join(map(str, VERSION))\n __author__ = \"Ask Solem\"\n __contact__ = \"askh@opera.com\""
    },
    {
        "commit_id": "1b98a82e6b63077f500eb3350ab62a90496314d5",
        "commit_message": "Fixed \"no such variable result\" error in the database backends, get_result()\nmethod.",
        "commit_url": "https://github.com/celery/celery/commit/1b98a82e6b63077f500eb3350ab62a90496314d5",
        "buggy_code": "return result",
        "fixed_code": "return meta.result",
        "patch": "@@ -32,7 +32,7 @@ def get_result(self, task_id):\n         if meta.status == \"FAILURE\":\n             return self.exception_to_python(meta.result)\n         else:\n-            return result\n+            return meta.result\n \n     def _get_task_meta_for(self, task_id):\n         if task_id in self._cache:"
    },
    {
        "commit_id": "dcced376cc53a51fc75436c116c1492d8835011b",
        "commit_message": "Fix typo :cls: -> :class:",
        "commit_url": "https://github.com/celery/celery/commit/dcced376cc53a51fc75436c116c1492d8835011b",
        "buggy_code": ":param pool: A :cls:`multiprocessing.Pool` instance.",
        "fixed_code": ":param pool: A :class:`multiprocessing.Pool` instance.",
        "patch": "@@ -152,7 +152,7 @@ def execute(self, loglevel=None, logfile=None):\n     def execute_using_pool(self, pool, loglevel=None, logfile=None):\n         \"\"\"Like :meth:`execute`, but using the :mod:`multiprocessing` pool.\n \n-        :param pool: A :cls:`multiprocessing.Pool` instance.\n+        :param pool: A :class:`multiprocessing.Pool` instance.\n \n         :keyword loglevel: The loglevel used by the task.\n "
    },
    {
        "commit_id": "617a3aa465ba74506ffea3c40c0b7e895eccb781",
        "commit_message": "Fix typo",
        "commit_url": "https://github.com/celery/celery/commit/617a3aa465ba74506ffea3c40c0b7e895eccb781",
        "buggy_code": ":class:`BaseExecption` and :class:`object`). If that happens",
        "fixed_code": ":class:`BaseException` and :class:`object`). If that happens",
        "patch": "@@ -11,7 +11,7 @@ def find_nearest_pickleable_exception(exc):\n     \"\"\"With an exception instance, iterate over its super classes (by mro)\n     and find the first super exception that is pickleable. It does\n     not go below :exc:`Exception` (i.e. it skips :exc:`Exception`,\n-    :class:`BaseExecption` and :class:`object`). If that happens\n+    :class:`BaseException` and :class:`object`). If that happens\n     you should use :exc:`UnpickleableException` instead.\n   \n     :param exc: An exception instance."
    },
    {
        "commit_id": "6787df2dac12f756eeadba0c0ca40be6e89a1096",
        "commit_message": "Fix celery daemon documentaion.",
        "commit_url": "https://github.com/celery/celery/commit/6787df2dac12f756eeadba0c0ca40be6e89a1096",
        "buggy_code": "scripts=[\"celery/bin/celeryd\"],",
        "fixed_code": "scripts=[\"bin/celeryd\"],",
        "patch": "@@ -59,7 +59,7 @@ def run(self):\n     url=celery.__homepage__,\n     platforms=[\"any\"],\n     packages=find_packages(exclude=['ez_setup']),\n-    scripts=[\"celery/bin/celeryd\"],\n+    scripts=[\"bin/celeryd\"],\n     zip_safe=False,\n     install_requires=[\n         'django-unittest-depth',"
    },
    {
        "commit_id": "64526470221e72f4c4782fae38030a33d3e2fa97",
        "commit_message": "Fix typo TimeOutTimer -> TimeoutTimer",
        "commit_url": "https://github.com/celery/celery/commit/64526470221e72f4c4782fae38030a33d3e2fa97",
        "buggy_code": "timeout_timer = TimeOutTimer(timeout) # Timeout timer starts here.",
        "fixed_code": "timeout_timer = TimeoutTimer(timeout) # Timeout timer starts here.",
        "patch": "@@ -230,7 +230,7 @@ def join(self, timeout=None):\n         the :class:`celery.timer.TimeoutError` exception.\n \n         \"\"\"\n-        timeout_timer = TimeOutTimer(timeout) # Timeout timer starts here.\n+        timeout_timer = TimeoutTimer(timeout) # Timeout timer starts here.\n         taskset_id, subtask_ids = self.run()\n         pending_results = map(AsyncResult, subtask_ids)\n         results = PositionQueue(length=len(subtask_ids))"
    },
    {
        "commit_id": "b6216d8c29803ef1aec1864163bdefe70232729d",
        "commit_message": "Fix typo DEFAULT_AMQP_CONSUMER_KEY -> DEFAULT_AMQP_CONSUMER_QUEUE",
        "commit_url": "https://github.com/celery/celery/commit/b6216d8c29803ef1aec1864163bdefe70232729d",
        "buggy_code": "DEFAULT_AMQP_CONSUMER_KEY)",
        "fixed_code": "DEFAULT_AMQP_CONSUMER_QUEUE)",
        "patch": "@@ -70,4 +70,4 @@\n AMQP_ROUTING_KEY = getattr(settings, \"CELERY_AMQP_ROUTING_KEY\",\n                             DEFAULT_AMQP_ROUTING_KEY)\n AMQP_CONSUMER_QUEUE = getattr(settings, \"CELERY_AMQP_CONSUMER_QUEUE\",\n-                            DEFAULT_AMQP_CONSUMER_KEY)\n+                            DEFAULT_AMQP_CONSUMER_QUEUE)"
    },
    {
        "commit_id": "ea151e858dda765c8805038bb967e2dcdf65116a",
        "commit_message": "Fix typo auto_add -> auto_now",
        "commit_url": "https://github.com/celery/celery/commit/ea151e858dda765c8805038bb967e2dcdf65116a",
        "buggy_code": "date_done = models.DateTimeField(_(u\"done at\"), auto_add=True)",
        "fixed_code": "date_done = models.DateTimeField(_(u\"done at\"), auto_now=True)",
        "patch": "@@ -9,7 +9,7 @@\n class TaskMeta(models.Model):\n     task_id = models.CharField(_(u\"task id\"), max_length=255, unique=True)\n     is_done = models.BooleanField(_(u\"is done\"), default=False)\n-    date_done = models.DateTimeField(_(u\"done at\"), auto_add=True)\n+    date_done = models.DateTimeField(_(u\"done at\"), auto_now=True)\n     objects = TaskManager()\n \n     class Meta:"
    }
]